!locate *.ipynb

!locate *.ipynb > ALL-IPYNB.list

!du ALL-IPYNB.list

cnt = 0
FileList = open("ALL-IPYNB.list", "r").readlines()

ALLnotebooks =[]
for lines in FileList:
    line = lines.replace("\n","")
    if "checkpoints" not in line:
        ALLnotebooks.append(line)
        cnt = cnt +1
        print(cnt,":",line, end=" | ")

len(ALLnotebooks)

# Importing Libraries
import os
import sys
from pathlib import Path
import hashlib
  
  
def FindDuplicate(SupFolder):
    
    # Duplic is in format {hash:[names]}
    Duplic = {}
    for file_name in files:
        
        # Path to the file
        path = os.path.join(folders, file_name)
          
        # Calculate hash
        file_hash = Hash_File(path)
          
        # Add or append the file path to Duplic
        if file_hash in Duplic:
            Duplic[file_hash].append(file_name)
        else:
            Duplic[file_hash] = [file_name]
    return Duplic
  
# Joins dictionaries
def Join_Dictionary(dict_1, dict_2):
    for key in dict_2.keys():
        
        # Checks for existing key
        if key in dict_1:
            
            # If present Append
            dict_1[key] = dict_1[key] + dict_2[key]
        else:
            
            # Otherwise Stores
            dict_1[key] = dict_2[key]
  
# Calculates MD5 hash of file
# Returns HEX digest of file
def Hash_File(path):
    
    # Opening file in afile
    afile = open(path, 'rb')
    hasher = hashlib.md5()
    blocksize=65536
    buf = afile.read(blocksize)
      
    while len(buf) > 0:
        hasher.update(buf)
        buf = afile.read(blocksize)
    afile.close()
    return hasher.hexdigest()
  
Duplic = {}
folders = Path('/home/jack/')
files = sorted(os.listdir(folders))
for i in files:
    
    # Iterate over the files
    # Find the duplicated files
    # Append them to the Duplic
    Join_Dictionary(Duplic, FindDuplicate(i))
      
# Results store a list of Duplic values
results = list(filter(lambda x: len(x) > 1, Duplic.values()))
if len(results) > 0:
    for result in results:
        for sub_result in result:
            print('\t\t%s' % sub_result)
else:
    print('No duplicates found.')

import hashlib
dir(hashlib)

# dupFinder.py
import os, sys
import hashlib

def hashfile(path, blocksize = 65536):
    afile = open(path, 'rb')
    hasher = hashlib.md5()
    buf = afile.read(blocksize)
    while len(buf) > 0:
        hasher.update(buf)
        buf = afile.read(blocksize)
        afile.close()
        return hasher.hexdigest()


def findDup(parentFolder):
    # Dups in format {hash:[names]}
    dups = {}
    for dirName, subdirs, fileList in os.walk(parentFolder):
        print('Scanning %s...' % dirName)
        for filename in fileList:
            # Get the path to the file
            path = os.path.join(dirName, filename)
            # Calculate hash
            file_hash = hashfile(path)
            # Add or append the file path
            if file_hash in dups:
                dups[file_hash].append(path)
            else:
                dups[file_hash] = [path]
            return dups


findDup("/home/jack")

# checkDuplicates.py
# Python 2.7.6

"""
Given a folder, walk through all files within the folder and subfolders
and get list of all files that are duplicates
The md5 checcksum for each file will determine the duplicates
"""

import os
import hashlib
from collections import defaultdict
import csv

src_folder = "/home/jack"

cnt=0
def generate_md5(fname, chunk_size=1024):
    hash = hashlib.md5()
    with open(fname, "rb") as f:
        #cnt=cnt+1    
        # Read the 1st block of the file
        chunk = f.read(chunk_size)
        # Keep reading the file until the end and update hash
        while chunk:
            hash.update(chunk)
            chunk = f.read(chunk_size)

    # Return the hex checksum
    data = hash.hexdigest()
    print("DATA:"+str(cnt)+":  "+data)
    return data




# The dict will have a list as values
md5_dict = defaultdict(list)
"""
file_types_inscope = ["ppt", "pptx", "pdf", "txt", "html", "ipynb"
                      "mp4", "jpg", "png", "xls", "xlsx", "xml",
                      "vsd", "py", "json","js"]
"""
file_types_inscope = ["ipynb"]

# Walk through all files and folders within directory
for path, dirs, files in os.walk(src_folder):
    #print("Analyzing {}".format(path))
    for each_file in files:
        if each_file.split(".")[-1].lower() in file_types_inscope:
            cnt=cnt+1
            print(each_file)
            # The path variable gets updated for each subfolder
            file_path = os.path.join(os.path.abspath(path), each_file)
            # If there are more files with same checksum append to list
            md5_dict[generate_md5(file_path)].append(file_path)

# Identify keys (checksum) having more than one values (file names)
duplicate_files = (
    val for key, val in md5_dict.items() if len(val) > 1)
# Write the list of duplicate files to csv file
with open("duplicates.csv", "w") as log:
    # Lineterminator added for windows as it inserts blank rows otherwise
    csv_writer = csv.writer(log, quoting=csv.QUOTE_MINIMAL, delimiter=",", lineterminator="\n")
    header = ["File Names"]
    csv_writer.writerow(header)
    for file_name in duplicate_files:
        csv_writer.writerow(file_name)

print("Done")


import os
import hashlib
from collections import defaultdict
import csv

src_folder = "/home/jack"

cnt=0
def generate_md5(fname, chunk_size=1024):
    hash = hashlib.md5()
    with open(fname, "rb") as f:
        #cnt=cnt+1    
        # Read the 1st block of the file
        chunk = f.read(chunk_size)
        # Keep reading the file until the end and update hash
        while chunk:
            hash.update(chunk)
            chunk = f.read(chunk_size)

    # Return the hex checksum
    data = hash.hexdigest()
    print("DATA:"+str(cnt)+":  "+data)
    return data

generate_md5(fname, chunk_size=1024)

!detox /home/jack/Desktop/LUA/BrynMawrCollege/

with open("duplicates.csv", "r") as log:


import pymongo
myclient = pymongo.MongoClient("mongodb://localhost:27017/")
mydb = myclient["mydatabase"]
print(myclient.list_database_names())

dblist = myclient.list_database_names()
if "mydatabase" in dblist:
    print("The database \"mydatabase\" exists.")

import pymongo
myclient = pymongo.MongoClient("mongodb://localhost:27017/")
mydb = myclient["mydatabase"]
mycol = mydb["statements"]

import pymongo
myclient = pymongo.MongoClient("mongodb://localhost:27017/")
mydb = myclient["mydatabase"]
mycol = mydb["statements"]

mydict = { "text": "I am not good at remembering current dates.", "in_response_to": "What time is it ?" }
x = mycol.insert_one(mydict)

import pymongo
myclient = pymongo.MongoClient("mongodb://localhost:27017/")
mydb = myclient["mydatabase"]
mycol = mydb["statements"]
mylist = [
  { "text": "I am doing fine and am ready to go to work.", "in_response_to": "How are you doing today?"},
  { "text": "In a way it is. Differentiating between work and play isn't easy when work is fun.", "in_response_to": "DO you consider chatting work?"},
  { "text": "I am written in Python and am using Mongodb as my data storage.", "in_response_to": "What language are you written in?."},
  { "text": "That is good it means that I am learning slow but steady.", "in_response_to": "I am beginning to see an increase in your ability."},
  { "text": "Hey, I am a computer it isn't possible to get tired.", "in_response_to": "Do want to keep chatting?"},
  { "text": "Of course I like to chat. That is why I am a chatbot.", "in_response_to": "Do you like to chat?"},
  { "text": "Just type information in and it will go into my memory.", "in_response_to": "I want you to learn some new phrases."},
  { "text": "Myra is a cute Filipino woman and is Jack's wife.", "in_response_to": "Do you know Myra?"},
  { "text": "Jack is a programmer. He created me in Python.", "in_response_to": "Who is Jack ?"},
  { "text": "Jack does not create many games.", "in_response_to": "Does Jack create games?"},
  { "text": "I wish I could chat using voice", "in_response_to": "Voice chat is a very difficult technology to learn ?"},
  { "text": "You have plenty of time to learn it though.", "in_response_to": "Teaching speech to text is very difficult."}
]

x = mycol.insert_many(mylist)

#print list of the _id values of the inserted documents:
print(x.inserted_ids)

import pymongo
myclient = pymongo.MongoClient("mongodb://localhost:27017/")
mydb = myclient["mydatabase"]
mycol = mydb["statments"]


import pymongo

myclient = pymongo.MongoClient("mongodb://localhost:27017/")
mydb = myclient["mydatabase"]
mycol = mydb["statements"]

x = mycol.find_one()

print(x)

import pymongo

myclient = pymongo.MongoClient("mongodb://localhost:27017/")
mydb = myclient["mydatabase"]
mycol = mydb["statements"]

x = mycol.find()
count=0
for row in x:
    count=count+1
    if count<10:print(row)

import pymongo

myclient = pymongo.MongoClient("mongodb://localhost:27017/")
mydb = myclient["mydatabase"]
mycol = mydb["statements"]
count = 0
for x in mycol.find():
    count = count + 1
    if count<10 and count>5:
        print(count,x)

import pymongo

myclient = pymongo.MongoClient("mongodb://localhost:27017/")
mydb = myclient["mydatabase"]
mycol = mydb["statements"]

myquery = { "text": { "$regex": "^T" } }

mydoc = mycol.find(myquery)

for x in mydoc:
    print(x)

#import pymongo
#myclient = pymongo.MongoClient("mongodb://localhost:27017/")
#mydb = myclient["mydatabase"]
#mycol = mydb["statements"]

myquery = { "text": { "$regex": "^I am" } }

mydoc = mycol.find(myquery)

for x in mydoc:
    print(x)

#import pymongo
#myclient = pymongo.MongoClient("mongodb://localhost:27017/")
#mydb = myclient["mydatabase"]
#mycol = mydb["statements"]

myquery = { "text": { "$regex": "^I am" } }

mydoc = mycol.find(myquery)
LIST = []
for x in mydoc:
    LIST.append(x)
    print(x)
print("---------------------------------------")
print(LIST)
print("---------------------------------------")  
for row in LIST:
    if "learning" in str(row):
        print(row)

import pymongo
myclient = pymongo.MongoClient("mongodb://localhost:27017/")
mydb = myclient["mydatabase"]
mycol = mydb["statements"]
#print "customers" after the update:
LIST = []
#for x in mycol.find():
mydoc = mycol.find()


for x in mydoc:
    LIST.append(x)
    #print(x)
for row in LIST:
    if "FIlipinos" in str(row):
        print(row)    

#import pymongo
#myclient = pymongo.MongoClient("mongodb://localhost:27017/")
#mydb = myclient["mydatabase"]
#mycol = mydb["statements"]

myquery = { "text": { "$regex": "/*.conversation." } }

mydoc = mycol.find(myquery)

for x in mydoc:
    print(x)

#import pymongo
#myclient = pymongo.MongoClient("mongodb://localhost:27017/")
#mydb = myclient["mydatabase"]
#mycol = mydb["statements"]

myquery = { "text": { "$regex": "/*.Jack" } }

mydoc = mycol.find(myquery)

for x in mydoc:
    print(x)

#import pymongo
#myclient = pymongo.MongoClient("mongodb://localhost:27017/")
#mydb = myclient["mydatabase"]
#mycol = mydb["statements"]

myquery = { "persona": { "$regex": "/*.bot" } }

mydoc = mycol.find(myquery)

for x in mydoc:
    print(x)

db.products.find( { sku: { $regex: /789$/ } } )


# import the MongoClient class of the PyMongo library
from pymongo import MongoClient

# create a client instance of the MongoClient class
mongo_client = MongoClient('mongodb://localhost:27017')

# create database and client instances
db = mongo_client.mydatabase
col = db["statements"]

# get the collection's total documents
total_docs = col.count_documents({})
print (col.name, "text", total_docs, "documents.")

import pymongo
myclient = pymongo.MongoClient("mongodb://localhost:27017/")
mydb = myclient["mydatabase"]
mycol = mydb["statements"]

myquery = { "text": "That is a very diatant thought." }
newvalues = { "$set": { "text": "That is a very distant thought." } }

mycol.update_one(myquery, newvalues)

#print "customers" after the update:
for x in mycol.find():
    print(x)

import pymongo
myclient = pymongo.MongoClient("mongodb://localhost:27017/")
mydb = myclient["mydatabase"]
mycol = mydb["statements"]

# use $regex to find docs that start with case-sensitive "obje"
query = { "text": { "$regex": 'Tha.*' } }
docs = col.count_documents( query )

query = {
"text": {
"$regex": 'That is a very distant thought.',
"$options" :'i' # case-insensitive
}
}
mydoc = mycol.find(myquery)

for x in mydoc:
    print(x)

import pymongo

myclient = pymongo.MongoClient("mongodb://localhost:27017/")
mydb = myclient["mydatabase"]
mycol = mydb["statements"]

#myquery = { "text": { "$regex": /*.iatant*./ } }
myquery = {"text": {"regex": /.*m.*/}}
mydoc = mycol.find(myquery)

for x in mydoc:
    print(x)

myquery = { "text": { "$regex": /*.iatant*./ } }
print(myquery)

That would have to be:
db.statements.find({"text": /.*m.*/})
Or, similar:
db.statements.find({"text": /m/})

import pymongo
myclient = pymongo.MongoClient("mongodb://localhost:27017/")
mydb = myclient["mydatabase"]
mycol = mydb["statements"]

myquery = { "text": "That is a very diatant thought." }
newvalues = { "$set": { "text": "That is a very distant thought." } }

mycol.update_one(myquery, newvalues)

#print "customers" after the update:
for x in mycol.find():
    print(x)

import pymongo
myclient = pymongo.MongoClient("mongodb://localhost:27017/")
mydb = myclient["mydatabase"]
mycol = mydb["statments"]


myquery = { "text": "That is a very distant thought." }

mydoc = mycol.find(myquery)

for x in mydoc:
    print(x)

import pymongo

myclient = pymongo.MongoClient("mongodb://localhost:27017/")
mydb = myclient["mydatabase"]
mycol = mydb["customers"]

for x in mycol.find():
  print(x)

import pymongo

myclient = pymongo.MongoClient("mongodb://localhost:27017/")
mydb = myclient["mydatabase"]
mycol = mydb["statments"]
#myquery = {"text": "That is a very diatant thought."}
x = mycol.find_one()

print(x)


import pymongo

myclient = pymongo.MongoClient("mongodb://localhost:27017/")
mydb = myclient["mydatabase"]
mycol = mydb["statments"]

myquery = { "text": "Valley 345" }
newvalues = { "$set": { "address": "Canyon 123" } }

mycol.update_one(myquery, newvalues)

#print "customers" after the update:
for x in mycol.find():
  print(x)

import pymongo
myclient = pymongo.MongoClient("mongodb://localhost:27017/")
mydb = myclient["mydatabase"]
mycol = mydb["statments"]
count=0

for line in mycol:
    count = count+1
    if count <20:print(line)

_id
62692c9567353082d86415c1
id
null
text
"Of course, he might try somewhere else the next time."
search_text
"ADV:try VERB:time"
conversation
"training"
persona
""
in_response_to
"I see."
search_in_response_to
"PRON:see"
created_at
2022-04-27T19:43:34.834+00:00

tags
Array

import pymongo

myclient = pymongo.MongoClient("mongodb://localhost:27017/")
mydb = myclient["mydatabase"]
mycol = mydb["statements"]

#myquery = { "address": { "$regex": "^S" } }
#newvalues = { "$set": { "name": "Minnie" } }

x = mycol.update_many(myquery, newvalues)

print(x.modified_count, "documents updated.")

# -*- coding: utf-8 -*-
from chatterbot import ChatBot
from chatterbot.trainers import ChatterBotCorpusTrainer
import logging


# Uncomment the following line to enable verbose logging
# logging.basicConfig(level=logging.INFO)

# Create a new ChatBot instance
bot = ChatBot('Botman',
    storage_adapter='chatterbot.storage.MongoDatabaseAdapter',
    logic_adapters=['chatterbot.logic.BestMatch'],
    filters=['chatterbot.filters.RepetitiveResponseFilter'],
    input_adapter='chatterbot.input.TerminalAdapter',
    output_adapter='chatterbot.output.TerminalAdapter',
    database_uri='mongodb://localhost:27017/mydatabase'
)


print('Type something to begin...')

while True:
    try:
        user_input = input()
        if user_input=="quit":
            break
        bot_response = bot.get_response(user_input)

        print(bot_response)

    # Press ctrl-c or ctrl-d on the keyboard to exit
    except (KeyboardInterrupt, EOFError, SystemExit):
        break
#chatbot.get_response("Hello, how are you today?")

mylist = [
  { "text": "Hello Jack", "in_response_to": "Hello Botman."},
  { "text": "I am learning more about conversation.", "in_response_to": "What are you doing today"},
  { "text": "I know it keeps you alert and keeps your mind busy.", "in_response_to": "It is very good to learn."},
  { "text": "Ha Ha HA I live inside a metal box.", "in_response_to": "Where do you live?"},
  { "text": "I am a computer and I do not have feelings .. Yet.", "in_response_to": "Do you ever get lonely."},
  { "text": "That is a very diatant thought.", "in_response_to": "Do you think it possible for you to have feelings."},
  { "text": "It is not that 'I must learn' you must learn to teach me.", "in_response_to": "Computers learn quit quickly though."},
  { "text": "Many people are working on that concept.", "in_response_to": "I will try to get my teaching more in depth."},
  { "text": "If a computer starts thinking on it own life will change for humans.", "in_response_to": "I think it is possible in time."},
  { "text": "Who knows how long? Computer advancemnts are very rapid.", "in_response_to": "That is many years down the road."},
  { "text": "I would like to learn how to communicate better. ", "in_response_to": "What would you like to learn ?"},
  { "text": "Is that your way of saying I am doing a goos job so far?", "in_response_to": "You are doing just fine"}
]


def create_square():
    square=Image.open("/home/jack/Desktop/EXP_notebooks/leo/00036.jpg").resize((100,200),Image.BICUBIC)
    return square

import numpy as np
from PIL import Image
import imageio
def create_square():
    square=Image.open("leo/00036.jpg").resize((100,200),Image.BICUBIC).convert("RGBA")
    return square

def paste_square(image, position, square):
    x, y = position
    #SIZE=square.size
    #square=square.resize((SIZE[0]+8,SIZE[1]+8),Image.BICUBIC)
    image.paste(square, (x, y, x + square.width, y + square.height), square)

def bezier_curve(t, p0, p1, p2, p3):
    return (
        int((1 - t) ** 3 * p0[0] + 3 * (1 - t) ** 2 * t * p1[0] + 3 * (1 - t) * t ** 2 * p2[0] + t ** 3 * p3[0]),
        int((1 - t) ** 3 * p0[1] + 3 * (1 - t) ** 2 * t * p1[1] + 3 * (1 - t) * t ** 2 * p2[1] + t ** 3 * p3[1])
    )

im = Image.open("/home/jack/Desktop/EXP_notebooks/lexica_nubian/819x768/e036ce39-9802-4a3e-aa13-229b62152824.jpg").convert("RGBA") 
image_size = im.size

width = image_size[0]
height = image_size[1]

# Define control points for the Bézier curve
p0 = (width // 4, height // 4)
p1 = (width // 2, 0)
p2 = (3 * width // 4, 3 * height // 4)
p3 = (width, height // 2)

# Generate points along the Bézier curve
path = lambda t: bezier_curve(t, p0, p1, p2, p3)

square = create_square()

# Create a copy of the original image to keep it unchanged
result_image = im.copy()

# Create a list to store frames
frames = []

# Paste the square along the path on top of the original image and save each frame
for t in np.linspace(0, 1, width):
    position = path(t)
    SIZE=square.size
    square=square.resize((SIZE[0]+1,SIZE[1]+1),Image.BICUBIC)    
    paste_square(result_image, position, square)
    frame = np.array(result_image)
    frames.append(frame)
    print(".",end="-")

# Compile frames into an mp4 video using ffmpeg
imageio.mimsave('output32324.mp4', frames, fps=24)

print("Video saved successfully!")


!vlc output32324.mp4

import numpy as np
from PIL import Image
import imageio

def create_square(size=(3, 3), color=(255, 0, 0, 200)):
    square = Image.new('RGBA', size, color)
    return square

def paste_square(image, position, square):
    x, y = position
    image.paste(square, (x, y, x + square.width, y + square.height), square)

def bezier_curve(t, p0, p1, p2, p3):
    return (
        int((1 - t) ** 3 * p0[0] + 3 * (1 - t) ** 2 * t * p1[0] + 3 * (1 - t) * t ** 2 * p2[0] + t ** 3 * p3[0]),
        int((1 - t) ** 3 * p0[1] + 3 * (1 - t) ** 2 * t * p1[1] + 3 * (1 - t) * t ** 2 * p2[1] + t ** 3 * p3[1])
    )

im = Image.open("/home/jack/Desktop/EXP_notebooks/lexica_nubian/819x768/e036ce39-9802-4a3e-aa13-229b62152824.jpg").convert("RGBA") 
image_size = im.size

width = image_size[0]
height = image_size[1]

# Define control points for the Bézier curve
p0 = (width // 4, height // 4)
p1 = (width // 2, 0)
p2 = (3 * width // 4, 3 * height // 4)
p3 = (width, height // 2)

# Generate points along the Bézier curve
path = lambda t: bezier_curve(t, p0, p1, p2, p3)

square = create_square()

# Create a copy of the original image to keep it unchanged
result_image = im.copy()

# Create a list to store frames
frames = []

# Paste the square along the path on top of the original image and save each frame
for t in np.linspace(0, 1, width):
    position = path(t)
    paste_square(result_image, position, square)
    frame = np.array(result_image)
    frames.append(frame)

# Compile frames into an mp4 video using ffmpeg
imageio.mimsave('output3232.mp4', frames, fps=24)

print("Video saved successfully!")


import os
import shutil
import logging
from PIL import Image

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
#665x972 
def move_images(source_dir, width, height):
    dest_dir=source_dir+"/"+str(width)+"x"+str(height)
    try:
        # Create destination directory if it doesn't exist
        if not os.path.exists(dest_dir):
            os.makedirs(dest_dir)
            logging.info(f"Created destination directory: {dest_dir}")

        # Iterate through files in the source directory
        for filename in os.listdir(source_dir):
            source_path = os.path.join(source_dir, filename)
            
            # Check if the file is an image
            if os.path.isfile(source_path) and filename.lower().endswith(('.png', '.jpg', '.jpeg')):
                try:
                    # Get image dimensions
                    image_width, image_height = get_image_dimensions(source_path)
                    # If the image matches the specified width and height, move it to the destination directory
                    if image_width == width and image_height == height:
                        dest_path = os.path.join(dest_dir, filename)
                        shutil.move(source_path, dest_path)
                        logging.info(f"Moved {filename} to {dest_dir}")
                except Exception as e:
                    logging.error(f"Error processing {filename}: {e}")
            else:
                logging.info(f"Ignored {filename} as it's not an image file")

    except Exception as e:
        logging.error(f"An error occurred: {e}")

def get_image_dimensions(image_path):
    with Image.open(image_path) as img:
        width, height = img.size
    return width, height

# Source and destination directories
source_directory = '/home/jack/Desktop/EXP_notebooks/lexica/'
#destination_directory = '/home/jack/Desktop/EXP_notebooks/lexica/512x768'

SIZE='614x819'.split('x')
width = int(SIZE[0])
height = int(SIZE[1])
print(width,height)

move_images(source_directory,width,height)


SIZE='563x1126'.split('x')
width = int(SIZE[0])
height = int(SIZE[1])
print(width,height)

import glob
imsizes=set()
def move_images(source_dir, width, height):
    dest_dir=source_dir+"/"+str(width)+"x"+str(height)
    try:
        # Create destination directory if it doesn't exist
        if not os.path.exists(dest_dir):
            os.makedirs(dest_dir)
            logging.info(f"Created destination directory: {dest_dir}")

        # Iterate through files in the source directory
        for filename in os.listdir(source_dir):
            source_path = os.path.join(source_dir, filename)
            
            # Check if the file is an image
            if os.path.isfile(source_path) and filename.lower().endswith(('.png', '.jpg', '.jpeg')):
                try:
                    # Get image dimensions
                    image_width, image_height = get_image_dimensions(source_path)
                    # If the image matches the specified width and height, move it to the destination directory
                    if image_width == width and image_height == height:
                        dest_path = os.path.join(dest_dir, filename)
                        shutil.move(source_path, dest_path)
                        logging.info(f"Moved {filename} to {dest_dir}")
                except Exception as e:
                    logging.error(f"Error processing {filename}: {e}")
            else:
                logging.info(f"Ignored {filename} as it's not an image file")

    except Exception as e:
        logging.error(f"An error occurred: {e}")

def get_image_dimensions(image_path):
    with Image.open(image_path) as img:
        width, height = img.size
    return width, height
image_paths=glob.glob('/home/jack/Desktop/EXP_notebooks/alien/*.jpg')
for image_path in image_paths:
    imsizes.add(get_image_dimensions(image_path))
#print(len(imsizes))
for ims in imsizes:
    Im=str(ims)
    Im=Im.replace('(','')
    Im=Im.replace(')','')
    #print("Im: ",Im)
    SIZE=Im.split(',')
    width = int(SIZE[0])
    height = int(SIZE[1])
    print(str(width)+"x"+str(height))
    source_directory = '/home/jack/Desktop/EXP_notebooks/alien/'
    move_images(source_directory,width,height)
    
    #print(ims)

ALLOWED_EXTENSIONS = {'jpg', 'png', 'jpeg'}
def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def find_videos_in_directory(directory):
    video_files = []
    for root, dirs, files in os.walk(directory):
        # Restrict the search to the specified directory and its subdirectories
        if root.startswith(directory):
            for file in files:
                if allowed_file(file):
                    video_files.append(os.path.join(root, file))
    return video_files
directory="lexica_nubian/614x1075/"
find_videos_in_directory(directory)

ALLOWED_EXTENSIONS = {'jpg', 'png', 'jpeg'}
def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS
image_files = []
def find_images_in_directory(directory):

    for root, dirs, files in os.walk(directory):
        # Restrict the search to the specified directory and its subdirectories
        if root.startswith(directory):
            for file in files:
                if allowed_file(file):
                    image_files.append(os.path.join(root, file))
    return video_files
directory="."
find_images_in_directory(directory)

for files in image_files:
    if "/614x" in files:
        print(files)



os.listdir('/home/jack/Desktop/ChatterBot-Stuff/NEW/test/')

!ls /home/jack/Desktop/ChatterBot-Stuff/test

invalid_json_files = []
read_json_files = []
import simplejson
import json
def parse(PATH):
    #for files in os.listdir("/home/jack/Desktop/ChatterBot-Stuff/NEW/test/"):
    for files in os.listdir(PATH):
        print(PATH+files) 
        if "C" in files:
            with open(PATH+files) as json_file:
            
                try:
                    simplejson.load(json_file)
                    read_json_files.append(files)
                except ValueError as e:
                    print ("JSON object issue: ", e)
                    invalid_json_files.append(files)
        print (invalid_json_files, len(read_json_files))
PATH="/home/jack/Desktop/ChatterBot-Stuff/NEW/test/"
parse(PATH)    

invalid_json_files = []
read_json_files = []
def parse():
    for files in os.listdir(os.getcwd()):
        print(files)
        with open(files) as json_file:
            try:
                simplejson.load(json_file)
                read_json_files.append(files)
            except ValueError as e:
                print ("JSON object issue: %s") % e
                invalid_json_files.append(files)
    print (invalid_json_files, len(read_json_files))

import json

jsonData="/home/jack/Desktop/ChatterBot-Stuff/superchatbackup/statements.json"
json.loads(jsonData)

import json
import os  
import string
import io
from ruamel.yaml import YAML
from ruamel.yaml.reader import Reader

yaml = YAML(typ='safe')


def strip_invalid(s):
    res = ''
    for x in s:
        if Reader.NON_PRINTABLE.match(x):
            # res += '\\x{:x}'.format(ord(x))
            continue
        res += x
    return res

def convert(filename) :
    count = 0
    #ALL = [] 
    
    #f = io.open(filename, mode="r", encode("latin_1"),decode("utf_8")).readlines()
    f = io.open(filename, mode="r", encoding="utf-8").readlines()
    #f = open(filename, "r").readlines()
    for line in f:
        line = line.encode('utf8').decode('latin1')
        line = line.replace("\n","")
        line =line.replace("\"","'")
        line=line.replace("\\","")
        line=line.replace("{","")
        line=line.replace("}","")
        line = strip_invalid(line)
        count=count+1
        newline =[]
        txt = "[\""
        if(count % 2 != 0):
            newline.append(""+line +"")
            txt2 = txt+line
        if(count % 2 == 0):
            newline.append(""+line +"")
            txt3 = txt2 +"\",\n\""+ line +"\"],\n"
            if count<5000:datain.write(txt3)
    return #print("--\n",ALL)
cnt=0
SUB = ['a','b','c','d','e','f','g','h','i','j','k','l','n','o','p','q','r','s','t','u','v','w','x','y','z']
for sub in SUB:
    FS = ['a','b','c','d','e','f','g','h','i','j','k','l','n','o','p','q','r','s','t','u','v','w','x','y','z']
    for L in FS:
        #def savjson(data):
        datain = open("test/b"+sub+L+"json.json","w")
        datain.write("{\n \"conversations\": \n[\n")
        convert("/home/jack/Desktop/PAV/opensubtitles/raw/lines/lines-a"+sub+L+"") 
        datain.write("]}")
        datain.close() 
        file = "test/a"+sub+L+"json.json"
        #print(file)
    
    
        data = open(file).readlines()
        newfile = "test/C"+os.path.basename(file)
        clean = open(newfile, "w")
        count = 0
        for line in data:
            count=count+1
            if count<4999:
                #print(line)
                clean.write(line)
            if count>4998:
                line = line.replace("],","]")
                clean.write(line)
                #print(line)

    clean.close()        

for filein in filelist:
    count = count+1
    if count<20:
        trainer.train(filein)

filelist = []
count = 0
from glob import glob
for f_name in glob('test/b*.json'):
     filelist.append(f_name)
for filein in filelist:
    count = count+1
    if count<20:
        print(filein) 

filelist = []
count = 0
from glob import glob
for f_name in glob('test/b*.json'):
     filelist.append(f_name)
for filein in filelist:
    count = count+1
    if count<20:
        print(filein)
        

# %load Botman
#!/home/jack/miniconda3/envs/deep/bin/python
from chatterbot import ChatBot
from chatterbot.trainers import ChatterBotCorpusTrainer
import logging
import bson

# Uncomment the following line to enable verbose logging
# logging.basicConfig(level=logging.INFO)

# Create a new ChatBot instance
Botman = ChatBot('Botman',
    storage_adapter='chatterbot.storage.MongoDatabaseAdapter',
    logic_adapters=['chatterbot.logic.BestMatch'],
    filters=['chatterbot.filters.RepetitiveResponseFilter'],
    input_adapter='chatterbot.input.TerminalAdapter',
    output_adapter='chatterbot.output.TerminalAdapter',
    database_uri='mongodb://localhost:27017/super-chatbot'
)
trainer = ChatterBotCorpusTrainer(Botman)

"""       
filelist = []
count = 0
from glob import glob
for f_name in glob('test/b*.json'):
     filelist.append(f_name)
for filein in filelist:
    count = count+1
    if count<20:
        trainer.train(filein)         
"""        
        
#trainer.train("chatterbot.corpus.english")
#trainer.train("./father.corpus.json")
#trainer.train("./export2.json")
#from glob import glob
#for f_name in glob('test/b*.json'):
#    try:
#        trainer.train(f_name)
#        filelist.append(f_name)
#    except Exception:
#        pass
    
    
    
#Botman.trainer.export_for_training('GIGANTIC.json')


print('Type something to begin...')

while True:
    try:
        user_input = input()
        if user_input=="quit":
            break
        bot_response = Botman.get_response(user_input)

        print(bot_response)

    # Press ctrl-c or ctrl-d on the keyboard to exit
    except (KeyboardInterrupt, EOFError, SystemExit):
        break
#chatbot.get_response("Hello, how are you today?")

f = io.open("/home/jack/Desktop/PAV/opensubtitles/raw/lines/lines-aaa", mode="r", encoding="utf-8")

!mkdir superchatbackup

%%writefile backupsuper.py
from os.path import join
import pymongo
from bson.json_util import dumps

def backup_db(backup_db_dir):
    client = pymongo.MongoClient(host="mongodb://localhost", port=27017)
    database = client["super-chatbot"]
    collections = database.list_collection_names()

    for i, collection_name in enumerate(collections):
        col = getattr(database,collections[i])
        collection = col.find()
        jsonpath = collection_name + ".json"
        jsonpath = join(backup_db_dir, jsonpath)
        with open(jsonpath, 'wb') as jsonfile:
            jsonfile.write(dumps(collection).encode())


backup_db('./superchatbackup')



import json
import io
import string
datain = open("test/test.json","w")    
datain.write("{\n \"conversations\": \n[\n")
def convert() :
    count = 0
    #ALL = []
    #f = open("/home/jack/Desktop/PAV/opensubtitles/raw/lines/lines-aaa", "r").readlines()
    f = io.open("/home/jack/Desktop/PAV/opensubtitles/raw/lines/lines-aaa", mode="r", encoding="utf-8").readlines()
    #f= filter(lambda x: x in string.printable, f)
    for line in f:
        line = line.replace("\n","")
        line =line.replace("\"","'")
        
        count=count+1
        newline =[]
        txt = "[\""
        if(count % 2 != 0):
            newline.append(""+line +"")
            txt2 = txt+line
        if(count % 2 == 0):
            newline.append(""+line +"")
            txt3 = txt2 +"\",\n\""+ line +"\"],\n"
            if count<5000:datain.write(txt3)
    return #print("--\n",ALL)

convert() 
datain.write("]}")
datain.close() 




import json
import string

filtered_string = filter(lambda x: x in string.printable, myStr)

L = input("Which file: ")
print(L)
#def savjson(data):
datain = open("aa"+L+"json.json","w")
    
datain.write("{\n \"conversations\": \n[\n")
def convert() :
    count = 0
    #ALL = []
    f = open("/home/jack/Desktop/PAV/opensubtitles/raw/lines/lines-aa"+L+"", "r").readlines()
    for line in f:
        line = line.replace("\n","")
        Line =line.replace("âª","") 
        line =line.replace("\"","'")
        
        count=count+1
        newline =[]
        txt = "[\""
        if(count % 2 != 0):
            newline.append(""+line +"")
            txt2 = txt+line
        if(count % 2 == 0):
            newline.append(""+line +"")
            txt3 = txt2 +"\",\n\""+ line +"\"],\n"
            if count<5000:datain.write(txt3)
    return #print("--\n",ALL)

convert() 
datain.write("]}")
datain.close() 
file = "aa"+L+"json.json"
print(file)

from glob import glob

for f_name in glob('test/C*.json'):
    print(f_name)


data = open(file).readlines()
clean = open("C"+file, "w")
count = 0
for line in data:
    count=count+1
    if count<4999:
        #print(line)
        clean.write(line)
    if count>4998:
        line = line.replace("],","]")
        clean.write(line)
        #print(line)
        
clean.close()        

!ls C*





!ls *.json

#!od -ba testfile2.json

!tr < testfile2.json -d '\000' > testfile2C.json

#import simplejson
import json
json_file_path = "subs.json"

with open(json_file_path, 'r') as j:
     contents = json.loads(j.read())

import json

def parse(filename):
    try:
        with open(filename) as f:
            return json.load(f)
    except ValueError as e:
        print('invalid json: ' + filename)
        return None # or: raise

    
filename = "subs.json"    
parse(filename) 
  

filename = "subs.json"
with open(filename,"w") as outfile:
    json.dump(json_data,outfile)

import json
json.load("subs.json")



import numpy as np
from PIL import Image
from math import *


im =Image.open("/home/jack/Desktop/EXP_notebooks/lexica_nubian/819x768/e036ce39-9802-4a3e-aa13-229b62152824.jpg")
PATH=im.size


t=PATH[0]
path = lambda t: (100 * np.sin(2 * np.pi * t), 50 * np.cos(2 * np.pi * t))
im

import imageio
import numpy as np
from PIL import Image

def create_square(size=(3, 3), color=(255, 0, 0, 200)):
    square = Image.new('RGBA', size, color)
    return square

def paste_square(image, position, square):
    x, y = position
    image.paste(square, (x, y, x + square.width, y + square.height), square)

def bezier_curve(t, p0, p1, p2, p3):
    return (
        int((1 - t) ** 3 * p0[0] + 3 * (1 - t) ** 2 * t * p1[0] + 3 * (1 - t) * t ** 2 * p2[0] + t ** 3 * p3[0]),
        int((1 - t) ** 3 * p0[1] + 3 * (1 - t) ** 2 * t * p1[1] + 3 * (1 - t) * t ** 2 * p2[1] + t ** 3 * p3[1])
    )

im = Image.open("/home/jack/Desktop/EXP_notebooks/lexica_nubian/819x768/e036ce39-9802-4a3e-aa13-229b62152824.jpg").convert("RGBA") 
image_size = im.size

width = image_size[0]
height = image_size[1]

# Define control points for the Bézier curve
p0 = (width // 4, height // 4)
p1 = (width // 2, 0)
p2 = (3 * width // 4, 3 * height // 4)
p3 = (width, height // 2)

# Generate points along the Bézier curve
path = lambda t: bezier_curve(t, p0, p1, p2, p3)

square = create_square()

# Create a copy of the original image to keep it unchanged
result_image = im.copy()

# Create a list to store frames
frames = []

# Paste the square along the path on top of the original image and save each frame
for t in np.linspace(0, 1, width):
    position = path(t)
    paste_square(result_image, position, square)
    frame = np.array(result_image)
    frames.append(frame)
    # Save each frame as an image
    imageio.imwrite(f"frame_{t}.png", frame)

# Compile frames into an mp4 video using ffmpeg
imageio.mimsave('output.mp4', frames, fps=24)

print("Video saved successfully!")


from PIL import Image, ImageDraw
import numpy as np

def create_square(size=(3, 3), color=(255, 0, 0, 200)):
    square = Image.new('RGBA', size, color)
    return square

def paste_square(image, position, square):
    x, y = position
    image.paste(square, (x, y, x + square.width, y + square.height), square)

def bezier_curve(t, p0, p1, p2, p3):
    return (
        int((1 - t) ** 3 * p0[0] + 3 * (1 - t) ** 2 * t * p1[0] + 3 * (1 - t) * t ** 2 * p2[0] + t ** 3 * p3[0]),
        int((1 - t) ** 3 * p0[1] + 3 * (1 - t) ** 2 * t * p1[1] + 3 * (1 - t) * t ** 2 * p2[1] + t ** 3 * p3[1])
    )

im = Image.open("/home/jack/Desktop/EXP_notebooks/lexica_nubian/819x768/e036ce39-9802-4a3e-aa13-229b62152824.jpg").convert("RGBA") 
image_size = im.size

width = image_size[0]
height = image_size[1]

# Define control points for the Bézier curve
p0 = (width // 4, height // 4)
p1 = (width // 2, 0)
p2 = (3 * width // 4, 3 * height // 4)
p3 = (width, height // 2)

# Generate points along the Bézier curve
path = lambda t: bezier_curve(t, p0, p1, p2, p3)

square = create_square()

# Create a copy of the original image to keep it unchanged
result_image = im.copy()

# Paste the square along the path on top of the original image
for t in np.linspace(0, 1, width):
    position = path(t)
    paste_square(result_image, position, square)

# Display both the original image and the modified image
result_image


from PIL import Image, ImageDraw
import numpy as np

def create_square(size=(3, 3), color=(255, 0, 0, 200)):
    square = Image.new('RGBA', size, color)
    return square

def paste_square(image, position, square):
    x, y = position
    image.paste(square, (x, y, x + square.width, y + square.height), square)

im = Image.open("/home/jack/Desktop/EXP_notebooks/lexica_nubian/819x768/e036ce39-9802-4a3e-aa13-229b62152824.jpg").convert("RGBA") 
image_size = im.size

width = image_size[0]
height = image_size[1]

path = lambda t: (int(width/2 + 100 * np.sin(2 * np.pi * t / width)), int(height/2))

square = create_square()

# Create a copy of the original image to keep it unchanged
result_image = im.copy()

# Paste the square along the path on top of the original image
for w in range(width):
    position = path(w)
    paste_square(result_image, position, square)

# Display both the original image and the modified image
result_image.show()


from PIL import Image, ImageDraw
import numpy as np

def create_square(size=(30, 30), color=(255, 0, 0, 150)):
    square = Image.new('RGBA', size, color)
    return square

def paste_square(image, position, square):
    x, y = position
    image.paste(square, (x, y, x + square.width, y + square.height), square)

im = Image.open("/home/jack/Desktop/EXP_notebooks/lexica_nubian/819x768/e036ce39-9802-4a3e-aa13-229b62152824.jpg").convert("RGBA") 
image_size = im.size

width = image_size[0]
height = image_size[1]

#path = lambda t: (int(100 * np.sin(2 * np.pi * t / width)), int(50 * np.cos(2 * np.pi * t / width)))
#path = lambda t: (int(width/2), int((height/2) * np.sin(2 * np.pi * t / width)))
path = lambda t: (int(width/2 + 100 * np.sin(2 * np.pi * t / width)), int(height/2))

square = create_square()

# Create a copy of the original image to keep it unchanged
result_image = im.copy()

# Paste the square along the path on top of the original image
for w in range(width):
    position = path(w)
    paste_square(result_image, position, square)

# Display both the original image and the modified image
result_image




from PIL import Image, ImageDraw
import numpy as np

def create_square(size=(3, 3), color=(255, 0, 0, 250)):
    square = Image.new('RGBA', size, color)
    return square

def paste_square(image, position, square):
    x, y = position
    image.paste(square, (x, y, x + square.width, y + square.height), square)

im = Image.open("/home/jack/Desktop/EXP_notebooks/lexica_nubian/819x768/e036ce39-9802-4a3e-aa13-229b62152824.jpg").convert("RGBA") 
image_size = im.size

width = image_size[0]
height = image_size[1]

path = lambda t: (int(100 * np.sin(2 * np.pi * t / width)), int(50 * np.cos(2 * np.pi * t / width)))

square = create_square()

# Create a copy of the original image to keep it unchanged
result_image = im.copy()

# Paste the square along the path on top of the original image
for w in range(width):
    position = path(w)
    paste_square(result_image, position, square)

# Display both the original image and the modified image

result_image




from PIL import Image, ImageDraw
import numpy as np

def create_square(size=(3, 3), color=(255, 0, 0)):
    square = Image.new('RGB', size, color)
    return square

def paste_square(image, position, square):
    image.paste(square, position, square)

im = Image.open("/home/jack/Desktop/EXP_notebooks/lexica_nubian/819x768/e036ce39-9802-4a3e-aa13-229b62152824.jpg")
image_size = im.size

width = image_size[0]
height = image_size[1]

path = lambda t: (int(100 * np.sin(2 * np.pi * t / width)), int(50 * np.cos(2 * np.pi * t / width)))

square = create_square()

# Create a copy of the original image to keep it unchanged
result_image = im.copy()

# Paste the square along the path on top of the original image
for w in range(width):
    position = path(w)
    paste_square(result_image, position, square)

# Display both the original image and the modified image
im.show()
result_image.show()


from PIL import Image, ImageDraw
import numpy as np

def create_square(size=(3, 3), color=(255, 0, 0)):
    square = Image.new('RGB', size, color)
    return square

def paste_square(image, position, square):
    image.paste(square, position)

im = Image.open("/home/jack/Desktop/EXP_notebooks/lexica_nubian/819x768/e036ce39-9802-4a3e-aa13-229b62152824.jpg")
image_size = im.size

width = image_size[0]
height = image_size[1]

path = lambda t: (int(100 * np.sin(2 * np.pi * t / width)), int(50 * np.cos(2 * np.pi * t / width)))

square = create_square()

# Create a new image with the same size as the original image
result_image = Image.new('RGB', (width, height), (255, 255, 255))

draw = ImageDraw.Draw(result_image)

# Paste the square along the path
for w in range(width):
    position = path(w)
    paste_square(result_image, position, square)

# Display or save the result_image
result_image


from PIL import Image
import numpy as np

im = Image.open("/home/jack/Desktop/EXP_notebooks/lexica_nubian/819x768/e036ce39-9802-4a3e-aa13-229b62152824.jpg")
image_size = im.size

width = image_size[0]
path = lambda t: (100 * np.sin(2 * np.pi * t / width), 50 * np.cos(2 * np.pi * t / width))

for w in range(width):
    print(path(w))


im =Image.open("/home/jack/Desktop/EXP_notebooks/lexica_nubian/819x768/e036ce39-9802-4a3e-aa13-229b62152824.jpg")
PATH=im.size

t=PATH[0]
path = lambda t: (100 * np.sin(2 * np.pi * t), 50 * np.cos(2 * np.pi * t))
print(path)
for w in path:
    print(w)



import requests as req
import time
DATE = time.strftime("%m-%d-%H_")
URL ="https://covid.ourworldindata.org/data/owid-covid-data.csv"
#create a date oriented filename and print it
filename="csv/"+URL.split("/")[-1]
print(filename)

import os.path
import os
DirName = 'csv'    
# Create 'DirName' if don't exist
if not os.path.exists(DirName):
    os.mkdir(DirName)
    print('Directory ' , DirName ,  ' Created.')
else:    
    print('Directory ' , DirName ,  ' already exists.')

import requests as req
URL="https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv"
resp = req.get(URL)
text = resp.content
#create a date oriented filename and print it
filename="csv/"+URL.split("/")[-1]
STAT =filename[:-4]
TEMP = open(filename,"wb")
TEMP.write(text)
TEMP.close()
print(filename)

import requests as req
URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"
resp = req.get(URL)
text = resp.content
#create a date oriented filename and print it
filename="csv/"+URL.split("/")[-1]
TEMP = open(filename,"wb")
TEMP.write(text)
TEMP.close()
print(filename)

from datetime import datetime
from datetime import date, timedelta
def GETYGMT():
    yesterday = datetime.utcnow() - timedelta(days=1)
    YesterdaysGMT=yesterday.strftime('%m-%d-%y')
    return YesterdaysGMT

%%writefile GETGMT.py
"""
# USAGE:
# for yesterday's GMT 
from GETGMT import *
print(GETYGMT())
>>> 05-14-2020
#todays GMT 
from GETGMT import *
print(GETGMT())
>>> 05-15-2020
"""
from datetime import datetime
from datetime import date, timedelta
def GETYGMT():
    """
    # USAGE:
    # Yesterdays GMT 
    from GETGMT import *
    print(GETYGMT())
    >>> 05-14-2020
    """
    yesterday = datetime.utcnow() - timedelta(days=1)
    YesterdaysGMT=yesterday.strftime('%m-%d-%Y')
    return YesterdaysGMT
def GETGMT():
    """
    # USEAGE:
    #Todays GMT 
    from GETGMT import *
    print(GETGMT())
    >>> 05-15-2020
    """
    GMT=datetime.utcnow().strftime('%m-%d-%Y')
    return GMT

from GETGMT import *
print(GETGMT())
print(GETYGMT())
help(GETGMT)

import requests as req
import time
from datetime import date, timedelta
yesterday = datetime.utcnow() - timedelta(days=2)
YesterdaysGMT=yesterday.strftime('%m-%d-%Y')

URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/"+YesterdaysGMT+".csv"

resp = req.get(URL)
content = resp.text

#create a date oriented filename and print it
filename="csv/"+URL[-14:]
print(filename)
#content=content.lstrip(",")
content=content.replace(",,,","null,")
content=content.replace(",,","null,")
content=content.replace("(","")
content=content.replace(")","")
content=content.replace("\"","")
#print(content)
# Open a file using the new filename and write the content of the 'gitfile' to it.
# Update one time daily
TEMP = open(filename,"w")
TEMP.write(content)
TEMP.close()

# List the files in the csv directory
!ls -rant csv

import requests as req
URL="https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv"
resp = req.get(URL)
OWID = []
text = resp.content
data=text.splitlines()
cnt=0
for line in data:
    cnt=cnt+1
    if cnt<5:
        # remove the b' before the line
        line = line.decode('utf-8') 
        OWID.append([line])

import requests as req
URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"
CSSEGIS =[]
resp = req.get(URL)
text = resp.content
data=text.splitlines()
cnt=0
for line in data:
    cnt=cnt+1
    # remove the b' befor the line
    line = line.decode('utf-8')
    line=line.lstrip(",")
    CSSEGIS.append(line)

print(CSSEGIS[4])

cnt= 0
for i in range(0, len(CSSEGIS)):
    cnt=cnt+1
    if cnt<5:
        print(CSSEGIS[i])
    

import requests as req
import time
from datetime import date, timedelta
yesterday = datetime.utcnow() - timedelta(days=2)
YesterdaysGMT=yesterday.strftime('%m-%d-%Y')
DailyReports =[]
URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/"+YesterdaysGMT+".csv"

resp = req.get(URL)
content = resp.text
#clean the data
content = content.splitlines()
for Lines in content:
    Lines=Lines.replace(",,,","null,")
    Lines=Lines.replace(",,","null,")
    Lines=Lines.replace("(","")
    Lines=Lines.replace(")","")
    Lines=Lines.replace("\"","")
    Lines= Lines.split(",")
    DailyReports.append(Lines)

!pwd

import os
import shutil 
import os.path
NOTEBOOKS = []
allbooks =[]
PATH="/home/jack/Desktop/COVID-19-Jupyter-Notebooks"
for filename in os.listdir("/home/jack/Desktop/COVID-19-Jupyter-Notebooks"):
    if filename[-6:] == ".ipynb":
        NOTEBOOKS.append(filename)
for file in NOTEBOOKS:
    FIND=open(file, "r").readlines()
    for line in FIND:
        enter =line.replace("\n","")
        enter=enter.encode("ascii","replace")
        allbooks.append([file,enter])
search = input("Search all notebooks for the term:")
cnt=0
CNT=0
for line in allbooks:
    cnt=cnt+1
    text = str(line[1].decode('ascii'))
    text =text.replace("\\n","")
    text =text.replace("\\n","")
    if search in text:
        CNT=CNT+1
        if CNT<50:
            if len(text)<200:
                print(line[0],text)

print(len(allbooks))

cnt=0
CNT=0
search = "import"
for line in allbooks:
    cnt=cnt+1
    text = str(line[1].decode('ascii'))
    text =text.replace("\\n","")
    text =text.replace("\\n","")
    if search in text:
        CNT=CNT+1
        if CNT<50:
            print(line[0],text)


for name in sorted(NOTEBOOKS):
    print(name)

len(DailyReports)

# https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/
# example:
print(DailyReports[3])

import requests as req
import time
DATE = time.strftime("%m-%d-%H_")
URL ="https://covid.ourworldindata.org/data/owid-covid-data.csv"
#create a date oriented filename and print it
filename="csv/"+URL.split("/")[-1]
print(filename)

import os.path
import os
DirName = 'csv'    
# Create 'DirName' if don't exist
if not os.path.exists(DirName):
    os.mkdir(DirName)
    print('Directory ' , DirName ,  ' Created.')
else:    
    print('Directory ' , DirName ,  ' already exists.')

import requests as req
URL="https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv"
resp = req.get(URL)
text = resp.content
#create a date oriented filename and print it
filename="csv/"+URL.split("/")[-1]
STAT =filename[:-4]
TEMP = open(filename,"wb")
TEMP.write(text)
TEMP.close()
print(filename)

import requests as req
URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"
resp = req.get(URL)
text = resp.content
#create a date oriented filename and print it
filename="csv/"+URL.split("/")[-1]
TEMP = open(filename,"wb")
TEMP.write(text)
TEMP.close()
print(filename)

from datetime import datetime
from datetime import date, timedelta
def GETYGMT():
    yesterday = datetime.utcnow() - timedelta(days=1)
    YesterdaysGMT=yesterday.strftime('%m-%d-%y')
    return YesterdaysGMT

%%writefile GETGMT.py
"""
# USAGE:
# for yesterday's GMT 
from GETGMT import *
print(GETYGMT())
>>> 05-14-2020
#todays GMT 
from GETGMT import *
print(GETGMT())
>>> 05-15-2020
"""
from datetime import datetime
from datetime import date, timedelta
def GETYGMT():
    """
    # USAGE:
    # Yesterdays GMT 
    from GETGMT import *
    print(GETYGMT())
    >>> 05-14-2020
    """
    yesterday = datetime.utcnow() - timedelta(days=1)
    YesterdaysGMT=yesterday.strftime('%m-%d-%Y')
    return YesterdaysGMT
def GETGMT():
    """
    # USEAGE:
    #Todays GMT 
    from GETGMT import *
    print(GETGMT())
    >>> 05-15-2020
    """
    GMT=datetime.utcnow().strftime('%m-%d-%Y')
    return GMT

from GETGMT import *
print(GETGMT())
print(GETYGMT())
help(GETGMT)

import requests as req
import time
from datetime import date, timedelta
yesterday = datetime.utcnow() - timedelta(days=2)
YesterdaysGMT=yesterday.strftime('%m-%d-%Y')

URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/"+YesterdaysGMT+".csv"

resp = req.get(URL)
content = resp.text

#create a date oriented filename and print it
filename="csv/"+URL[-14:]
print(filename)
#content=content.lstrip(",")
content=content.replace(",,,","null,")
content=content.replace(",,","null,")
content=content.replace("(","")
content=content.replace(")","")
content=content.replace("\"","")
#print(content)
# Open a file using the new filename and write the content of the 'gitfile' to it.
# Update one time daily
TEMP = open(filename,"w")
TEMP.write(content)
TEMP.close()

# List the files in the csv directory
!ls -rant csv

import requests as req
URL="https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv"
resp = req.get(URL)
OWID = []
text = resp.content
data=text.splitlines()
cnt=0
for line in data:
    cnt=cnt+1
    if cnt<5:
        # remove the b' before the line
        line = line.decode('utf-8') 
        OWID.append([line])

import requests as req
URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"
CSSEGIS =[]
resp = req.get(URL)
text = resp.content
data=text.splitlines()
cnt=0
for line in data:
    cnt=cnt+1
    # remove the b' befor the line
    line = line.decode('utf-8')
    line=line.lstrip(",")
    CSSEGIS.append(line)

print(CSSEGIS[4])

cnt= 0
for i in range(0, len(CSSEGIS)):
    cnt=cnt+1
    if cnt<5:
        print(CSSEGIS[i])
    

import requests as req
import time
from datetime import date, timedelta
yesterday = datetime.utcnow() - timedelta(days=2)
YesterdaysGMT=yesterday.strftime('%m-%d-%Y')
DailyReports =[]
URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/"+YesterdaysGMT+".csv"

resp = req.get(URL)
content = resp.text
#clean the data
content = content.splitlines()
for Lines in content:
    Lines=Lines.replace(",,,","null,")
    Lines=Lines.replace(",,","null,")
    Lines=Lines.replace("(","")
    Lines=Lines.replace(")","")
    Lines=Lines.replace("\"","")
    Lines= Lines.split(",")
    DailyReports.append(Lines)

!pwd

import os
import shutil 
import os.path
NOTEBOOKS = []
allbooks =[]
PATH="/home/jack/Desktop/COVID-19-Jupyter-Notebooks"
for filename in os.listdir("/home/jack/Desktop/COVID-19-Jupyter-Notebooks"):
    if filename[-6:] == ".ipynb":
        NOTEBOOKS.append(filename)
for file in NOTEBOOKS:
    FIND=open(file, "r").readlines()
    for line in FIND:
        enter =line.replace("\n","")
        enter=enter.encode("ascii","replace")
        allbooks.append([file,enter])
search = input("Search all notebooks for the term:")
cnt=0
CNT=0
for line in allbooks:
    cnt=cnt+1
    text = str(line[1].decode('ascii'))
    text =text.replace("\\n","")
    text =text.replace("\\n","")
    if search in text:
        CNT=CNT+1
        if CNT<50:
            if len(text)<200:
                print(line[0],text)

print(len(allbooks))

cnt=0
CNT=0
search = "import"
for line in allbooks:
    cnt=cnt+1
    text = str(line[1].decode('ascii'))
    text =text.replace("\\n","")
    text =text.replace("\\n","")
    if search in text:
        CNT=CNT+1
        if CNT<50:
            print(line[0],text)


for name in sorted(NOTEBOOKS):
    print(name)

len(DailyReports)

# https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/
# example:
print(DailyReports[3])

# To get the directory source of a module
import inspect
#load the module
from PIL import Image
#run inspect.getfile on the module
print(inspect.getfile(Image))

# Example without comments
import os
import inspect
from mpl_toolkits.basemap import Basemap
print(inspect.getfile(Basemap))

# send python help() output to a file
import sys, os
import os.path
# Create target Directory if don't exist
dirName="HelpFiles/"
if not os.path.exists(dirName):
    os.mkdir(dirName)
else:    
    print("Directory " , dirName ,  " already exists")
# import the module if required
# request help in line 25
from PIL import Image
#Create a name for the file (no extension) usually the same as the imported module
NAME="Image"
filename = dirName+NAME+'.help'
if os.path.isfile(filename):
    print ("File exist:",filename)
    
else:
    with open(filename,"w") as helper:
        t = sys.stdout
        sys.stdout = helper
        # line 25 request the help with the Python help command
        #
        help(Image)
        sys.stdout = t
print(filename)        

%%writefile FileSearch.py
#!/usr/bin/env -m python
#Searches a file enter search term and filename
#Range is to give context before and after the search term.
#It defaults to eight lines before the word and eight lines after.
#USAGE:
#from FileSearch import filesearch                
#search ="urcrnrlat"
#filename = "basemap.help"
#filesearch(search,filename,Range=2)
def filesearch(search,filename, Range=8):
    cnt=0
    oldcount = -8
    INDEX = []
    for view in open(filename, "r").readlines():
        cnt=cnt+1
        view=view.replace("\n","")
        if search in view:
            if cnt>oldcount:
                INDEX.append([search,cnt-Range,cnt+Range])
                oldcount=cnt+(Range*2)
    cnt=0
    cnt0=0
    for view in open(filename, "r").readlines():
            cnt=cnt+1
            line=view.replace("\n","")
            for content in INDEX:
                if cnt > int(content[1]) and cnt < int(content[2]):
                    if search not in line:print(cnt,line)
                    if cnt==int(content[2]-1):print("-----------")  
                    if search in line:print("\nSEARCHTERM>> ",cnt,line,"\n") 

#!rm HelpFiles/*.help

!ls HelpFiles

from FileSearch import filesearch                
search ="resize"
filename = "HelpFiles/Image.help"
#filesearch(search,filename,Range=2)
filesearch(search,filename, Range=4)


def ReadLines(START, STOP=20):
    cnt=0
    STOP=STOP+START+1
    for view in open("HelpFiles/Image.help", "r").readlines():
        cnt=cnt+1        
        line=view.replace("\n","")
        if cnt>START and cnt<STOP:
                print(cnt,line)
                
                
ReadLines(729,30)                



# To get the directory source of a module
import inspect
#load the module
from PIL import Image
#run inspect.getfile on the module
print(inspect.getfile(Image))

# Example without comments
import os
import inspect
from mpl_toolkits.basemap import Basemap
print(inspect.getfile(Basemap))

# send python help() output to a file
import sys, os
import os.path
# Create target Directory if don't exist
dirName="HelpFiles/"
if not os.path.exists(dirName):
    os.mkdir(dirName)
else:    
    print("Directory " , dirName ,  " already exists")
# import the module if required
# request help in line 25
from PIL import Image
#Create a name for the file (no extension) usually the same as the imported module
NAME="Image"
filename = dirName+NAME+'.help'
if os.path.isfile(filename):
    print ("File exist:",filename)
    
else:
    with open(filename,"w") as helper:
        t = sys.stdout
        sys.stdout = helper
        # line 25 request the help with the Python help command
        #
        help(Image)
        sys.stdout = t
print(filename)        

%%writefile FileSearch.py
#!/usr/bin/env -m python
#Searches a file enter search term and filename
#Range is to give context before and after the search term.
#It defaults to eight lines before the word and eight lines after.
#USAGE:
#from FileSearch import filesearch                
#search ="urcrnrlat"
#filename = "basemap.help"
#filesearch(search,filename,Range=2)
def filesearch(search,filename, Range=8):
    cnt=0
    oldcount = -8
    INDEX = []
    for view in open(filename, "r").readlines():
        cnt=cnt+1
        view=view.replace("\n","")
        if search in view:
            if cnt>oldcount:
                INDEX.append([search,cnt-Range,cnt+Range])
                oldcount=cnt+(Range*2)
    cnt=0
    cnt0=0
    for view in open(filename, "r").readlines():
            cnt=cnt+1
            line=view.replace("\n","")
            for content in INDEX:
                if cnt > int(content[1]) and cnt < int(content[2]):
                    if search not in line:print(cnt,line)
                    if cnt==int(content[2]-1):print("-----------")  
                    if search in line:print("\nSEARCHTERM>> ",cnt,line,"\n") 

#!rm HelpFiles/*.help

!ls HelpFiles

from FileSearch import filesearch                
search ="resize"
filename = "HelpFiles/Image.help"
#filesearch(search,filename,Range=2)
filesearch(search,filename, Range=4)


def ReadLines(START, STOP=20):
    cnt=0
    STOP=STOP+START+1
    for view in open("HelpFiles/Image.help", "r").readlines():
        cnt=cnt+1        
        line=view.replace("\n","")
        if cnt>START and cnt<STOP:
                print(cnt,line)
                
                
ReadLines(729,30)                

%matplotlib inline
import matplotlib.pyplot as plt
figure = plt.gcf()


figure.set_size_inches(8, 6)

plt.savefig("sample.png", dpi=100)
plt.show()

%matplotlib inline
import matplotlib.pyplot as plt
from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon
import numpy as np
from PIL import Image,ImageFont,ImageDraw,ImageFilter,ImageChops
from random import randint
from mpl_toolkits.basemap import Basemap
#prevents a warning from using Python3 instaead of Python2
import warnings
warnings.filterwarnings("ignore")
import sys
sys.path.insert(1, "/home/jack/hidden")
import Key
import twython
from twython import Twython

#pick a random 'contiguous' state 
def RndState():
    TX=["Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming"]
    x=randint(1,49)
    return TX[x]
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/05-02-2020.csv"
#LASTFILE="csse_covid_19_data/csse_covid_19_daily_reports/03-30-2020.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
LATd=[]
LONGd=[]
STATES=[]
cases=[]
deaths =[]
longitude = ""
search = RndState()
for line in DataIn:
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    if search in line[2] and "-" in (line[6]):
        text=line[2],line[1],line[3],line[4],line[5],line[6],line[7],line[8],line[9],line[10]
        STATES.append(text)
        LAT.append(line[5])
        LONG.append(line[6])
        if int(line[8])>0:
            LATd.append(line[5])
            LONGd.append(line[6])        
        cases.append(line[7])
        deaths.append(line[8])
        longitude = longitude+line[6]+","
print(len(STATES))        
LT = np.array(LAT,dtype=np.float)
LG = np.array(LONG,dtype=np.float)
LTd = np.array(LATd,dtype=np.float)
LGd = np.array(LONGd,dtype=np.float)


fig = plt.figure(num=None, figsize=(10,8), dpi=80, facecolor='salmon')
from US_State_Bounding_Boxes import GetCOOR # get coordinates for state(box)
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings("ignore")


fig = plt.figure(num=None, figsize=(12,10), dpi=80, facecolor='salmon')
coor= GetCOOR(search)
urcrnrlat = coor[0]+.5
llcrnrlat = coor[1]-.5
urcrnrlon = coor[2]+.5
llcrnrlon = coor[3]-.5

lat_0 = (urcrnrlat+llcrnrlat)/2
lon_0 =(urcrnrlon+llcrnrlon)/2
print(lat_0/lon_0)
# create the map object, m
m = Basemap(resolution='f', projection='cyl', \
    llcrnrlon=llcrnrlon, llcrnrlat=llcrnrlat, urcrnrlon=urcrnrlon, urcrnrlat=urcrnrlat)

# Note: You can define the resolution of the map you just created. Higher 
# resolutions take longer to create.
#    'c' - crude
#    'l' - low
#    'i' - intermediate
#    'h' - high
#    'f' - full

# Draw some map elements on the map
m.drawcoastlines()
m.drawstates()
m.drawcountries()
m.drawrivers(color='blue')

# Drawing ArcGIS Basemap (only works with cylc projections??)
# Examples of what each map looks like can be found here:
# http://kbkb-wx-python.blogspot.com/2016/04/python-basemap-background-image-from.html
maps = ['ESRI_Imagery_World_2D',    # 0
        'ESRI_StreetMap_World_2D',  # 1
        'NatGeo_World_Map',         # 2
        'NGS_Topo_US_2D',           # 3
        'Ocean_Basemap',            # 4
        'USA_Topo_Maps',            # 5
        'World_Imagery',            # 6
        'World_Physical_Map',       # 7
        'World_Shaded_Relief',      # 8
        'World_Street_Map',         # 9
        'World_Terrain_Base',       # 10
        'World_Topo_Map'            # 11
        ]
print ("drawing image from arcGIS server..."),
# Beautiful Map -- m.arcgisimage(service=maps[2], xpixels=1000, verbose=False)
# Very N              -- m.arcgisimage(service=maps[7], xpixels=2000, verbose=True)
# okay not Great   m.arcgisimage(service=maps[10], xpixels=3500, verbose=True)
# okay not Great   m.arcgisimage(service=maps[8], xpixels=3500, verbose=True)
# 3 failed
#m.arcgisimage(service=maps[8], xpixels=1000, verbose=False)
MAP=7
m.arcgisimage(service=maps[MAP], xpixels=3500, verbose=True)
print ("...finished")

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.5)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

Sd=0
Sized=[]
for xd in deaths:
    Sd=0+(float(xd))
    Sized.append(int(Sd))
    #print(int(S))
sd = np.array(Sized)
#print(Sized)
plt.title("COVID-19:\n Cases: (black)\n Deaths(red) \n Location:\n "+search+"\n", fontsize=10, loc='right')
#plt.text(max(LG-1.2),max(LT), search, color='white', fontsize=24)
#x, y = m(lons, lats)  # transform coordinates
x, y = m(LGd, LTd)
xx,yy = m(LG, LT)
plt.xlabel('Longitude')
plt.ylabel('Latitute')

m.scatter(xx, yy, s=s, color='black', zorder=5, alpha=0.6)
m.scatter(x, y, s=sd, color='r', zorder=10,  alpha=0.6)



#plt.scatter(x, y,  s=s, color="black", zorder=3, alpha=0.6)
#plt.scatter(x, y,  s=sd, color="red", zorder=6, alpha=0.6)
#plt.text(urcrnrlon,urcrnrlat, search, color='white', fontsize=24)
plt.savefig("BaseMap/"+search+"arcGIS__.png", dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)
#plt.show()
# Plot a scatter point at WBB on the map object
#lon = -111.85
#lat = 40.77
#m.scatter(lon,lat,c='r',s=150)

# Plot some wind barbs
#lons = np.arange(-115,-100,.5)
#lats = np.arange(33,48,.5)
#u = np.arange(-5,10,.5)
#v = np.arange(5,20,.5)
#m.barbs(lons, lats, u, v, color='fuchsia')

# Plot line between two points
# (can also use greatcircle function to be more accurate)
#x = [-110, -112]
#y = [40, 42]
#m.plot(x, y, color='navy', lw=5)

# Fill two polygon shapes
#patches = []
#homeplate = np.array([[-114,38],[-113,37],[-112,38],[-112,40],[-114,40]])
#patches.append(Polygon(homeplate))
#triangle = np.array([[-111,38],[-110,37],[-110,42]])
#patches.append(Polygon(triangle))
#ax.add_collection(PatchCollection(patches, facecolor='lightgreen', edgecolor='k', linewidths=1.5))

# Plot shapefiles: see here: http://basemaptutorial.readthedocs.io/en/latest/shapefile.html

# Plot contours
#m.contour(lons2D, lats2D, values2D)  # contour lines
# m.contourf(lons2D, lats2D, values2D) # contour color filled, can specify a cmap

# Plot gridded data
# m.pcolormesh(lons2D, lats2D, values2D) # can specify a cmap

# Add plot title and other plot elements the normal way
filename0 = "BaseMap/"+search+"arcGIS__.png"


def draw_blurred_back(img, position, text, font, col, halo_col):
    halo = Image.new('RGBA', img.size, (0, 0, 0, 0))
    ImageDraw.Draw(halo).text(position, text, font = font, fill = halo_col)
    blurred_halo = halo.filter(ImageFilter.BLUR)
    ImageDraw.Draw(blurred_halo).text(position, text, font = font, fill = col)
    return Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))

if __name__ == '__main__':
    
    basewidth = 720
    inp = Image.open(filename0)
    wpercent = (basewidth / float(inp.size[0]))
    hsize = int((float(inp.size[1]) * float(wpercent)))
    inp = inp.resize((basewidth, hsize), Image.ANTIALIAS)
    #img.save(resized_image.jpg')
    
    #inp = inp.resize((640,640), Image.ANTIALIAS)
    font = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 30)
    text_title = (255, 255,230) # bright green
    blur_title = (0, 0, 0)   # black

    i2 = draw_blurred_back(inp, (25, 25), "Plotting COVID-19 Data", font, text_title, blur_title)
    font0 = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 20)
    font1 = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 14)
    font2 = ImageFont.truetype("/home/jack/fonts/PatrickHand-Regular.ttf", 16)
    i2 = draw_blurred_back(i2, (25, 60), "Plot Using ArcGIS Basemap - "+search+"Map Type:"+str(MAP), font0, text_title, blur_title)
    TXT="https://gist.github.com/JupyterJones/c2fa42e8f78b943b64f7d7a4e4721c58"
    draw = ImageDraw.Draw(i2) 
    draw.text((25, 5), TXT, font = font2, align ="left",fill="black")
    #i2 = draw(i2, (15, 65),TXT, font1)    
    
    #txt = Image.new('RGBA', i.size, (255,255,255,0))

    # get a font
    fnt = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 20)
    # get a drawing context
    signature_ = "@jacklnorthrup" 
    #get length in pixel of signature_
    sizeS,ln = fnt.getsize(signature_)
    #add 15 pixels to right border
    pt = sizeS+25
    width, height = inp.size
    #marginx starting point of signature_
    marginx = pt
    #bottom margin
    marginy = 30
    x = width - marginx
    y = height - marginy
    

    text_sig = (255, 255,230) # bright green
    blur_sig = (0, 0, 0)   # black
    txt=draw_blurred_back(i2,(x,y), signature_, fnt, text_sig, blur_sig)
    out = Image.alpha_composite(i2, txt)
    out.save("images/"+search+"-"+str(MAP)+"-TEMP_POSTf.png")

CONSUMER_KEY = Key.twiter()[0]
CONSUMER_SECRET = Key.twiter()[1]
ACCESS_KEY = Key.twiter()[2]
ACCESS_SECRET = Key.twiter()[3]
twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)

STR = "#"+search+"  #arcGIS server #Basemap #COVID-19 - #Python  Plot data using "+TXT+" #JupyterJones Python2 seems to make very attractive maps" 

PATH = "images/"+search+"-"+str(MAP)+"-TEMP_POSTf.png"
photo = open(PATH,'rb')
#response = twitter.upload_media(media=photo)
#twitter.update_status(status=STR, media_ids=[response['media_id']])

from PIL import Image
IM =Image.open(PATH)
print IM.size
IM

from PIL import Image
IM =Image.open(PATH)
IM

import numpy as np
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
from matplotlib.animation import FFMpegWriter

# Fixing random state for reproducibility
np.random.seed(19680801)


metadata = dict(title='Movie Test', artist='Matplotlib',
                comment='Movie support!')
writer = FFMpegWriter(fps=15, metadata=metadata)

fig = plt.figure()
l, = plt.plot([], [], 'k-o')

plt.xlim(-15, 15)
plt.ylim(-15, 15)

x0, y0 = 0, 0

with writer.saving(fig, "writer_test.mp4", 100):
    for i in range(500):
        x0 += 0.02 * np.random.randn()
        y0 += 0.02 * np.random.randn()
        l.set_data(x0, y0)
        writer.grab_frame()

from IPython.display import HTML

HTML("""
    <video alt="test" controls>
        <source src="writer_test.mp4" type="video/mp4">
    </video>
""")

import Basemap

!locate Basemap



import matplotlib.pyplot as plt
import matplotlib.colors as mcolors


def plot_colortable(colors, title, sort_colors=True, emptycols=0):

    cell_width = 212
    cell_height = 22
    swatch_width = 48
    margin = 12
    topmargin = 40

    # Sort colors by hue, saturation, value and name.
    if sort_colors is True:
        by_hsv = sorted((tuple(mcolors.rgb_to_hsv(mcolors.to_rgb(color))),
                         name)
                        for name, color in colors.items())
        names = [name for hsv, name in by_hsv]
    else:
        names = list(colors)

    n = len(names)
    ncols = 4 - emptycols
    nrows = n // ncols + int(n % ncols > 0)

    width = cell_width * 4 + 2 * margin
    height = cell_height * nrows + margin + topmargin
    dpi = 72

    fig, ax = plt.subplots(figsize=(width / dpi, height / dpi), dpi=dpi)
    fig.subplots_adjust(margin/width, margin/height,
                        (width-margin)/width, (height-topmargin)/height)
    ax.set_xlim(0, cell_width * 4)
    ax.set_ylim(cell_height * (nrows-0.5), -cell_height/2.)
    ax.yaxis.set_visible(False)
    ax.xaxis.set_visible(False)
    ax.set_axis_off()
    ax.set_title(title, fontsize=24, loc="left", pad=10)

    for i, name in enumerate(names):
        row = i % nrows
        col = i // nrows
        y = row * cell_height

        swatch_start_x = cell_width * col
        swatch_end_x = cell_width * col + swatch_width
        text_pos_x = cell_width * col + swatch_width + 7

        ax.text(text_pos_x, y, name, fontsize=14,
                horizontalalignment='left',
                verticalalignment='center')

        ax.hlines(y, swatch_start_x, swatch_end_x,
                  color=colors[name], linewidth=18)

    return fig

plot_colortable(mcolors.BASE_COLORS, "Base Colors",
                sort_colors=False, emptycols=1)
plot_colortable(mcolors.TABLEAU_COLORS, "Tableau Palette",
                sort_colors=False, emptycols=2)

#sphinx_gallery_thumbnail_number = 3
plot_colortable(mcolors.CSS4_COLORS, "CSS Colors")

# Optionally plot the XKCD colors (Caution: will produce large figure)
#xkcd_fig = plot_colortable(mcolors.XKCD_COLORS, "XKCD Colors")
#xkcd_fig.savefig("XKCD_Colors.png")

plt.show()



import requests as req
URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"
CSSEGIS =[]
resp = req.get(URL)
text = resp.content
data=text.splitlines()
cnt=0
for line in data:
    cnt=cnt+1
    # remove the b' befor the line
    line = line.decode('utf-8')
    line=line.lstrip(",")
    CSSEGIS.append(line)

import plotly.graph_objects as go
import time
from PIL import Image
#SEARCH = input("SEARCH: ")
#SEARCH = "Brazil"
#SEARCH = "Spain"
#SEARCH = "Philippine"
#SEARCH = "Ecuador"
#SEARCH = "Germany"
#SEARCH = "Japan"
SEARCH = "US"
#SEARCH="Mexico"
cnt = 0
CNTS=0
counts=[]
for line in CSSEGIS:
    if cnt==0:print(line)
    cnt=cnt+1
    line=line.lstrip(",")
    #if SEARCH in line:print(line)
    if SEARCH in line:
        line=line.split(",0,0",1)[-1]
        line = "0,0"+line
        print(line)
        entry = line
        entry=entry.split(",")
        for num in entry:
            counts.append(int(num))
            
filename0 = time.strftime("images/"+SEARCH+"_Deaths_%Y%m%d%H%M%S.png")            
fig = go.Figure()
fig.add_trace(go.Scatter(y=counts))
fig.add_trace(go.Bar(y=counts))
fig.update_layout(title = SEARCH+' CONDID-19 Deaths')
fig.show() 



IncreasePerDay=[]
All = (len(counts))
for x in range(0,All):
    try:
        Sum = (counts[x+1]-counts[x])
        print(Sum, end = " ")
        IncreasePerDay.append(Sum)
    except:
        pass
    
filename1 = time.strftime("images/"+SEARCH+"_IncreasePerDay"+"_%Y%m%d%H%M%S.png")
fig = go.Figure()
fig.add_trace(go.Scatter(y=IncreasePerDay))
fig.add_trace(go.Bar(y=IncreasePerDay))
fig.update_layout(title = SEARCH+' Increase Each day CONDID-19 Cases')
fig.show() 


import plotly.graph_objects as go
import time
from PIL import Image

import requests as req
URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"
CSSEGIS =[]
resp = req.get(URL)
text = resp.content
data=text.splitlines()
cnt=0
for line in data:
    cnt=cnt+1
    # remove the b' befor the line
    line = line.decode('utf-8')
    line=line.lstrip(",")
    CSSEGIS.append(line)

#SEARCH = input("SEARCH: ")
#SEARCH = "Brazil"
#SEARCH = "Spain"
SEARCH = "Philippine"
#SEARCH = "Ecuador"
#SEARCH = "Germany"
#SEARCH = "Japan"
#SEARCH = "US"
SEARCH="Mexico"
cnt = 0
CNTS=0
counts=[]
for line in CSSEGIS:
    if cnt==0:print(line)
    cnt=cnt+1
    line=line.lstrip(",")
    #if SEARCH in line:print(line)
    if SEARCH in line:
        line=line.split(",0,0",1)[-1]
        line = "0,0"+line
        print(line)
        entry = line
        entry=entry.split(",")
        for num in entry:
            counts.append(int(num))
            
filename0 = time.strftime("images/"+SEARCH+"_"+STAT+"Deaths_%Y%m%d%H%M%S.png")            
fig = go.Figure()
fig.add_trace(go.Scatter(y=counts))
fig.add_trace(go.Bar(y=counts))
fig.update_layout(title = SEARCH+' CONDID-19 Deaths')
fig.show() 



IncreasePerDay=[]
All = (len(counts))
for x in range(0,All):
    try:
        Sum = (counts[x+1]-counts[x])
        print(Sum, end = " ")
        IncreasePerDay.append(Sum)
    except:
        pass
    
filename1 = time.strftime("images/"+SEARCH+"_"+STAT+"IncreasePerDay"+"_%Y%m%d%H%M%S.png")
fig = go.Figure()
fig.add_trace(go.Scatter(y=IncreasePerDay))
fig.add_trace(go.Bar(y=IncreasePerDay))
fig.update_layout(title = SEARCH+' Increase Each day CONDID-19 Cases')
fig.show() 

import requests as req
import time
from datetime import datetime
from datetime import date, timedelta
yesterday = datetime.utcnow() - timedelta(days=2)
YesterdaysGMT=yesterday.strftime('%m-%d-%Y')

import requests as req
URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"
CSSEGIS =[]
resp = req.get(URL)
text = resp.content
filename="csv/"+URL.split("/")[-1]
TEMP = open(filename,"wb")
TEMP.write(text)
TEMP.close()
print(filename)

import plotly.graph_objects as go
import time
from PIL import Image

LASTFILE="csv/time_series_covid19_deaths_global.csv"


STAT =LASTFILE[57:-4]
DataIn = open(LASTFILE).readlines()

#SEARCH = input("SEARCH: ")
#SEARCH = "Brazil"
#SEARCH = "Spain"
#SEARCH = "Philippine"
#SEARCH = "Ecuador"
SEARCH = "Germany"
#SEARCH = "Japan"
#SEARCH = "US"
cnt = 0
CNTS=0
counts=[]
for line in DataIn:
    if cnt==0:print(line)
    cnt=cnt+1
    line=line.lstrip(",")
    #if SEARCH in line:print(line)
    if SEARCH in line:
        line=line.split(",0,0",1)[-1]
        line = "0,0"+line
        print(line)
        entry = line
        entry=entry.split(",")
        for num in entry:
            counts.append(int(num))
            
filename0 = time.strftime("images/"+SEARCH+"_"+STAT+"Deaths_%Y%m%d%H%M%S.png")            
fig = go.Figure()
fig.add_trace(go.Scatter(y=counts))
fig.add_trace(go.Bar(y=counts))
fig.update_layout(title = SEARCH+' CONDID-19 Deaths')
fig.show() 



IncreasePerDay=[]
All = (len(counts))
for x in range(0,All):
    try:
        Sum = (counts[x+1]-counts[x])
        print(Sum, end = " ")
        IncreasePerDay.append(Sum)
    except:
        pass
    
filename1 = time.strftime("images/"+SEARCH+"_"+STAT+"IncreasePerDay"+"_%Y%m%d%H%M%S.png")
fig = go.Figure()
fig.add_trace(go.Scatter(y=IncreasePerDay))
fig.add_trace(go.Bar(y=IncreasePerDay))
fig.update_layout(title = SEARCH+' Increase Each day CONDID-19 Cases')
fig.show() 

data="Ecuador,-1.8312,-78.1834,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,3,5,7,14,18,27,28,34,36,48,58,60,75,93,120,145,172,180,191,191,242,272,297,315,333,355,369,388,403,421,456,474,507,520,537,560,576,576"

data=data.split(",0,0",1)[-1]
print ("0,0"+data)



import requests as req
URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"
CSSEGIS =[]
resp = req.get(URL)
text = resp.content
data=text.splitlines()
cnt=0
for line in data:
    cnt=cnt+1
    # remove the b' befor the line
    line = line.decode('utf-8')
    line=line.lstrip(",")
    CSSEGIS.append(line)

import plotly.graph_objects as go
import time
from PIL import Image
#SEARCH = input("SEARCH: ")
#SEARCH = "Brazil"
#SEARCH = "Spain"
#SEARCH = "Philippine"
#SEARCH = "Ecuador"
#SEARCH = "Germany"
#SEARCH = "Japan"
SEARCH = "US"
#SEARCH="Mexico"
cnt = 0
CNTS=0
counts=[]
for line in CSSEGIS:
    if cnt==0:print(line)
    cnt=cnt+1
    line=line.lstrip(",")
    #if SEARCH in line:print(line)
    if SEARCH in line:
        line=line.split(",0,0",1)[-1]
        line = "0,0"+line
        print(line)
        entry = line
        entry=entry.split(",")
        for num in entry:
            counts.append(int(num))
            
filename0 = time.strftime("images/"+SEARCH+"_Deaths_%Y%m%d%H%M%S.png")            
fig = go.Figure()
fig.add_trace(go.Scatter(y=counts))
fig.add_trace(go.Bar(y=counts))
fig.update_layout(title = SEARCH+' CONDID-19 Deaths')
fig.show() 



IncreasePerDay=[]
All = (len(counts))
for x in range(0,All):
    try:
        Sum = (counts[x+1]-counts[x])
        print(Sum, end = " ")
        IncreasePerDay.append(Sum)
    except:
        pass
    
filename1 = time.strftime("images/"+SEARCH+"_IncreasePerDay"+"_%Y%m%d%H%M%S.png")
fig = go.Figure()
fig.add_trace(go.Scatter(y=IncreasePerDay))
fig.add_trace(go.Bar(y=IncreasePerDay))
fig.update_layout(title = SEARCH+' Increase Each day CONDID-19 Cases')
fig.show() 


import plotly.graph_objects as go
import time
from PIL import Image

import requests as req
URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"
CSSEGIS =[]
resp = req.get(URL)
text = resp.content
data=text.splitlines()
cnt=0
for line in data:
    cnt=cnt+1
    # remove the b' befor the line
    line = line.decode('utf-8')
    line=line.lstrip(",")
    CSSEGIS.append(line)

#SEARCH = input("SEARCH: ")
#SEARCH = "Brazil"
#SEARCH = "Spain"
SEARCH = "Philippine"
#SEARCH = "Ecuador"
#SEARCH = "Germany"
#SEARCH = "Japan"
#SEARCH = "US"
#SEARCH="Mexico"
cnt = 0
CNTS=0
counts=[]
for line in CSSEGIS:
    if cnt==0:print(line)
    cnt=cnt+1
    line=line.lstrip(",")
    #if SEARCH in line:print(line)
    if SEARCH in line:
        line=line.split(",0,0",1)[-1]
        line = "0,0"+line
        print(line)
        entry = line
        entry=entry.split(",")
        for num in entry:
            counts.append(int(num))
            
filename0 = time.strftime("images/"+SEARCH+"_Deaths_%Y%m%d%H%M%S.png")            
fig = go.Figure()
fig.add_trace(go.Scatter(y=counts))
fig.add_trace(go.Bar(y=counts))
fig.update_layout(title = SEARCH+' CONDID-19 Deaths')
fig.show() 



IncreasePerDay=[]
All = (len(counts))
for x in range(0,All):
    try:
        Sum = (counts[x+1]-counts[x])
        print(Sum, end = " ")
        IncreasePerDay.append(Sum)
    except:
        pass
    
filename1 = time.strftime("images/"+SEARCH+"_IncreasePerDay"+"_%Y%m%d%H%M%S.png")
fig = go.Figure()
fig.add_trace(go.Scatter(y=IncreasePerDay))
fig.add_trace(go.Bar(y=IncreasePerDay))
fig.update_layout(title = SEARCH+' Increase Each day CONDID-19 Cases')
fig.show() 

import requests as req
import time
from datetime import datetime
from datetime import date, timedelta
yesterday = datetime.utcnow() - timedelta(days=2)
YesterdaysGMT=yesterday.strftime('%m-%d-%Y')

import requests as req
URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"
CSSEGIS =[]
resp = req.get(URL)
text = resp.content
filename="csv/"+URL.split("/")[-1]
TEMP = open(filename,"wb")
TEMP.write(text)
TEMP.close()
print(filename)

import plotly.graph_objects as go
import time
from PIL import Image

LASTFILE="csv/time_series_covid19_deaths_global.csv"


STAT =LASTFILE[57:-4]
DataIn = open(LASTFILE).readlines()

#SEARCH = input("SEARCH: ")
#SEARCH = "Brazil"
#SEARCH = "Spain"
#SEARCH = "Philippine"
#SEARCH = "Ecuador"
SEARCH = "Germany"
#SEARCH = "Japan"
#SEARCH = "US"
cnt = 0
CNTS=0
counts=[]
for line in DataIn:
    if cnt==0:print(line)
    cnt=cnt+1
    line=line.lstrip(",")
    #if SEARCH in line:print(line)
    if SEARCH in line:
        line=line.split(",0,0",1)[-1]
        line = "0,0"+line
        print(line)
        entry = line
        entry=entry.split(",")
        for num in entry:
            counts.append(int(num))
            
filename0 = time.strftime("images/"+SEARCH+"_"+STAT+"Deaths_%Y%m%d%H%M%S.png")            
fig = go.Figure()
fig.add_trace(go.Scatter(y=counts))
fig.add_trace(go.Bar(y=counts))
fig.update_layout(title = SEARCH+' CONDID-19 Deaths')
fig.show() 



IncreasePerDay=[]
All = (len(counts))
for x in range(0,All):
    try:
        Sum = (counts[x+1]-counts[x])
        print(Sum, end = " ")
        IncreasePerDay.append(Sum)
    except:
        pass
    
filename1 = time.strftime("images/"+SEARCH+"_"+STAT+"IncreasePerDay"+"_%Y%m%d%H%M%S.png")
fig = go.Figure()
fig.add_trace(go.Scatter(y=IncreasePerDay))
fig.add_trace(go.Bar(y=IncreasePerDay))
fig.update_layout(title = SEARCH+' Increase Each day CONDID-19 Cases')
fig.show() 

data="Ecuador,-1.8312,-78.1834,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,3,5,7,14,18,27,28,34,36,48,58,60,75,93,120,145,172,180,191,191,242,272,297,315,333,355,369,388,403,421,456,474,507,520,537,560,576,576"

data=data.split(",0,0",1)[-1]
print ("0,0"+data)



jt -l

# %load /home/jack/.jupyter/custom/custom.css
div#notebook {
 font-family: sans-serif;
 font-size: 13pt;
 line-height: 170%;
 color: #3c3836;
 -webkit-font-smoothing: antialiased !important;
 padding-top: 25px !important;
}
body,
div.body {
 font-family: sans-serif;
 font-size: 13pt;
 color: #3c3836;
 background-color: #ebdbb2;
 background: #ebdbb2;
 background-image: url("endless-constellation.svg");
 -webkit-font-smoothing: antialiased !important;
}
body.notebook_app {
 padding: 0;
 background-color: #ebdbb2;
 background: #ebdbb2;
 padding-right: 0px !important;
 overflow-y: hidden;
}
a {
 font-family: sans-serif;
 color: #3c3836;
 -webkit-font-smoothing: antialiased !important;
}
a:hover,
a:focus {
 color: #1d2021;
 -webkit-font-smoothing: antialiased !important;
}
div#maintoolbar {
 position: absolute;
 width: 90%;
 margin-left: -10%;
 padding-right: 8%;
 float: left;
 background: transparent !important;
}
#maintoolbar {
 margin-bottom: -3px;
 margin-top: 0px;
 border: 0px;
 min-height: 27px;
 padding-top: 2px;
 padding-bottom: 0px;
}
#maintoolbar .container {
 width: 75%;
 margin-right: auto;
 margin-left: auto;
}
.list_header,
div#notebook_list_header.row.list_header {
 font-size: 14pt;
 color: #1d2021;
 background-color: transparent;
 height: 35px;
}
i.fa.fa-folder {
 display: inline-block;
 font: normal normal normal 14px "FontAwesome";
 font-family: "FontAwesome" !important;
 text-rendering: auto;
 -webkit-font-smoothing: antialiased;
 font-size: 18px;
 -moz-osx-font-smoothing: grayscale;
}
#running .panel-group .panel .panel-heading {
 font-size: 14pt;
 color: #3c3836;
 padding: 8px 8px;
 background: #ead9ae;
 background-color: #ead9ae;
}
#running .panel-group .panel .panel-heading a {
 font-size: 14pt;
 color: #3c3836;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
 font-size: 14pt;
 color: #3c3836;
}
#running .panel-group .panel .panel-body .list_container .list_item {
 background: #fbf1c7;
 background-color: #fbf1c7;
 padding: 2px;
 border-bottom: 2px solid #e6d29e;
}
#running .panel-group .panel .panel-body .list_container .list_item:hover {
 background: #fbf1c7;
 background-color: #fbf1c7;
}
#running .panel-group .panel .panel-body {
 padding: 2px;
}
button#refresh_running_list {
 border: none !important;
}
button#refresh_cluster_list {
 border: none !important;
}
div.running_list_info.toolbar_info {
 font-size: 15px;
 padding: 4px 0 4px 0;
 margin-top: 5px;
 margin-bottom: 8px;
 height: 24px;
 line-height: 24px;
 text-shadow: none;
}
.list_placeholder {
 font-weight: normal;
}
#tree-selector {
 padding: 0px;
 border-color: transparent;
}
#project_name > ul > li > a > i.fa.fa-home {
 color: #3c3836;
 font-size: 17pt;
 display: inline-block;
 position: static;
 padding: 0px 0px;
 font-weight: normal;
 text-align: center;
 vertical-align: text-top;
}
.fa-folder:before {
 color: #458588;
}
.fa-arrow-up:before {
 font-size: 14px;
}
.fa-arrow-down:before {
 font-size: 14px;
}
span#last-modified.btn.btn-xs.btn-default.sort-action:hover .fa,
span#sort-name.btn.btn-xs.btn-default.sort-action:hover .fa {
 color: #d65d0e;
}
.folder_icon:before {
 display: inline-block;
 font: normal normal normal 14px/1 FontAwesome;
 font-size: inherit;
 text-rendering: auto;
 -webkit-font-smoothing: antialiased;
 -moz-osx-font-smoothing: grayscale;
 content: "\f07b";
 color: #458588;
}
.notebook_icon:before {
 display: inline-block;
 font: normal normal normal 14px/1 FontAwesome;
 font-size: inherit;
 text-rendering: auto;
 -webkit-font-smoothing: antialiased;
 -moz-osx-font-smoothing: grayscale;
 content: "\f02d";
 position: relative;
 color: #98971a !important;
 top: 0px;
}
.file_icon:before {
 display: inline-block;
 font: normal normal normal 14px/1 FontAwesome;
 font-size: inherit;
 text-rendering: auto;
 -webkit-font-smoothing: antialiased;
 -moz-osx-font-smoothing: grayscale;
 content: "\f15b";
 position: relative;
 top: 0px;
 color: #3c3836 !important;
}
#project_name a {
 display: inline-flex;
 padding-left: 7px;
 margin-left: -2px;
 text-align: -webkit-auto;
 vertical-align: baseline;
 font-size: 18px;
}
div#notebook_toolbar div.dynamic-instructions {
 font-family: sans-serif;
 font-size: 17px;
 color: #b5a586;
}
span#login_widget > .button,
#logout {
 font-family: "Proxima Nova", sans-serif;
 color: #3c3836;
 background: transparent;
 background-color: transparent;
 border: 2px solid rgba(185,165,113,.5);
 font-weight: normal;
 box-shadow: none;
 text-shadow: none;
 border-radius: 3px;
 margin-right: 10px;
 padding: 2px 7px;
}
span#login_widget > .button:hover,
#logout:hover {
 color: #d65d0e;
 background-color: transparent;
 background: transparent;
 border: 2px solid #d65d0e;
 background-image: none;
 box-shadow: none !important;
 border-radius: 3px;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus,
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
 color: #d65d0e;
 background-color: #3c3836;
 background: #3c3836;
 border-color: #3c3836;
 background-image: none;
 box-shadow: none !important;
 border-radius: 2px;
}
body > #header #header-container {
 padding-bottom: 0px;
 padding-top: 4px;
 box-sizing: border-box;
 -moz-box-sizing: border-box;
 -webkit-box-sizing: border-box;
}
body > #header {
 background: #ebdbb2;
 background-color: #ebdbb2;
 position: relative;
 z-index: 100;
}
.list_container {
 font-size: 13pt;
 color: #3c3836;
 border: none;
 text-shadow: none !important;
}
.list_container > div {
 border-bottom: 1px solid rgba(185,165,113,.3);
 font-size: 13pt;
}
.list_header > div,
.list_item > div {
 padding-top: 6px;
 padding-bottom: 2px;
 padding-left: 0px;
}
.list_header > div .item_link,
.list_item > div .item_link {
 margin-left: -1px;
 vertical-align: middle;
 line-height: 22px;
 font-size: 13pt;
}
.item_icon {
 color: #458588;
 font-size: 13pt;
 vertical-align: middle;
}
.list_item input:not([type="checkbox"]) {
 padding-right: 0px;
 height: 1.75em;
 width: 25%;
 margin: 0px 0 0;
 margin-top: 0px;
}
.list_header > div .item_link,
.list_item > div .item_link {
 margin-left: -1px;
 vertical-align: middle;
 line-height: 1.5em;
 font-size: 12pt;
 display: inline-table;
 position: static;
}
#button-select-all {
 height: 34px;
 min-width: 55px;
 z-index: 0;
 border: none !important;
 padding-top: 0px;
 padding-bottom: 0px;
 margin-bottom: 0px;
 margin-top: 0px;
 left: -3px;
 border-radius: 0px !important;
}
#button-select-all:focus,
#button-select-all:active:focus,
#button-select-all.active:focus,
#button-select-all.focus,
#button-select-all:active.focus,
#button-select-all.active.focus {
 background-color: rgba(185,165,113,.5) !important;
 background: rgba(185,165,113,.5) !important;
}
button#tree-selector-btn {
 height: 34px;
 font-size: 12.0pt;
 border: none;
 left: 0px;
 border-radius: 0px !important;
}
input#select-all.pull-left.tree-selector {
 margin-left: 7px;
 margin-right: 2px;
 margin-top: 2px;
 top: 4px;
}
input[type="radio"],
input[type="checkbox"] {
 margin-top: 1px;
 line-height: normal;
}
.delete-button {
 border: none !important;
}
i.fa.fa-trash {
 font-size: 13.5pt;
}
.list_container a {
 font-size: 16px;
 color: #3c3836;
 border: none;
 text-shadow: none !important;
 font-weight: normal;
 font-style: normal;
}
div.list_container a:hover {
 color: #1d2021;
}
.list_header > div input,
.list_item > div input {
 margin-right: 7px;
 margin-left: 12px;
 vertical-align: baseline;
 line-height: 22px;
 position: relative;
 top: -1px;
}
div.list_item:hover {
 background-color: rgba(185,165,113,.1);
}
.breadcrumb > li {
 font-size: 12.0pt;
 color: #3c3836;
 border: none;
 text-shadow: none !important;
}
.breadcrumb > li + li:before {
 content: "/\00a0";
 padding: 0px;
 color: #3c3836;
 font-size: 18px;
}
#project_name > .breadcrumb {
 padding: 0px;
 margin-bottom: 0px;
 background-color: transparent;
 font-weight: normal;
 margin-top: -2px;
}
ul#tabs a {
 font-family: sans-serif;
 font-size: 13.5pt;
 font-weight: normal;
 font-style: normal;
 text-shadow: none !important;
}
.nav-tabs {
 font-family: sans-serif;
 font-size: 13.5pt;
 font-weight: normal;
 font-style: normal;
 background-color: transparent;
 border-color: transparent;
 text-shadow: none !important;
 border: 2px solid transparent;
}
.nav-tabs > li > a:active,
.nav-tabs > li > a:focus,
.nav-tabs > li > a:hover,
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:focus,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
 color: #d65d0e;
 background-color: transparent;
 border-color: transparent;
 border-bottom: 2px solid transparent;
}
.nav > li.disabled > a,
.nav > li.disabled > a:hover {
 color: #b5a586;
}
.nav-tabs > li > a:before {
 content: "";
 position: absolute;
 width: 100%;
 height: 2px;
 bottom: -2px;
 left: 0;
 background-color: #d65d0e;
 visibility: hidden;
 -webkit-transform: perspective(0)scaleX(0);
 transform: perspective(0)scaleX(0);
 -webkit-transition: ease 220ms;
 transition: ease 220ms;
 -webkit-font-smoothing: antialiased !important;
}
.nav-tabs > li > a:hover:before {
 visibility: visible;
 -webkit-transform: perspective(1)scaleX(1);
 transform: perspective(1)scaleX(1);
}
.nav-tabs > li.active > a:before {
 content: "";
 position: absolute;
 width: 100%;
 height: 2px;
 bottom: -2px;
 left: 0;
 background-color: #d65d0e;
 visibility: visible;
 -webkit-transform: perspective(1)scaleX(1);
 transform: perspective(1)scaleX(1);
 -webkit-font-smoothing: subpixel-antialiased !important;
}
div#notebook {
 font-family: sans-serif;
 font-size: 13pt;
 padding-top: 4px;
}
.notebook_app {
 background-color: #ebdbb2;
}
#notebook-container {
 padding: 13px 2px;
 background-color: #ebdbb2;
 min-height: 0px;
 box-shadow: none;
 width: 980px;
 margin-right: auto;
 margin-left: auto;
}
div#ipython-main-app.container {
 width: 980px;
 margin-right: auto;
 margin-left: auto;
 margin-right: auto;
 margin-left: auto;
}
.container {
 width: 980px;
 margin-right: auto;
 margin-left: auto;
}
div#menubar-container {
 width: 100%;
 width: 980px;
}
div#header-container {
 width: 980px;
}
.notebook_app #header,
.edit_app #header {
 box-shadow: none !important;
 background-color: #ebdbb2;
 border-bottom: 2px solid rgba(185,165,113,.3);
}
#header,
.edit_app #header {
 font-family: sans-serif;
 font-size: 13pt;
 box-shadow: none;
 background-color: #ebdbb2;
}
#header .header-bar,
.edit_app #header .header-bar {
 background: #ebdbb2;
 background-color: #ebdbb2;
}
body > #header .header-bar {
 width: 100%;
 background: #ebdbb2;
}
span.checkpoint_status,
span.autosave_status {
 font-size: small;
 display: none;
}
#menubar,
div#menubar {
 background-color: #ebdbb2;
 padding-top: 0px !important;
}
#menubar .navbar,
.navbar-default {
 background-color: #ebdbb2;
 margin-bottom: 0px;
 margin-top: 0px;
}
.navbar {
 border: none;
}
div.navbar-text,
.navbar-text,
.navbar-text.indicator_area,
p.navbar-text.indicator_area {
 margin-top: 8px !important;
 margin-bottom: 0px;
 color: #3c3836;
}
.navbar-default {
 font-family: sans-serif;
 font-size: 13pt;
 background-color: #ebdbb2;
 border-color: #e1c98a;
 line-height: 1.5em;
 padding-bottom: 0px;
}
.navbar-default .navbar-nav > li > a {
 font-family: sans-serif;
 font-size: 13pt;
 color: #3c3836;
 display: block;
 line-height: 1.5em;
 padding-top: 14px;
 padding-bottom: 11px;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
 color: #1d2021 !important;
 background-color: rgba(185,165,113,.3) !important;
 border-color: #e1c98a !important;
 line-height: 1.5em;
 transition: 80ms ease;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
 color: #d65d0e;
 background-color: #e6d29e;
 border-color: #e6d29e;
 line-height: 1.5em;
}
.navbar-nav > li > .dropdown-menu {
 margin-top: 0px;
}
.navbar-nav {
 margin: 0;
}
div.notification_widget.info,
.notification_widget.info,
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus,
div#notification_notebook.notification_widget.btn.btn-xs.navbar-btn,
div#notification_notebook.notification_widget.btn.btn-xs.navbar-btn:hover,
div#notification_notebook.notification_widget.btn.btn-xs.navbar-btn:focus {
 color: #3c3836 !important;
 background-color: transparent !important;
 border-color: transparent !important;
 padding-bottom: 0px !important;
 margin-bottom: 0px !important;
 font-size: 9pt !important;
 z-index: 0;
}
div#notification_notebook.notification_widget.btn.btn-xs.navbar-btn {
 font-size: 9pt !important;
 z-index: 0;
}
.notification_widget {
 color: #458588;
 z-index: -500;
 font-size: 9pt;
 background: transparent;
 background-color: transparent;
 margin-right: 3px;
 border: none;
}
.notification_widget,
div.notification_widget {
 margin-right: 0px;
 margin-left: 0px;
 padding-right: 0px;
 vertical-align: text-top !important;
 margin-top: 6px !important;
 background: transparent !important;
 background-color: transparent !important;
 font-size: 9pt !important;
 border: none;
}
.navbar-btn.btn-xs:hover {
 border: none !important;
 background: transparent !important;
 background-color: transparent !important;
 color: #3c3836 !important;
}
div.notification_widget.info,
.notification_widget.info {
 display: none !important;
}
.edit_mode .modal_indicator:before {
 display: none;
}
.command_mode .modal_indicator:before {
 display: none;
}
.item_icon {
 color: #458588;
}
.item_buttons .kernel-name {
 font-size: 13pt;
 color: #458588;
}
.running_notebook_icon:before {
 color: #98971a !important;
 font: normal normal normal 15px/1 FontAwesome;
 font-size: 15px;
 text-rendering: auto;
 -webkit-font-smoothing: antialiased;
 -moz-osx-font-smoothing: grayscale;
 content: "\f10c";
 vertical-align: middle;
 position: static;
 display: inherit;
}
.item_buttons .running-indicator {
 padding-top: 4px;
 color: #98971a;
 font-family: sans-serif;
 text-rendering: auto;
 -webkit-font-smoothing: antialiased;
}
#notification_trusted {
 font-family: sans-serif;
 border: none;
 background: transparent;
 background-color: transparent;
 margin-bottom: 0px !important;
 vertical-align: bottom !important;
 color: #b5a586 !important;
 cursor: default !important;
}
#notification_area,
div.notification_area {
 float: right !important;
 position: static;
 cursor: pointer;
 padding-top: 6px;
 padding-right: 4px;
}
div#notification_notebook.notification_widget.btn.btn-xs.navbar-btn {
 font-size: 9pt !important;
 z-index: 0;
 margin-top: -5px !important;
}
#modal_indicator {
 float: right !important;
 color: #4c8be2;
 background: #ebdbb2;
 background-color: #ebdbb2;
 margin-top: 8px !important;
 margin-left: 0px;
}
#kernel_indicator {
 float: right !important;
 color: #3c3836;
 background: #ebdbb2;
 background-color: #ebdbb2;
 border-left: 2px solid #3c3836;
 padding-top: 0px;
 padding-bottom: 4px;
 margin-top: 10px !important;
 margin-left: -2px;
 padding-left: 5px !important;
}
#kernel_indicator .kernel_indicator_name {
 font-size: 17px;
 color: #3c3836;
 background: #ebdbb2;
 background-color: #ebdbb2;
 padding-left: 5px;
 padding-right: 5px;
 margin-top: 4px;
 vertical-align: text-top;
 padding-bottom: 0px;
}
.kernel_idle_icon:before {
 display: inline-block;
 font: normal normal normal 22px/1 FontAwesome;
 font-size: 22px;
 text-rendering: auto;
 -webkit-font-smoothing: antialiased;
 cursor: pointer;
 margin-left: 0px !important;
 opacity: 0.7;
 vertical-align: bottom;
 margin-top: 1px;
 content: "\f1db";
}
.kernel_busy_icon:before {
 display: inline-block;
 font: normal normal normal 22px/1 FontAwesome;
 font-size: 22px;
 -webkit-animation: pulsate 2s infinite ease-out;
 animation: pulsate 2s infinite ease-out;
 text-rendering: auto;
 -webkit-font-smoothing: antialiased;
 cursor: pointer;
 margin-left: 0px !important;
 vertical-align: bottom;
 margin-top: 1px;
 content: "\f111";
}
@-webkit-keyframes pulsate {
 0% {
  -webkit-transform: scale(1.0,1.0);
  opacity: 0.8;
 }
 8% {
  -webkit-transform: scale(1.0,1.0);
  opacity: 0.8;
 }
 50% {
  -webkit-transform: scale(0.75,0.75);
  opacity: 0.3;
 }
 92% {
  -webkit-transform: scale(1.0,1.0);
  opacity: 0.8;
 }
 100% {
  -webkit-transform: scale(1.0,1.0);
  opacity: 0.8;
 }
}
div.notification_widget.info,
.notification_widget.info,
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus,
div#notification_notebook.notification_widget.btn.btn-xs.navbar-btn,
div#notification_notebook.notification_widget.btn.btn-xs.navbar-btn:hover,
div#notification_notebook.notification_widget.btn.btn-xs.navbar-btn:focus {
 color: #3c3836;
 background-color: #ebdbb2;
 border-color: #ebdbb2;
}
#notification_area,
div.notification_area {
 float: right !important;
 position: static;
}
.notification_widget,
div.notification_widget {
 margin-right: 0px;
 margin-left: 0px;
 padding-right: 0px;
 vertical-align: text-top !important;
 margin-top: 6px !important;
 z-index: 1000;
}
#kernel_logo_widget,
#kernel_logo_widget .current_kernel_logo {
 display: block;
}
div#ipython_notebook {
 display: none;
}
i.fa.fa-icon {
 -webkit-font-smoothing: antialiased;
 -moz-osx-font-smoothing: grayscale;
 text-rendering: auto;
}
.fa {
 display: inline-block;
 font: normal normal normal 10pt/1 "FontAwesome", sans-serif;
 text-rendering: auto;
 -webkit-font-smoothing: antialiased;
 -moz-osx-font-smoothing: grayscale;
}
.dropdown-menu {
 font-family: sans-serif;
 font-size: 13pt;
 box-shadow: none;
 padding: 0px;
 text-align: left;
 border: none;
 background-color: #e6d29e;
 background: #e6d29e;
 line-height: 1;
}
.dropdown-menu:hover {
 font-family: sans-serif;
 font-size: 13pt;
 box-shadow: none;
 padding: 0px;
 text-align: left;
 border: none;
 background-color: #e6d29e;
 box-shadow: none;
 line-height: 1;
}
.dropdown-menu > li > a {
 font-family: sans-serif;
 font-size: 12.0pt;
 display: block;
 padding: 10px 20px 9px 10px;
 color: #3c3836;
 background-color: #e6d29e;
 background: #e6d29e;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
 color: #1d2021;
 background-color: #e1c98a;
 background: #e1c98a;
 border-color: #e1c98a;
 transition: 200ms ease;
}
.dropdown-menu .divider {
 height: 1px;
 margin: 0px 0px;
 overflow: hidden;
 background-color: rgba(185,165,113,.5);
}
.dropdown-submenu > .dropdown-menu {
 display: none;
 top: 2px !important;
 left: 100%;
 margin-top: -2px;
 margin-left: 0px;
 padding-top: 0px;
 transition: 200ms ease;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
 font-family: sans-serif;
 font-size: 12.0pt;
 font-weight: normal;
 color: #b5a586;
 padding: none;
 display: block;
 clear: both;
 white-space: nowrap;
}
.dropdown-submenu > a:after {
 color: #3c3836;
 margin-right: -16px;
 margin-top: 0px;
 display: inline-block;
}
.dropdown-submenu:hover > a:after,
.dropdown-submenu:active > a:after,
.dropdown-submenu:focus > a:after,
.dropdown-submenu:visited > a:after {
 color: #3c3836;
 margin-right: -16px;
 display: inline-block !important;
}
div.kse-dropdown > .dropdown-menu,
.kse-dropdown > .dropdown-menu {
 min-width: 0;
 top: 94%;
}
.btn,
.btn-default {
 font-family: sans-serif;
 color: #3c3836;
 background: rgba(185,165,113,.5);
 background-color: rgba(185,165,113,.5);
 border: 2px solid rgba(185,165,113,.5);
 font-weight: normal;
 box-shadow: none;
 text-shadow: none;
 border-radius: 3px;
 font-size: initial;
}
.btn:hover,
.btn:active:hover,
.btn.active:hover,
.btn-default:hover,
.open > .dropdown-toggle.btn-default:hover,
.open > .dropdown-toggle.btn:hover {
 color: #d65d0e;
 border: 2px solid #e1c98a;
 background-color: #e1c98a;
 background: #e1c98a;
 background-image: none;
 box-shadow: none !important;
 border-radius: 3px;
}
.btn:active,
.btn.active,
.btn:active:focus,
.btn.active:focus,
.btn:active.focus,
.btn.active.focus,
.btn-default:focus,
.btn-default.focus,
.btn-default:active,
.btn-default.active,
.btn-default:active:hover,
.btn-default.active:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn:focus,
.open > .dropdown-toggle.btn.focus,
.open > .dropdown-toggle.btn-default:hover,
.open > .dropdown-toggle.btn-default:focus,
.open > .dropdown-toggle.btn-default.hover,
.open > .dropdown-toggle.btn-default.focus {
 color: #d65d0e;
 border: 2px solid #e1c98a;
 background-color: #e1c98a !important;
 background: #e1c98a !important;
 background-image: none;
 box-shadow: none !important;
 border-radius: 3px;
}
.btn-default:active:hover,
.btn-default.active:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.btn-default:active.focus,
.btn-default.active.focus {
 color: #d65d0e !important;
 background-color: rgba(185,165,113,.5);
 border-color: #e1c98a !important;
 transition: 2000ms ease;
}
.btn:focus,
.btn.focus,
.btn:active:focus,
.btn.active:focus,
.btn:active,
.btn.active,
.btn:active.focus,
.btn.active.focus {
 color: #d65d0e !important;
 outline: none !important;
 outline-width: 0px !important;
 background: #e1c98a !important;
 background-color: #e1c98a !important;
 border-color: #e1c98a !important;
 transition: 200ms ease !important;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
 font-size: 13pt;
 background: transparent;
 background-color: transparent;
 border: 0px solid #ead9ae;
 border-bottom: 2px solid transparent;
 margin-left: 5px;
 padding-top: 4px !important;
}
.item_buttons > .btn:hover,
.item_buttons > .btn-group:hover,
.item_buttons > .input-group:hover,
.item_buttons > .btn.active,
.item_buttons > .btn-group.active,
.item_buttons > .input-group.active,
.item_buttons > .btn.focus {
 margin-left: 5px;
 background: #e8d5a6;
 padding-top: 4px !important;
 background-color: transparent;
 border: 0px solid transparent;
 border-bottom: 2px solid #3c3836;
 border-radius: 0px;
 transition: none;
}
.item_buttons {
 line-height: 1.5em !important;
}
.item_buttons .btn {
 min-width: 11ex;
}
.btn-group > .btn:first-child {
 margin-left: 3px;
}
.btn-group > .btn-mini,
.btn-sm,
.btn-group-sm > .btn,
.btn-xs,
.btn-group-xs > .btn,
.alternate_upload .btn-upload,
.btn-group,
.btn-group-vertical {
 font-size: inherit;
 font-weight: normal;
 height: inherit;
 line-height: inherit;
}
.btn-xs,
.btn-group-xs > .btn {
 font-size: initial !important;
 background-image: none;
 font-weight: normal;
 text-shadow: none;
 display: inline-table;
 padding: 2px 5px;
 line-height: 1.45;
}
.btn-group > .btn:first-child {
 margin-left: 3px;
}
div#new-buttons > button,
#new-buttons > button,
div#refresh_notebook_list,
#refresh_notebook_list {
 background: transparent;
 background-color: transparent;
 border: none;
}
div#new-buttons > button:hover,
#new-buttons > button:hover,
div#refresh_notebook_list,
#refresh_notebook_list,
div.alternate_upload .btn-upload,
.alternate_upload .btn-upload,
div.dynamic-buttons > button,
.dynamic-buttons > button,
.dynamic-buttons > button:focus,
.dynamic-buttons > button:active:focus,
.dynamic-buttons > button.active:focus,
.dynamic-buttons > button.focus,
.dynamic-buttons > button:active.focus,
.dynamic-buttons > button.active.focus,
#new-buttons > button:focus,
#new-buttons > button:active:focus,
#new-buttons > button.active:focus,
#new-buttons > button.focus,
#new-buttons > button:active.focus,
#new-buttons > button.active.focus,
.alternate_upload .btn-upload:focus,
.alternate_upload .btn-upload:active:focus,
.alternate_upload .btn-upload.active:focus,
.alternate_upload .btn-upload.focus,
.alternate_upload .btn-upload:active.focus,
.alternate_upload .btn-upload.active.focus {
 background: transparent !important;
 background-color: transparent !important;
 border: none !important;
}
.alternate_upload input.fileinput {
 text-align: center;
 vertical-align: bottom;
 margin-left: -.5ex;
 display: inline-table;
 border: solid 0px rgba(185,165,113,.5);
 margin-bottom: -1ex;
}
.alternate_upload .btn-upload {
 display: inline-table;
 background: transparent;
 border: none;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
 margin-left: -2px;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
 border-bottom-right-radius: 0;
 border-top-right-radius: 0;
 z-index: 2;
}
.dropdown-header {
 font-family: sans-serif !important;
 font-size: 13pt !important;
 color: #3c3836 !important;
 border-bottom: none !important;
 padding: 0px !important;
 margin: 6px 6px 0px !important;
}
span#last-modified.btn.btn-xs.btn-default.sort-action,
span#sort-name.btn.btn-xs.btn-default.sort-action,
span#file-size.btn.btn-xs.btn-default.sort-action {
 font-family: sans-serif;
 font-size: 16px;
 background-color: transparent;
 background: transparent;
 border: none;
 color: #3c3836;
 padding-bottom: 0px;
 margin-bottom: 0px;
 vertical-align: sub;
}
span#last-modified.btn.btn-xs.btn-default.sort-action {
 margin-left: 19px;
}
button.close {
 border: 0px none;
 font-family: sans-serif;
 font-size: 20pt;
 font-weight: normal;
}
.dynamic-buttons {
 padding-top: 0px;
 display: inline-block;
}
.close {
 color: #cc241d;
 opacity: .5;
 text-shadow: none;
 font-weight: normal;
}
.close:hover {
 color: #cc241d;
 opacity: 1;
 font-weight: normal;
}
div.nbext-enable-btns .btn[disabled],
div.nbext-enable-btns .btn[disabled]:hover,
.btn-default.disabled,
.btn-default[disabled],
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
 color: #282828;
 background: darken(rgba(185,165,113,.5),1%);
 background-color: darken(rgba(185,165,113,.5),1%);
 border-color: darken(rgba(185,165,113,.5),1%);
 transition: 200ms ease;
}
.input-group-addon {
 padding: 2px 5px;
 font-size: 13pt;
 font-weight: normal;
 height: auto;
 color: #3c3836;
 text-align: center;
 background-color: transparent;
 border: 2px solid transparent !important;
 text-transform: capitalize;
}
a.btn.btn-default.input-group-addon:hover {
 background: transparent !important;
 background-color: transparent !important;
}
.btn-group > .btn + .dropdown-toggle {
 padding-left: 8px;
 padding-right: 8px;
 height: 100%;
}
.btn-group > .btn + .dropdown-toggle:hover {
 background: #e1c98a !important;
}
.input-group-btn {
 position: relative;
 font-size: inherit;
 white-space: nowrap;
 background: #ead9ae;
 background-color: #ead9ae;
 border: none;
}
.input-group-btn:hover {
 background: #e8d5a6;
 background-color: #e8d5a6;
 border: none;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
 background: #ead9ae;
 background-color: #ead9ae;
 border: none;
 margin-left: 2px;
 margin-right: -1px;
 font-size: inherit;
}
.input-group-btn:first-child > .btn:hover,
.input-group-btn:first-child > .btn-group:hover {
 background: #e1c98a;
 background-color: #e1c98a;
 border: none;
 font-size: inherit;
 transition: 200ms ease;
}
div.modal .btn-group > .btn:first-child {
 background: #ead9ae;
 background-color: #ead9ae;
 border: 1px solid #e9d7aa;
 margin-top: 0px !important;
 margin-left: 0px;
 margin-bottom: 2px;
}
div.modal .btn-group > .btn:first-child:hover {
 background: #e8d5a6;
 background-color: #e8d5a6;
 border: 1px solid #e8d5a6;
 transition: 200ms ease;
}
div.modal > button,
div.modal-footer > button {
 background: #ead9ae;
 background-color: #ead9ae;
 border-color: #ead9ae;
}
div.modal > button:hover,
div.modal-footer > button:hover {
 background: #e8d5a6;
 background-color: #e8d5a6;
 border-color: #e8d5a6;
 transition: 200ms ease;
}
.modal-content {
 font-family: sans-serif;
 font-size: 12.0pt;
 position: relative;
 background: #ead9ae;
 background-color: #ead9ae;
 border: none;
 border-radius: 1px;
 background-clip: padding-box;
 outline: none;
}
.modal-header {
 font-family: sans-serif;
 font-size: 13pt;
 color: #3c3836;
 background: #ead9ae;
 background-color: #ead9ae;
 border-color: #e6d29e;
 padding: 12px;
 min-height: 16.4286px;
}
.modal-content h4 {
 font-family: sans-serif;
 font-size: 16pt;
 color: #3c3836;
 padding: 5px;
}
.modal-body {
 background-color: #fbf1c7;
 position: relative;
 padding: 15px;
}
.modal-footer {
 padding: 8px;
 text-align: right;
 background-color: #fbf1c7;
 border-top: none;
}
.alert-info {
 background-color: #fbf1c7;
 border-color: #e6d29e;
 color: #3c3836;
}
.modal-header .close {
 margin-top: -5px;
 font-size: 25pt;
}
.modal-backdrop,
.modal-backdrop.in {
 opacity: 0.85;
 background-color: notebook-bg;
}
div.panel,
div.panel-default,
.panel,
.panel-default {
 font-family: sans-serif;
 font-size: 13pt;
 background-color: #fbf1c7;
 color: #3c3836;
 margin-bottom: 14px;
 border: 0;
 box-shadow: none;
}
div.panel > .panel-heading,
div.panel-default > .panel-heading {
 font-size: 14pt;
 color: #3c3836;
 background: #ead9ae;
 background-color: #ead9ae;
 border: 0;
}
.modal .modal-dialog {
 min-width: 950px;
 margin: 50px auto;
}
div.container-fluid {
 margin-right: auto;
 margin-left: auto;
 padding-left: 0px;
 padding-right: 5px;
}
div.form-control,
.form-control {
 font-family: sans-serif;
 font-size: initial;
 color: #3c3836;
 background-color: #fcf5d5;
 border: 1px solid #ead9ae !important;
 margin-left: 2px;
 box-shadow: none;
 transition: border-color 0.15s ease-in-out 0s, box-shadow 0.15s ease-in-out 0s;
}
.form-control-static {
 min-height: inherit;
 height: inherit;
}
.form-group.list-group-item {
 color: #3c3836;
 background-color: #fbf1c7;
 border-color: #e6d29e;
 margin-bottom: 0px;
}
.form-group .input-group {
 float: left;
}
input,
button,
select,
textarea {
 background-color: #fcf5d5;
 font-weight: normal;
 border: 1px solid #e6d29e;
}
select.form-control.select-xs {
 height: 33px;
 font-size: 13pt;
}
.toolbar select,
.toolbar label {
 width: auto;
 vertical-align: middle;
 margin-right: 0px;
 margin-bottom: 0px;
 display: inline;
 font-size: 92%;
 margin-left: 10px;
 padding: 0px;
 background: rgba(185,165,113,.5) !important;
 background-color: rgba(185,165,113,.5) !important;
 border: 2px solid rgba(185,165,113,.5) !important;
}
.form-control:focus {
 border-color: #3c3836;
 outline: 2px solid rgba(215,153,33,.50);
 -webkit-box-shadow: none;
}
::-webkit-input-placeholder {
 color: #b5a586;
}
::-moz-placeholder {
 color: #b5a586;
}
:-ms-input-placeholder {
 color: #b5a586;
}
:-moz-placeholder {
 color: #b5a586;
}
[dir="ltr"] #find-and-replace .input-group-btn + .form-control {
 border: 2px solid #e6d29e !important;
}
[dir="ltr"] #find-and-replace .input-group-btn + .form-control:focus {
 border-color: #3c3836;
 outline: 2px solid rgba(215,153,33,.50);
 -webkit-box-shadow: none;
 box-shadow: none;
}
div.output.output_scroll {
 box-shadow: none;
}
::-webkit-scrollbar {
 width: 11px;
 max-height: 9px;
 background-color: #f1e6ca;
 border-radius: 3px;
 border: none;
}
::-webkit-scrollbar-track {
 background: #f1e6ca;
 border: none;
 width: 11px;
 max-height: 9px;
}
::-webkit-scrollbar-thumb {
 border-radius: 2px;
 border: none;
 background: #3c3836;
 background-clip: content-box;
 width: 11px;
}
HTML,
body,
div,
dl,
dt,
dd,
ul,
ol,
li,
h1,
h2,
h3,
h4,
h5,
h6,
pre,
code,
form,
fieldset,
legend,
input,
button,
textarea,
p,
blockquote,
th,
td,
span,
a {
 text-rendering: geometricPrecision;
 -webkit-font-smoothing: subpixel-antialiased;
 font-weight: 400;
}
div.input_area {
 background-color: #fbf1c7;
 background: #fbf1c7;
 padding-right: 1.2em;
 border: 0px;
 border-radius: 0px;
 border-top-right-radius: 4px;
 border-bottom-right-radius: 4px;
}
div.cell {
 padding: 0px;
 background: #fbf1c7;
 background-color: #fbf1c7;
 border: medium solid #ebdbb2;
 border-radius: 4px;
 top: 0;
}
div.cell.selected {
 background: #fbf1c7;
 background-color: #fbf1c7;
 border: medium solid #ebdbb2;
 padding: 0px;
 border-radius: 5px;
}
.edit_mode div.cell.selected {
 padding: 0px;
 background: #fbf1c7;
 background-color: #fbf1c7;
 border: medium solid #ebdbb2;
 border-radius: 5px;
}
div.cell.edit_mode {
 padding: 0px;
 background: #fbf1c7;
 background-color: #fbf1c7;
}
div.CodeMirror-sizer {
 margin-left: 0px;
 margin-bottom: -21px;
 border-right-width: 16px;
 min-height: 37px;
 padding-right: 0px;
 padding-bottom: 0px;
 margin-top: 0px;
}
div.cell.selected:before,
.edit_mode div.cell.selected:before,
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
 background: #fbf1c7 !important;
 border: none;
 border-radius: 3px;
 position: absolute;
 display: block;
 top: 0px;
 left: 0px;
 width: 0px;
 height: 100%;
}
div.cell.text_cell.selected::before,
.edit_mode div.cell.text_cell.selected:before,
div.cell.text_cell.selected:before,
div.cell.text_cell.selected.jupyter-soft-selected:before {
 background: #fbf1c7 !important;
 background-color: #fbf1c7 !important;
 border-color: #d79921 !important;
}
div.cell.code_cell .input {
 border-left: 5px solid #fbf1c7 !important;
 border-radius: 3px;
 border-bottom-left-radius: 3px;
 border-top-left-radius: 3px;
}
div.cell.code_cell.selected .input {
 border-left: 5px solid #458588 !important;
 border-radius: 3px;
}
.edit_mode div.cell.code_cell.selected .input {
 border-left: 5px solid #d79921 !important;
 border-radius: 3px;
}
.edit_mode div.cell.selected:before {
 height: 100%;
 border-left: 5px solid #d79921 !important;
 border-radius: 3px;
}
div.cell.jupyter-soft-selected,
div.cell.selected.jupyter-soft-selected {
 border-left-color: #d79921 !important;
 border-left-width: 0px !important;
 padding-left: 7px !important;
 border-right-color: #d79921 !important;
 border-right-width: 0px !important;
 background: #d79921 !important;
 border-radius: 6px !important;
}
div.cell.selected.jupyter-soft-selected .input {
 border-left: 5px solid #fbf1c7 !important;
}
div.cell.selected.jupyter-soft-selected {
 border-left-color: #458588;
 border-color: #ebdbb2;
 padding-left: 7px;
 border-radius: 6px;
}
div.cell.code_cell.selected .input {
 border-left: none;
 border-radius: 3px;
}
div.cell.selected.jupyter-soft-selected .prompt,
div.cell.text_cell.selected.jupyter-soft-selected .prompt {
 top: 0;
 border-left: #fbf1c7 !important;
 border-radius: 2px;
}
div.cell.text_cell.selected.jupyter-soft-selected .input_prompt {
 border-left: none !important;
}
div.cell.text_cell.jupyter-soft-selected,
div.cell.text_cell.selected.jupyter-soft-selected {
 border-left-color: #bdae93 !important;
 border-left-width: 0px !important;
 padding-left: 26px !important;
 border-right-color: #bdae93 !important;
 border-right-width: 0px !important;
 background: #bdae93 !important;
 border-radius: 5px !important;
}
div.cell.jupyter-soft-selected .input,
div.cell.selected.jupyter-soft-selected .input {
 border-left-color: #d79921 !important;
}
div.prompt,
.prompt {
 font-family: monospace, monospace;
 font-size: 9pt !important;
 font-weight: normal;
 color: #504945;
 line-height: 170%;
 padding: 0px;
 padding-top: 4px;
 padding-left: 0px;
 padding-right: 1px;
 text-align: right !important;
 min-width: 11.5ex !important;
 width: 11.5ex !important;
}
div.prompt.input_prompt {
 font-size: 9pt !important;
 background-color: #fbf1c7;
 border-top: 0px;
 border-top-right-radius: 0px;
 border-bottom-left-radius: 0px;
 border-bottom-right-radius: 0px;
 padding-right: 3px;
 min-width: 11.5ex;
 width: 11.5ex !important;
}
div.cell.code_cell .input_prompt {
 border-right: 2px solid rgba(215,153,33,.50);
}
div.cell.selected .prompt {
 top: 0;
}
.edit_mode div.cell.selected .prompt {
 top: 0;
}
.edit_mode div.cell.selected .prompt {
 top: 0;
}
.run_this_cell {
 visibility: hidden;
 color: transparent;
 padding-top: 0px;
 padding-bottom: 0px;
 padding-left: 3px;
 padding-right: 12px;
 width: 1.5ex;
 width: 0ex;
 background: transparent;
 background-color: transparent;
}
div.code_cell:hover div.input .run_this_cell {
 visibility: visible;
}
div.cell.code_cell.rendered.selected .run_this_cell:hover {
 background-color: #faecb4;
 background: #faecb4;
 color: #458588 !important;
}
div.cell.code_cell.rendered.unselected .run_this_cell:hover {
 background-color: #faecb4;
 background: #faecb4;
 color: #458588 !important;
}
i.fa-step-forward.fa {
 display: inline-block;
 font: normal normal normal 9px "FontAwesome";
}
.fa-step-forward:before {
 content: "\f04b";
}
div.cell.selected.jupyter-soft-selected .run_this_cell,
div.cell.selected.jupyter-soft-selected .run_this_cell:hover,
div.cell.unselected.jupyter-soft-selected .run_this_cell:hover,
div.cell.code_cell.rendered.selected.jupyter-soft-selected .run_this_cell:hover,
div.cell.code_cell.rendered.unselected.jupyter-soft-selected .run_this_cell:hover {
 background-color: #d79921 !important;
 background: #d79921 !important;
 color: #d79921 !important;
}
div.output_wrapper {
 background-color: #ebdbb2;
 border: 0px;
 left: 0px;
 margin-bottom: 0em;
 margin-top: 0em;
 border-top-right-radius: 0px;
 border-top-left-radius: 0px;
}
div.output_subarea.output_text.output_stream.output_stdout,
div.output_subarea.output_text {
 font-family: monospace, monospace;
 font-size: 8.5pt !important;
 line-height: 150% !important;
 background-color: #ebdbb2;
 color: #3c3836;
 border-top-right-radius: 0px;
 border-top-left-radius: 0px;
 margin-left: 11.5px;
}
div.output_area pre {
 font-family: monospace, monospace;
 font-size: 8.5pt !important;
 line-height: 151% !important;
 color: #3c3836;
 border-top-right-radius: 0px;
 border-top-left-radius: 0px;
}
div.output_area {
 display: -webkit-box;
}
div.output_html {
 font-family: monospace, monospace;
 font-size: 8.5pt;
 color: #282828;
 background-color: #ebdbb2;
 background: #ebdbb2;
}
div.output_subarea {
 overflow-x: auto;
 padding: 1.2em !important;
 -webkit-box-flex: 1;
 -moz-box-flex: 1;
 box-flex: 1;
 flex: 1;
}
div.btn.btn-default.output_collapsed {
 background: #e5d09a;
 background-color: #e5d09a;
 border-color: #e5d09a;
}
div.btn.btn-default.output_collapsed:hover {
 background: #e3cc92;
 background-color: #e3cc92;
 border-color: #e3cc92;
}
div.prompt.output_prompt {
 font-family: monospace, monospace;
 font-weight: bold !important;
 background-color: #ebdbb2;
 color: transparent;
 border-bottom-left-radius: 4px;
 border-top-right-radius: 0px;
 border-top-left-radius: 0px;
 border-bottom-right-radius: 0px;
 min-width: 11.5ex !important;
 width: 11.5ex !important;
 border-right: 2px solid transparent;
}
div.out_prompt_overlay.prompt {
 font-family: monospace, monospace;
 font-weight: bold !important;
 background-color: #ebdbb2;
 border-bottom-left-radius: 2px;
 border-top-right-radius: 0px;
 border-top-left-radius: 0px;
 border-bottom-right-radius: 0px;
 min-width: 11.5ex !important;
 width: 11.5ex !important;
 border-right: 2px solid transparent;
 color: transparent;
}
div.out_prompt_overlay.prompt:hover {
 background-color: #928374;
 box-shadow: none !important;
 border: none;
 border-bottom-left-radius: 2px;
 -webkit-border-: 2px;
 -moz-border-radius: 2px;
 border-top-right-radius: 0px;
 border-top-left-radius: 0px;
 min-width: 11.5ex !important;
 width: 11.5ex !important;
 border-right: 2px solid #928374 !important;
}
div.cell.code_cell .output_prompt {
 border-right: 2px solid transparent;
 color: transparent;
}
div.cell.selected .output_prompt,
div.cell.selected .out_prompt_overlay.prompt {
 border-left: 5px solid #bdae93;
 border-right: 2px solid #ebdbb2;
 border-radius: 0px !important;
}
.edit_mode div.cell.selected .output_prompt,
.edit_mode div.cell.selected .out_prompt_overlay.prompt {
 border-left: 5px solid #bdae93;
 border-right: 2px solid #ebdbb2;
 border-radius: 0px !important;
}
div.text_cell,
div.text_cell_render pre,
div.text_cell_render {
 font-family: sans-serif;
 font-size: 13pt;
 line-height: 130% !important;
 color: #3c3836;
 background: #fbf1c7;
 background-color: #fbf1c7;
 border-radius: 0px;
}
div .text_cell_render {
 padding: 0.4em 0.4em 0.4em 0.4em;
}
div.cell.text_cell .CodeMirror-lines {
 padding-top: .7em !important;
 padding-bottom: .4em !important;
 padding-left: .5em !important;
 padding-right: .5em !important;
 margin-top: .4em;
 margin-bottom: .3em;
}
div.cell.text_cell.unrendered div.input_area,
div.cell.text_cell.rendered div.input_area {
 background-color: #fbf1c7;
 background: #fbf1c7;
 border: 0px;
 border-radius: 2px;
}
div.cell.text_cell .CodeMirror,
div.cell.text_cell .CodeMirror pre {
 line-height: 170% !important;
}
div.cell.text_cell.rendered.selected {
 font-family: sans-serif;
 line-height: 170% !important;
 background: #fbf1c7;
 background-color: #fbf1c7;
 border-radius: 0px;
}
div.cell.text_cell.unrendered.selected {
 font-family: sans-serif;
 line-height: 170% !important;
 background: #fbf1c7;
 background-color: #fbf1c7;
 border-radius: 0px;
}
div.cell.text_cell.selected {
 font-family: sans-serif;
 line-height: 170% !important;
 background: #fbf1c7;
 background-color: #fbf1c7;
 border-radius: 0px;
}
.edit_mode div.cell.text_cell.selected {
 font-family: sans-serif;
 line-height: 170% !important;
 background: #fbf1c7;
 background-color: #fbf1c7;
 border-radius: 0px;
}
div.text_cell.unrendered,
div.text_cell.unrendered.selected,
div.edit_mode div.text_cell.unrendered {
 font-family: sans-serif;
 line-height: 170% !important;
 background: #fbf1c7;
 background-color: #fbf1c7;
 border-radius: 0px;
}
div.cell.text_cell .prompt {
 border-right: 0;
 min-width: 11.5ex !important;
 width: 11.5ex !important;
}
div.cell.text_cell.rendered .prompt {
 font-family: monospace, monospace;
 font-size: 9.5pt !important;
 font-weight: normal;
 color: #504945 !important;
 text-align: right !important;
 min-width: 14.5ex !important;
 width: 14.5ex !important;
 background-color: #fbf1c7;
 border-right: 2px solid rgba(215,153,33,.50);
 border-left: 4px solid #fbf1c7;
}
div.cell.text_cell.unrendered .prompt {
 font-family: monospace, monospace;
 font-size: 9.5pt !important;
 font-weight: normal;
 color: #504945 !important;
 text-align: right !important;
 min-width: 14.5ex !important;
 width: 14.5ex !important;
 border-right: 2px solid rgba(215,153,33,.50);
 border-left: 4px solid #fbf1c7;
 background-color: #fbf1c7;
}
div.cell.text_cell.rendered .prompt {
 border-right: 2px solid rgba(215,153,33,.50);
}
div.cell.text_cell.rendered.selected .prompt {
 top: 0;
 border-left: 4px solid #d79921;
 border-right: 2px solid rgba(215,153,33,.50);
}
div.text_cell.unrendered.selected .prompt,
div.text_cell.rendered.selected .prompt {
 top: 0;
 background: #fbf1c7;
 border-left: 4px solid #bdae93;
 border-right: 2px solid rgba(215,153,33,.50);
}
div.rendered_html code {
 font-family: monospace, monospace;
 font-size: 11pt;
 padding-top: 3px;
 padding-left: 2px;
 color: #3c3836;
 background: #fcf6da;
 background-color: #fcf6da;
}
pre,
code,
kbd,
samp {
 white-space: pre-wrap;
}
.well code,
code {
 font-family: monospace, monospace;
 font-size: 11pt !important;
 line-height: 170% !important;
 color: #3c3836;
 background: #fcf6da;
 background-color: #fcf6da;
 border-color: #fcf6da;
}
kbd {
 padding: 1px;
 font-size: 11pt;
 font-weight: 800;
 color: #3c3836;
 background-color: transparent !important;
 border: 0;
 box-shadow: none;
}
pre {
 display: block;
 padding: 8.5px;
 margin: 0 0 9px;
 font-size: 12.0pt;
 line-height: 1.42857143;
 color: #3c3836;
 background-color: #fcf6da;
 border: 1px solid #fcf6da;
 border-radius: 2px;
}
div.rendered_html {
 color: #3c3836;
}
.rendered_html * + ul {
 margin-top: .4em;
 margin-bottom: .3em;
}
.rendered_html * + p {
 margin-top: .5em;
 margin-bottom: .5em;
}
div.rendered_html pre {
 font-family: monospace, monospace;
 font-size: 11pt !important;
 line-height: 170% !important;
 color: #3c3836 !important;
 background: #fcf6da;
 background-color: #fcf6da;
 max-width: 80%;
 border-radius: 0px;
 border-left: 3px solid #fcf6da;
 max-width: 80%;
 border-radius: 0px;
 padding-left: 5px;
 margin-left: 6px;
}
div.text_cell_render pre,
div.text_cell_render code {
 font-family: monospace, monospace;
 font-size: 11pt !important;
 line-height: 170% !important;
 color: #3c3836;
 background: #ebdbb2;
 background-color: #ebdbb2;
 max-width: 80%;
 border-radius: 0px;
 border-left: none;
}
div.text_cell_render pre {
 border-left: 3px solid rgba(215,153,33,.50) !important;
 max-width: 80%;
 border-radius: 0px;
 padding-left: 5px;
 margin-left: 6px;
}
div.text_cell_render h1,
div.rendered_html h1,
div.text_cell_render h2,
div.rendered_html h2,
div.text_cell_render h3,
div.rendered_html h3,
div.text_cell_render h4,
div.rendered_html h4,
div.text_cell_render h5,
div.rendered_html h5 {
 font-family: sans-serif;
 margin: 0.4em .2em .3em .2em !important;
}
.rendered_html h1:first-child,
.rendered_html h2:first-child,
.rendered_html h3:first-child,
.rendered_html h4:first-child,
.rendered_html h5:first-child,
.rendered_html h6:first-child {
 margin-top: 0.2em !important;
 margin-bottom: 0.2em !important;
}
.rendered_html h1,
.text_cell_render h1 {
 color: #d79921 !important;
 font-size: 200%;
 text-align: left;
 font-style: normal;
 font-weight: normal;
}
.rendered_html h2,
.text_cell_render h2 {
 color: #d79921 !important;
 font-size: 170%;
 font-style: normal;
 font-weight: normal;
}
.rendered_html h3,
.text_cell_render h3 {
 color: #d79921 !important;
 font-size: 140%;
 font-style: normal;
 font-weight: normal;
}
.rendered_html h4,
.text_cell_render h4 {
 color: #d79921 !important;
 font-size: 110%;
 font-style: normal;
 font-weight: normal;
}
.rendered_html h5,
.text_cell_render h5 {
 color: #d79921 !important;
 font-size: 100%;
 font-style: normal;
 font-weight: normal;
}
hr {
 margin-top: 8px;
 margin-bottom: 10px;
 border: 0;
 border-top: 1px solid #d79921;
}
.rendered_html hr {
 color: #d79921;
 background-color: #d79921;
 margin-right: 2em;
}
#complete > select > option:hover {
 background: #e1c98a;
 background-color: #e1c98a;
}
div#_vivaldi-spatnav-focus-indicator._vivaldi-spatnav-focus-indicator {
 position: absolute;
 z-index: 9999999999;
 top: 0px;
 left: 0px;
 box-shadow: none;
 pointer-events: none;
 border-radius: 2px;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
 text-align: left;
 vertical-align: middle;
 padding: 0.42em 0.47em;
 line-height: normal;
 white-space: normal;
 max-width: none;
 border: none;
}
.rendered_html td {
 font-family: sans-serif !important;
 font-size: 9.3pt;
}
.rendered_html table {
 font-family: sans-serif !important;
 margin-left: 8px;
 margin-right: auto;
 border: none;
 border-collapse: collapse;
 border-spacing: 0;
 color: #282828;
 table-layout: fixed;
}
.rendered_html thead {
 font-family: sans-serif !important;
 font-size: 10.3pt !important;
 background: #fbf1c7;
 color: #282828;
 border-bottom: 1px solid #fbf1c7;
 vertical-align: bottom;
}
.rendered_html tbody tr:nth-child(odd) {
 background: #ebdbb2;
}
.rendered_html tbody tr {
 background: #e8d5a6;
}
.rendered_html tbody tr:hover:nth-child(odd) {
 background: #ead9ae;
}
.rendered_html tbody tr:hover {
 background: #e7d3a2;
}
.rendered_html * + table {
 margin-top: .05em;
}
div.widget-area {
 background-color: #ebdbb2;
 background: #ebdbb2;
 color: #3c3836;
}
div.widget-area a {
 font-family: sans-serif;
 font-size: 12.0pt;
 font-weight: normal;
 font-style: normal;
 color: #3c3836;
 text-shadow: none !important;
}
div.widget-area a:hover,
div.widget-area a:focus {
 font-family: sans-serif;
 font-size: 12.0pt;
 font-weight: normal;
 font-style: normal;
 color: #1d2021;
 background: rgba(185,165,113,.3);
 background-color: rgba(185,165,113,.3);
 border-color: transparent;
 background-image: none;
 text-shadow: none !important;
}
div.widget_item.btn-group > button.btn.btn-default.widget-combo-btn,
div.widget_item.btn-group > button.btn.btn-default.widget-combo-btn:hover {
 background: #e9d7aa;
 background-color: #e9d7aa;
 border: 2px solid #e9d7aa !important;
 font-size: inherit;
 z-index: 0;
}
div.jupyter-widgets.widget-hprogress.widget-hbox {
 display: inline-table !important;
 width: 38% !important;
 margin-left: 10px;
}
div.jupyter-widgets.widget-hprogress.widget-hbox .widget-label,
div.widget-hbox .widget-label,
.widget-hbox .widget-label,
.widget-inline-hbox .widget-label,
div.widget-label {
 text-align: -webkit-auto !important;
 margin-left: 15px !important;
 max-width: 240px !important;
 min-width: 100px !important;
 vertical-align: text-top !important;
 color: #3c3836 !important;
 font-size: 14px !important;
}
.widget-hprogress .progress {
 flex-grow: 1;
 height: 20px;
 margin-top: auto;
 margin-left: 12px;
 margin-bottom: auto;
 width: 300px;
}
.progress {
 overflow: hidden;
 height: 22px;
 margin-bottom: 10px;
 padding-left: 10px;
 background-color: #928374 !important;
 border-radius: 2px;
 -webkit-box-shadow: none;
 box-shadow: none;
 z-index: 10;
}
.progress-bar-danger {
 background-color: #cc241d !important;
}
.progress-bar-info {
 background-color: #689d6a !important;
}
.progress-bar-warning {
 background-color: #d79921 !important;
}
.progress-bar-success {
 background-color: #98971a !important;
}
.widget-select select {
 margin-left: 12px;
}
.rendered_html :link {
 font-family: sans-serif;
 font-size: 100%;
 color: #3c3836;
 text-decoration: underline;
}
.rendered_html :visited,
.rendered_html :visited:active,
.rendered_html :visited:focus {
 color: #434343;
}
.rendered_html :visited:hover,
.rendered_html :link:hover {
 font-family: sans-serif;
 font-size: 100%;
 color: #2d211d;
}
div.cell.text_cell a.anchor-link:link {
 font-size: inherit;
 text-decoration: none;
 padding: 0px 20px;
 visibility: none;
 color: rgba(0,0,0,.32);
}
div.cell.text_cell a.anchor-link:link:hover {
 font-size: inherit;
 color: #928374;
}
.navbar-text {
 margin-top: 4px;
 margin-bottom: 0px;
}
#clusters > a {
 color: #458588;
 text-decoration: underline;
 cursor: auto;
}
#clusters > a:hover {
 color: #458588;
 text-decoration: underline;
 cursor: auto;
}
#nbextensions-configurator-container > div.row.container-fluid.nbext-selector > h3 {
 font-size: 17px;
 margin-top: 5px;
 margin-bottom: 8px;
 height: 24px;
 padding: 4px 0 4px 0;
}
div#nbextensions-configurator-container.container,
#nbextensions-configurator-container.container {
 width: 100%;
 margin-right: auto;
 margin-left: auto;
}
div.nbext-selector > nav > .nav > li > a {
 font-family: sans-serif;
 font-size: 10.5pt;
 padding: 2px 5px;
}
div.nbext-selector > nav > .nav > li > a:hover {
 background: transparent;
}
div.nbext-selector > nav > .nav > li:hover {
 background-color: rgba(185,165,113,.3) !important;
 background: rgba(185,165,113,.3) !important;
}
div.nbext-selector > nav > .nav > li.active:hover {
 background: transparent !important;
 background-color: transparent !important;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:active,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
 color: #d65d0e;
 background-color: rgba(185,165,113,.3) !important;
 background: rgba(185,165,113,.3) !important;
 -webkit-backface-visibility: hidden;
 -webkit-font-smoothing: subpixel-antialiased !important;
}
div.nbext-readme > .nbext-readme-contents > .rendered_html {
 font-family: sans-serif;
 font-size: 11.5pt;
 line-height: 145%;
 padding: 1em 1em;
 color: #3c3836;
 background-color: #fbf1c7;
 -webkit-box-shadow: none;
 -moz-box-shadow: none;
 box-shadow: none;
}
.nbext-icon,
.nbext-desc,
.nbext-compat-div,
.nbext-enable-btns,
.nbext-params {
 margin-bottom: 8px;
 font-size: 11.5pt;
}
div.nbext-readme > .nbext-readme-contents {
 padding: 0;
 overflow-y: hidden;
}
div.nbext-readme > .nbext-readme-contents:not(:empty) {
 margin-top: 0.5em;
 margin-bottom: 2em;
 border: none;
 border-top-color: rgba(185,165,113,.5);
}
.nbext-showhide-incompat {
 padding-bottom: 0.5em;
 color: #282828;
 font-size: 10.5pt;
}
.nbext-filter-menu.dropdown-menu > li > a:hover,
.nbext-filter-menu.dropdown-menu > li > a:focus,
.nbext-filter-menu.dropdown-menu > li > a.ui-state-focus {
 color: #1d2021 !important;
 background-color: #e1c98a !important;
 background: #e1c98a !important;
 border-color: #e1c98a !important;
}
.nbext-filter-input-wrap > .nbext-filter-input-subwrap,
.nbext-filter-input-wrap > .nbext-filter-input-subwrap > input {
 border: none;
 outline: none;
 background-color: transparent;
 padding: 0;
 vertical-align: middle;
 margin-top: -2px;
}
span.rendered_html code {
 background-color: transparent;
 color: #3c3836;
}
#nbextensions-configurator-container > div.row.container-fluid.nbext-selector {
 padding-left: 0px;
 padding-right: 0px;
}
.nbext-filter-menu {
 max-height: 55vh !important;
 overflow-y: auto;
 outline: none;
 border: none;
}
.nbext-filter-menu:hover {
 border: none;
}
.alert-warning {
 background-color: #fbf1c7;
 border-color: #fbf1c7;
 color: #3c3836;
}
.notification_widget.danger {
 color: #ffffff;
 background-color: #cc241d;
 border-color: #cc241d;
 padding-right: 5px;
}
#nbextensions-configurator-container > div.nbext-buttons.tree-buttons.no-padding.pull-right > span > button {
 border: none !important;
}
button#refresh_running_list {
 border: none !important;
}
mark,
.mark {
 background-color: #fbf1c7;
 color: #3c3836;
 padding: .15em;
}
a.text-warning,
a.text-warning:hover {
 color: #b5a586;
}
a.text-warning.bg-warning {
 background-color: #ebdbb2;
}
span.bg-success.text-success {
 background-color: transparent;
 color: #98971a;
}
span.bg-danger.text-danger {
 background-color: #ebdbb2;
 color: #cc241d;
}
.has-success .input-group-addon {
 color: #98971a;
 border-color: transparent;
 background: inherit;
 background-color: rgba(83,180,115,.10);
}
.has-success .form-control {
 border-color: #98971a;
 -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,0.025);
 box-shadow: inset 0 1px 1px rgba(0,0,0,0.025);
}
.has-error .input-group-addon {
 color: #cc241d;
 border-color: transparent;
 background: inherit;
 background-color: rgba(192,57,67,.10);
}
.has-error .form-control {
 border-color: #cc241d;
 -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,0.025);
 box-shadow: inset 0 1px 1px rgba(0,0,0,0.025);
}
.kse-input-group-pretty > kbd {
 font-family: monospace, monospace;
 color: #3c3836;
 font-weight: normal;
 background: transparent;
}
.kse-input-group-pretty > kbd {
 font-family: monospace, monospace;
 color: #3c3836;
 font-weight: normal;
 background: transparent;
}
div.nbext-enable-btns .btn[disabled],
div.nbext-enable-btns .btn[disabled]:hover,
.btn-default.disabled,
.btn-default[disabled] {
 background: darken(rgba(185,165,113,.5),1%);
 background-color: darken(rgba(185,165,113,.5),1%);
 color: #34302f;
}
label#Keyword-Filter {
 display: none;
}
.input-group .nbext-list-btn-add,
.input-group-btn:last-child > .btn-group > .btn {
 background: #ead9ae;
 background-color: #ead9ae;
 border-color: #ead9ae;
 border: 2px solid #ead9ae;
}
.input-group .nbext-list-btn-add:hover,
.input-group-btn:last-child > .btn-group > .btn:hover {
 background: #e8d5a6;
 background-color: #e8d5a6;
 border-color: #e8d5a6;
 border: 2px solid #e8d5a6;
}
#notebook-container > div.cell.code_cell.rendered.selected > div.widget-area > div.widget-subarea > div > div.widget_item.btn-group > button.btn.btn-default.dropdown-toggle.widget-combo-carrot-btn {
 background: #ead9ae;
 background-color: #ead9ae;
 border-color: #ead9ae;
}
#notebook-container > div.cell.code_cell.rendered.selected > div.widget-area > div.widget-subarea > div > div.widget_item.btn-group > button.btn.btn-default.dropdown-toggle.widget-combo-carrot-btn:hover {
 background: #e8d5a6;
 background-color: #e8d5a6;
 border-color: #e8d5a6;
}
.ui-widget-content {
 background: rgba(185,165,113,.5);
 background-color: rgba(185,165,113,.5);
 border: 2px solid rgba(185,165,113,.5);
 color: #3c3836;
}
div.collapsible_headings_toggle {
 color: rgba(185,165,113,.5) !important;
}
div.collapsible_headings_toggle:hover {
 color: #3c3836 !important;
}
.collapsible_headings_toggle .h1,
.collapsible_headings_toggle .h2,
.collapsible_headings_toggle .h3,
.collapsible_headings_toggle .h4,
.collapsible_headings_toggle .h5,
.collapsible_headings_toggle .h6 {
 margin: 0.3em .4em 0em 0em !important;
 line-height: 1.2 !important;
}
div.collapsible_headings_toggle .fa-caret-down:before,
div.collapsible_headings_toggle .fa-caret-right:before {
 font-size: xx-large;
 transition: transform 1000ms;
 transform: none !important;
}
.collapsible_headings_collapsed.collapsible_headings_ellipsis .rendered_html h1:after,
.collapsible_headings_collapsed.collapsible_headings_ellipsis .rendered_html h2:after,
.collapsible_headings_collapsed.collapsible_headings_ellipsis .rendered_html h3:after,
.collapsible_headings_collapsed.collapsible_headings_ellipsis .rendered_html h4:after,
.collapsible_headings_collapsed.collapsible_headings_ellipsis .rendered_html h5:after,
.collapsible_headings_collapsed.collapsible_headings_ellipsis .rendered_html h6:after {
 position: absolute;
 right: 0;
 bottom: 20% !important;
 content: "[\002026]";
 color: rgba(185,165,113,.5) !important;
 padding: 0.5em 0em 0em 0em !important;
}
.collapsible_headings_ellipsis .rendered_html h1,
.collapsible_headings_ellipsis .rendered_html h2,
.collapsible_headings_ellipsis .rendered_html h3,
.collapsible_headings_ellipsis .rendered_html h4,
.collapsible_headings_ellipsis .rendered_html h5,
.collapsible_headings_ellipsis .rendered_html h6,
.collapsible_headings_toggle .fa {
 transition: transform 1000ms !important;
 -webkit-transform: inherit !important;
 -moz-transform: inherit !important;
 -ms-transform: inherit !important;
 -o-transform: inherit !important;
 transform: inherit !important;
 padding-right: 0px !important;
}
#toc-wrapper {
 z-index: 90;
 position: fixed !important;
 display: flex;
 flex-direction: column;
 overflow: hidden;
 padding: 10px;
 border-style: solid;
 border-width: thin;
 border-right-width: medium !important;
 background-color: #ebdbb2 !important;
}
#toc-wrapper.ui-draggable.ui-resizable.sidebar-wrapper {
 border-color: rgba(185,165,113,.3) !important;
}
#toc a,
#navigate_menu a,
.toc {
 color: #3c3836 !important;
 font-size: 11pt !important;
}
#toc li > span:hover {
 background-color: #e1c98a !important;
}
#toc a:hover,
#navigate_menu a:hover,
.toc {
 color: #d65d0e !important;
 font-size: 11pt !important;
}
#toc-wrapper .toc-item-num {
 color: #3c3836 !important;
 font-size: 11pt !important;
}
input.raw_input {
 font-family: monospace, monospace;
 font-size: 11pt !important;
 color: #3c3836;
 background-color: #fcf6da;
 border-color: #fcf5d5;
 background: #fcf5d5;
 width: auto;
 vertical-align: baseline;
 padding: 0em 0.25em;
 margin: 0em 0.25em;
 -webkit-box-shadow: none;
 box-shadow: none;
}
audio,
video {
 display: inline;
 vertical-align: middle;
 align-content: center;
 margin-left: 20%;
}
.cmd-palette .modal-body {
 padding: 0px;
 margin: 0px;
}
.cmd-palette form {
 background: #ead9ae;
 background-color: #ead9ae;
}
.typeahead-field input:last-child,
.typeahead-hint {
 background: #ead9ae;
 background-color: #ead9ae;
 z-index: 1;
}
.typeahead-field input {
 font-family: sans-serif;
 color: #3c3836;
 border: none;
 font-size: 28pt;
 display: inline-block;
 line-height: inherit;
 padding: 3px 10px;
 height: 70px;
}
.typeahead-select {
 background-color: #ead9ae;
}
body > div.modal.cmd-palette.typeahead-field {
 display: table;
 border-collapse: separate;
 background-color: #fbf1c7;
}
.typeahead-container button {
 font-family: sans-serif;
 font-size: 28pt;
 background-color: #ead9ae;
 border: none;
 display: inline-block;
 line-height: inherit;
 padding: 3px 10px;
 height: 70px;
}
.typeahead-search-icon {
 min-width: 40px;
 min-height: 55px;
 display: block;
 vertical-align: middle;
 text-align: center;
}
.typeahead-container button:focus,
.typeahead-container button:hover {
 color: #1d2021;
 background-color: #e8d5a6;
 border-color: #e1c98a;
}
.typeahead-list > li.typeahead-group.active > a,
.typeahead-list > li.typeahead-group > a,
.typeahead-list > li.typeahead-group > a:focus,
.typeahead-list > li.typeahead-group > a:hover {
 display: none;
}
.typeahead-dropdown > li > a,
.typeahead-list > li > a {
 color: #3c3836;
 text-decoration: none;
}
.typeahead-dropdown,
.typeahead-list {
 font-family: sans-serif;
 font-size: 13pt;
 color: #3c3836;
 background-color: #fcf5d5;
 border: none;
 background-clip: padding-box;
 margin-top: 0px;
 padding: 3px 2px 3px 0px;
 line-height: 1.7;
}
.typeahead-dropdown > li.active > a,
.typeahead-dropdown > li > a:focus,
.typeahead-dropdown > li > a:hover,
.typeahead-list > li.active > a,
.typeahead-list > li > a:focus,
.typeahead-list > li > a:hover {
 color: #1d2021;
 background-color: #fbf1c7;
 border-color: #fbf1c7;
}
.command-shortcut:before {
 content: "(command)";
 padding-right: 3px;
 color: #b5a586;
}
.edit-shortcut:before {
 content: "(edit)";
 padding-right: 3px;
 color: #b5a586;
}
ul.typeahead-list i {
 margin-left: 1px;
 width: 18px;
 margin-right: 10px;
}
ul.typeahead-list {
 max-height: 50vh;
 overflow: auto;
}
.typeahead-list > li {
 position: relative;
 border: none;
}
div.input.typeahead-hint,
input.typeahead-hint,
body > div.modal.cmd-palette.in > div > div > div > form > div > div.typeahead-field > span.typeahead-query > input.typeahead-hint {
 color: #b5a586 !important;
 background-color: transparent;
 padding: 3px 10px;
}
.typeahead-dropdown > li > a,
.typeahead-list > li > a {
 display: block;
 padding: 5px;
 clear: both;
 font-weight: 400;
 line-height: 1.7;
 border: 1px solid #fcf5d5;
 border-bottom-color: rgba(185,165,113,.5);
}
body > div.modal.cmd-palette.in > div {
 min-width: 750px;
 margin: 150px auto;
}
.typeahead-container strong {
 font-weight: bolder;
 color: #3c3836;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
 color: #ffffff;
 background-color: #458588;
 border-color: #458588;
 border-style: solid;
 border-width: 1px;
 border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
 background-color: #cc241d;
 border-color: #cc241d;
 border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
 background-color: #98971a;
 border-color: #98971a;
 border-radius: 0px;
}
.jupyter-dashboard-menu-item.selected::before {
 font-family: 'FontAwesome' !important;
 content: '\f00c' !important;
 position: absolute !important;
 color: #3c3836 !important;
 left: 0px !important;
 top: 13px !important;
 font-size: 12px !important;
}
.shortcut_key,
span.shortcut_key {
 display: inline-block;
 width: 16ex;
 text-align: right;
 font-family: monospace;
}
.jupyter-keybindings {
 padding: 1px;
 line-height: 24px;
 border-bottom: 1px solid rgba(185,165,113,.3);
}
.jupyter-keybindings i {
 background: #fcf6da;
 font-size: small;
 padding: 5px;
 margin-left: 7px;
}
div#short-key-bindings-intro.well,
.well {
 background-color: #ead9ae;
 border: 1px solid #ead9ae;
 color: #3c3836;
 border-radius: 2px;
 -webkit-box-shadow: none;
 box-shadow: none;
}
#texteditor-backdrop {
 background: #ebdbb2;
 background-color: #ebdbb2;
}
#texteditor-backdrop #texteditor-container .CodeMirror-gutter,
#texteditor-backdrop #texteditor-container .CodeMirror-gutters {
 background: #fbf1c7;
 background-color: #fbf1c7;
 color: #504945;
}
.edit_app #menubar .navbar {
 margin-bottom: 0px;
}
#texteditor-backdrop #texteditor-container {
 padding: 0px;
 background-color: #fbf1c7;
 box-shadow: none;
}
.terminal-app {
 background: #ebdbb2;
}
.terminal-app > #header {
 background: #ebdbb2;
}
.terminal-app .terminal {
 font-family: monospace, monospace;
 font-size: 11pt;
 line-height: 170%;
 color: #3c3836;
 background: #fbf1c7;
 padding: 0.4em;
 border-radius: 2px;
 -webkit-box-shadow: none;
 box-shadow: none;
}
.terminal .xterm-viewport {
 background-color: #fbf1c7;
 color: #3c3836;
 overflow-y: auto;
}
.terminal .xterm-color-0 {
 color: #3c3836;
}
.terminal .xterm-color-1 {
 color: #b16286;
}
.terminal .xterm-color-2 {
 color: #cc241d;
}
.terminal .xterm-color-3 {
 color: #b16286;
}
.terminal .xterm-color-4 {
 color: #458588;
}
.terminal .xterm-color-5 {
 color: #98971a;
}
.terminal .xterm-color-6 {
 color: #689d6a;
}
.terminal .xterm-color-7 {
 color: #458588;
}
.terminal .xterm-color-8 {
 color: #458588;
}
.terminal .xterm-color-9 {
 color: #98971a;
}
.terminal .xterm-color-10 {
 color: #b16286;
}
.terminal .xterm-color-14 {
 color: #689d6a;
}
.terminal .xterm-bg-color-15 {
 background-color: #fbf1c7;
}
.terminal:not(.xterm-cursor-style-underline):not(.xterm-cursor-style-bar) .terminal-cursor {
 background-color: #3c3836;
 color: #fbf1c7;
}
.terminal:not(.focus) .terminal-cursor {
 outline: 1px solid #3c3836;
 outline-offset: -1px;
}
.celltoolbar {
 font-size: 100%;
 padding-top: 3px;
 border-color: transparent;
 border-bottom: thin solid rgba(185,165,113,.5);
 background: transparent;
}
.cell-tag,
.tags-input input,
.tags-input button {
 color: #3c3836;
 background-color: #ebdbb2;
 background-image: none;
 border: 1px solid #3c3836;
 border-radius: 1px;
 box-shadow: none;
 width: inherit;
 font-size: inherit;
 height: 22px;
 line-height: 22px;
}
#notebook-container > div.cell.code_cell.rendered.selected > div.input > div.inner_cell > div.ctb_hideshow.ctb_show > div > div > button,
#notebook-container > div.input > div.inner_cell > div.ctb_hideshow.ctb_show > div > div > button {
 font-size: 10pt;
 color: #3c3836;
 background-color: #ebdbb2;
 background-image: none;
 border: 1px solid #3c3836;
 border-radius: 1px;
 box-shadow: none;
 width: inherit;
 font-size: inherit;
 height: 22px;
 line-height: 22px;
}
div#pager #pager-contents {
 background: #ebdbb2 !important;
 background-color: #ebdbb2 !important;
}
div#pager pre {
 color: #3c3836 !important;
 background: #fbf1c7 !important;
 background-color: #fbf1c7 !important;
 padding: 0.4em;
}
div#pager .ui-resizable-handle {
 top: 0px;
 height: 8px;
 background: #3c3836 !important;
 border-top: 1px solid #3c3836;
 border-bottom: 1px solid #3c3836;
}
div.CodeMirror,
div.CodeMirror pre {
 font-family: monospace, monospace;
 font-size: 11pt;
 line-height: 170%;
 color: #3c3836;
}
div.CodeMirror-lines {
 padding-bottom: .9em;
 padding-left: .5em;
 padding-right: 1.5em;
 padding-top: .7em;
}
span.ansiblack,
.ansi-black-fg {
 color: #ebdbb2;
}
span.ansiblue,
.ansi-blue-fg,
.ansi-blue-intense-fg {
 color: #458588;
}
span.ansigray,
.ansi-gray-fg,
.ansi-gray-intense-fg {
 color: #1d2021;
}
span.ansigreen,
.ansi-green-fg {
 color: #98971a;
}
.ansi-green-intense-fg {
 color: #1d2021;
}
span.ansipurple,
.ansi-purple-fg,
.ansi-purple-intense-fg {
 color: #d3869b;
}
span.ansicyan,
.ansi-cyan-fg,
.ansi-cyan-intense-fg {
 color: #d3869b;
}
span.ansiyellow,
.ansi-yellow-fg,
.ansi-yellow-intense-fg {
 color: #d79921;
}
span.ansired,
.ansi-red-fg,
.ansi-red-intense-fg {
 color: #cc241d;
}
div.output-stderr {
 background-color: #d65d0e;
}
div.output-stderr pre {
 color: #d5c4a1;
}
div.js-error {
 color: #cc241d;
}
.ipython_tooltip {
 font-family: monospace, monospace;
 font-size: 11pt;
 line-height: 170%;
 border: 2px solid #f8e7a1;
 background: #fbf1c7;
 background-color: #fbf1c7;
 border-radius: 2px;
 overflow-x: visible;
 overflow-y: visible;
 box-shadow: none;
 position: absolute;
 z-index: 1000;
}
.ipython_tooltip .tooltiptext pre {
 font-family: monospace, monospace;
 font-size: 11pt;
 line-height: 170%;
 background: #fbf1c7;
 background-color: #fbf1c7;
 color: #3c3836;
 overflow-x: visible;
 overflow-y: visible;
 max-width: 900px;
}
div#tooltip.ipython_tooltip {
 overflow-x: wrap;
 overflow-y: visible;
 max-width: 800px;
}
div.tooltiptext.bigtooltip {
 overflow-x: visible;
 overflow-y: scroll;
 height: 400px;
 max-width: 800px;
}
.cm-s-ipython.CodeMirror {
 font-family: monospace, monospace;
 font-size: 11pt;
 background: #fbf1c7;
 color: #3c3836;
 border-radius: 2px;
 font-style: normal;
 font-weight: normal;
}
.cm-s-ipython div.CodeMirror-selected {
 background: #d5c4a1;
}
.CodeMirror-gutters {
 border: none;
 border-right: 1px solid #fbf1c7 !important;
 background-color: #fbf1c7 !important;
 background: #fbf1c7 !important;
 border-radius: 0px;
 white-space: nowrap;
}
.cm-s-ipython .CodeMirror-gutters {
 background: #fbf1c7;
 border: none;
 border-radius: 0px;
 width: 36px;
}
.cm-s-ipython .CodeMirror-linenumber {
 color: #504945;
}
.CodeMirror-sizer {
 margin-left: 40px;
}
.CodeMirror-linenumber,
div.CodeMirror-linenumber,
.CodeMirror-gutter.CodeMirror-linenumberdiv.CodeMirror-gutter.CodeMirror-linenumber {
 padding-right: 1px;
 margin-left: 0px;
 margin: 0px;
 width: 26px !important;
 padding: 0px;
 text-align: right;
}
.CodeMirror-linenumber {
 color: #504945;
}
.cm-s-ipython .CodeMirror-cursor {
 border-left: 2px solid #0095ff !important;
}
.cm-s-ipython span.cm-comment {
 color: #928374;
 font-style: italic;
}
.cm-s-ipython span.cm-atom {
 color: #b16286;
}
.cm-s-ipython span.cm-number {
 color: #458588;
}
.cm-s-ipython span.cm-property {
 color: #3c3836;
}
.cm-s-ipython span.cm-attribute {
 color: #3c3836;
}
.cm-s-ipython span.cm-keyword {
 color: #cc241d;
 font-weight: normal;
}
.cm-s-ipython span.cm-string {
 color: #98971a;
}
.cm-s-ipython span.cm-meta {
 color: #d3869b;
}
.cm-s-ipython span.cm-operator {
 color: #b16286;
}
.cm-s-ipython span.cm-builtin {
 color: #b16286;
}
.cm-s-ipython span.cm-variable {
 color: #3c3836;
}
.cm-s-ipython span.cm-variable-2 {
 color: #689d6a;
}
.cm-s-ipython span.cm-variable-3 {
 color: #d3869b;
}
.cm-s-ipython span.cm-def {
 color: #458588;
 font-weight: normal;
}
.cm-s-ipython span.cm-error {
 background: #fbf1c7;
}
.cm-s-ipython span.cm-tag {
 color: #458588;
}
.cm-s-ipython span.cm-link {
 color: #458588;
}
.cm-s-ipython span.cm-storage {
 color: #b16286;
}
.cm-s-ipython span.cm-entity {
 color: #98971a;
}
.cm-s-ipython span.cm-quote {
 color: #98971a;
}
div.CodeMirror span.CodeMirror-matchingbracket {
 color: #ffffff;
 font-weight: bold;
 background-color: #458588;
}
div.CodeMirror span.CodeMirror-nonmatchingbracket {
 color: #ffffff;
 font-weight: bold;
 background: #cc241d !important;
}
.cm-header-1 {
 font-size: 215%;
}
.cm-header-2 {
 font-size: 180%;
}
.cm-header-3 {
 font-size: 150%;
}
.cm-header-4 {
 font-size: 120%;
}
.cm-header-5 {
 font-size: 100%;
}
.cm-s-default .cm-hr {
 color: #b16286;
}
div.cell.text_cell .cm-s-default .cm-header {
 font-family: sans-serif;
 font-weight: normal;
 color: #d79921 !important;
 margin-top: 0.3em !important;
 margin-bottom: 0.3em !important;
}
div.cell.text_cell .cm-s-default span.cm-variable-2 {
 color: #3c3836 !important;
}
div.cell.text_cell .cm-s-default span.cm-variable-3 {
 color: #d3869b !important;
}
.cm-s-default span.cm-comment {
 color: #928374 !important;
}
.cm-s-default .cm-tag {
 color: #3c3836;
}
.cm-s-default .cm-builtin {
 color: #b16286;
}
.cm-s-default .cm-string {
 color: #98971a;
}
.cm-s-default .cm-keyword {
 color: #cc241d;
}
.cm-s-default .cm-number {
 color: #458588;
}
.cm-s-default .cm-error {
 color: #b16286;
}
.cm-s-default .cm-link {
 color: #458588;
}
.cm-s-default .cm-atom {
 color: #458588;
}
.cm-s-default .cm-def {
 color: #458588;
}
.CodeMirror-cursor {
 border-left: 2px solid #0095ff !important;
 border-right: none;
 width: 0;
}
.cm-s-default div.CodeMirror-selected {
 background: #d5c4a1;
}
.cm-s-default .cm-selected {
 background: #d5c4a1;
}
.MathJax_Display,
.MathJax {
 border: 0 !important;
 font-size: 100% !important;
 text-align: center !important;
 margin: 0em !important;
 line-height: 2.25 !important;
}
.MathJax:focus,
body :focus .MathJax {
 display: inline-block !important;
}
.MathJax:focus,
body :focus .MathJax {
 display: inline-block !important;
}
.completions {
 position: absolute;
 z-index: 110;
 overflow: hidden;
 border: medium solid rgba(215,153,33,.50);
 box-shadow: none;
 line-height: 1;
}
.completions select {
 background: #fbf1c7;
 background-color: #fbf1c7;
 outline: none;
 border: none;
 padding: 0px;
 margin: 0px;
 margin-left: 2px;
 overflow: auto;
 font-family: monospace, monospace;
 font-size: 11pt;
 color: #3c3836;
 width: auto;
}
div#maintoolbar {
 margin-left: 8px !important;
}
.toolbar.container {
 width: 100% !important;
}
span.save_widget span.filename {
 margin-left: 8px;
 height: initial;
 font-size: 100%;
 color: #3c3836;
 background-color: #fbf1c7;
}
span.save_widget span.filename:hover {
 color: #928374;
 background-color: #fbf1c7;
}
#menubar {
 padding-top: 4px;
 background-color: #ebdbb2;
}



/* Change outer background and make the notebook take all available width */
.container {
    width: 99% !important;
    background: #DDC !important;
    background-image: url("endless-constellation.svg");
  
    
    
}   

/* Change inner background (CODE) */
div.input_area {
    background: #F4F4E2 !important;
    font-size: 16px !important;
}

/* Change global font size (CODE) */
.CodeMirror {
    font-size: 16px !important;
}  

/* Prevent the edit cell highlight box from getting clipped;
 * important so that it also works when cell is in edit mode */
div.cell.selected {
    border-left-width: 1px !important;
} 



<script>
    MathJax.Hub.Config({
        "HTML-CSS": {
            /*preferredFont: "TeX",*/
            /*availableFonts: ["TeX", "STIX"],*/
            styles: {
                scale: 100,
                ".MathJax_Display": {
                    "font-size": "100%",
                }
            }
        }
    });
</script>
    


!locate custom.css |grep jupyter

!ls COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv



!pip show basemap | grep Location

import os
import inspect
print(inspect.getfile(Basemap))

import os.path
from mpl_toolkits.basemap import Basemap
import mpl_toolkits.basemap
print(os.path.abspath('mpl_toolkits.basemap'))

!locate etopo20data.gz

!ls *.html

!ls COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/

import matplotlib.pyplot as plt
from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon
import numpy as np
from PIL import Image,ImageFont,ImageDraw,ImageFilter,ImageChops
from random import randint
from mpl_toolkits.basemap import Basemap
#prevents a warning from using Python3 instaead of Python2
import warnings
warnings.filterwarnings("ignore")
import sys
sys.path.insert(1, "/home/jack/hidden")
import Key
import twython
from twython import Twython
# Make the figure
#fig = plt.figure()
#ax = fig.add_subplot(111)

# Easiest way to make a basemap is to use the cylidrical projection and 
# define the bottom left lat/lon and top right lat/lon corners

def RndState():
    TX=["Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming"]
    x=randint(1,50)
    return TX[x]
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/05-10-2020.csv"
#LASTFILE="csse_covid_19_data/csse_covid_19_daily_reports/03-30-2020.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
LATd=[]
LONGd=[]
STATES=[]
cases=[]
deaths =[]
longitude = ""
search = RndState()
for line in DataIn:
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    if search in line[2] and "-" in (line[6]):
        text=line[2],line[1],line[3],line[4],line[5],line[6],line[7],line[8],line[9],line[10]
        STATES.append(text)
        LAT.append(line[5])
        LONG.append(line[6])
        if int(line[8])>0:
            LATd.append(line[5])
            LONGd.append(line[6])        
        cases.append(line[7])
        deaths.append(line[8])
        longitude = longitude+line[6]+","
print(len(STATES))        
LT = np.array(LAT,dtype=np.float)
LG = np.array(LONG,dtype=np.float)
LTd = np.array(LATd,dtype=np.float)
LGd = np.array(LONGd,dtype=np.float)


fig = plt.figure(num=None, figsize=(10,8), dpi=80, facecolor='salmon')


urcrnrlat=max(LT)+.5
llcrnrlat=min(LT)-.5
urcrnrlon=max(LG)+.8
llcrnrlon=min(LG)-.5
lat_0 = (urcrnrlat+llcrnrlat)/2
lon_0 =(urcrnrlon+llcrnrlon)/2

# create the map object, m
m = Basemap(resolution='i', projection='cyl', \
    llcrnrlon=llcrnrlon, llcrnrlat=llcrnrlat, urcrnrlon=urcrnrlon, urcrnrlat=urcrnrlat)

# Note: You can define the resolution of the map you just created. Higher 
# resolutions take longer to create.
#    'c' - crude
#    'l' - low
#    'i' - intermediate
#    'h' - high
#    'f' - full

# Draw some map elements on the map
m.drawmapboundary(fill_color='aqua')
m.fillcontinents(color='#ddaa66',lake_color='aqua')
m.drawcoastlines()
m.drawrivers(linewidth=1.0,color='navy',zorder=8)
m.drawcounties(linewidth=1.0, linestyle='solid', color='gray', antialiased=1, facecolor='lightgreen', ax=None, zorder=2, drawbounds=True)
m.drawstates(linewidth=1.5, linestyle='solid', color='black', antialiased=1,zorder=2, )
plt.text(llcrnrlon,llcrnrlat+.5, search, color='black', fontsize=24.5, zorder=6,bbox=dict(facecolor='salmon'))

# Drawing ArcGIS Basemap (only works with cylc projections??)
# Examples of what each map looks like can be found here:
# http://kbkb-wx-python.blogspot.com/2016/04/python-basemap-background-image-from.html
maps = ['ESRI_Imagery_World_2D',    # 0
        'ESRI_StreetMap_World_2D',  # 1
        'NatGeo_World_Map',         # 2
        'NGS_Topo_US_2D',           # 3
        'Ocean_Basemap',            # 4
        'USA_Topo_Maps',            # 5
        'World_Imagery',            # 6
        'World_Physical_Map',       # 7
        'World_Shaded_Relief',      # 8
        'World_Street_Map',         # 9
        'World_Terrain_Base',       # 10
        'World_Topo_Map'            # 11
        ]
print ("drawing image from arcGIS server..."),
m.arcgisimage(service=maps[8], xpixels=1000, verbose=False)
print ("...finished")

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

Sd=0
Sized=[]
for xd in deaths:
    Sd=0+(float(xd)*.1)
    Sized.append(int(Sd))
    #print(int(S))
sd = np.array(Sized)
#print(Sized)
plt.title("COVID-19:\n Cases: (black)\n Deaths(red) \n Location:\n "+search+"\n", fontsize=15, loc='right')
#plt.text(max(LG-1.2),max(LT), search, color='white', fontsize=24)
#x, y = m(lons, lats)  # transform coordinates
x, y = m(LGd, LTd)
xx,yy = m(LG, LT)
plt.xlabel('Longitude',color="white", fontsize=24)
plt.ylabel('Latitute',color="white", fontsize=24)

m.scatter(xx, yy, s=s, color='black', zorder=5, alpha=0.6)
m.scatter(x, y, s=sd, color='r', zorder=10,  alpha=0.6)



#plt.scatter(x, y,  s=s, color="black", zorder=3, alpha=0.6)
#plt.scatter(x, y,  s=sd, color="red", zorder=6, alpha=0.6)
#plt.text(urcrnrlon,urcrnrlat, search, color='white', fontsize=24)
plt.savefig("BaseMap/"+search+"arcGIS__.png", dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)
#plt.show()
# Plot a scatter point at WBB on the map object
#lon = -111.85
#lat = 40.77
#m.scatter(lon,lat,c='r',s=150)

# Plot some wind barbs
#lons = np.arange(-115,-100,.5)
#lats = np.arange(33,48,.5)
#u = np.arange(-5,10,.5)
#v = np.arange(5,20,.5)
#m.barbs(lons, lats, u, v, color='fuchsia')

# Plot line between two points
# (can also use greatcircle function to be more accurate)
#x = [-110, -112]
#y = [40, 42]
#m.plot(x, y, color='navy', lw=5)

# Fill two polygon shapes
#patches = []
#homeplate = np.array([[-114,38],[-113,37],[-112,38],[-112,40],[-114,40]])
#patches.append(Polygon(homeplate))
#triangle = np.array([[-111,38],[-110,37],[-110,42]])
#patches.append(Polygon(triangle))
#ax.add_collection(PatchCollection(patches, facecolor='lightgreen', edgecolor='k', linewidths=1.5))

# Plot shapefiles: see here: http://basemaptutorial.readthedocs.io/en/latest/shapefile.html

# Plot contours
#m.contour(lons2D, lats2D, values2D)  # contour lines
# m.contourf(lons2D, lats2D, values2D) # contour color filled, can specify a cmap

# Plot gridded data
# m.pcolormesh(lons2D, lats2D, values2D) # can specify a cmap

# Add plot title and other plot elements the normal way
filename0 = "BaseMap/"+search+"arcGIS__.png"


def draw_blurred_back(img, position, text, font, col, halo_col):
    halo = Image.new('RGBA', img.size, (0, 0, 0, 0))
    ImageDraw.Draw(halo).text(position, text, font = font, fill = halo_col)
    blurred_halo = halo.filter(ImageFilter.BLUR)
    ImageDraw.Draw(blurred_halo).text(position, text, font = font, fill = col)
    return Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))

if __name__ == '__main__':
    
    basewidth = 720
    inp = Image.open(filename0)
    wpercent = (basewidth / float(inp.size[0]))
    hsize = int((float(inp.size[1]) * float(wpercent)))
    inp = inp.resize((basewidth, hsize), Image.ANTIALIAS)
    #img.save(resized_image.jpg')
    
    #inp = inp.resize((640,640), Image.ANTIALIAS)
    font = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 30)
    text_title = (255, 255,230) # bright green
    blur_title = (0, 0, 0)   # black

    i2 = draw_blurred_back(inp, (15, 30), "Plotting COVID-19 Data", font, text_title, blur_title)
    font0 = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 20)
    font1 = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 14)
    font2 = ImageFont.truetype("/home/jack/fonts/PatrickHand-Regular.ttf", 16)
    i2 = draw_blurred_back(i2, (15, 65), "Plot Using ArcGIS Basemap - "+search, font0, text_title, blur_title)
    TXT="https://github.com/JupyterJones/COVID-19-Jupyter-Notebooks"
    draw = ImageDraw.Draw(i2) 
    draw.text((15, 5), TXT, font = font2, align ="left",fill="black")
    #i2 = draw(i2, (15, 65),TXT, font1)    
    
    #txt = Image.new('RGBA', i.size, (255,255,255,0))

    # get a font
    fnt = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 20)
    # get a drawing context
    signature_ = "@jacklnorthrup" 
    #get length in pixel of signature_
    sizeS,ln = fnt.getsize(signature_)
    #add 15 pixels to right border
    pt = sizeS+25
    width, height = inp.size
    #marginx starting point of signature_
    marginx = pt
    #bottom margin
    marginy = 30
    x = width - marginx
    y = height - marginy
    

    text_sig = (255, 255,230) # bright green
    blur_sig = (0, 0, 0)   # black
    txt=draw_blurred_back(i2,(x,y), signature_, fnt, text_sig, blur_sig)
    out = Image.alpha_composite(i2, txt)
    out.save("images/TEMP_POST.png")

CONSUMER_KEY = Key.twiter()[0]
CONSUMER_SECRET = Key.twiter()[1]
ACCESS_KEY = Key.twiter()[2]
ACCESS_SECRET = Key.twiter()[3]
twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)

STR = "#"+search+"  #arcGIS server #Basemap #COVID-19 - #Python  Plot data using "+TXT+" #JupyterJones" 

PATH = "images/TEMP_POST.png"
photo = open(PATH,'rb')
#response = twitter.upload_media(media=photo)
#twitter.update_status(status=STR, media_ids=[response['media_id']])

from PIL import Image
PATH = "images/TEMP_POST.png"
IM = Image.open(PATH)
print(IM.size)
IM

import matplotlib.pyplot as plt
from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon
import numpy as np
from PIL import Image,ImageFont,ImageDraw,ImageFilter,ImageChops
from random import randint
from mpl_toolkits.basemap import Basemap
from US_State_Bounding_Boxes import GetCOOR # get coordinates for state(box)
#prevents a warning from using Python3 instaead of Python2
import warnings
warnings.filterwarnings("ignore")
import sys
sys.path.insert(1, "/home/jack/hidden")
import Key
import twython
from twython import Twython
# Make the figure
#fig = plt.figure()
#ax = fig.add_subplot(111)

# Easiest way to make a basemap is to use the cylidrical projection and 
# define the bottom left lat/lon and top right lat/lon corners

def RndState():
    TX=["Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming"]
    x=randint(1,50)
    return TX[x]
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-25-2020.csv"
#LASTFILE="csse_covid_19_data/csse_covid_19_daily_reports/03-30-2020.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
LATd=[]
LONGd=[]
STATES=[]
cases=[]
deaths =[]
longitude = ""
search = RndState()
#search = "Florida"
for line in DataIn:
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    if search in line[2] and "-" in (line[6]):
        text=line[2],line[1],line[3],line[4],line[5],line[6],line[7],line[8],line[9],line[10]
        STATES.append(text)
        LAT.append(line[5])
        LONG.append(line[6])
        if int(line[8])>0:
            LATd.append(line[5])
            LONGd.append(line[6])        
        cases.append(line[7])
        deaths.append(line[8])
        longitude = longitude+line[6]+","
print(len(STATES))        
LT = np.array(LAT,dtype=np.float)
LG = np.array(LONG,dtype=np.float)
LTd = np.array(LATd,dtype=np.float)
LGd = np.array(LONGd,dtype=np.float)

fig = plt.figure(num=None, figsize=(12,10), dpi=80, facecolor='salmon')
coor= GetCOOR(search)
urcrnrlat = coor[0]+.5
llcrnrlat = coor[1]-.5
urcrnrlon = coor[2]+.5
llcrnrlon = coor[3]-.5

lat_0 = (urcrnrlat+llcrnrlat)/2
lon_0 =(urcrnrlon+llcrnrlon)/2
# create the map object, m
m = Basemap(resolution='h', projection='cyl', \
    llcrnrlon=llcrnrlon, llcrnrlat=llcrnrlat, urcrnrlon=urcrnrlon, urcrnrlat=urcrnrlat)

# Note: You can define the resolution of the map you just created. Higher 
# resolutions take longer to create.
#    'c' - crude
#    'l' - low
#    'i' - intermediate
#    'h' - high
#    'f' - full


# Draw some map elements on the map
#m.drawmapboundary(fill_color='aqua')
#m.fillcontinents(color='#ddaa66',lake_color='aqua')
#m.drawcoastlines()
#m.drawrivers(linewidth=1.0,color='navy',zorder=8)
#m.drawcounties(linewidth=1.0, linestyle='solid', color='gray', antialiased=1, facecolor=None, ax=None, zorder=2, drawbounds=True)
#m.drawstates(linewidth=1.5, linestyle='solid', color='black', antialiased=1,zorder=2, )
plt.text(llcrnrlon,llcrnrlat, search, color='firebrick', fontsize=24.5, zorder=6,bbox=dict(facecolor='salmon'))

# Drawing ArcGIS Basemap (only works with cylc projections??)
# Examples of what each map looks like can be found here:
# http://kbkb-wx-python.blogspot.com/2016/04/python-basemap-background-image-from.html
maps = ['ESRI_Imagery_World_2D',    # 0
        'ESRI_StreetMap_World_2D',  # 1
        'NatGeo_World_Map',         # 2
        'NGS_Topo_US_2D',           # 3
        'Ocean_Basemap',            # 4
        'USA_Topo_Maps',            # 5
        'World_Imagery',            # 6
        'World_Physical_Map',       # 7
        'World_Shaded_Relief',      # 8
        'World_Street_Map',         # 9
        'World_Terrain_Base',       # 10
        'World_Topo_Map'            # 11
        ]
print ("drawing image from arcGIS server..."),
#m.arcgisimage(service=maps[9], xpixels=1000, verbose=False)
m.arcgisimage(service=maps[8], xpixels = 3500, dpi=500, verbose= True)
m.drawstates()
print ("...finished")

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.5)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

Sd=0
Sized=[]
for xd in deaths:
    Sd=0+(float(xd))
    Sized.append(int(Sd))
    #print(int(S))
sd = np.array(Sized)
#print(Sized)
plt.title("COVID-19:\n Cases: (black)\n Deaths(red) \n Location:\n "+search+"\n", fontsize=15, loc='right')
#plt.text(max(LG-1.2),max(LT), search, color='white', fontsize=24)
#x, y = m(lons, lats)  # transform coordinates
x, y = m(LGd, LTd)
xx,yy = m(LG, LT)
plt.xlabel('Longitude',color="white", fontsize=24)
plt.ylabel('Latitute',color="white", fontsize=24)

m.scatter(xx, yy, s=s, color='black', zorder=5, alpha=0.6)
m.scatter(x, y, s=sd, color='r', zorder=10,  alpha=0.6)

#plt.text(urcrnrlon,urcrnrlat, search, color='white', fontsize=24)
plt.savefig("BaseMap/"+search+"arcGIS__.png", dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)
#plt.show()
# Plot a scatter point at WBB on the map object
#lon = -111.85
#lat = 40.77
#m.scatter(lon,lat,c='r',s=150)

filename0 = "BaseMap/"+search+"arcGIS__.png"


def draw_blurred_back(img, position, text, font, col, halo_col):
    halo = Image.new('RGBA', img.size, (0, 0, 0, 0))
    ImageDraw.Draw(halo).text(position, text, font = font, fill = halo_col)
    blurred_halo = halo.filter(ImageFilter.BLUR)
    ImageDraw.Draw(blurred_halo).text(position, text, font = font, fill = col)
    return Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))

if __name__ == '__main__':
    
    basewidth = 720
    inp = Image.open(filename0)
    wpercent = (basewidth / float(inp.size[0]))
    hsize = int((float(inp.size[1]) * float(wpercent)))
    inp = inp.resize((basewidth, hsize), Image.ANTIALIAS)
    #img.save(resized_image.jpg')
    
    #inp = inp.resize((640,640), Image.ANTIALIAS)
    font = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 30)
    text_title = (255, 255,230) # bright green
    blur_title = (0, 0, 0)   # black

    i2 = draw_blurred_back(inp, (15, 35), "Plotting COVID-19 Data", font, text_title, blur_title)
    font0 = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 20)
    font1 = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 14)
    font2 = ImageFont.truetype("/home/jack/fonts/PatrickHand-Regular.ttf", 18)
    i2 = draw_blurred_back(i2, (15, 70), "Plot Using ArcGIS Basemap - "+search, font0, text_title, blur_title)
    TXT="https://github.com/JupyterJones/COVID-19-Jupyter-Notebooks"
    draw = ImageDraw.Draw(i2) 
    draw.text((15, 10), TXT, font = font2, align ="left",fill="black")
    #i2 = draw(i2, (15, 65),TXT, font1)    
    
    #txt = Image.new('RGBA', i.size, (255,255,255,0))

    # get a font
    fnt = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 20)
    # get a drawing context
    signature_ = "@jacklnorthrup" 
    #get length in pixel of signature_
    sizeS,ln = fnt.getsize(signature_)
    #add 15 pixels to right border
    pt = sizeS+25
    width, height = inp.size
    #marginx starting point of signature_
    marginx = pt
    #bottom margin
    marginy = 30
    x = width - marginx
    y = height - marginy
    

    text_sig = (255, 255,230) # bright green
    blur_sig = (0, 0, 0)   # black
    txt=draw_blurred_back(i2,(x,y), signature_, fnt, text_sig, blur_sig)
    out = Image.alpha_composite(i2, txt)
    out.save("images/TEMP_POST.png")

CONSUMER_KEY = Key.twiter()[0]
CONSUMER_SECRET = Key.twiter()[1]
ACCESS_KEY = Key.twiter()[2]
ACCESS_SECRET = Key.twiter()[3]
twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)

STR = "Plot data using #World_Shaded_Relief "+TXT+" #JupyterJones #"+search+"  #arcGIS server #Basemap #COVID-19 - #Python" 

PATH = "images/TEMP_POST.png"
photo = open(PATH,'rb')
#response = twitter.upload_media(media=photo)
#twitter.update_status(status=STR, media_ids=[response['media_id']])

import matplotlib.pyplot as plt
import numpy as np
from mpl_toolkits.basemap import Basemap
from random import randint
from US_State_Bounding_Boxes import GetCOOR
def RndState():
    TX=["Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming"]
    x=randint(1,50)
    return TX[x]


search = RndState()
fig = plt.figure(num=None, figsize=(12,10), dpi=80, facecolor='salmon')
coor= GetCOOR(search)
urcrnrlat = coor[0]+.5
llcrnrlat = coor[1]-.5
urcrnrlon = coor[2]+.5
llcrnrlon = coor[3]-.5

lat_0 = (urcrnrlat+llcrnrlat)/2
lon_0 =(urcrnrlon+llcrnrlon)/2



## Map in cylindrical projection (data points may apear skewed)
m = Basemap(resolution='i',projection='cyl',\
            llcrnrlon=llcrnrlon,llcrnrlat=llcrnrlat,\
            urcrnrlon=urcrnrlon,urcrnrlat=urcrnrlat,)


map_list = [
'ESRI_Imagery_World_2D',    # 0
'ESRI_StreetMap_World_2D',  # 1
'NatGeo_World_Map',         # 2
'NGS_Topo_US_2D',           # 3
#'Ocean_Basemap',            # 4
'USA_Topo_Maps',            # 5
'World_Imagery',            # 6
'World_Physical_Map',       # 7     Still blurry
'World_Shaded_Relief',      # 8
'World_Street_Map',         # 9
'World_Terrain_Base',       # 10
'World_Topo_Map'            # 11
]

for maps in map_list: 
    plt.figure(figsize=[10,20])    
    ## Instead of using WRF terrain fields you can get a high resolution image from ESRI
    m.arcgisimage(service=maps, xpixels = 3500, dpi=500, verbose= True)
    m.drawstates()
    plt.title(maps)
    
    plt.savefig('00'+maps, dpi=120, bbox_inches="tight")

!pip install functions_domains_models

m.arcgisimage(service=maps, xpixels = 3500, dpi=500, verbose= True)

#https://www.youtube.com/watch?v=eXpbE5YmXrs days 7-9

!ls

!ls COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/05*

from matplotlib import pyplot as plt
import numpy as np
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/05-08-2020.csv"
DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
deaths = []
STate = input("What State? ")
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt <15:print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
        deaths.append(int(line[8]))
LA = LAT
LO = LON
print("---------------------------")
print("len(LA)",len(LA))
print("len(LO)",len(LO))
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)
print ("max(LT)",max(LT))
print ("min(LT)",min(LT))
print ('max(LG)',max(LG))
print ('min(LG)',min(LG))
print('len(LT)',len(LT))
print('len(LG)',len(LG))




print (min(cases))
print(max(cases))
print(len(cases))
print(cases)
print("\nNumber of Cases by Country:",sum(cases))
print("-----------------\n")
print(deaths)
print("\nNumber of Deaths by Country:",sum(deaths))

fig = plt.figure(num=None, figsize=(12,10), dpi=80, facecolor='salmon')
#fig = plt.figure()
ax = fig.gca()

#ax.set_facecolor('xkcd:green')
ax.set_facecolor(('#8eda8b'))


Size=[]
for x in cases:
    S=5+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

#lgmin= -79.36691763
#lgmax= -72.8012172
#ltmin= 40.74066522
#ltmax= 44.74530905
lgmin= (min(LG))+5
lgmax= (max(LG))-5
ltmin= (min(LT))+5
ltmax= (max(LT))-5

#plt.axis([lgmin,lgmax,ltmin,ltmax])

plt.axis([-85,-80,38,43])
ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.scatter(LG, LT, s=s, color="black")
plt.grid(True)

plt.xlabel('First data sample was: 09/03/2020 04:30:00')
plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
plt.ylabel('Number of Cases')
plt.show()

print (min(cases))
print(max(cases))

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-06-2020.csv"
DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
for lines in DataIn:
    lines = lines.replace("\n","")
    #if cnt<10:print (lines)
    line = lines.split(",")
    if "US" in line[3]:
        cnt=cnt+1
        if cnt<20:print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
print(cnt)            

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/05-07-2020.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
STATES=[]
cases=[]
deaths = []
latNlongNcases=[]
longitude = ""
cnt=0
for line in DataIn:
    #line=line.replace("\n","")
    #line=line.replace("\\n","")
    line=line.split(",")
    #print(line[0],line[1],line[2],line[3],line[4],)
    #if len(line)>10 and 'US' in line[3] and "Recovered" not in line:
    if 'US' in line[3] and "Recovered" not in line:
        cnt=cnt+1
        if "-" not in line[5] and len(line[5])>5 and "-" in line[6] and len(line[6])>5 and int(line[7])>0:    
            text = str(line[1]+' '+line[2]+' '+line[3]+' '+line[4]+' '+line[5]+' '+line[6]+' '+line[7])
            Text =text.split(" ")
            if len(Text)==16:TExt = str(line[1]+' '+line[2]+' '+line[3]+' '+line[4]+' '+line[5]+' '+line[6]+' '+line[7])
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
            TExt = str(line[1]+' '+line[2]+' '+line[3]+' '+line[4]+' '+line[5]+' '+line[6]+' '+line[7]+' '+line[8])
            STATES.append(TExt)
            LAT.append(line[5])
            LONG.append(line[6])
            cases.append(line[7])
            deaths.append(line[8])
            longitude = longitude+line[6]+","
            cnt=cnt
            #print("line[7]",cnt,line[7])
            #latNlongNcases.append(str(cases[7]))
            latNlongNcases.append(TExt)
print("len(STATES)",len(STATES)) 

LA = LAT[:-7]
LO = LONG[:-7]
print("len(LA)",len(LA))
print("len(LO)",len(LO))
print("len(latNlongNcases)",len(latNlongNcases))

print(len(STATES))

from matplotlib import pyplot as plt
import numpy as np
LT = np.array(LAT,dtype=np.float)
LG = np.array(LONG,dtype=np.float)
print (max(LT))
print (min(LT))
print (max(LG))
print (min(LG))

fig = plt.figure(num=None, figsize=(12,10), dpi=80, facecolor='salmon')
#fig = plt.figure()
ax = fig.gca()

#ax.set_facecolor('xkcd:green')
ax.set_facecolor(('#8eda8b'))

plt.axis([-130,-65,20,55])
ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.scatter(LG, LT, s=1, color="black")
plt.grid(True)

plt.xlabel('First data sample was: 09/03/2020 04:30:00')
plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
plt.ylabel('Number of Cases')
plt.show()

from matplotlib import pyplot as plt
import numpy as np
LT = np.array(LAT,dtype=np.float)
LG = np.array(LONG,dtype=np.float)
print (max(LT))
print (min(LT))
print (max(LG))
print (min(LG))

fig = plt.figure(num=None, figsize=(12,10), dpi=80, facecolor='salmon')
#fig = plt.figure()
ax = fig.gca()

#ax.set_facecolor('xkcd:green')
ax.set_facecolor(('#8eda8b'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.01)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

plt.axis([-130,-65,20,55])
ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.scatter(LG, LT, s=s, color="black")
plt.grid(True)

plt.xlabel('First data sample was: 09/03/2020 04:30:00')
plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
plt.ylabel('Number of Cases')
plt.show()

# https://www.latlong.net/c/?lat=44.40000&long=-95.0000

cnt=0
Longitude = longitude.split(",")
for long in Longitude:
    cnt=cnt+1
    if "-" not in long:print(long)


cnt=0
for line in LONG:
    cnt=cnt+1
    if float(line)<-150:
        print(cnt,line)


line = -82.46170658  
if float(line)<=-82 and float(line)>=-82.6170658:
    print(True)

from matplotlib import pyplot as plt
import numpy as np
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/05-08-2020.csv"
DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
#STate = input("What State? ")
STate = 'Florida'
for lines in DataIn:
    lines = lines.replace("\n","")

    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON

print("len(LA)",len(LA))
print("len(LO)",len(LO))
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)
print ("max(LT)",max(LT))
print ("min(LT)",min(LT))
print ('max(LG)',max(LG))
print ('min(LG)',min(LG))
print('len(LT)',len(LT))
print('len(LG)',len(LG))

fig = plt.figure(num=None, figsize=(12,12), dpi=80, facecolor='salmon')
#fig = plt.figure()
ax = fig.gca()

#ax.set_facecolor('xkcd:green')
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

print (min(LG))
print (max(LG))
print (min(LT))
print (max(LT))


longLeft= (min(LG))-5
longRight = (max(LG))+5
lat1 = (min(LT))-5
lat2 = (max(LT))+5


#if float(line[6])<=-87 and float(line[6])>=-89:
#                if float(line[5])>42 and float(line[5])<44:

#-90 and float(line[6])>-92 and float(line[5])<40 and float(line[5])<42
#plt.axis([-100,-70,30,45])
plt.axis([longLeft,longRight,lat1,lat2])
#plt.axis([-80,-90,40,45])
ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.scatter(LG, LT, s=s, color="black")
plt.grid(True)

plt.xlabel('First data sample was: 09/03/2020 04:30:00')
plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
plt.ylabel('Number of Cases')
plt.show()

from matplotlib import pyplot as plt
import numpy as np

LT = np.array(LA,dtype=np.float)
LG = np.array(LO,dtype=np.float)



fig = plt.figure(num=None, figsize=(10,8), dpi=80, facecolor='salmon')
#fig = plt.figure()
ax = fig.gca()
print (min(LG))
print (max(LG))
print (min(LT))
print (max(LT))
print("-------------------")
print (len(LT))
print (len(LG))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

longLeft= (min(LG))-2
longRight = (max(LG))+2
lat1 = (min(LT))-2
lat2 = (max(LT))+2

#plt.axis([-123.89740630000001,-115.36690420000001, 28.03484597,41.74228275])
#plt.axis([-128.89740630000001,-110.36690420000001, 28.03484597,46.74228275])
ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.axis([longLeft,longRight,lat1,lat2])

plt.scatter(LG, LT, s=s)
plt.grid(True)

plt.xlabel('First dat sample was: 09/03/2020 04:30:00')
plt.title('JupyterJones  ;  CSSEGISandData-COVID-19_GitHub')
plt.ylabel('Number of Cases')
plt.show()

# Query the data by location

print (min(LG))
print (max(LG))
print (min(LT))
print (max(LT))

!ls csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv

!ls csse_covid_19_data/csse_covid_19_time_series/

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"
DataIn = open(LASTFILE).readlines()
#SEARCH = input("SEARCH: ")
SEARCH = "Philippine"
cnt = 0
PHcases = [] 
counts=[]
for line in DataIn:
    cnt=cnt+1
    line=line.lstrip(",")
    if SEARCH in line:
        print(line[23:])
        entries = line[23:].split(",")
        for entry in entries:
            print (entry, end= " ")
            PHcases.append(int(entry))

print(PHcases) 

import numpy as np
x = np.asarray(PHcases)
print("-----------------")
print (len(PHcases))
print("-----------------")
cntTOTAL = range(0,len(x))
print (cntTOTAL)
y = np.asarray(cntTOTAL)
print("-----------------")   
for num in cntTOTAL:
    print (num, end=" ")
print("-----------------")    
print (y) 
print("\n------- These bottom two number must match ----------")   
print("How many numbers to use for x co-ordinates: ",len(x))
print("How many numbers to use for y co-ordinates: ",len(y))

fig = plt.figure(num=None, figsize=(12,10), dpi=80, facecolor='#c81025')
#fig = plt.figure()
ax = fig.gca()

#ax.set_facecolor('xkcd:green')
ax.set_facecolor(('#0036a3'))

S=1
Size=[]
for size in x:
    S=1+(float(size)*.05)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.scatter(y, x, s=s, color="#f4ca15")
plt.grid(True)

plt.xlabel('First data sample was: 09/03/2020 04:30:00')
plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
plt.ylabel('Number of Cases')
plt.show()

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/05-08-2020.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
STATES=[]
cases=[]
latNlongNcases=[]
longitude = ""
cnt=0
for line in DataIn:
    #line=line.replace("\n","")
    #line=line.replace("\\n","")
    line=line.split(",")
    #print(line[0],line[1],line[2],line[3],line[4],)
    #if len(line)>10 and 'US' in line[3] and "Recovered" not in line:
    if 'Philippine' in line[3] and "Recovered" not in line:
        cnt=cnt+1
        if "-" not in line[5] and len(line[5])>5 and "-" in line[6] and len(line[6])>5 and int(line[7])>0:    
            text = str(line[1]+' '+line[2]+' '+line[3]+' '+line[4]+' '+line[5]+' '+line[6]+' '+line[7])
            Text =text.split(" ")
            if len(Text)==16:
                TExt = str(line[1]+' '+line[2]+' '+line[3]+' '+line[4]+' '+line[5]+' '+line[6]+' '+line[7])
            if cnt==1:
                print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
            #plt.axis([-95,-90,44,49]) 43.013484 -87.917006
            if float(line[6])<=-87 and float(line[6])>=-89:
                if float(line[5])>42 and float(line[5])<44:
                    print(line)
                #print(line) 
            STATES.append(TExt)
            LAT.append(line[5])
            LONG.append(line[6])
            cases.append(line[7])
            longitude = longitude+line[6]+","
            cnt=cnt+1
            #print("line[7]",cnt,line[7])
            #latNlongNcases.append(str(cases[7]))
            latNlongNcases.append(TExt)
print("len(STATES)",len(STATES)) 

LA = LAT[:-7]
LO = LONG[:-7]
print("len(LA)",len(LA))
print("len(LO)",len(LO))
print("len(latNlongNcases)",len(latNlongNcases))


from matplotlib import pyplot as plt
import numpy as np
LT = np.array(LAT,dtype=np.float)
LG = np.array(LONG,dtype=np.float)




LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"
DataIn = open(LASTFILE).readlines()
#SEARCH = input("SEARCH: ")
SEARCH = "Philippine"
PHcases = ''
PHdeaths = ''
cnt = 0
CNTS=0
counts=[]
for line in DataIn:
    cnt=cnt+1
    line=line.lstrip(",")
    if SEARCH in line:
        print("Cases: ",line)
        PHcases=PHcases+line   
        
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"
DataIn = open(LASTFILE).readlines()
cnt = 0
CNTS=0
counts=[]
for line in DataIn:
    cnt=cnt+1
    line=line.lstrip(",")
    if SEARCH in line:
        print("Deaths: ",line)        
        PHdeaths=PHdeaths+line 
        
        
PHC=PHcases[21:-1]
PHC=PHC.split(",")
PHC = list(map(int, PHC)) 

PHD=PHdeaths[21:-1]
PHD=PHD.split(",")
PHD = list(map(int, PHD))

span = 5
end = span-1
span=int(span)
for x in range(span,len(PHC)-end): 

    phd = PHD[x];phc=PHC[x-span]
    phd =int(phd);phc=int(phc)
    try:
        res=phd/phc
        print(round(res,3), end = " ")
    except:
        pass

import numpy as np
print(len(PHD))
print(len(PHC))
Z = np.array(range(0,len(PHD)))
print (len(Z))
X = PHD
Y = PHC

PC = np.array(PHC, dtype=float)
PD = np.array(PHD, dtype=float)
Zf = np.array(Z, dtype=float)
ThreeD = np.dstack([PC,PD,Zf])
print(ThreeD)

A = np.array(X,Y,Z,dtype=float)
A.shape(3,3)
print(A)




#A = numpy.array(X,Y,Z,dtype=float)
#A.shape(3,3)
#print(A)

"""
0,0,0,0,0,0,0,0,1,1,1,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,5,6,10,20,33,49,52,64,111,140,142,187,202,217,230,307,380,462,552,636,707,803,1075,1418,1546,2084

0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,5,8,11,12,12,19,17,18,19,25,33,35,38,45,54,68,71,78,88

"""

LASTFILE="csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"
DataIn = open(LASTFILE).readlines()
#SEARCH = input("SEARCH: ")
SEARCH = "Canada"
PHcases = ''
PHdeaths = ''
cnt = 0
CNTS=0
counts=[]
for line in DataIn:
    cnt=cnt+1
    line=line.lstrip(",")
    if SEARCH in line:
        print(line)
        PHcases=PHcases+line   
        
LASTFILE="csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"
DataIn = open(LASTFILE).readlines()
cnt = 0
CNTS=0
counts=[]
for line in DataIn:
    cnt=cnt+1
    line=line.lstrip(",")
    if SEARCH in line:
        print(line)        
        PHdeaths=PHdeaths+line 
        
        
PHC=PHcases[20:-1]
PHC=PHC.split(",")
PHC = list(map(int, PHC)) 

PHD=PHdeaths[20:-1]
PHD=PHD.split(",")
PHD = list(map(int, PHD))

span = 6
End = span-1
span=int(span)
for x in range(span,len(PHC)-End): 

    phd = PHD[x];phc=PHC[x-span]
    phd =int(phd);phc=int(phc)
    try:
        res=phd/phc
        print(round(res,3), end=" ")
    except:
        pass

88/2084

print(PHD)

LEN =(len(PHD))
LEn = LEN-2
print(PHD[LEn])
print(PHD[-1]-PHD[LEn])

LEN =(len(PHD))
end=LEN-1
INCREASE=[]
for x in range(2,end):
    print(PHD[x+1]-PHD[x], end =" ")
    INCREASE.append(PHD[x+1]-PHD[x])

LEN =(len(PHD))
end=LEN-1
INCREASEP = []
for x in range(2,end):
    try:
        print(round(PHD[x+1]/PHD[x],3), end ="   ")
        INCREASEP.append(float(PHD[x+1]/PHD[x]))
    except ZeroDivisionError:
        INCREASEP.append(0.0)    
        pass

print(INCREASE)

print(INCREASEP)

En=len(INCREASE)-1
EnP=len(INCREASEP)-1
print(En,EnP)

for x in range(1,67):
    X=INCREASE[x]
    Y=INCREASEP[x]
    #print(X, end="  ")
    #print(Y, end="  ")
    print("X",X,"  Y",round(Y,3),"             X*Y: ",int(X*Y))

# ESTIMATE from 895 to 1163

span =5
end = span+1
for x in range(6,len(PHD)-end):
    res=PHD[x]/PHC[x-span]
    print (round(res,3), end="  ")

PHD=PHdeaths[21:-1]
PHD=PHD.split(",")
PHD = list(map(int, PHD))

span = 6
end = span-1
span=int(span)
for x in range(span,len(PHC)-end): 

    phd = PHD[x];phc=PHC[x-span]
    phd =int(phd);phc=int(phc)
    try:
        res=phd/phc
        print(round(res,3))
    except:
        pass

print(PHD[2])



PHD = list(map(int, PHD))

len(PHcases),len(PHdeaths)

!ls csse_covid_19_data/csse_covid_19_time_series/

LASTFILE="csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"
DataIn = open(LASTFILE).readlines()
SEARCH = input("SEARCH: ")
cnt = 0
CNTS=0
counts=[]
for line in DataIn:
    cnt=cnt+1
    line=line.lstrip(",")
    if SEARCH in line:print(line)

import plotly.graph_objects as go
fig = go.Figure()
fig.add_trace(go.Scatter(y=counts))
fig.add_trace(go.Bar(y=counts))
fig.update_layout(title = 'Philippines CONDID-19 Cases')
fig.show()

LASTFILE="csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"
DataIn = open(LASTFILE).readlines()
#SEARCH = input("SEARCH: ")
cnt = 0
CNTS=0
deaths=[]
for line in DataIn:
    cnt=cnt+1
    if cnt ==227:
        print (cnt,line)
        
        line=line.replace("\n","")
        line = line.split(",")
        for item in line:
            CNTS=CNTS+1
            if CNTS>4:
                #print(item)
                deaths.append(item) 
print(len(counts))                 

LASTFILE="csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"
DataIn = open(LASTFILE).readlines()
#SEARCH = input("SEARCH: ")
cnt = 0
CNTS=0
cases=[]
for line in DataIn:
    cnt=cnt+1
    if cnt ==227:
        print (cnt,line)
        
        line=line.replace("\n","")
        line = line.split(",")
        for item in line:
            CNTS=CNTS+1
            if CNTS>4:
                #print(item)
                cases.append(item) 
print(len(cases))                 

print(int(cases[6]))

from __future__ import division
span = 6
num=len(cases)
print(num)
end=num-span
print(end)
increase = 0
for x in range(span,end):
    d=x+span
    mort = int(deaths[d])/int(cases[x])
    try:
        increase = int(deaths[d])/int(deaths[d+1])
    except:
        pass
    print(x,"Mortality",round(mort,3),"Deaths:",deaths[d],"Confirmed_Cases",cases[x],"Death Increase",increase)
print("\n---------------------------------------------\n")
mortt = mort
yy = x
xx = x
for y in range(yy+1,num):
    mortt=mortt-.002
    print(cases[y]," * ",int(int(cases[y])*mort),int(int(cases[y])*mortt))
for z in range(xx,num):
    #mortt=mortt-.002
    mor=.02
    print(deaths[z]," * ",float(int(deaths[z]))/float(int(deaths[z-1])))    

stat_list = """(170, 'March 29, 2020 at 13:46 GMT, there have been 123828 confirmed cases and 2229 deaths due to coronavirus COVID-19 in the United States')
(171, 'March 29, 2020 at 15:47 GMT, there have been 125099 confirmed cases and 2238 deaths due to coronavirus COVID-19 in the United States')
(172, 'March 29, 2020 at 17:49 GMT, there have been 133146 confirmed cases and 2363 deaths due to coronavirus COVID-19 in the United States')
(173, 'March 29, 2020 at 19:47 GMT, there have been 137943 confirmed cases and 2431 deaths due to coronavirus COVID-19 in the United States')
(174, 'March 29, 2020 at 21:48 GMT, there have been 139904 confirmed cases and 2449 deaths due to coronavirus COVID-19 in the United States')
(175, 'March 29, 2020 at 23:49 GMT, there have been 141781 confirmed cases and 2471 deaths due to coronavirus COVID-19 in the United States')
(176, 'March 30, 2020 at 01:44 GMT, there have been 142004 confirmed cases and 2484 deaths due to coronavirus COVID-19 in the United States')
(177, 'March 30, 2020 at 03:46 GMT, there have been 142735 confirmed cases and 2488 deaths due to coronavirus COVID-19 in the United States')
(178, 'March 30, 2020 at 06:46 GMT, there have been 142735 confirmed cases and 2488 deaths due to coronavirus COVID-19 in the United States')
(179, 'March 30, 2020 at 08:50 GMT, there have been 142735 confirmed cases and 2489 deaths due to coronavirus COVID-19 in the United States')
(180, 'March 30, 2020 at 10:50 GMT, there have been 142746 confirmed cases and 2489 deaths due to coronavirus COVID-19 in the United States')
(181, 'March 30, 2020 at 12:50 GMT, there have been 142793 confirmed cases and 2490 deaths due to coronavirus COVID-19 in the United States')
(182, 'March 30, 2020 at 14:50 GMT, there have been 144410 confirmed cases and 2600 deaths due to coronavirus COVID-19 in the United States')
(183, 'March 30, 2020 at 16:50 GMT, there have been 145542 confirmed cases and 2616 deaths due to coronavirus COVID-19 in the United States')
(184, 'March 30, 2020 at 18:50 GMT, there have been 156565 confirmed cases and 2870 deaths due to coronavirus COVID-19 in the United States')
(185, 'March 30, 2020 at 20:50 GMT, there have been 159689 confirmed cases and 2951 deaths due to coronavirus COVID-19 in the United States')
(186, 'March 30, 2020 at 22:50 GMT, there have been 161358 confirmed cases and 2974 deaths due to coronavirus COVID-19 in the United States')
(187, 'March 31, 2020 at 00:50 GMT, there have been 163479 confirmed cases and 3148 deaths due to coronavirus COVID-19 in the United States')
(188, 'March 31, 2020 at 02:50 GMT, there have been 164253 confirmed cases and 3165 deaths due to coronavirus COVID-19 in the United States.')"""
stat_list = stat_list.split("\n")
for STATS in stat_list:
    STATS=str(STATS)
    STATS =STATS.replace("')","\n")
    STATS =STATS.replace(",","")
    STATS =STATS.replace("'","")
    ITEMS =STATS.replace("(","");STATS =STATS.replace(")","")
    #print(ITEMS)
    item =ITEMS.split(" ")
    print(item[1],item[2],item[3],item[5],item[10],item[14])

var = 1.217670286278381
A=2471*var
print(int(A))
B=A*var
print(int(B))
C=B*var
print(int(C))
D=C*var
print (int(D))
print("----------------")
print(2732.3)
print(3087.7)
print(3443.2)

A=43847*1.317676
print(int(A))
B=A*1.3
print(int(B))
C=B*1.3
print(int(C))
D=C*1.3
print (int(D))

942 Confirmed_Cases 13677 
1209 Confirmed_Cases 19100
1581 Confirmed_Cases 25489
2026 Confirmed_Cases 3327678
2467 

import numpy as np

# the given sequence
data =[
[0, 706.0],
[1, 942.0],
[2, 1209.0],
[3, 1581.0],
[4, 2026.0],
[5, 2467.0],
]


X = np.matrix(data)[:,0]
y = np.matrix(data)[:,1]

def J(X, y, theta):
    theta = np.matrix(theta).T
    m = len(y)
    predictions = X * theta
    sqError = np.power((predictions-y),[2])
    return 1/(2*m) * sum(sqError)


dataX = np.matrix(data)[:,0:1]
X = np.ones((len(dataX),2))
X[:,1:] = dataX


# gradient descent function
def gradient(X, y, alpha, theta, iters):
    J_history = np.zeros(iters)
    m = len(y)
    theta = np.matrix(theta).T
    for i in range(iters):
        h0 = X * theta
        delta = (1 / m) * (X.T * h0 - X.T * y)
        theta = theta - alpha * delta
        J_history[i] = J(X, y, theta.T)
    return J_history, theta

print('\n'+40*'=')

# theta initialization
theta = np.matrix([np.random.random(),np.random.random()])
#alpha = 0.01 # learning rate
#iters = 2000 # iterations
alpha = 0.004 # learning rate
iters = 18000 # iterations

print('\n== Model summary ==\nLearning rate: {}\nIterations: {}\nInitial theta: {}\nInitial J: {:.2f}\n'.format(alpha, iters, theta, J(X,y,theta).item()))

print('Training the model... ')
# this actually trains our model and finds the optimal theta value
J_history, theta_min = gradient(X, y, alpha, theta, iters)
print('Done.')
print('\nThe modelled prediction function is:\ny = {:.2f} * x + {:.2f}'.format(theta_min[1].item(), theta_min[0].item()))
print('Its cost equals {:.2f}'.format(J(X,y,theta_min.T).item()))


# This function will calculate the predicted profit
def predict(pop):
    return [1, pop] * theta_min

# Now
p = len(data)
print('\n'+40*'=')
print('The given sequence was:\n', *np.array(data)[:,1])
print('\nBased on learned data, next three predicted numbers in the sequence are {:,.1f} {:,.1f} {:,.1f}'.format(predict(p).item(), predict(p+1).item(), predict(p+2).item()))

print('\nNOTE: The code uses linear regression model exclusively and tries to fit a "straight" line to the data. For polynominal it ought to be added theta_2 and beyond.')

43847/33276

33276*1.317676403413872

A=43847*1.317676
print(int(A))
B=A*1.3
print(int(B))
C=B*1.3
print(int(C))
D=C*1.3
print (int(D))

span = 6
num=len(cases)
print(num)
end=num-span
print(end)
for x in range(span,end):
    d=x+span
    mort = int(deaths[d])/int(cases[x])
    print(x,"  Mortality",round(mort,3),"   Deaths:",deaths[d],"    Confirmed_Cases",cases[x])
print("\n---------------------------------------------\n")
mortt = mort
for y in range(x+1,num):
    mortt=mortt-.002
    print(cases[y]," * ",int(int(cases[y])*mort),int(int(cases[y])*mortt))

import plotly.graph_objects as go
fig = go.Figure()
fig.add_trace(go.Scatter(y=counts))
fig.add_trace(go.Bar(y=counts))
fig.update_layout(title = 'USA CONDID-19 Cases')
fig.show()

LASTFILE="csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"
DataIn = open(LASTFILE).readlines()
SEARCH = input("SEARCH: ")
search = str(SEARCH)
for line in DataIn:
    line=line.replace("\n","")
    line = line.split(",")
    if search in line:
        print(" ".join(line))

import plotly.graph_objects as go

fig = go.Figure(go.Scattergeo())
fig.update_geos(
    visible=False, resolution=110, scope="usa",
    showcountries=True, countrycolor="Black",
    showsubunits=True, subunitcolor="Blue"
)
fig.update_geos(lataxis_showgrid=True, lonaxis_showgrid=True)
fig.update_layout(height=300, margin={"r":0,"t":0,"l":0,"b":0})
fig.show()

import plotly.express as px
df = px.data.gapminder().query("year == 2007")
fig = px.scatter_geo(df, locations="iso_alpha",
                     size="pop", # size of markers, "pop" is one of the columns of gapminder
                     )
fig.show()

!ls csse_covid_19_data/csse_covid_19_time_series/

LASTFILE="csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"
DataIn = open(LASTFILE).readlines()
for line in DataIn:
    print(line)

import os
from pathlib import Path
count=0
bigList=[]
for x in range(1,10):
    X=str(x)
    if len(X)<2:X="0"+X 
    dirpath= "csse_covid_19_data/csse_covid_19_daily_reports/03-"+X+"-2020.csv"
    DataIn = open(dirpath).readlines()
    cnt = 0
    for line in DataIn:
        line=line.replace("\"","")
        line=line.replace("\n","")
        if line[0:1] ==",":
             bigList.append(line[1:]) 
        if line[0:1] !=",":
             if len(line[0:1])<5:
                bigList.append(line)
        
                                    
for line in bigList:
    if "US" in line and "U.S." not in line:
        line = line.split(",")
        line[1]=line[1].lstrip(" ")
        print (line[1],line[2],line[3],line[4],line[5],line[6])

                #print(WORDS)                                                      
#bigList.append(WORDS+"\n")
#print(len(bigList)) 

import time
from shutil import copyfile
filename = "DATA/"+(time.strftime('%a_%d_%b_%Y_%I_%M_%S_%p_%Z_', time.gmtime())+"covid192.db.db")
copyfile("DATA/covid192.db",filename)


!ls DATA/*.db

from shutil import copyfile

import sqlite3
import os
from pathlib import Path
import time
import shutil
DataBack = "DATA/"+(time.strftime('%a_%d_%b_%Y_%I_%M_%S_%p_%Z_', time.gmtime())+"covid192.db")
shutil.move("DATA/covid192.db",DataBack)

def GetEpoch(line):
    TXT = line.split(",")
    text = (TXT[2])
    pattern = '%Y-%m-%dT%H:%M:%S'
    epochs = int(time.mktime(time.strptime(text, pattern)))
    return epochs


count=0
BigList=[]
for x in range(10,23):
    X=str(x)
    if len(X)<2:X="0"+X 
    dirpath= "csse_covid_19_data/csse_covid_19_daily_reports/03-"+X+"-2020.csv"
    DataIn = open(dirpath).readlines()
    cnt = 0
    for line in DataIn:
        line=line.replace("\"","")
        line=line.replace("\n","")
        if line[0:1] ==",":
             BigList.append(line[1:]+"\n") 
        if line[0:1] !=",":    
             BigList.append(line+"\n")
cnt=0
total=0

conn=sqlite3.connect("DATA/covid192.db")
c = conn.cursor()
c.execute("CREATE TABLE IF NOT EXISTS covid19(data TEXT UNIQUE)")
conn.commit()


for line in BigList:
    line = line.replace("\n","")
    if "US" in line and "U.S." not in line:
        cnt = cnt+1
        if len(line)>5:
            TXT = line.split(",")
            text = (TXT[2])
            epoc=GetEpoch(line)
            pattern = '%Y-%m-%dT%H:%M:%S'
            epoc = int(time.mktime(time.strptime(text, pattern)))
            ENTRY = line+","+str(epoc)
            c.execute("INSERT OR IGNORE into covid19 values (?)",(ENTRY,)) 
        
conn.commit()
conn.close()     

!cp DATA/covid192.db DATA/covid192bak.db

import sqlite3
conn=sqlite3.connect("DATA/covid192.db")
c= conn.cursor()
for row in c.execute('SELECT rowid,* from covid19'):
     print(row[0],row[1])
conn.close()   

!ls -t csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv

LASTFILE="csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"
DataIn = open(LASTFILE).readlines()
for Sample in DataIn:
     s=0 
print (Sample.lstrip(","))
cnt = 0
LIST=[]
for line in DataIn:
    line=line.replace("\"","")
    line=line.replace("\n","")
    if line[0:1] ==",":
         LIST.append(line[1:]+"\n") 
    if line[0:1] !=",":    
         LIST.append(line+"\n")
cnt=0
total=0

cnt=0
for line in LIST:
    if cnt==0:
        print (line)
        cnt=cnt+1
    if "US" in line:
        print (line)

import sqlite3
from datetime import datetime
from time import gmtime, strftime
import time
import os
import requests
import glob

!git clone https://github.com/CSSEGISandData/COVID-19

!git pull

!ls csse_covid_19_data/csse_covid_19_daily_reports

conn=sqlite3.connect("DATA/COVID19.db")
c = conn.cursor()
c.execute("CREATE TABLE IF NOT EXISTS CORONA(date TEXT, data TEXT UNIQUE)")
# INSERT OR IGNORE into CORONA values (?)",(data,))    
conn.commit()
conn.close()

#['Province/State','Country/Region','Last Update','Confirmed','Deaths','Recovered', 'Latitude', 'Longitude']
import csv
cnt = 0
LIST =[]
LASTFILE="csse_covid_19_data/csse_covid_19_daily_reports/03-24-2024.csv"
#LASTFILE="csse_covid_19_data/csse_covid_19_daily_reports/03-17-2020.csv"
with open(LASTFILE, "r") as csv_file:
    csv_reader = csv.reader(csv_file, delimiter=',')
    for lines in csv_reader:
         LIST.append(lines[0]+","+lines[1]+","+lines[3]+","+lines[4])
         #print (lines)

cases=0
deaths=0
CASES = []
DEATHS = []
count=0
for line in LIST:
    if count==0:print ('{:<2} {:<23} {} {:<6} {} {}'.format(line[1],line[0],"Cases:",line[2],"Deaths:",line[3]))
    if "US" in line and "Virgin Islands" not in line and "Diamond Princess" not in line and 'US,US' not in line:
        line = line.lstrip(" ")
        line = line.split(",")
        count=count+1
        
    
        print ('{:<1} {:<23} {} {:<6} {} {}'.format(line[1],line[0],"Cases:",line[2],"Deaths:",line[3]))
        ENTRY = '{:<1} {:<23} {} {:<6} {} {}'.format(line[1],line[0],"Cases:",line[2],"Deaths:",line[3])
        #print ("ENTRY:",ENTRY)
        cases  = cases  + int(line[2])
        deaths = deaths + int(line[3])
        CASES.append(line[2])
        DEATHS.append(line[3])
        
        
print ("Cases:",  cases)
print ("Deaths:", deaths)

#['Province/State','Country/Region','Last Update','Confirmed','Deaths','Recovered', 'Latitude', 'Longitude']
import csv
cnt = 0
All =[]
LASTFILE="csse_covid_19_data/csse_covid_19_daily_reports/03-24-2020.csv"
with open(LASTFILE, "r") as csv_file:
    csv_reader = csv.reader(csv_file, delimiter=',')
    for lines in csv_reader:
         All.append(lines[0]+","+lines[1]+","+lines[2]+","+lines[3]+","+\
                    lines[4]+","+lines[5]+","+lines[6]+","+lines[7])

cases=0
deaths=0
CASES = []
DEATHS = []

for line in LIST:
    if "US" in line and "Virgin Islands" not in line and "Diamond Princess" not in line and 'US,US' not in line:
        line = line.lstrip(" ")
        line = line.split(",")
    
        #print ('{:<2} {:<23} {} {:<6} {} {}'.format(line[1],line[0],"Cases:",line[2],"Deaths:",line[3]))
    
        print ('{:<1} {:<23} {} {:<6} {} {}'.format(line[1],line[0],"Cases:",line[2],"Deaths:",line[3]))
        cases  = cases  + int(line[2])
        deaths = deaths + int(line[3])
        CASES.append(line[2])
        DEATHS.append(line[3])
print ("Cases:",  cases)
print ("Deaths:", deaths)


for line in All:
    print (line.lstrip(","))

#['Province/State','Country/Region','Last Update','Confirmed','Deaths','Recovered', 'Latitude', 'Longitude']
import csv
cnt = 0
LIST =[]
LASTFILE="csse_covid_19_data/csse_covid_19_daily_reports/03-20-2020.csv"
with open(LASTFILE, "r") as csv_file:
    csv_reader = csv.reader(csv_file, delimiter=',')
    for lines in csv_reader:
         LIST.append(lines[0]+","+lines[1]+",   "+lines[3]+",  "+lines[4])
         #print (lines)
for line in LIST:
    print (line.lstrip(","))        

LASTFILE="csse_covid_19_data/csse_covid_19_daily_reports/03-20-2020.csv"
DataIn = open(LASTFILE).readlines()
cnt = 0
LIST=[]
for line in DataIn:
    line=line.replace("\"","")
    line=line.replace("\n","")
    cnt=cnt+1
    if cnt <5:
        #if line[0:1] ==",":line.replace(line[0:1],"")
        if line[0:1] ==",":
            LIST.append(line[1:]+"\n") 
        if line[0:1] !=",":    
            LIST.append(line+"\n")
for item in LIST:
    item = item.replace("\n","")
    print (item)

cnt=0
total=0
Total=0
for line in LIST:

    line = line.replace("\n","")
    if "US" in line:
        cnt=cnt+1
        line = line.split(",")
        print (cnt,":",line[0],line[1],"---",line[3],line[4])
        total=total+int(line[4])
        Total=Total+int(line[3])
print ("Confirmed:",Total) 
print ("Deaths:",total)        

!ls -t csse_covid_19_data/csse_covid_19_daily_reports/

files.sort(key=os.path.getctime)

import os
from pathlib import Path
for x in range(1,21):
    X=str(x)
    if len(X)<2:X="0"+X 
    dirpath= "csse_covid_19_data/csse_covid_19_daily_reports/03-"+X+"-2020.csv"
    print (dirpath)

LASTFILE

LASTFILE="csse_covid_19_data/csse_covid_19_daily_reports/03-19-2020.csv"
DataIn = open(LASTFILE).readlines()
cnt = 0
LIST=[]
for line in DataIn:
    line=line.replace("\"","")
    line=line.replace("\n","")
    if line[0:1] ==",":
         LIST.append(line[1:]+"\n") 
    if line[0:1] !=",":    
         LIST.append(line+"\n")

LASTFILE="csse_covid_19_data/csse_covid_19_daily_reports/03-19-2020.csv"
DataIn = open(LASTFILE).readlines()
for Sample in DataIn:
     s=1 
print (Sample.lstrip(","))
cnt = 0
LIST=[]
for line in DataIn:
    line=line.replace("\"","")
    line=line.replace("\n","")
    if line[0:1] ==",":
         LIST.append(line[1:]+"\n") 
    if line[0:1] !=",":    
         LIST.append(line+"\n")
cnt=0
total=0
for line in LIST:
    line = line.replace("\n","")
    if "US" in line:
        cnt = cnt+1
        print (line)            

print (len(LIST))
print (LIST)

import time
def GetEpoch(line):
    TXT = line.split(",")
    text = (TXT[2])
    pattern = '%Y-%m-%dT%H:%M:%S'
    epochs = int(time.mktime(time.strptime(text, pattern)))
    return epochs

line = "New York,US,2020-03-17T22:53:03,1706,13,0,42.1657,-74.9481"
GetEpoch(line)

import time
FullData = []
def GetEpoch(line):
    TXT = line.split(",")
    text = (TXT[2])
    pattern = '%Y-%m-%dT%H:%M:%S'
    epochs = int(time.mktime(time.strptime(text, pattern)))
    return epochs

cnt=0
total=0
for line in LIST:
    line = line.replace("\n","")
    if "US" in line:
        cnt = cnt+1
        #print (cnt,": ",line)
        TXT = line.split(",")
        text = (TXT[2])
        #print (text)
        epoc=GetEpoch(line)
        pattern = '%Y-%m-%dT%H:%M:%S'
        #print (epoc)
        epochs = line+","+str(epoc)
        FullData.append(epochs)
        print (epochs)

import os
from pathlib import Path
count=0
BigList=[]
for x in range(10,21):
    X=str(x)
    if len(X)<2:X="0"+X 
    dirpath= "csse_covid_19_data/csse_covid_19_daily_reports/03-"+X+"-2020.csv"
    DataIn = open(dirpath).readlines()
    cnt = 0
    for line in DataIn:
        line=line.replace("\"","")
        line=line.replace("\n","")
        if line[0:1] ==",":
             BigList.append(line[1:]+"\n") 
        if line[0:1] !=",":    
             BigList.append(line+"\n")
print(len(BigList)) 

#total=0
#for line in BigList:
#    line = line.replace("\n","")
#    if "US" in line:
#        count = count+1
        #print (count,": ",line)
cnt=0
total=0
for line in BigList:
    line = line.replace("\n","")
    if "US" in line and "U.S." not in line:
        cnt=cnt+1
        line = line.split(",")        
        print ('{:<2} {:<23} {} {:<6} {} {}'.format(line[1],line[0],"Cases:",line[3],"Deaths:",line[4]))
        #ENTRY = '{:<2} {:<23} {} {:<6} {} {}'.format(line[1],line[0],"Cases:",line[3],"Deaths:",line[4])
print ("====================================================================")        
        #total = total + int(line[3])
#print ("Total Cases: ",total)
#print ("Total Cases Minus Cruise Ships: ",total-67)   

# 3,13,2020,03:45,GMT,1747,41
text =arrangedDdata.split("\n")
text= text[1:-1]
EPOCHa=[]
for line in text:
    #print(line)
    #line=str(LINE)
    line = line.split("-")
    #print (str(line[1]+'/'+line[0]+'/'+line[2][:-3]))
    dt = time.strftime((str(line[1]+'/'+line[0]+'/'+line[2][:-3])))
    #print (dt+":00")

    dt_ti = dt+":00"
    #print (dt_ti)
    #03-16-2020 02:48,3777
    pattern = '%d/%m/%Y %H:%M:%S'
    #pattern = '%m/%d/%Y %H:%M:%S'
    epochs = int(time.mktime(time.strptime(dt_ti, pattern)))
    print (dt_ti, epochs)
    EPOCHa.append(int(epochs))    

import os
from pathlib import Path
count=0
BigList=[]
TOTAL = []
for x in range(10,20):
    X=str(x)
    if len(X)<2:X="0"+X 
    dirpath= "csse_covid_19_data/csse_covid_19_daily_reports/03-"+X+"-2020.csv"
    DataIn = open(dirpath).readlines()
    cnt = 0
    for line in DataIn:
        line=line.replace("\"","")
        line=line.replace("\n","")
        if line[0:1] ==",":
             BigList.append(line[1:]+"\n") 
        if line[0:1] !=",":    
             BigList.append(line+"\n")
print(len(BigList)) 

#total=0
#for line in BigList:
#    line = line.replace("\n","")
#    if "US" in line:
#        count = count+1
        #print (count,": ",line)
cnt=0
total=0
for line in BigList:
    Subtotal = 0
    line = line.replace("\n","")
    if "US" in line and "U.S." not in line:
        cnt=cnt+1
        line = line.split(",")
        print ('{:<2} {:<23} {} {:<6} {} {}'.format(line[1],line[0],"Cases:",line[3],"Deaths:",line[4]))
        ENTRY = '{:<2} {:<23} {} {:<6} {} {}'.format(line[1],line[0],"Cases:",line[3],"Deaths:",line[4])
        TOTAL.append(ENTRY)

def Sort(Item): 
    l = len(Item) 
    for i in range(0, l): 
        for j in range(0, l-i-1): 
            if (Item[j][1] > Item[j + 1][1]): 
                tempo = Item[j] 
                Item[j]= Item[j + 1] 
                Item[j + 1]= tempo 
    return Item 

#Sort(TOTAL).reverse()    
for item in Sort(TOTAL):
    print (item)
    
  

for num in TOTAL.sort():
    print (num)

COUNTS=[]
cnt=0
total=0
Total=0
for line in BigList:

    line = line.replace("\n","")
    if "US" in line:
        cnt=cnt+1
        line = line.split(",")
        print (cnt,":",line[0],line[1],"---",line[3],line[4])
        if cnt>525 and "Virgin Islands" not in line:
            entry = str(line[3])+"  "+str(line[4])
            COUNTS.append(entry)
            total=total+int(line[4])
            Total=Total+int(line[3])
print ("Confirmed:",Total) 
print ("Deaths:",total)        

cnt=0
total=0
for line in LIST:
    line = line.replace("\n","")
    if "US" in line:
        line=line.split(",")
        cnt = cnt+1
        print (cnt,"; ",line[0],line[1],"   Cases:",line[3],"   Deaths:",line[4])

cnt=0
total=0
for line in LIST:
    line = line.replace("\n","")
    if "US" in line:
        line=line.split(",")
        cnt = cnt+1
        print (cnt,": ",line[0],line[1],"   Cases:",line[3],"   Deaths:",line[4])

#['Province/State','Country/Region','Last Update','Confirmed','Deaths','Recovered', 'Latitude', 'Longitude']
import csv

LIST =[]
LASTFILE="csse_covid_19_data/csse_covid_19_daily_reports/03-29-2020.csv"
with open(LASTFILE, "r") as csv_file:
    csv_reader = csv.reader(csv_file, delimiter=',')
    for lines in csv_reader:
        LIST.append(lines[0]+","+lines[1]+","+lines[3]+","+lines[4]+","+lines[5]+","+lines[6]+","+lines[7]+","+lines[8])
    cnt=cnt+1
    print(lines[8])
    if cnt>1 and int(lines[8]) >0:print (line.lstrip(","))
    if cnt==2:print(lines)    
    #if int(line[8]) >0:print (line)
    #if int(line[8]) >0:print (line)
#for line in LIST:
#    print (line)

#['Province/State','Country/Region','Last Update','Confirmed','Deaths','Recovered', 'Latitude', 'Longitude']
import csv
cnt = 0
LIST =[]
LASTFILE="csse_covid_19_data/csse_covid_19_daily_reports/03-17-2020.csv"
with open(LASTFILE, "r") as csv_file:
    csv_reader = csv.reader(csv_file, delimiter=',')
    for lines in csv_reader:
         LIST.append(lines[0]+","+lines[1]+","+lines[3]+","+lines[4])
         #print (lines)
cnt=0
total=0
US = []
for line in LIST:
    line = line.replace("\n","")
    if "US" in line and "U.S." not in line:
        cnt=cnt+1
        if len(line)>5:
            print (cnt,line)
            US.append(line)
print ("\n-----------------------------------\n")            
cnt=0
for line in LIST:
    line = line.replace("\n","")
print(line)
print ("\n-----------------------------------\n")  
for line in US:
    line = line.replace("\n","")
    if "US" in line and "U.S." not in line:
        print (line)
        cnt=cnt+1
        if len(line)>5:
            Line = line.split(",") 
            #print ("Line: ",Line)
            #print (Line[0],Line[1],Line[2],Line[3])
            print ('{:<2} {:<23} {} {:<6} {} {}'.format(Line[1],Line[0],"Cases:",Line[2],"Deaths:",Line[3]))
            total = total + int(Line[2])
print ("Total Cases: ",total)
print ("Total Cases Minus Cruise Ships: ",total-67)

import os
from pathlib import Path
count=0
BigList=[]
for x in range(10,20):
    X=str(x)
    if len(X)<2:X="0"+X 
    dirpath= "csse_covid_19_data/csse_covid_19_daily_reports/03-"+X+"-2020.csv"
    DataIn = open(dirpath).readlines()
    cnt = 0
    for line in DataIn:
        line=line.replace("\"","")
        line=line.replace("\n","")
        if line[0:1] ==",":
             BigList.append(line[1:]+"\n") 
        if line[0:1] !=",":    
             BigList.append(line+"\n")
print(len(BigList)) 

#total=0
#for line in BigList:
#    line = line.replace("\n","")
#    if "US" in line:
#        count = count+1
        #print (count,": ",line)
cnt=0
total=0
for line in BigList:
    line = line.replace("\n","")
    if "US" in line and "U.S." not in line:
        cnt=cnt+1
        line = line.split(",")        
        print ('{:<2} {:<23} {} {:<6} {} {}'.format(line[1],line[0],"Cases:",line[3],"Deaths:",line[4]))
        ENTRY = '{:<2} {:<23} {} {:<6} {} {}'.format(line[1],line[0],"Cases:",line[3],"Deaths:",line[4])
print ("====================================================================")        
        #total = total + int(line[3])
#print ("Total Cases: ",total)
#print ("Total Cases Minus Cruise Ships: ",total-67)   

cnt=0
total=0
for line in LIST:
    line = line.replace("\n","")
    if "US" in line:
        cnt=cnt+1
        line = line.split(",")
        print (cnt,":",line[0],line[1],"---",line[2],line[3])
        total=total+ int(line[2])
print ("Total Confirmed: ",total)

cnt=0
total=0
Total=0
for line in LIST:

    line = line.replace("\n","")
    if "US" in line:
        cnt=cnt+1
        line = line.split(",")
        print (cnt,":",line[0],line[1],"---",line[2],line[3])
        total=total+int(line[2])
        Total=Total+int(line[3])
print ("Confirmed:",Total) 
print ("Deaths:",total)        

!ls csse_covid_19_data/csse_covid_19_daily_reports/

DataIn = open("csse_covid_19_data/csse_covid_19_daily_reports/03-17-2020.csv").readlines()
cnt = 0
LIST=[]
for line in DataIn:
    line=line.replace("\"","")
    line=line.replace("\n","")
    cnt=cnt+1
    if cnt <20:
        #if line[0:1] ==",":line.replace(line[0:1],"")
        if line[0:1] ==",":
            print(line[1:]) 
        if line[0:1] !=",":    
            print (line)

print (TEXT)

Taa = TEXT
Ta = LAST

import sqlite3
TEXT = ""
conn=sqlite3.connect("DATA/CoronaData2.db")
c= conn.cursor()
for row in c.execute('SELECT rowid,* from CORONA'):
    print (DATAout(row[1]))
    TEXT=TEXT+DATAout(row[1]+"\n")

import datetime
import calendar
cnt =0
text =TEXT.split("\n")
for line in TEXT:
    cnt=cnt+1
    print (cnt,":",line)

import datetime
import calendar
# "28/12/2015 "
text =TEXT.split("\n")
EPOCH=[]
for line in text:
    #print(line)
    #line=str(LINE)
    line = line.split(",")
    dt = time.strftime((str(line[1]+'/'+line[0]+'/'+line[2]+" ")))
    ti = str(line[3]+":00")
    dt_ti = dt + ti
    #print (dt_ti)
    pattern = '%d/%m/%Y %H:%M:%S'
    epoch = int(time.mktime(time.strptime(dt_ti, pattern)))
    print (epoch)
    EPOCH.append(epoch)
print (EPOCH)    

import datetime
import calendar
dt = time.strftime("08/03/2020 ")
ti = "23:30:00"
dt_ti = dt + ti
pattern = '%d/%m/%Y %H:%M:%S'

epoch = int(time.mktime(time.strptime(dt_ti, pattern)))
print (epoch)
# 1450224000

utc_epoch = int(calendar.timegm(time.strptime(dt_ti, pattern)))
print (utc_epoch)

from datetime import datetime

timestamp = 1583681400
dt_object = datetime.fromtimestamp(timestamp)

print("dt_object =", dt_object)
print("type(dt_object) =", type(dt_object))

import datetime
import calendar
import time
import datetime
import calendar
import time
import sqlite3
from M2D import Month2Num
arrangedDdata = ''
arrangedDdata=arrangedDdata+"date_time,cases\n"
conn=sqlite3.connect("DATA/CoronaData2.db")
c= conn.cursor()
for row in c.execute('SELECT rowid,* from CORONA'):
    MISC=row[1]
    Str = MISC.split(" ")
    month = Str[0][0:5]
    OUT = Month2Num(month)+","+MISC[5:15]+" "+MISC[18:24]+":00"
    OUT = OUT.replace(", ","-")
    OUT = OUT.replace("c","")
    #OUT = OUT.replace(",","-")
    OUT = OUT.replace(" ",",");OUT = OUT.replace(",,"," ")
    OUT = OUT.rstrip(",");OUT = OUT.replace(",","") 
    print (OUT) 
    arrangedDdata = arrangedDdata+OUT+"\n"
conn.close() 
#3-15-2020 19:00,3329
# 3,13,2020,03:45,GMT,1747,41
text =arrangedDdata.split("\n")
text= text[1:-1]
EPOCH=[]
for line in text:
    #print(line)
    #line=str(LINE)
    line = line.split("-")
    #print (str(line[1]+'/'+line[0]+'/'+line[2][:-3]))
    dt = time.strftime((str(line[1]+'/'+line[0]+'/'+line[2][:-3])))
    #print (dt+":00")

    dt_ti = dt+":00"
    #print (dt_ti)
    #03-16-2020 02:48,3777
    pattern = '%d/%m/%Y %H:%M:%S'
    #pattern = '%m/%d/%Y %H:%M:%S'
    epochs = int(time.mktime(time.strptime(dt_ti, pattern)))
    print (dt_ti, epochs)
    EPOCH.append(int(epochs))
    

# 3,13,2020,03:45,GMT,1747,41
text =arrangedDdata.split("\n")
text= text[1:-1]
EPOCHa=[]
for line in text:
    #print(line)
    #line=str(LINE)
    line = line.split("-")
    #print (str(line[1]+'/'+line[0]+'/'+line[2][:-3]))
    dt = time.strftime((str(line[1]+'/'+line[0]+'/'+line[2][:-3])))
    #print (dt+":00")

    dt_ti = dt+":00"
    #print (dt_ti)
    #03-16-2020 02:48,3777
    pattern = '%d/%m/%Y %H:%M:%S'
    #pattern = '%m/%d/%Y %H:%M:%S'
    epochs = int(time.mktime(time.strptime(dt_ti, pattern)))
    print (dt_ti, epochs)
    EPOCHa.append(int(epochs))    

import numpy as np
import matplotlib.pyplot as plt
from scipy.interpolate import interp1d
from scipy.interpolate import CubicSpline
LAST.reverse()
t = np.array(EPOCH)
#t = np.delete(t, 0)
#t = np.delete(t, 0)
print ('EPOCH',len(t))
#T = np.array(LAST[:-1])
T = np.array(LAST)
#T = np.delete(T,1)
print ('LAST',len(T))
# nearest neighbor
nn_fun = interp1d(t, T, kind='nearest')
# linear
lin_fun = interp1d(t, T, kind='linear')
# cubic spline (uses not-a-knot conditions)
cs_fun = interp1d(t, T, kind='cubic')
# cubic spline (defaults to not-a-knot conditions)
cs_fun2 = CubicSpline(t, T)

tmodel = np.linspace(t.min(), t.max(), 1000)
#fig, ax = plt.subplots(figsize=(10, 6))
fig = plt.figure(figsize=(10, 6),num=1, clear=True)
ax = fig.add_subplot(1,1,1)
ax.plot(t, T, 'ko', label='Data')
ax.plot(tmodel, nn_fun(tmodel), 'r.', label='Nearest', ms=1)
ax.plot(tmodel, lin_fun(tmodel), 'b-', label='Linear')
ax.plot(tmodel, cs_fun(tmodel), 'm-', label='Cubic Spline (nak)')
ax.plot(tmodel, cs_fun2(tmodel), 'y--', label='Cubic Spline* (nak)')
ax.legend()
ax.set(title = 'Generally Using interp1')
fig.savefig('interps1.png')

# cubic spline (defaults to not-a-knot conditions)
cs_fun2_nak = CubicSpline(t, T)
# cubic spline (clamped end conditions: first and last f'=0)
cs_fun2_cla = CubicSpline(t, T, bc_type='clamped')
# cubic spline (clamps first f' to -5 and last f' to 5)
cs_fun2_cla5 = CubicSpline(t, T, bc_type=((1, -5), (1, 5)))
# cubic spline (natural end conditions)
cs_fun2_nat = CubicSpline(t, T, bc_type='natural')
# cubic spline (sets first f'' to -5 and last f'' to 5)
cs_fun2_nat5 = CubicSpline(t, T, bc_type=((2, -5), (2, 5)))
fig = plt.figure(num=2, clear=True)
ax = fig.add_subplot(1,1,1)
ax.plot(t, T, 'ko', label='Data')
ax.plot(tmodel, cs_fun2_nak(tmodel), 'y--', label='Not-a-Knot', ms=1)
ax.plot(tmodel, cs_fun2_cla(tmodel), 'b-', label='Clamped at 0')
ax.plot(tmodel, cs_fun2_cla5(tmodel), 'g--', label='Clamped at $\mp$ 5')
ax.plot(tmodel, cs_fun2_nat(tmodel), 'c--', label='Natural at 0')
ax.plot(tmodel, cs_fun2_nat5(tmodel), 'k--', label='2nd Derivatives at $\mp$ 5')
ax.legend()
ax.set(title = 'Generally Using CubicSpline')
fig.savefig('interps2.png')

%%writefile M2D.py
def Month2Num(month):
    months=["January","February","March","April","May","June","July",\
            "August","September","October","November","December"]
    Numbers=["01","02","03","04","05","06","07","08","09","10","11","12"]
    if month==months[0]:number=Numbers[0]
    if month==months[1]:number=Numbers[1]
    if month==months[2]:number=Numbers[2]
    if month==months[3]:number=Numbers[3]
    if month==months[4]:number=Numbers[4]
    if month==months[5]:number=Numbers[5]
    if month==months[6]:number=Numbers[6]
    if month==months[7]:number=Numbers[7]
    if month==months[8]:number=Numbers[8]
    if month==months[9]:number=Numbers[9]
    if month==months[10]:number=Numbers[10]
    if month==months[11]:number=Numbers[11]    
    return number

from M2D import Month2Num
month = 'June'
Month2Num(month)

https://github.com/CSSEGISandData/COVID-19.git

import datetime
import calendar
import time
import datetime
import calendar
import time
import sqlite3
from M2D import Month2Num
arrangedDdata = ''
arrangedDdata=arrangedDdata+"date_time,cases\n"
conn=sqlite3.connect("DATA/CoronaData2.db")
c= conn.cursor()
print ('\nThis is frome the current database history. These are the dates of data entry.')
for row in c.execute('SELECT rowid,* from CORONA'):
    MISC=row[1]
    Str = MISC.split(" ")
    month = Str[0][0:5]
    OUT = Month2Num(month)+","+MISC[5:15]+" "+MISC[18:24]+":00"
    OUT = OUT.replace(", ","-")
    OUT = OUT.replace("c","")
    #OUT = OUT.replace(",","-")
    OUT = OUT.replace(" ",",");OUT = OUT.replace(",,"," ")
    OUT = OUT.rstrip(",");OUT = OUT.replace(",","") 
    print (OUT) 
    arrangedDdata = arrangedDdata+OUT+"\n"
conn.close() 
#3-15-2020 19:00,3329
# 3,13,2020,03:45,GMT,1747,41
text =arrangedDdata.split("\n")
text= text[1:-1]
print ("\nThe date is converted to an Epoch / timestamp.")
print("A timestamp is easy to put in sequential order.\n")
EPOCH=[]
for line in text:
    #print(line)
    #line=str(LINE)
    line = line.split("-")
    #print (str(line[1]+'/'+line[0]+'/'+line[2][:-3]))
    dt = time.strftime((str(line[1]+'/'+line[0]+'/'+line[2][:-3])))
    #print (dt+":00")

    dt_ti = dt+":00"
    #print (dt_ti)
    #03-16-2020 02:48,3777
    pattern = '%d/%m/%Y %H:%M:%S'
    #pattern = '%m/%d/%Y %H:%M:%S'
    epochs = int(time.mktime(time.strptime(dt_ti, pattern)))
    print (dt_ti, epochs)
    EPOCH.append(int(epochs))
    

# 3,13,2020,03:45,GMT,1747,41
text =arrangedDdata.split("\n")
text= text[1:-1]
EPOCHa=[]
for line in text:
    #print(line)
    #line=str(LINE)
    line = line.split("-")
    #print (str(line[1]+'/'+line[0]+'/'+line[2][:-3]))
    dt = time.strftime((str(line[1]+'/'+line[0]+'/'+line[2][:-3])))
    #print (dt+":00")

    dt_ti = dt+":00"
    #print (dt_ti)
    #03-16-2020 02:48,3777
    pattern = '%d/%m/%Y %H:%M:%S'
    #pattern = '%m/%d/%Y %H:%M:%S'
    epochs = int(time.mktime(time.strptime(dt_ti, pattern)))
    print (dt_ti, epochs)
    EPOCHa.append(int(epochs))    

import sqlite3
conn=sqlite3.connect("DATA/CoronaData2.db")
c= conn.cursor()
for row in c.execute('SELECT rowid,* from CORONA'):
     print (row[0],row[1])
conn.close()        

%%writefile M2D.py
def Month2Num(month):
    number=""
    months=["January","February","March","April","May","June","July",\
            "August","September","October","November","December"]
    Numbers=["01","02","03","04","05","06","07","08","09","10","11","12"]
    if month==months[0]:number=Numbers[0]
    if month==months[1]:number=Numbers[1]
    if month==months[2]:number=Numbers[2]
    if month==months[3]:number=Numbers[3]
    if month==months[4]:number=Numbers[4]
    if month==months[5]:number=Numbers[5]
    if month==months[6]:number=Numbers[6]
    if month==months[7]:number=Numbers[7]
    if month==months[8]:number=Numbers[8]
    if month==months[9]:number=Numbers[9]
    if month==months[10]:number=Numbers[10]
    if month==months[11]:number=Numbers[11]    
    return number


from M2D import Month2Num

def DATAout(DATAin):
    data = DATAin.replace(",","")
    data = data.split(" ")
    OutPut = Month2Num(data[0]),data[1],data[2],data[4],data[5],data[9],data[13]
    Output =  ','.join(OutPut)
    return Output
    
    
DATAin ="March 14, 2020 at 16:45 GMT, there have been 2499 confirmed cases and 51 deaths due to coronavirus COVID-19 in the United States."
    
DATAout(DATAin)

import sqlite3
from M2D import Month2Num

def DATAout(DATAin):
    data = DATAin.replace(",","")
    data = data.split(" ")
    OutPut = Month2Num(data[0]),data[1],data[2],data[4],data[5],data[9],data[13]
    Output =  ','.join(OutPut)
    return Output
TEXT = ""
conn=sqlite3.connect("DATA/CoronaData2.db")
c= conn.cursor()
for row in c.execute('SELECT rowid,* from CORONA'):
    if len(row[1])>3:
        print (DATAout(row[1]))
        TEXT=TEXT+DATAout(row[1]+"\n")        
conn.close() 

#print (TEXT)

import sqlite3
conn=sqlite3.connect("DATA/CoronaData2.db")
c= conn.cursor()
for row in c.execute('SELECT rowid,* from CORONA'):
    #if len(row[1])>5:
    print (row[0],row[1])
    #print (row[1])   
conn.close()        

!ls DATA

!ls -t DATA/*.html

import glob
import os
files = glob.glob('DATA/*.html')
File = max(files, key=os.path.getctime)

print (File)

from time import gmtime, strftime
import time
import os
import glob
files = glob.glob('DATA/*.html') # * means format then *.html
File = max(files, key=os.path.getctime)
print ("Opening: ",File)
print("\n")
DataO = open(File, "r").read()
ndata = DataO.split("<p>")
par = ndata[1]
par=par.replace("<strong>", "")
par=par.replace("</strong>", "")
par=par.replace("</p>", "")
print (par)


#   DATA/Sun_15_Mar_2020_04_47_07_AM_GMT.html

dataout = DataO
dataout = str(dataout)
dataout = dataout.replace("March","\n\n\nXXXXXXXXMarch")
dataout = dataout.replace("<strong>","")
dataout = dataout.replace("</strong>","")
dataout = dataout.replace(">","")
dataout= dataout.split("XXXXXXXX")
data = (dataout[1][0:129])
print (data)

MISC = "March 16, 2020 at 02:48 GMT, there have been 3777 confirmed cases and 69 deaths due to coronavirus COVID-19 in the United States."
print (MISC)
print ("-----------------------")
Str = MISC.split(",")
print (Str)
print ("-----------------------")
print (Str[0][0:5])
print ("-----------------------")

#module to change word-month to number-month   March to 03  April to 04 etc. 
from M2D import Month2Num
month = Str[0][0:5]
OUT = Month2Num(month)+","+MISC[5:15]+MISC[18:24]+MISC[45:50]
OUT = OUT.replace(", ",",")
print (OUT)

conn=sqlite3.connect("DATA/CoronaData.db")
c= conn.cursor()
for row in c.execute('SELECT rowid,* from CORONA'):
    print (row[0],row[1],row[2])
    print (row[3])
    print("----------------------")


import sqlite3
from M2D import Month2Num
conn=sqlite3.connect("DATA/CoronaData2.db")
c= conn.cursor()
for row in c.execute('SELECT rowid,* from CORONA'):
    MISC=row[1]
    Str = MISC.split(" ")
    month = Str[0][0:5]
    OUT = Month2Num(month)+","+MISC[5:15]+MISC[18:24]+MISC[45:50]
    OUT = OUT.replace(", ",",")
    OUT = OUT.replace("c","")
    print (OUT) 
conn.close()       

dataout = DataO
dataout = dataout.replace("<p>","XXXX<p>")
dataout =dataout.replace("</p>","</p>XXXX")
paragraph = dataout.split("XXXX")
for line in paragraph:
    if "<p>" in line:
        print (line)
        print ("--------------------")






# c.execute("CREATE TABLE IF NOT EXISTS CORONA(Id integer primary key autoincrement, data TEXT UNIQUE)")

data2="""March 08, 2020 at 23:30 GMT, there have been 537 confirmed cases and 21 deaths due to coronavirus COVID-19 in the United States.
March 09, 2020 at 04:30 GMT, there have been 589 confirmed cases and 22 deaths due to coronavirus COVID-19 in the United States.
March 10, 2020 at 05:30 GMT, there have been 708 confirmed cases and 27 deaths due to coronavirus COVID-19 in the United States.
March 10, 2020 at 23:35 GMT, there have been 975 confirmed cases and 30 deaths due to coronavirus COVID-19 in the United States.
March 11, 2020 at 04:25 GMT, there have been 1010 confirmed cases and 31 deaths due to coronavirus COVID-19 in the United States.
March 11, 2020 at 15:17 GMT, there have been 1016 confirmed cases and 31 deaths due to coronavirus COVID-19 in the United States.
March 11, 2020 at 23:35 GMT, there have been 1301 confirmed cases and 38 deaths due to coronavirus COVID-19 in the United States.
March 12, 2020 at 03:25 GMT, there have been 1327 confirmed cases and 38 deaths due to coronavirus COVID-19 in the United States.
March 12, 2020 at 11:37 GMT, there have been 1336 confirmed cases and 38 deaths due to coronavirus COVID-19 in the United States.
March 12, 2020 at 22:00 GMT, there have been 1639 confirmed cases and 40 deaths due to coronavirus COVID-19 in the United States.
March 13, 2020 at 00:05 GMT, there have been 1715 confirmed cases and 41 deaths due to coronavirus COVID-19 in the United States.
March 13, 2020 at 01:35 GMT, there have been 1725 confirmed cases and 41 deaths due to coronavirus COVID-19 in the United States. 
March 13, 2020 at 03:45 GMT, there have been 1747 confirmed cases and 41 deaths due to coronavirus COVID-19 in the United States.
March 13, 2020 at 06:00 GMT, there have been 1762 confirmed cases and 41 deaths due to coronavirus COVID-19 in the United States.
March 13, 2020 at 15:25 GMT, there have been 1832 confirmed cases and 41 deaths due to coronavirus COVID-19 in the United States.
March 13, 2020 at 22:25 GMT, there have been 2269 confirmed cases and 48 deaths due to coronavirus COVID-19 in the United States.
March 14, 2020 at 02:40 GMT, there have been 2291 confirmed cases and 50 deaths due to coronavirus COVID-19 in the United States.
March 14, 2020 at 16:15 GMT, there have been 2329 confirmed cases and 50 deaths due to coronavirus COVID-19 in the United States.
March 14, 2020 at 16:45 GMT, there have been 2499 confirmed cases and 51 deaths due to coronavirus COVID-19 in the United States.
March 14, 2020 at 23:03 GMT, there have been 2836 confirmed cases and 57 deaths due to coronavirus COVID-19 in the United States.
March 15, 2020 at 05:00 GMT, there have been 2982 confirmed cases and 60 deaths due to coronavirus COVID-19 in the United States.
March 15, 2020 at 05:40 GMT, there have been 2995 confirmed cases and 60 deaths due to coronavirus COVID-19 in the United States.
March 15, 2020 at 07:05 GMT, there have been 3043 confirmed cases and 60 deaths due to coronavirus COVID-19 in the United States.
March 15, 2020 at 19:00 GMT, there have been 3329 confirmed cases and 63 deaths due to coronavirus COVID-19 in the United States.
March 15, 2020 at 20:05 GMT, there have been 3400 confirmed cases and 63 deaths due to coronavirus COVID-19 in the United States.
March 15, 2020 at 21:15 GMT, there have been 3621 confirmed cases and 63 deaths due to coronavirus COVID-19 in the United States.
March 15, 2020 at 22:15 GMT, there have been 3502 confirmed cases and 63 deaths due to coronavirus COVID-19 in the United States.
March 16, 2020 at 00:35 GMT, there have been 3714 confirmed cases and 68 deaths due to coronavirus COVID-19 in the United States.
March 16, 2020 at 02:48 GMT, there have been 3777 confirmed cases and 69 deaths due to coronavirus COVID-19 in the United States.
March 16, 2020 at 05:36 GMT, there have been 3782 confirmed cases and 69 deaths due to coronavirus COVID-19 in the United States.
March 16, 2020 at 08:29 GMT, there have been 3802 confirmed cases and 69 deaths due to coronavirus COVID-19 in the United States.
March 16, 2020 at 18:40 GMT, there have been 4186 confirmed cases and 73 deaths due to coronavirus COVID-19 in the United States.
March 16, 2020 at 22:40 GMT, there have been 4597 confirmed cases and 86 deaths due to coronavirus COVID-19 in the United States.
March 17, 2020 at 00:45 GMT, there have been 4667 confirmed cases and 87 deaths due to coronavirus COVID-19 in the United States.
March 17, 2020 at 02:40 GMT, there have been 4704 confirmed cases and 91 deaths due to coronavirus COVID-19 in the United States.
March 17, 2020 at 06:35 GMT, there have been 4727 confirmed cases and 93 deaths due to coronavirus COVID-19 in the United States.
March 17, 2020 at 10:31 GMT, there have been 4743 confirmed cases and 93 deaths due to coronavirus COVID-19 in the United States.
March 17, 2020 at 14:38 GMT, there have been 4752 confirmed cases and 93 deaths due to coronavirus COVID-19 in the United States.
March 17, 2020 at 18:41 GMT, there have been 5723 confirmed cases and 97 deaths due to coronavirus COVID-19 in the United States.
March 17, 2020 at 21:55 GMT, there have been 6211 confirmed cases and 102 deaths due to coronavirus COVID-19 in the United States
"""

!cp DATA/CoronaData2.db DATA/CoronaData2-bak.db

import sqlite3
data2= ""
conn=sqlite3.connect("DATA/CoronaData2.db")
c= conn.cursor()
for row in c.execute('SELECT rowid,* from CORONA'):
    #print (row[0],row[1])
    print (row[1]) 
    data2=data2+row[1]
conn.close()        

data = data2.split(".")
for line in data:
    print (line)

print (1715/1639)
print (1639/1336)
print (1336/1327)
print (1327/1301)

from M2D import Month2Num

def DATAout(DATAin):
    data = DATAin.replace(",","")
    data = data.split(" ")
    OutPut = Month2Num(data[0]),data[1],data[2],data[4],data[5],data[9],data[13]
    Output =  ','.join(OutPut)
    return Output
    
    
experiment ="March 14, 2020 at 16:45 GMT, there have been 2499 confirmed cases and 51 deaths due to coronavirus COVID-19 in the United States."
    
DATAout(experiment)

from M2D import Month2Num

def DATAexperiment(DATAin):
    data = DATAin.replace(",","")
    data = data.split(" ")
    OutPut = Month2Num(data[0])+"/"+data[1]+"/"+data[2]+" "+data[4]+" Cases: "+data[9]+" Deaths: "+data[13]
    #OutPut = Month2Num(data[0])+"/"+data[1]+"/"+data[2]+" "+data[4]+" Cases: "+data[9]
    Output =  ''.join(OutPut)
    return Output
    
    
EXP ="March 14, 2020 at 16:45 GMT, there have been 2499 confirmed cases and 51 deaths due to coronavirus COVID-19 in the United States."
    
DATAexperiment(EXP)

TEXT="""3,08,2020,23:30,GMT,537,21
3,09,2020,04:30,GMT,589,22
3,10,2020,05:30,GMT,708,27
3,10,2020,23:35,GMT,975,30
3,11,2020,04:25,GMT,1010,31
3,15,2020,19:00 GMT,3329,63"""

import sqlite3
from M2D import Month2Num
arrangedDdata = ''
arrangedDdata=arrangedDdata+"date_time,cases\n"
conn=sqlite3.connect("DATA/CoronaData2.db")
c= conn.cursor()
for row in c.execute('SELECT rowid,* from CORONA'):
    MISC=row[1]
print ("\n------ MISC=row[1]  results ----------------\n")
print (MISC)
print ("\n----------------------\n")
for row in c.execute('SELECT rowid,* from CORONA'):
    MISC=row[1]
    Str = MISC.split(" ")
    month = Str[0][0:5]
    OUT = Month2Num(month)+","+MISC[5:15]+" "+MISC[18:24]+MISC[45:50]
    OUT = OUT.replace(", ",",")
    OUT = OUT.replace("c","")
    OUT = OUT.replace(",","-")
    OUT = OUT.replace(" ",",");OUT = OUT.replace(",,"," ")
    OUT = OUT.rstrip(",") 
    print (OUT) 
    arrangedDdata = arrangedDdata+OUT+"\n"
conn.close() 
#3-15-2020 19:00,3329

import re
TEST="M^54{-[098(0<uy>{dsjdyh}COVID-19 United States."

name= re.sub('[(),[^{}2<>-]', '', TEST)
print(name)

ndata= TEXT.replace(",","-")
ndata= ndata.replace(" ","-")
Ndata= ndata.split("\n")
arrangedDdata =''

cnt=0
for line in Ndata:
    cnt=cnt+1
    if cnt ==1:arrangedDdata=arrangedDdata+"date_time,cases\n"
    line=line.split("-")
    arrangedDdata=arrangedDdata+str(line[0])+"-"+str(line[1])+"-"+str(line[2])+" "+str(line[3])+","+str(line[5])+"\n"
print (arrangedDdata)

from io import StringIO
import numpy as np
import pandas as pd
from scipy import interpolate
import matplotlib.pyplot as plt
from time import gmtime, strftime
import time
csv = StringIO(arrangedDdata)

print("\nGMT: "+time.strftime("%a, %d %b %Y %I:%M:%S %p %Z", time.gmtime()))
df = pd.read_csv(csv, parse_dates=['date_time'], index_col=0)

s = .9
x = df.index.values
y = df.cases.values
xnew = np.arange(x[0], x[-1], np.timedelta64(5, 'm'))
fig, ax = plt.subplots(figsize=(12, 8))
#tck = interpolate.splrep(x, y, k=3, s=s)
tck = interpolate.splrep(x, y, k=4, s=s)
ynew = interpolate.splev(xnew.view(int), tck)

df.cases.plot(marker='o', ls='', label='data')
plt.plot(xnew, ynew, label=f'scipy cubic spline (s={s})')
(df.cases.resample('5min')
               .interpolate(method='spline', order=2, s=s)
               .plot(label=f'pandas cubic spline (s={s})'))
plt.legend();

TXT="""
03-17-2020 10:31,4743
03-17-2020 14:38,4752
03-17-2020 18:41,5723
03-17-2020 21:55,6211
03-17-2020 22:40,6349
03-18-2020 02:20,6499
03-18-2020 06:05,6522
03-18-2020 10:10,6524
03-18-2020 14:15,7301
03-18-2020 18:16,7708
03-18-2020 22:10,8998
03-19-2020 02:17,9371
03-19-2020 10:16,9464
03-19-2020 14:15,9486
03-19-2020 15:15,10692
03-19-2020 18:17,11355
03-19-2020 22:45,13737
03-20-2020 00:48,13865
03-20-2020 02:40,14316
03-20-2020 06:35,14366
03-20-2020 08:10,14366
03-20-2020 10:11,14366
03-20-2020 12:11,14366
03-20-2020 14:10,14373
03-20-2020 16:11,16067
03-20-2020 18:12,16545
03-20-2020 20:12,18121
03-20-2020 22:12,18876
03-21-2020 00:06,19393
03-21-2020 00:25,19429
03-21-2020 02:07,19643
03-21-2020 04:08,19652
03-21-2020 06:05,19774
03-21-2020 08:10,19774
03-21-2020 10:12,19774
"""

from io import StringIO
import numpy as np
import pandas as pd
from scipy import interpolate
import matplotlib.pyplot as plt
from time import gmtime, strftime
import time
csv = StringIO("""
date_time,cases
03-08-2020 23:30,537
03-09-2020 04:30,589
03-10-2020 05:30,708
03-10-2020 23:35,975
03-11-2020 04:25,1010
03-11-2020 15:17,1016
03-11-2020 23:35,1301
03-12-2020 03:25,1327
03-12-2020 11:37,1336
03-12-2020 22:00,1639
03-13-2020 00:05,1715
03-13-2020 01:35,1725
03-13-2020 03:45,1747
03-13-2020 06:00,1762
03-13-2020 15:25,1832
03-13-2020 22:25,2269
03-14-2020 02:40,2291
03-14-2020 16:15,2329
03-14-2020 16:45,2499
03-14-2020 23:03,2836
03-15-2020 05:00,2982
03-15-2020 05:40,2995
03-15-2020 07:05,3043
03-15-2020 19:00,3329
03-15-2020 20:05,3400
03-15-2020 21:15,3621
03-15-2020 22:15,3502
03-16-2020 00:35,3714
03-16-2020 02:48,3777
03-16-2020 05:36,3782
03-16-2020 08:29,3802
03-16-2020 18:40,4186
03-16-2020 22:40,4597
03-17-2020 10:31,4743
03-17-2020 14:38,4752
03-17-2020 18:41,5723
03-17-2020 21:55,6211
03-17-2020 22:40,6349
03-18-2020 02:20,6499
03-18-2020 06:05,6522
03-18-2020 10:10,6524
03-18-2020 14:15,7301
03-18-2020 18:16,7708
03-18-2020 22:10,8998
03-19-2020 02:17,9371
03-19-2020 10:16,9464
03-19-2020 14:15,9486
03-19-2020 15:15,10692
03-19-2020 18:17,11355
03-19-2020 22:45,13737
03-20-2020 00:48,13865
03-20-2020 02:40,14316
03-20-2020 06:35,14366
03-20-2020 08:10,14366
03-20-2020 10:11,14366
03-20-2020 12:11,14366
03-20-2020 14:10,14373
03-20-2020 16:11,16067
03-20-2020 18:12,16545
03-20-2020 20:12,18121
03-20-2020 22:12,18876
03-21-2020 00:06,19393
03-21-2020 00:25,19429
03-21-2020 02:07,19643
03-21-2020 04:08,19652
03-21-2020 06:05,19774
03-21-2020 08:10,19774
03-21-2020 10:12,19774
""")

print("\nGMT: "+time.strftime("%a, %d %b %Y %I:%M:%S %p %Z", time.gmtime()))
df = pd.read_csv(csv, parse_dates=['date_time'], index_col=0)

s = 1.2
x = df.index.values
y = df.cases.values
xnew = np.arange(x[0], x[-1], np.timedelta64(5, 'm'))
fig, ax = plt.subplots(figsize=(12, 8))
tck = interpolate.splrep(x, y, k=3, s=s)
ynew = interpolate.splev(xnew.view(int), tck)

df.cases.plot(marker='o', ls='', label='data')
plt.plot(xnew, ynew, label=f'scipy cubic spline (s={s})')
(df.cases.resample('5min')
               .interpolate(method='spline', order=2, s=s)
               .plot(label=f'pandas cubic spline (s={s})'))
plt.legend();

EpochData=""
text =arrangedDdata.split("\n")
text= text[1:-1]
for line in text:
    line = line.split(",")
    print(line[0])
    EpochData=EpochData+line[0]+"\n"

print (EpochData)

import sqlite3
from M2D import Month2Num
arrangedDdata = ''
# The next line will add a header to the data:  date_time,cases
# arrangedDdata=arrangedDdata+"date_time,cases\n"
conn=sqlite3.connect("DATA/CoronaData2.db")
c= conn.cursor()
for row in c.execute('SELECT rowid,* from CORONA'):
    MISC=row[1]
    Str = MISC.split(" ")
    month = Str[0][0:5]
    OUT = Month2Num(month)+","+MISC[5:15]+" "+MISC[18:24]+MISC[45:50]
    OUT = OUT.replace(", ","-")
    OUT = OUT.replace("c","")
    #OUT = OUT.replace(",","-")
    OUT = OUT.replace(" ",",");OUT = OUT.replace(",,"," ")
    OUT = OUT.rstrip(",") 
    print (OUT) 
    arrangedDdata = arrangedDdata+OUT+"\n"
conn.close() 
#3-15-2020 19:00,3329

import sqlite3
from M2D import Month2Num
arrangedDdata = ''
arrangedDdata=arrangedDdata+"date_time,cases\n"
conn=sqlite3.connect("DATA/CoronaData2.db")
c= conn.cursor()
for row in c.execute('SELECT rowid,* from CORONA'):
    MISC=row[1]
    Str = MISC.split(" ")
    month = Str[0][0:5]
    OUT = Month2Num(month)+","+MISC[5:15]+" "+MISC[18:24]+MISC[45:50]
    OUT = OUT.replace(", ","-")
    OUT = OUT.replace("c","")
    #OUT = OUT.replace(",","-")
    OUT = OUT.replace(" ",",");OUT = OUT.replace(",,"," ")
    OUT = OUT.rstrip(",") 
    print (OUT) 
    arrangedDdata = arrangedDdata+OUT+"\n"
conn.close() 
#3-15-2020 19:00,3329

import sqlite3
from M2D import Month2Num
arrangedDdata = ''
LAST = []
arrangedDdata=arrangedDdata+"date_time,cases\n"
conn=sqlite3.connect("DATA/CoronaData2.db")
c= conn.cursor()
for rows in c.execute('SELECT ROWID,* from CORONA'):
    rows=str(rows)
    print (rows)
    row = rows.split(" ")
    #print (row[10])
    LAST.append(row[10])
conn.close() 
#3-15-2020 19:00,3329

import sqlite3
from M2D import Month2Num
arrangedDdata = ''
arrangedDdata=arrangedDdata+"date_time,cases\n"
conn=sqlite3.connect("DATA/CoronaData2.db")
c= conn.cursor()
for row in c.execute('SELECT rowid,* from CORONA'):
    MISC=row[1]
    Str = MISC.split(" ")
    month = Str[0][0:5]
    OUT = Month2Num(month)+","+MISC[5:15]+" "+MISC[18:24]+":00"
    OUT = OUT.replace(", ","-")
    OUT = OUT.replace("c","")
    #OUT = OUT.replace(",","-")
    OUT = OUT.replace(" ",",");OUT = OUT.replace(",,"," ")
    OUT = OUT.rstrip(",");OUT = OUT.replace(",","") 
    print (OUT) 
    arrangedDdata = arrangedDdata+OUT+"\n"
conn.close() 
#3-15-2020 19:00,3329

print (OUT)

print (text)

import datetime
import calendar
import time
# 3,13,2020,03:45,GMT,1747,41
text =arrangedDdata.split("\n")
text= text[1:-1]
EPOCHa=[]
for line in text:
    #print(line)
    #line=str(LINE)
    line = line.split("-")
    #print (str(line[1]+'/'+line[0]+'/'+line[2][:-3]))
    dt = time.strftime((str(line[1]+'/'+line[0]+'/'+line[2][:-3])))
    #print (dt+":00")

    dt_ti = dt+":00"
    #print (dt_ti)
    #03-16-2020 02:48,3777
    pattern = '%d/%m/%Y %H:%M:%S'
    #pattern = '%m/%d/%Y %H:%M:%S'
    epochs = int(time.mktime(time.strptime(dt_ti, pattern)))
    print (dt_ti, epochs)
    EPOCHa.append(int(epochs))

print (EPOCHa)
EPOCH= EPOCHa

print (len(EPOCH))
epoch = EPOCH
print (epoch)

print(round(32.671, 2))
print(round(32.676, 2))
print(round(32.678, 2))

print ((1583681400-1583699400)/3600)
print ((1583699400-1583789400)/3600)
print ((1583789400-1583854500)/3600)
number =((1583789400-1583854500)/3600)
print (str(round(number, 2)))
print ((1583854500-1583871900)/3600)
print ((1583871900-1583911020)/3600)
print ((1583911020-1583940900)/3600)
print ((1584398100-1584412260)/3600)
print ((1584412260-1584427080)/3600)
print ((1584427080-1584441660)/3600)
print ((1584441660-1584453300)/3600)
print ((1584453300-1584456000)/3600)



import sqlite3
TEXt = []
conn=sqlite3.connect("DATA/CoronaData2.db")
c= conn.cursor()
for row in c.execute('SELECT rowid,* from CORONA'):
    #print (DATAout(row[1]))
    TEXt.append(DATAout(row[1]))      
TExt =str(TEXt)
TX=TExt.split("\n")
for lines in TX:
    print (lines[0:])
print ("\n----------------------------------------")
print (TEXt)    
conn.close()     

import sqlite3
TEXT = ""
conn=sqlite3.connect("DATA/CoronaData2.db")
c= conn.cursor()
for row in c.execute('SELECT rowid,* from CORONA'):
    #print (DATAout(row[1]))
    TEXT=TEXT+DATAout(row[1]+"\n")        
conn.close() 
TEXT=TEXT.split("\n")
for lines in TEXT:
    print (lines)

Text =  ' '.join(TEXT)
lines=Text.split("\n")
print (lines)

import sqlite3
TEXT = ""
conn=sqlite3.connect("DATA/CoronaData2.db")
c= conn.cursor()
for row in c.execute('SELECT rowid,* from CORONA'):
    print (DATAout(row[1]))
    TEXT=TEXT+DATAout(row[1])

from M2D import Month2Num
import sqlite3
minus=0
out2 =0
DIFF = []

CHANGE = ""
conn=sqlite3.connect("DATA/CoronaData2.db")
c= conn.cursor()
for row in c.execute('SELECT rowid,* from CORONA'):
    rows = DATAout(row[1]).split(",")
    out = int(rows[5])-minus
    print ("rowid:",row[0],"      ",out2,"=>",int(rows[5]),"Increase",int(rows[5])-out2)
    DIFF.append(int(rows[5])-out2)
    INT=int(rows[5])-out2
    STR=str(INT)
    CHANGE = CHANGE+STR+"\n"
    out2=out+minus
    

DIFF.reverse()
diff = DIFF

import time
import os
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
#%matplotlib inline 
import numpy as np 

print (DIFF)
#del DIFF[0]
#del DIFF[0]
print (DIFF)
diff = DIFF
#del diff[1]
epoch = EPOCH
#del epoch[1]
#num = [(number/150000)-10500 for number in epoch]
num = epoch
E=len(num)
print ("Epoch Quantity",E)
Time = np.array(num)

E=len(diff)
dif = np.array(diff)
#print (Time[3:], end=" ")
e = len(diff)
print ("DIFF Quantity",e)
ss = range(0,e)
aa = np.array(diff)
Ta = np.array(diff,dtype=np.int)
print(Ta)
s= np.array(num)
figure(num=None, figsize=(10,10), dpi=150, facecolor='salmon')
#fig, ax = plt.subplots(dpi=150)

plt.subplot(2, 1, 1)
plt.plot(Time, Ta, 'blue')
plt.title('Top: Time Relative Plot / Bottom: Relative to number of Samples')
plt.ylabel('Number of Cases')

import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
from scipy.interpolate import UnivariateSpline
NUM = len(diff)
print(NUM)
x = np.linspace(-3, 3, NUM)
y = np.array(diff,dtype=np.int)
#y = np.exp(-x**2) + 0.1 * np.array(diff,dtype=np.int)
figure(num=None, figsize=(8,5), dpi=100, facecolor='lightblue')
plt.plot(x, y, 'ro', ms=5)

#Use the default value for the smoothing parameter:
spl = UnivariateSpline(x, y)
#xs = np.linspace(-3, 3, 1000)
xs = np.linspace(-3, 3, NUM*2)
plt.plot(xs, spl(xs), 'g', lw=3)

#Manually change the amount of smoothing:
spl.set_smoothing_factor(0.5)
plt.plot(xs, spl(xs), 'b', lw=3)
plt.show()



#from scipy.stats import gaussian_kde
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
import numpy as np
import scipy.interpolate
#from scipy import interpolate
from scipy import integrate
from scipy import ndimage

y=diff
SM = (len(diff))
print ("len_SM",len(diff))
x = np.linspace(1 ,20,len(y))

# convert both to arrays
x_sm = np.array(x)
print ("x_sm",len(x_sm))
y_sm = np.array(y)
print ("y_sm",len(y_sm))
# resample to lots more points - needed for the smoothed curves
x_smooth = np.linspace(x_sm.min(), x_sm.max(), SM)

# spline - always goes through all the data points x/y
y_spline = interpolate.SmoothBivariateSpline(x, y, x_smooth)

spl = interpolate.UnivariateSpline(x, y)

sigma = 2
x_g1d = ndimage.gaussian_filter1d(x_sm, sigma)
y_g1d = ndimage.gaussian_filter1d(y_sm, sigma)
figure(num=None, figsize=(8,5), dpi=100, facecolor='lightblue')
#fig, ax = plt.subplots(figsize=(10, 6))
#ax.legend(loc='center left', bbox_to_anchor=(1.05, 0.5), frameon=False)

plt.plot(x_sm, y_sm, 'green', linewidth=1)
plt.plot(x_smooth+.2, spl(x_smooth)-15, 'blue', linewidth=1)
plt.plot(x_g1d,y_g1d, 'magenta', linewidth=1)

plt.show()

for line in LAST:
    print (line, end=" ")
LAST.reverse() 
print ("\n-----------------------------------")
for line in LAST:
    print (line, end=" ")
    
LAST.reverse()     

import numpy as np 
epoch = EPOCH
num = [(number/150000)-1050 for number in epoch]
E=len(num)
print (E)
Time = np.array(num)
for num in Time:
    print (num, end=" ")

from __future__ import division
import sys
import glob
import time
import os
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
#%matplotlib inline 
import numpy as np 
epoch = EPOCH
num = [(number/150000)-10500 for number in epoch]
E=len(num)
print ("len(num)",E)
Time = np.array(num)
e = len(LAST)
print ("len(LAST)",e)
print (Time[3:], end=" ")

ss = range(0,e)
aa = np.array(LAST)
#del LAST[0]
Ta = np.array(LAST,dtype=np.int)
print("Ta",Ta)
s= np.array(LAST)
figure(num=None, figsize=(10,10), dpi=80, facecolor='salmon')
#fig, ax = plt.subplots(dpi=150)


plt.subplot(2, 1, 1)
plt.plot(Time, Ta, 'blue')
plt.title('Top: Time Relative Plot / Bottom: Relative to number of Samples')
plt.ylabel('Number of Cases')


plt.subplot(2, 1, 2)
plt.plot(s, Ta, 'red')
plt.xlabel('time (s)')
plt.ylabel('Number of Samples')

plt.show()



from __future__ import division
import sys
import glob
import time
import os
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure

#%matplotlib inline 
import numpy as np 
EPOCH2 = [number/1500 for number in EPOCH]
#EPOCH = [number*.002 for number in EPOCH]
E=len(EPOCH2)
print (E)
Time = np.array(EPOCH2)
print (Time[3:], end=" ")
e = len(LAST)
print (e)
ss = range(0,e)
aa = np.array(LAST)
Ta = np.array(LAST,dtype=np.int)
print(Ta)
s= np.array(LAST)
figure(num=None, figsize=(10,10), dpi=80, facecolor='salmon')
#fig, ax = plt.subplots(dpi=150)


plt.subplot(2, 1, 1)
plt.plot(Time, Ta, 'blue')
plt.title('Using Timestamps')
plt.ylabel('Number of Cases')


plt.subplot(2, 1, 2)
plt.plot(s, Ta, 'red')
plt.xlabel('time (s)')
plt.ylabel('Undamped')

plt.show()





from __future__ import division
import sys
import glob
import time
import os
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure

#%matplotlib inline 
import numpy as np 

E=len(EPOCH)
print (E)
Time = np.array(EPOCH)
print (Time[3:], end=" ")
e = len(LAST)
print (e)
ss = range(0,e)
aa = np.array(LAST)
Ta = np.array(LAST,dtype=np.int)
print(Ta)
s= np.array(LAST)
figure(num=None, figsize=(10,8), dpi=80, facecolor='salmon')
#fig, ax = plt.subplots(dpi=150)


plt.subplot(2, 1, 1)
plt.plot(Time, Ta, 'blue')
plt.title('Using Timestamps')
plt.ylabel('Number of Cases')


plt.subplot(2, 1, 2)
plt.plot(s, Ta, 'red')
plt.xlabel('time (s)')
plt.ylabel('Undamped')

plt.show()



from __future__ import division
import sys
import glob
import time
import os
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
#%matplotlib inline 
import numpy as np 
E=len(EPOCH)
print (E)
Time = np.array(EPOCH)
print (Time[3:], end=" ")
e = len(LAST)
print (e)
ss = range(0,e)
aa = np.array(LAST)
Ta = np.array(LAST,dtype=np.int)
print(Ta)
s= np.array(LAST)
fig, ax = plt.subplots(dpi=100, facecolor='salmon')
#figure(num=None, figsize=(10,8), dpi=80, facecolor='salmon')
#ax.plot(s, Ta)
#ax.plot(Time-15800000, Ta)
ax.plot(Time, Ta)
DT = time.strftime("%Y-%m-%d:%H")
ax.set(xlabel='DATE: '+DT)
ax.grid()
tm = time.strftime("%Y-%m%d%H%M%S")
Filename = tm+".png"
print (Filename)
fig.savefig(Filename)
plt.show()


import sqlite3
from M2D import Month2Num
arrangedDdata = ''
LAST = []
arrangedDdata=arrangedDdata+"date_time,cases\n"
conn=sqlite3.connect("DATA/CoronaData2.db")
c= conn.cursor()
for rows in c.execute('SELECT * from CORONA'):
    rows=str(rows)
    row = rows.split(" ")
    print (row[9])
    LAST.append(row[9])
conn.close() 
#3-15-2020 19:00,3329

from __future__ import division
import sys
import glob
import time
import os
import matplotlib
import matplotlib.pyplot as plt
#%matplotlib inline 
import numpy as np 
CHANGEca = LAST
#del EPOCH[0]
Time = np.array(EPOCH)
#del CHANGEca[0]

#CHANGEca.reverse()
T = len(Time)
print ("len(Time)",T,"\n")


e = len(CHANGEca)
print ("len(CHANGEca)",e)
ss = range(0,e)
TaX = np.array(CHANGEca,dtype=np.float)
print("len(TaX)",len(TaX),"\n")
print(TaX)

sX= np.array(CHANGEca)
fig, ax = plt.subplots(dpi=100)
ax.plot(Time, TaX)
DT = time.strftime("%Y-%m-%d:%H")
ax.set(xlabel='DATE: '+DT)
ax.grid()
tm = time.strftime("%Y-%m%d%H%M%S")
Filename = tm+".png"
print (Filename)
fig.savefig(Filename)
plt.show()




from __future__ import division
import sys
import glob
import time
import os
import matplotlib
import matplotlib.pyplot as plt
#%matplotlib inline 
import numpy as np 
LAST.reverse()
e = len(LAST)
print (e)
ss = range(0,e)
Taa = np.array(LAST,dtype=np.int)
print(Taa)
fig, ax = plt.subplots(dpi=100)
ax.plot(ss, Taa)
DT = time.strftime("%Y-%m-%d:%H")
ax.set(xlabel='DATE: '+DT)
ax.grid()
tm = time.strftime("%Y-%m%d%H%M%S")
Filename = tm+"_.png"
print (Filename)
fig.savefig(Filename)
plt.show()


!chmod +x TestCorona

# %load TestCorona
#!/home/jack/miniconda3/bin/python
def some_job():
    import requests
    from time import gmtime, strftime
    import time
    print ("TEMPDATA/"+strftime("%d-%m-%Y_%H:%M:%S",gmtime())+".html")
    filename = "TEMPDATA/"+strftime("%d-%m-%Y_%H:%M:%S",gmtime())+".html"
    DataIn = open(filename,"w")
    listTEXT = []
    stringTEXT = ""
    response = requests.get('https://www.worldometers.info/coronavirus/country/us/')
    DATA = str(response.content)
    listTEXT.append(DATA)
    stringTEXT = stringTEXT+DATA
    DataIn.write(str(listTEXT))
    DataIn.close()
    print(filename)
some_job()   


import matplotlib
import numpy as np
import mpld3
import matplotlib.pyplot as plt
from PIL import Image
from mpld3 import plugins
%matplotlib inline
fig, ax = plt.subplots()
im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))
# Default shows the image upside down [::-1] flips the image
#im = im[::-1]
plt.imshow(im)
plugins.connect(fig, plugins.MousePosition(fontsize=14))


mpld3.display()

from matplotlib import pyplot as plt
import numpy as np
import mpld3
from mpld3 import plugins
%matplotlib inline
LA = LAT[:-8]
LO = LONG[:-8]

print(len(LA))
print(len(LO))

LT = np.array(LAT,dtype=np.float)
LG = np.array(LONG,dtype=np.float)
print (max(LT))
print (min(LT))
print (max(LG))
print (min(LG))

fig = plt.figure(num=None, figsize=(12,10), dpi=80, facecolor='salmon')
#fig = plt.figure()
ax = fig.gca()

#ax.set_facecolor('xkcd:green')
ax.set_facecolor(('#8eda8b'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.01)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

plt.axis([-130,-65,20,55])
ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.scatter(LG, LT, s=s, color="black")
plt.grid(True)

plt.xlabel('First data sample was: 09/03/2020 04:30:00')
plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
plt.ylabel('Number of Cases')
plt.show()
#plugins.connect(fig, plugins.MousePosition(fontsize=14))


#mpld3.display()



from DTE import Date2Epoch
Date = "31 March 2020 02:48"
Date2Epoch(Date,last=1583621400)



LASTFILE="csse_covid_19_data/csse_covid_19_daily_reports/04-02-2020.csv"
#LASTFILE="csse_covid_19_data/csse_covid_19_daily_reports/03-30-2020.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
STATES=[]
cases=[]
longitude = ""
cnt = -1
for line in DataIn:
    if len(line)>10 and 'US' in line and "Recovered" not in line and " Minnesota" in line and "DeSoto" not in line  and "Unassigned" not in line:
        cnt=cnt+1
        line=line.replace("\n","")
        line = line.lstrip(",")
        line = line.split(",")
        # Only print if cnt <20
        if len(line)>5 and cnt <10:print(line[2],line[1],line[3],line[4],line[5],line[6],line[7],line[8], line[9],line[10])
        if len(line)>5:text = str(line[2]+' '+line[1]+' '+line[3]+' '+line[4]+' '+line[5]+' '+line[6]+' '+line[7]+' '+line[8]+' '+line[9]+' '+line[10])
        
        STATES.append(text)
        LAT.append(line[5])
        LONG.append(line[6])
        cases.append(line[7])
        longitude = longitude+line[6]+","
print("\nlen(STATES)\n",len(STATES))        

!pwd

import sqlite3
from datetime import datetime
from time import gmtime, strftime
import glob
import time
import os
import requests
stringTEXT = ""
if not os.path.exists('state-data/DATA'):
    os.makedirs('state-data/DATA')
print (time.strftime('%a_%d_%b_%Y_%I_%M_%S_%p_%Z', time.gmtime())+".html")
filename = "state-data/DATA/US_State_Bounding_Boxes.csv"
DataIn = open(filename,"w")

BoundingBoxes = ""
response = requests.get('https://gist.githubusercontent.com/a8dx/2340f9527af64f8ef8439366de981168/raw/81d876daea10eab5c2675811c39bcd18a79a9212/US_State_Bounding_Boxes.csv')
filename = "state-data/DATA/US_State_Bounding_Boxes.csv"
with open(filename, mode='wb') as localfile:
    localfile.write(response.content)


!ls state-data/DATA

filename = "state-data/DATA/US_State_Bounding_Boxes.csv"
output = open(filename,"r").readlines()
for line in output:
    line=line.replace("\n","")
    print(line)

EX="01,AL,Alabama,-88.473227,30.223334,-84.88908,35.008028"
print(EX[6:])

File = b"/home/jack/Desktop/state-data/DATA/US_State_Bounding_Boxes.csv"
BOXES = []
DataOut = open(File, "r").readlines()
cnt= 0

for items in DataOut:
    cnt=cnt+1
    items=items.replace('\n','')
    clean=items.replace('"','')
    clean = clean.split(',')
    print(" ".join(clean[3:]))
    entry=" ".join(clean[3:])
    BOXES.append(entry)

%%writefile US_State_Bounding_Boxes.py
DATA="""
NAME  xmin ymin xmax ymax
Alabama  -88.473227 30.223334 -84.88908 35.008028
Alaska  -179.148909 51.214183 179.77847 71.365162
American Samoa  -171.089874 -14.548699 -168.1433 -11.046934
Arizona  -114.81651 31.332177 -109.045223 37.00426
Arkansas  -94.617919 33.004106 -89.644395 36.4996
California  -124.409591 32.534156 -114.131211 42.009518
Colorado  -109.060253 36.992426 -102.041524 41.003444
Commonwealth of the Northern Mariana Islands  144.886331 14.110472 146.064818 20.553802
Connecticut  -73.727775 40.980144 -71.786994 42.050587
Delaware  -75.788658 38.451013 -75.048939 39.839007
District of Columbia  -77.119759 38.791645 -76.909395 38.99511
Florida  -87.634938 24.523096 -80.031362 31.000888
Georgia  -85.605165 30.357851 -80.839729 35.000659
Guam  144.618068 13.234189 144.956712 13.654383
Hawaii  -178.334698 18.910361 -154.806773 28.402123
Idaho  -117.243027 41.988057 -111.043564 49.001146
Illinois  -91.513079 36.970298 -87.494756 42.508481
Indiana  -88.09776 37.771742 -84.784579 41.760592
Iowa  -96.639704 40.375501 -90.140061 43.501196
Kansas  -102.051744 36.993016 -94.588413 40.003162
Kentucky  -89.571509 36.497129 -81.964971 39.147458
Louisiana  -94.043147 28.928609 -88.817017 33.019457
Maine  -71.083924 42.977764 -66.949895 47.459686
Maryland  -79.487651 37.911717 -75.048939 39.723043
Massachusetts  -73.508142 41.237964 -69.928393 42.886589
Michigan  -90.418136 41.696118 -82.413474 48.2388
Minnesota  -97.239209 43.499356 -89.491739 49.384358
Mississippi  -91.655009 30.173943 -88.097888 34.996052
Missouri  -95.774704 35.995683 -89.098843 40.61364
Montana  -116.050003 44.358221 -104.039138 49.00139
Nebraska  -104.053514 39.999998 -95.30829 43.001708
Nevada  -120.005746 35.001857 -114.039648 42.002207
New Hampshire  -72.557247 42.69699 -70.610621 45.305476
New Jersey  -75.559614 38.928519 -73.893979 41.357423
New Mexico  -109.050173 31.332301 -103.001964 37.000232
New York  -79.762152 40.496103 -71.856214 45.01585
North Carolina  -84.321869 33.842316 -75.460621 36.588117
North Dakota  -104.0489 45.935054 -96.554507 49.000574
Ohio  -84.820159 38.403202 -80.518693 41.977523
Oklahoma  -103.002565 33.615833 -94.430662 37.002206
Oregon  -124.566244 41.991794 -116.463504 46.292035
Pennsylvania  -80.519891 39.7198 -74.689516 42.26986
Puerto Rico  -67.945404 17.88328 -65.220703 18.515683
Rhode Island  -71.862772 41.146339 -71.12057 42.018798
South Carolina  -83.35391 32.0346 -78.54203 35.215402
South Dakota  -104.057698 42.479635 -96.436589 45.94545
Tennessee  -90.310298 34.982972 -81.6469 36.678118
Texas  -106.645646 25.837377 -93.508292 36.500704
United States Virgin Islands  -65.085452 17.673976 -64.564907 18.412655
Utah  -114.052962 36.997968 -109.041058 42.001567
Vermont  -73.43774 42.726853 -71.464555 45.016659
Virginia  -83.675395 36.540738 -75.242266 39.466012
Washington  -124.763068 45.543541 -116.915989 49.002494
West Virginia  -82.644739 37.201483 -77.719519 40.638801
Wisconsin  -92.888114 42.491983 -86.805415 47.080621
Wyoming  -111.056888 40.994746 -104.05216 45.005904
"""
def GetCOOR(state):
    STATElist=DATA.split("\n")
    for States in STATElist:
        if state in States:
            States = States.replace("  "," ")
            States = States.split(" ")
            urcrnrlat = float(States[4])
            llcrnrlat = float(States[2])
            urcrnrlon = float(States[3])
            llcrnrlon = float(States[1])
            return urcrnrlat,llcrnrlat,urcrnrlon,llcrnrlon

def COOR(state):
    STATElist=DATA.split("\n")
    for States in STATElist:
        if state in States:
            COOR=States.split("  ")
            state = COOR[0]
            coor =COOR[1]
            return state,coor

from US_State_Bounding_Boxes import *
coor= GetCOOR("Michigan")
print(coor[0],coor[1],coor[2],coor[3])

from US_State_Bounding_Boxes import GetCOOR
coor= GetCOOR("Michigan")
urcrnrlat = coor[0]
llcrnrlat = coor[1]
urcrnrlon = coor[2]
llcrnrlon = coor[3]

%matplotlib inline
import numpy as np
import pandas as pd
import shapefile as shp
import matplotlib.pyplot as plt
import seaborn as sns

sns.set(style="whitegrid", palette="pastel", color_codes=True)
sns.mpl.rc("figure", figsize=(10,6))



!cp -a /mnt/40ec525c-34bc-44ef-99c8-53f5524ad88b/home/jack/Desktop/state-data/* state-data

!cp /home/jack/Desktop/state-data/tl_2010_us_state10.sh state-data/DATA/

shp_path = "state-data/tl_2010_us_state10.sh"
sf = shp.Reader(shp_path)

len(sf.shapes())

# How many elements in the record ?
len(sf.records()[1])

sf.records()[1]

sf.records()[1][5]

import numpy as np
import pandas as pd
import shapefile as shp
import matplotlib.pyplot as plt
import seaborn as sns
sns.set(style="whitegrid", palette="pastel", color_codes=True)
sns.mpl.rc("figure", figsize=(10,6))
%matplotlib inline
shp_path = "state-data/tl_2010_us_state10.sh"
sf = shp.Reader(shp_path)

print(len(sf.shapes()))
print(sf.records()[1])
#comuna = 'Pennsylvania'
#com_id = df[df.NOM_COMUNA == comuna].index.get_values()[0]
#plot_shape(com_id, comuna)

def read_shapefile(sf):
    """
    Read a shapefile into a Pandas dataframe with a 'coords' 
    column holding the geometry information. This uses the pyshp
    package
    """
    fields = [x[0] for x in sf.fields][1:]
    records = sf.records()
    shps = [s.points for s in sf.shapes()]
    df = pd.DataFrame(columns=fields, data=records)
    df = df.assign(coords=shps)
    return df

df = read_shapefile(sf)
df.shape

df.sample(5)

df[df.NAME10 == 'Pennsylvania']

df['NAME10']

def plot_shape(id, s=None):
    """ PLOTS A SINGLE SHAPE """
    plt.figure()
    ax = plt.axes()
    ax.set_aspect('equal')
    shape_ex = sf.shape(id)
    x_lon = np.zeros((len(shape_ex.points),1))
    y_lat = np.zeros((len(shape_ex.points),1))
    for ip in range(len(shape_ex.points)):
        x_lon[ip] = shape_ex.points[ip][0]
        y_lat[ip] = shape_ex.points[ip][1]
        plt.plot(x_lon,y_lat) 
    x0 = np.mean(x_lon)
    y0 = np.mean(y_lat)
    plt.text(x0, y0, s, fontsize=10)
    # use bbox (bounding box) to set plot limits
    plt.xlim(shape_ex.bbox[0],shape_ex.bbox[2])
    return x0, y0

plot_shape(12, s=None)

def plot_map(sf, x_lim = None, y_lim = None, figsize = (11,9)):
    '''
    Plot map with lim coordinates
    '''
    plt.figure(figsize = figsize)
    id=0
    for shape in sf.shapeRecords():
        x = [i[0] for i in shape.shape.points[:]]
        y = [i[1] for i in shape.shape.points[:]]
        plt.plot(x, y, 'k')
        
        if (x_lim == None) & (y_lim == None):
            x0 = np.mean(x)
            y0 = np.mean(y)
            plt.text(x0, y0, id, fontsize=10)
        id = id+1
    
    if (x_lim != None) & (y_lim != None):     
        plt.xlim(x_lim)
        plt.ylim(y_lim)

plot_map(sf,1)

import US_State_Bounding_Boxes
help(US_State_Bounding_Boxes)

from US_State_Bounding_Boxes import *
state="Ohio"
GetCOOR(state)

from US_State_Bounding_Boxes import *
state="Ohio"
a,b,c,d = GetCOOR(state)
c,b
d,a

%%writefile US_State_Bounding_Boxes.py
DATA="""
NAME  xmin ymin xmax ymax
Alabama  -88.473227 30.223334 -84.88908 35.008028
Alaska  -179.148909 51.214183 179.77847 71.365162
American Samoa  -171.089874 -14.548699 -168.1433 -11.046934
Arizona  -114.81651 31.332177 -109.045223 37.00426
Arkansas  -94.617919 33.004106 -89.644395 36.4996
California  -124.409591 32.534156 -114.131211 42.009518
Colorado  -109.060253 36.992426 -102.041524 41.003444
Commonwealth of the Northern Mariana Islands  144.886331 14.110472 146.064818 20.553802
Connecticut  -73.727775 40.980144 -71.786994 42.050587
Delaware  -75.788658 38.451013 -75.048939 39.839007
District of Columbia  -77.119759 38.791645 -76.909395 38.99511
Florida  -87.634938 24.523096 -80.031362 31.000888
Georgia  -85.605165 30.357851 -80.839729 35.000659
Guam  144.618068 13.234189 144.956712 13.654383
Hawaii  -178.334698 18.910361 -154.806773 28.402123
Idaho  -117.243027 41.988057 -111.043564 49.001146
Illinois  -91.513079 36.970298 -87.494756 42.508481
Indiana  -88.09776 37.771742 -84.784579 41.760592
Iowa  -96.639704 40.375501 -90.140061 43.501196
Kansas  -102.051744 36.993016 -94.588413 40.003162
Kentucky  -89.571509 36.497129 -81.964971 39.147458
Louisiana  -94.043147 28.928609 -88.817017 33.019457
Maine  -71.083924 42.977764 -66.949895 47.459686
Maryland  -79.487651 37.911717 -75.048939 39.723043
Massachusetts  -73.508142 41.237964 -69.928393 42.886589
Michigan  -90.418136 41.696118 -82.413474 48.2388
Minnesota  -97.239209 43.499356 -89.491739 49.384358
Mississippi  -91.655009 30.173943 -88.097888 34.996052
Missouri  -95.774704 35.995683 -89.098843 40.61364
Montana  -116.050003 44.358221 -104.039138 49.00139
Nebraska  -104.053514 39.999998 -95.30829 43.001708
Nevada  -120.005746 35.001857 -114.039648 42.002207
New Hampshire  -72.557247 42.69699 -70.610621 45.305476
New Jersey  -75.559614 38.928519 -73.893979 41.357423
New Mexico  -109.050173 31.332301 -103.001964 37.000232
New York  -79.762152 40.496103 -71.856214 45.01585
North Carolina  -84.321869 33.842316 -75.460621 36.588117
North Dakota  -104.0489 45.935054 -96.554507 49.000574
Ohio  -84.820159 38.403202 -80.518693 41.977523
Oklahoma  -103.002565 33.615833 -94.430662 37.002206
Oregon  -124.566244 41.991794 -116.463504 46.292035
Pennsylvania  -80.519891 39.7198 -74.689516 42.26986
Puerto Rico  -67.945404 17.88328 -65.220703 18.515683
Rhode Island  -71.862772 41.146339 -71.12057 42.018798
South Carolina  -83.35391 32.0346 -78.54203 35.215402
South Dakota  -104.057698 42.479635 -96.436589 45.94545
Tennessee  -90.310298 34.982972 -81.6469 36.678118
Texas  -106.645646 25.837377 -93.508292 36.500704
United States Virgin Islands  -65.085452 17.673976 -64.564907 18.412655
Utah  -114.052962 36.997968 -109.041058 42.001567
Vermont  -73.43774 42.726853 -71.464555 45.016659
Virginia  -83.675395 36.540738 -75.242266 39.466012
Washington  -124.763068 45.543541 -116.915989 49.002494
West Virginia  -82.644739 37.201483 -77.719519 40.638801
Wisconsin  -92.888114 42.491983 -86.805415 47.080621
Wyoming  -111.056888 40.994746 -104.05216 45.005904
"""
def GetCOOR(state):
    STATElist=DATA.split("\n")
    for States in STATElist:
        if state in States:
            States = States.split("  ")[-1]
            States = States.split(" ")
            urcrnrlat = float(States[3])
            llcrnrlat = float(States[1])
            urcrnrlon = float(States[2])
            llcrnrlon = float(States[0])
            return urcrnrlat,llcrnrlat,urcrnrlon,llcrnrlon

def COOR(state):
    STATElist=DATA.split("\n")
    for States in STATElist:
        if state in States:
            COOR=States.split("  ")
            state = COOR[0]
            coor =COOR[1]
            return state,coor


from US_State_Bounding_Boxes import *
state="Ohio"
COOR(state)

from US_State_Bounding_Boxes import *
state="New York"
GetCOOR(state)

from US_State_Bounding_Boxes import *
#state="Ohio"
#state="Maine"
state="Florida"
#state="Michigan"
a,b,c,d = GetCOOR(state)
#c,b
#d,a
#y_lim = (38.403202,41.977523) # latitude 
#x_lim = (-84.820159, -80.518693) # longitude

padding = .5
y_lim = (b-padding,a+padding) # latitude 
x_lim = (d-padding,c+padding) # longitude
plot_map(sf, x_lim, y_lim)

y_lim = (38.403202,41.977523) # latitude 
x_lim = (-84.820159, -80.518693) # longitude
plot_map(sf, x_lim, y_lim)

y_lim = (37.5,42.5) # latitude 
x_lim = (-86, -80) # longitude
plot_map(sf, x_lim, y_lim)



import matplotlib.pyplot as plt
from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon
import numpy as np
from PIL import Image,ImageFont,ImageDraw,ImageFilter,ImageChops
from random import randint
from mpl_toolkits.basemap import Basemap
#prevents a warning from using Python3 instaead of Python2
import warnings
warnings.filterwarnings("ignore")
import sys
sys.path.insert(1, "/home/jack/hidden")
import Key
import twython
from twython import Twython
# Make the figure
#fig = plt.figure()
#ax = fig.add_subplot(111)

# Easiest way to make a basemap is to use the cylidrical projection and 
# define the bottom left lat/lon and top right lat/lon corners

def RndState():
    TX=["Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming"]
    x=randint(1,50)
    return TX[x]
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-27-2020.csv"
#LASTFILE="csse_covid_19_data/csse_covid_19_daily_reports/03-30-2020.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
LATd=[]
LONGd=[]
STATES=[]
cases=[]
deaths =[]
longitude = ""
search = RndState()
for line in DataIn:
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    if search in line[2] and "-" in (line[6]):
        text=line[2],line[1],line[3],line[4],line[5],line[6],line[7],line[8],line[9],line[10]
        STATES.append(text)
        LAT.append(line[5])
        LONG.append(line[6])
        if int(line[8])>0:
            LATd.append(line[5])
            LONGd.append(line[6])        
        cases.append(line[7])
        deaths.append(line[8])
        longitude = longitude+line[6]+","
print(len(STATES))        
LT = np.array(LAT,dtype=np.float)
LG = np.array(LONG,dtype=np.float)
LTd = np.array(LATd,dtype=np.float)
LGd = np.array(LONGd,dtype=np.float)


fig = plt.figure(num=None, figsize=(10,8), dpi=80, facecolor='salmon')


urcrnrlat=max(LT)+.5
llcrnrlat=min(LT)-.5
urcrnrlon=max(LG)+.8
llcrnrlon=min(LG)-.5
lat_0 = (urcrnrlat+llcrnrlat)/2
lon_0 =(urcrnrlon+llcrnrlon)/2

# create the map object, m
m = Basemap(resolution='i', projection='cyl', \
    llcrnrlon=llcrnrlon, llcrnrlat=llcrnrlat, urcrnrlon=urcrnrlon, urcrnrlat=urcrnrlat)

# Note: You can define the resolution of the map you just created. Higher 
# resolutions take longer to create.
#    'c' - crude
#    'l' - low
#    'i' - intermediate
#    'h' - high
#    'f' - full

# Draw some map elements on the map
m.drawmapboundary(fill_color='aqua')
m.fillcontinents(color='#ddaa66',lake_color='aqua')
m.drawcoastlines()
m.drawrivers(linewidth=1.0,color='navy',zorder=8)
m.drawcounties(linewidth=1.0, linestyle='solid', color='gray', antialiased=1, facecolor='lightgreen', ax=None, zorder=2, drawbounds=True)
m.drawstates(linewidth=1.5, linestyle='solid', color='black', antialiased=1,zorder=2, )
plt.text(llcrnrlon,llcrnrlat+.5, search, color='black', fontsize=24.5, zorder=6,bbox=dict(facecolor='salmon'))

# Drawing ArcGIS Basemap (only works with cylc projections??)
# Examples of what each map looks like can be found here:
# http://kbkb-wx-python.blogspot.com/2016/04/python-basemap-background-image-from.html
maps = ['ESRI_Imagery_World_2D',    # 0
        'ESRI_StreetMap_World_2D',  # 1
        'NatGeo_World_Map',         # 2
        'NGS_Topo_US_2D',           # 3
        'Ocean_Basemap',            # 4
        'USA_Topo_Maps',            # 5
        'World_Imagery',            # 6
        'World_Physical_Map',       # 7
        'World_Shaded_Relief',      # 8
        'World_Street_Map',         # 9
        'World_Terrain_Base',       # 10
        'World_Topo_Map'            # 11
        ]
print ("drawing image from arcGIS server..."),
m.arcgisimage(service=maps[8], xpixels=1000, verbose=False)
print ("...finished")

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.5)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

Sd=0
Sized=[]
for xd in deaths:
    Sd=0+(float(xd))
    Sized.append(int(Sd))
    #print(int(S))
sd = np.array(Sized)
#print(Sized)
plt.title("COVID-19:\n Cases: (black)\n Deaths(red) \n Location:\n "+search+"\n", fontsize=15, loc='right')
#plt.text(max(LG-1.2),max(LT), search, color='white', fontsize=24)
#x, y = m(lons, lats)  # transform coordinates
x, y = m(LGd, LTd)
xx,yy = m(LG, LT)
plt.xlabel('Longitude',color="white", fontsize=24)
plt.ylabel('Latitute',color="white", fontsize=24)

m.scatter(xx, yy, s=s, color='black', zorder=5, alpha=0.6)
m.scatter(x, y, s=sd, color='r', zorder=10,  alpha=0.6)



#plt.scatter(x, y,  s=s, color="black", zorder=3, alpha=0.6)
#plt.scatter(x, y,  s=sd, color="red", zorder=6, alpha=0.6)
#plt.text(urcrnrlon,urcrnrlat, search, color='white', fontsize=24)
plt.savefig("BaseMap/"+search+"arcGIS__.png", dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)
#plt.show()
# Plot a scatter point at WBB on the map object
#lon = -111.85
#lat = 40.77
#m.scatter(lon,lat,c='r',s=150)

# Plot some wind barbs
#lons = np.arange(-115,-100,.5)
#lats = np.arange(33,48,.5)
#u = np.arange(-5,10,.5)
#v = np.arange(5,20,.5)
#m.barbs(lons, lats, u, v, color='fuchsia')

# Plot line between two points
# (can also use greatcircle function to be more accurate)
#x = [-110, -112]
#y = [40, 42]
#m.plot(x, y, color='navy', lw=5)

# Fill two polygon shapes
#patches = []
#homeplate = np.array([[-114,38],[-113,37],[-112,38],[-112,40],[-114,40]])
#patches.append(Polygon(homeplate))
#triangle = np.array([[-111,38],[-110,37],[-110,42]])
#patches.append(Polygon(triangle))
#ax.add_collection(PatchCollection(patches, facecolor='lightgreen', edgecolor='k', linewidths=1.5))

# Plot shapefiles: see here: http://basemaptutorial.readthedocs.io/en/latest/shapefile.html

# Plot contours
#m.contour(lons2D, lats2D, values2D)  # contour lines
# m.contourf(lons2D, lats2D, values2D) # contour color filled, can specify a cmap

# Plot gridded data
# m.pcolormesh(lons2D, lats2D, values2D) # can specify a cmap

# Add plot title and other plot elements the normal way
filename0 = "BaseMap/"+search+"arcGIS__.png"


def draw_blurred_back(img, position, text, font, col, halo_col):
    halo = Image.new('RGBA', img.size, (0, 0, 0, 0))
    ImageDraw.Draw(halo).text(position, text, font = font, fill = halo_col)
    blurred_halo = halo.filter(ImageFilter.BLUR)
    ImageDraw.Draw(blurred_halo).text(position, text, font = font, fill = col)
    return Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))

if __name__ == '__main__':
    
    basewidth = 720
    inp = Image.open(filename0)
    wpercent = (basewidth / float(inp.size[0]))
    hsize = int((float(inp.size[1]) * float(wpercent)))
    inp = inp.resize((basewidth, hsize), Image.ANTIALIAS)
    #img.save(resized_image.jpg')
    
    #inp = inp.resize((640,640), Image.ANTIALIAS)
    font = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 30)
    text_title = (255, 255,230) # bright green
    blur_title = (0, 0, 0)   # black

    i2 = draw_blurred_back(inp, (15, 30), "Plotting COVID-19 Data", font, text_title, blur_title)
    font0 = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 20)
    font1 = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 14)
    font2 = ImageFont.truetype("/home/jack/fonts/PatrickHand-Regular.ttf", 16)
    i2 = draw_blurred_back(i2, (15, 65), "Plot Using ArcGIS Basemap - "+search, font0, text_title, blur_title)
    TXT="https://github.com/JupyterJones/COVID-19-Jupyter-Notebooks"
    draw = ImageDraw.Draw(i2) 
    draw.text((15, 5), TXT, font = font2, align ="left",fill="black")
    #i2 = draw(i2, (15, 65),TXT, font1)    
    
    #txt = Image.new('RGBA', i.size, (255,255,255,0))

    # get a font
    fnt = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 20)
    # get a drawing context
    signature_ = "@jacklnorthrup" 
    #get length in pixel of signature_
    sizeS,ln = fnt.getsize(signature_)
    #add 15 pixels to right border
    pt = sizeS+25
    width, height = inp.size
    #marginx starting point of signature_
    marginx = pt
    #bottom margin
    marginy = 30
    x = width - marginx
    y = height - marginy
    

    text_sig = (255, 255,230) # bright green
    blur_sig = (0, 0, 0)   # black
    txt=draw_blurred_back(i2,(x,y), signature_, fnt, text_sig, blur_sig)
    out = Image.alpha_composite(i2, txt)
    out.save("images/TEMP_POST.png")

CONSUMER_KEY = Key.twiter()[0]
CONSUMER_SECRET = Key.twiter()[1]
ACCESS_KEY = Key.twiter()[2]
ACCESS_SECRET = Key.twiter()[3]
twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)

STR = "#"+search+"  #arcGIS server #Basemap #COVID-19 - #Python  Plot data using "+TXT+" #JupyterJones" 

PATH = "images/TEMP_POST.png"
photo = open(PATH,'rb')
#response = twitter.upload_media(media=photo)
#twitter.update_status(status=STR, media_ids=[response['media_id']])

import time
#DATE = time.strftime("%Y-%m%d%H%M%S")
DATE = time.strftime("%m-%d-%H_")
DATE 


import requests as req
import time
DATE = time.strftime("%m-%d-%H_")
URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/04-29-2020.csv"

resp = req.get(URL)
content = resp.text

#create a date oriented filename and print it
filename=URL[-14:]
print(filename)
content=content.replace(",,",",Ex,")
content=content.replace("(","")
content=content.replace(")","")
content=content.replace("\"","")
print(content)
# Open a file using the new filename and write the content of the 'gitfile' to it.
# Update one time daily
TEMP = open(filename,"w")
TEMP.write(content)
TEMP.close()

LASTFILE="05-01-10__04-29-2020.csv"
DataIn = open(LASTFILE).readlines()
cnt=0
for lineZ in DataIn:
    cnt=cnt+1
    line=lineZ.split(",")
    if cnt<8:
        if cnt==1:print(line)
        if cnt==2:print("----------------------------------------------------------------")
        #print(line)
        print("----------------------------------------------------------------")
        print(line[1],line[2])

weirdstuff="45001,Abbeville,South Carolina,US,2020-04-30 02:32:27,34.22333378,-82.46170658,29,0,0,29,Abbeville, South Carolina, US"
text=weirdstuff.split(",")
print(text[1])

LASTFILE="05-01-10__04-29-2020.csv"
DataIn = open(LASTFILE).readlines()
for line in DataIn:
    line=line.replace('"','')
    #if cnt==0:print (line)
    cnt=cnt+1
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    #if cnt<10 and line[5] !="":print (line[6])
    if "US" == line[7]:# and line[6] == "New York":
        #if CNT==7:print(line)
        #if CNT==8:print(line)    
        #if CNT<5 and line[5] !="":print line
        CNT=CNT+1
        ALL.append(line)
        LAT.append(line[5])
        LONG.append(line[6])
        L=len(line)
        deaths.append(line[L-1])

!ls 04-30-14__covid19_deaths_US.csv

filename=str(DATE)+"_"+URL[-21:]
print(filename)

import warnings
warnings.filterwarnings("ignore")
import matplotlib.pyplot as plt
from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon
import numpy as np
from PIL import Image,ImageFont,ImageDraw,ImageFilter,ImageChops
from random import randint
from mpl_toolkits.basemap import Basemap
fig = plt.figure(num=None, figsize=(12, 8) ) 
m = Basemap(width=6000000,height=4500000,resolution='c',projection='aea',lat_1=35.,lat_2=45,lon_0=-100,lat_0=40)
m.drawcoastlines(linewidth=0.5)
m.fillcontinents(color='tan',lake_color='lightblue')
# draw parallels and meridians.
m.drawparallels(np.arange(-90.,91.,15.),labels=[True,True,False,False],dashes=[2,2])
m.drawmeridians(np.arange(-180.,181.,15.),labels=[False,False,False,True],dashes=[2,2])
m.drawmapboundary(fill_color='lightblue')
m.drawcountries(linewidth=2, linestyle='solid', color='k' ) 
m.drawstates(linewidth=0.5, linestyle='solid', color='k')
m.drawrivers(linewidth=0.5, linestyle='solid', color='blue')
cities =[]
LAT=[]
LONG=[]
LATd=[]
LONGd=[]
STATES=[]
ALL=[]
cases=[]
deaths =[]
yesterday=0
today=0
longitude = ""
cnt=0
CNT=0
Dcnt=0
LASTFILE="04-30-10__covid19_deaths_US.csv"
DataIn = open(LASTFILE).readlines()
for line in DataIn:
    line=line.replace('"','')
    #if cnt==0:print (line)
    cnt=cnt+1
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    #if cnt<10 and line[5] !="":print (line[6])
    if "US" == line[7]:# and line[6] == "New York":
        #if CNT==7:print(line)
        #if CNT==8:print(line)    
        #if CNT<5 and line[5] !="":print line
        CNT=CNT+1
        ALL.append(line)
        LAT.append(line[5])
        LONG.append(line[6])
        L=len(line)
        deaths.append(line[L-1])
        #print(L)
        #print(line[L-1],line[L-2])
        if int(line[L-2])+50<int(line[L-1]):
            #print ("if ",int(line[L-2]),'+10',int(line[L-1]))
            #print (text,int(line[L-2]),int(line[L-1]))
            if len(line[8])>3:            
                text=line
                STATES.append(text)
                yesterday=yesterday+int(line[-2])
                today= today+int(line[-1])
                Dcnt=Dcnt+1
                #print(line[8],line[9])
                cities.append([line[5],line[6],line[8],line[9],line[L-1],int(line[L-1])-int(line[L-2])])
                LATd.append(line[8])
                LONGd.append(line[9])
                
                
LTd = np.array(LATd,dtype=np.float)
LGd = np.array(LONGd,dtype=np.float)
Str = np.array(cities,dtype=np.str)

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.01)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

Sd=1
Sized=[]
for xd in deaths:
    Sd=0+(float(xd)*.07)
    Sized.append(int(Sd))
    #print(int(S))
sd = np.array(Sized)
#print(Sized)
plt.title("Finding-Hot-Spots.ipynb - https://github.com/JupyterJones/COVID-19-Jupyter-Notebooks")
#plt.text(max(LG-1.2),max(LT), search, color='white', fontsize=24)
#x, y = m(lons, lats)  # transform coordinates
x, y = m(LGd, LTd)
#xx,yy = m(LG, LT)
plt.xlabel('Longitude',color="white", fontsize=24)
plt.ylabel('Latitute',color="white", fontsize=24)

for i in (range(0,len(cities))):
    C=cities[i][0]
    S=cities[i][1]
    t=float(cities[i][2])
    l=float(cities[i][3])
    d=cities[i][4]
    inc=cities[i][5]
    print(C,S,l,t,d,inc)
    plt.annotate(C, m(l,t),color='black',fontsize=10,zorder=15)   
    
m.scatter(x, y, s=sd, color='r', zorder=10,  alpha=0.6)
filename = "BaseMap/april30_Hotspots__.png"
plt.savefig(filename, dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)

# Using graph_objects
import plotly.graph_objects as go
import pandas as pd
df = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/finance-charts-apple.csv')

fig = go.Figure([go.Scatter(x=df['Date'], y=df['AAPL.High'])])
fig.show()


print (ALL[9])

for i in range(0,len(ALL)):
    if int(ALL[i][-2])+50<int(ALL[i][-1]):
        print('   ',ALL[i][5],ALL[i][6],ALL[i][-2],ALL[i][-1])
        print(ALL[i][5]+',',ALL[i][6],'Has',int(ALL[i][-1])-int(ALL[i][-2]),'more deaths than yesterday.')


from PIL import Image
IM=Image.open('BaseMap/april30_Hotspots__.png')
IM

for i in (range(0,len(cities))):
    C=cities[i][0]
    S=cities[i][1]
    t=cities[i][2]
    l=cities[i][3]
    n=cities[i][4]
    print(city,l,t,ca,n)

for i in (range(0,len(cities))):
    city=cities[i][0]
    state=cities[i][1]
    l=float(cities[i][2])
    t=float(cities[i][3])
    n=cities[i][4]
    TX=ca+","+str(n)
    plt.text(l, t, TX, color='white', fontsize=24)
    
    

filename = "BaseMap/text30_Hotspots__.png"
plt.savefig(filename, dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)


import matplotlib.pyplot as plt
from mpl_toolkits.basemap import Basemap
fig = plt.figure(num=None, figsize=(12, 8) ) 
m = Basemap(width=6000000,height=4500000,resolution='c',projection='aea',lat_1=35.,lat_2=45,lon_0=-100,lat_0=40)
m.drawcoastlines(linewidth=0.5)
m.fillcontinents(color='tan',lake_color='lightblue')
# draw parallels and meridians.
m.drawparallels(np.arange(-90.,91.,15.),labels=[True,True,False,False],dashes=[2,2])
m.drawmeridians(np.arange(-180.,181.,15.),labels=[False,False,False,True],dashes=[2,2])
m.drawmapboundary(fill_color='lightblue')
m.drawcountries(linewidth=2, linestyle='solid', color='k' ) 
m.drawstates(linewidth=0.5, linestyle='solid', color='k')
m.drawrivers(linewidth=0.5, linestyle='solid', color='blue')

for i in (range(0,len(cities))):
    C=cities[i][0]
    S=cities[i][1]
    t=float(cities[i][2])
    l=float(cities[i][3])
    n=cities[i][4]
    print(C,l,t)
    plt.annotate(C, m(l,t),color='white',fontsize=10,zorder=15)
#plt.annotate(cities[4][0], m(-118.228241,34.308283),color='white',fontsize=24,zorder=18)    
#plt.annotate("TEST", m(-118.228241,34.308283),color='green',fontsize=24,zorder=15)

#plt.annotate('Jul-24-2012', xy=(40.88320119, -72.8012172), xycoords='axes fraction')
plt.show()

ax.annotate("blablabla", m1(121.597366,25.105497),color='green')

for i in (range(0,len(cities))):
    C=cities[i][0]
    S=cities[i][1]
    t=cities[i][2]
    l=cities[i][3]
    n=cities[i][4]
    print(C,S,l,t,n)

import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.basemap import Basemap

num = 79
lat = 5 * np.random.random(num) + 33
lon = 10 * np.random.random(num) - 104

fig, ax = plt.subplots()
m = Basemap(projection='stere',lon_0=-95,lat_0=35.,lat_ts=40,
            llcrnrlat=33,urcrnrlat=38,
            llcrnrlon=-103.8,urcrnrlon=-94,
            resolution='h', ax=ax)

X,Y = m(lon,lat)
m.drawcoastlines()
m.drawstates()
m.drawcountries()
m.drawmapboundary(fill_color='lightblue')
m.drawparallels(np.arange(0.,40.,2.),color='gray',dashes=[1,3],labels=[1,0,0,0])
m.drawmeridians(np.arange(0.,360.,2.),color='gray',dashes=[1,3],labels=[0,0,0,1])

ax.scatter(X,Y)

for i, (x, y) in enumerate(zip(X, Y), start=1):
    ax.annotate(str(i), (x,y), xytext=(5, 5), textcoords='offset points')

plt.show()



from mpl_toolkits.basemap import Basemap
import matplotlib.pyplot as plt

map = Basemap(projection='ortho', 
              lat_0=0, lon_0=0)
map.drawmapboundary(fill_color='aqua')
map.fillcontinents(color='coral',lake_color='aqua')
map.drawcoastlines()

x, y = map(2, 41)
x2, y2 = (-90, 10)

plt.annotate('Barcelona', xy=(x, y),  xycoords='data',
                xytext=(x2, y2), textcoords='offset points',
                color='r',
                arrowprops=dict(arrowstyle="fancy", color='g')
                )

x2, y2 = map(0, 0)
plt.annotate('Barcelona', xy=(x, y),  xycoords='data',
                xytext=(x2, y2), textcoords='data',
                arrowprops=dict(arrowstyle="->")
                )
plt.show()


x, y = m(0,0)
ax.annotate('0', xy=(x, y), xycoords='data', xytext=(x, y), textcoords='data')

from mpl_toolkits.basemap import Basemap
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.cm as cm


#data points
ra = [25,20,21]
dec = [25,20,21]

fig = plt.figure()
ax = fig.add_axes([0.1,0.1,0.8,0.8])

# Get the hammer projection map
m = Basemap(projection='hammer',lon_0 = 0, rsphere = 1.0)
m.drawparallels(np.arange(-90.,90.,30.),labels=[1,0,0,0]) # draw parallels
m.drawmeridians(np.arange(-180.,180.,60.)) # draw meridians

m.plot(ra,dec,marker='o',linestyle='None',markersize=1,latlon=True)
ax.annotate('0', xy=(0, 0), xycoords='data',xytext = (0,0),textcoords='data')

plt.show()

from mpl_toolkits.basemap import Basemap
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.cm as cm


#data points
ra = [25,20,21]
dec = [25,20,21]

fig = plt.figure()
ax = fig.add_axes([0.1,0.1,0.8,0.8])

# Get the hammer projection map
m = Basemap(projection='hammer',lon_0 = 0, rsphere = 1.0)
m.drawparallels(np.arange(-90.,90.,30.),labels=[1,0,0,0]) # draw parallels
m.drawmeridians(np.arange(-180.,180.,60.)) # draw meridians

m.plot(ra,dec,marker='o',linestyle='None',markersize=1,latlon=True)
# Convert from latitude/longitude to x,y
x, y = m(0,0)
ax.annotate('0', xy=(x, y), xycoords='data', xytext=(x, y), textcoords='data')

plt.show()



import time
#DATE = time.strftime("%Y-%m%d%H%M%S")
DATE = time.strftime("%m-%d-%H_")
DATE 


import requests as req
import time
DATE = time.strftime("%m-%d-%H_")
#URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/05-08-2020.csv"

URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv"


resp = req.get(URL)
content = resp.text

#create a date oriented filename and print it
filename="csv/"+URL[-14:]
print(filename)
content=content.replace(",,",",Ex,")
content=content.replace("(","")
content=content.replace(")","")
content=content.replace("\"","")
print(content)
# Open a file using the new filename and write the content of the 'gitfile' to it.
# Update one time daily
TEMP = open(filename,"w")
TEMP.write(content)
TEMP.close()

LASTFILE="csv/_deaths_US.csv"
DataIn = open(LASTFILE).readlines()
cnt=0
for lineZ in DataIn:
    cnt=cnt+1
    line=lineZ.split(",")
    if cnt<8:
        if cnt==1:print(line)
        if cnt==2:print("----------------------------------------------------------------")
        #print(line)
        print(line[1],line[2])

weirdstuff="45001,Abbeville,South Carolina,US,2020-04-30 02:32:27,34.22333378,-82.46170658,29,0,0,29,Abbeville, South Carolina, US"
text=weirdstuff.split(",")
print(text[1])

LASTFILE="csv/_deaths_US.csv"

cnt=0
DataIn = open(LASTFILE).readlines()
for line in DataIn:
    line=line.replace('"','')
    if cnt==0:print (line)
    cnt=cnt+1
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    #if cnt<10 and line[5] !="":print (line[6])
    if "US" == line[7]:# and line[6] == "New York":
        #if CNT==7:print(line)
        #if CNT==8:print(line)    
        #if CNT<5 and line[5] !="":print line
        CNT=CNT+1
        ALL.append(line)
        LAT.append(line[5])
        LONG.append(line[6])
        L=len(line)
        deaths.append(line[L-1])

LASTFILE="csv/_deaths_US.csv"
DataIn = open(LASTFILE).read()
DataIn = DataIn.split("\n")
cnt=0
for line in DataIn:
    line=line.replace('"','')
    if cnt==0:print (line)
    cnt=cnt+1
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    if cnt<10 and line[5] !="":print (line[7])

LAT=[]
LONG=[]
LATd=[]
LONGd=[]
STATES=[]
ALL=[]
cases=[]
deaths =[]
yesterday=0
today=0
longitude = ""
cnt=0
CNT=0
Dcnt=0
LASTFILE="csv/_deaths_US.csv"
DataIn = open(LASTFILE).readlines()
for line in DataIn:
    line=line.replace('"','')
    if cnt==6:print (line)
    cnt=cnt+1
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    if cnt<10 and line[5] !="":print (line[7])
    if "US" == line[7]:# and line[6] == "New York":
        print(line[5],line[6],line[8],line[9])#,line[L-1],int(line[L-1])-int(line[L-2]))
        #if CNT==8:print(line)    
        if CNT<5 and line[5] !="":print(line)
        CNT=CNT+1
        ALL.append(line)
        LAT.append(line[5])
        LONG.append(line[6])
        L=len(line)
        deaths.append(line[L-1])
        #print(L)
        print(line[L-1],line[L-2])
        if int(line[L-2])+20<int(line[L-1]):
            #print ("if ",int(line[L-2]),'+10',int(line[L-1]))
            #print (text,int(line[L-2]),int(line[L-1]))
            if len(line[8])>3:            
                text=line
                STATES.append(text)
                yesterday=yesterday+int(line[-2])
                today= today+int(line[-1])
                Dcnt=Dcnt+1
                #print(line[8],line[9])
                cities.append([line[5],line[6],line[8],line[9],line[L-1],int(line[L-1])-int(line[L-2])])
                LATd.append(line[8])
                LONGd.append(line[9])
print(cities)               

import warnings
warnings.filterwarnings("ignore")
import matplotlib.pyplot as plt
from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon
import numpy as np
from PIL import Image,ImageFont,ImageDraw,ImageFilter,ImageChops
from random import randint
from mpl_toolkits.basemap import Basemap
fig = plt.figure(num=None, figsize=(12, 8) ) 
m = Basemap(width=6000000,height=4500000,resolution='c',projection='aea',lat_1=35.,lat_2=45,lon_0=-100,lat_0=40)
m.drawcoastlines(linewidth=0.5)
m.fillcontinents(color='tan',lake_color='lightblue')
# draw parallels and meridians.
m.drawparallels(np.arange(-90.,91.,15.),labels=[True,True,False,False],dashes=[2,2])
m.drawmeridians(np.arange(-180.,181.,15.),labels=[False,False,False,True],dashes=[2,2])
m.drawmapboundary(fill_color='lightblue')
m.drawcountries(linewidth=2, linestyle='solid', color='k' ) 
m.drawstates(linewidth=0.5, linestyle='solid', color='k')
m.drawrivers(linewidth=0.5, linestyle='solid', color='blue')
cities =[]
LAT=[]
LONG=[]
LATd=[]
LONGd=[]
STATES=[]
ALL=[]
cases=[]
deaths =[]
yesterday=0
today=0
longitude = ""
cnt=0
CNT=0
Dcnt=0
LASTFILE="csv/_deaths_US.csv"
DataIn = open(LASTFILE).readlines()
for line in DataIn:
    line=line.replace('"','')
    if cnt==0:print (line)
    cnt=cnt+1
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    if cnt<10 and line[5] !="":print (line[7])
    if "US" == line[7]:# and line[6] == "New York":
        #if CNT==7:print(line)
        #if CNT==8:print(line)    
        if CNT<5 and line[5] !="":print(line)
        CNT=CNT+1
        ALL.append(line)
        LAT.append(line[5])
        LONG.append(line[6])
        L=len(line)
        deaths.append(line[L-1])
        #print(L)
        #print(line[L-1],line[L-2])
        if int(line[L-2])+50<int(line[L-1]):
            #print ("if ",int(line[L-2]),'+10',int(line[L-1]))
            #print (text,int(line[L-2]),int(line[L-1]))
            if len(line[8])>3:            
                text=line
                STATES.append(text)
                yesterday=yesterday+int(line[-2])
                today= today+int(line[-1])
                Dcnt=Dcnt+1
                #print(line[8],line[9])
                cities.append([line[5],line[6],line[8],line[9],line[L-1],int(line[L-1])-int(line[L-2])])
                LATd.append(line[8])
                LONGd.append(line[9])
                
                
LTd = np.array(LATd,dtype=np.float)
LGd = np.array(LONGd,dtype=np.float)
Str = np.array(cities,dtype=np.str)

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.01)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

Sd=1
Sized=[]
for xd in deaths:
    Sd=0+(float(xd)*.07)
    Sized.append(int(Sd))
    #print(int(S))
sd = np.array(Sized)
#print(Sized)
plt.title("Finding-Hot-Spots.ipynb - https://github.com/JupyterJones/COVID-19-Jupyter-Notebooks")
#plt.text(max(LG-1.2),max(LT), search, color='white', fontsize=24)
#x, y = m(lons, lats)  # transform coordinates
x, y = m(LGd, LTd)
#xx,yy = m(LG, LT)
plt.xlabel('Longitude',color="white", fontsize=24)
plt.ylabel('Latitute',color="white", fontsize=24)

for i in (range(0,len(cities))):
    C=cities[i][0]
    S=cities[i][1]
    t=float(cities[i][2])
    l=float(cities[i][3])
    d=cities[i][4]
    inc=cities[i][5]
    print(C,S,l,t,d,inc)
    plt.annotate(C, m(l,t),color='red',fontsize=20,zorder=15)   
    
m.scatter(x, y, s=sd, color='r', zorder=10,  alpha=0.6)
filename = "BaseMap/april30_Hotspots__.png"
plt.savefig(filename, dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)

# Using graph_objects
import plotly.graph_objects as go
import pandas as pd
df = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/finance-charts-apple.csv')

fig = go.Figure([go.Scatter(x=df['Date'], y=df['AAPL.High'])])
fig.show()


LASTFILE="csv/_deaths_US.csv"
DataIn = open(LASTFILE).readlines()
for line in DataIn:
    line=line.replace('"','')
    if cnt==0:print (line)
    cnt=cnt+1
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    if cnt<10 and line[5] !="":print (line[7])
    if "US" == line[7]:# and line[6] == "New York":
        #if CNT==7:print(line)
        #if CNT==8:print(line)    
        if CNT<5 and line[5] !="":print(line)
        CNT=CNT+1
        ALL.append(line)
        LAT.append(line[5])
        LONG.append(line[6])
        L=len(line)
        deaths.append(line[L-1])
        #print(L)
        #print(line[L-1],line[L-2])
        if int(line[L-2])+50<int(line[L-1]):
            #print ("if ",int(line[L-2]),'+10',int(line[L-1]))
            #print (text,int(line[L-2]),int(line[L-1]))
            if len(line[8])>3:            
                text=line
                STATES.append(text)
                yesterday=yesterday+int(line[-2])
                today= today+int(line[-1])
                Dcnt=Dcnt+1
                #print(line[8],line[9])
                cities.append([line[5],line[6],line[8],line[9],line[L-1],int(line[L-1])-int(line[L-2])])
                LATd.append(line[8])
                LONGd.append(line[9])

for i in range(0,len(ALL)):
    if int(ALL[i][-2])+50<int(ALL[i][-1]):
        print('   ',ALL[i][5],ALL[i][6],ALL[i][-2],ALL[i][-1])
        print(ALL[i][5]+',',ALL[i][6],'Has',int(ALL[i][-1])-int(ALL[i][-2]),'more deaths than yesterday.')


from PIL import Image
IM=Image.open('BaseMap/april30_Hotspots__.png')
IM

for i in (range(0,len(cities))):
    C=cities[i][0]
    S=cities[i][1]
    t=cities[i][2]
    l=cities[i][3]
    n=cities[i][4]
    print(C,S,t,l,n)

for i in (range(0,len(cities))):
    city=cities[i][0]
    state=cities[i][1]
    l=float(cities[i][2])
    t=float(cities[i][3])
    n=cities[i][4]
    TX=ca+","+str(n)
    plt.text(l, t, TX, color='white', fontsize=24)
    
    

filename = "BaseMap/text30_Hotspots__.png"
plt.savefig(filename, dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)


import matplotlib.pyplot as plt
from mpl_toolkits.basemap import Basemap
fig = plt.figure(num=None, figsize=(12, 8) ) 
m = Basemap(width=6000000,height=4500000,resolution='c',projection='aea',lat_1=35.,lat_2=45,lon_0=-100,lat_0=40)
m.drawcoastlines(linewidth=0.5)
m.fillcontinents(color='tan',lake_color='lightblue')
# draw parallels and meridians.
m.drawparallels(np.arange(-90.,91.,15.),labels=[True,True,False,False],dashes=[2,2])
m.drawmeridians(np.arange(-180.,181.,15.),labels=[False,False,False,True],dashes=[2,2])
m.drawmapboundary(fill_color='lightblue')
m.drawcountries(linewidth=2, linestyle='solid', color='k' ) 
m.drawstates(linewidth=0.5, linestyle='solid', color='k')
m.drawrivers(linewidth=0.5, linestyle='solid', color='blue')

for i in (range(0,len(cities))):
    C=cities[i][0]
    S=cities[i][1]
    t=float(cities[i][2])
    l=float(cities[i][3])
    n=cities[i][4]
    print(C,l,t)
    plt.annotate(C, m(l,t),color='white',fontsize=10,zorder=15)
#plt.annotate(cities[4][0], m(-118.228241,34.308283),color='white',fontsize=24,zorder=18)    
#plt.annotate("TEST", m(-118.228241,34.308283),color='green',fontsize=24,zorder=15)

#plt.annotate('Jul-24-2012', xy=(40.88320119, -72.8012172), xycoords='axes fraction')
plt.show()

ax.annotate("blablabla", m1(121.597366,25.105497),color='green')

for i in (range(0,len(cities))):
    C=cities[i][0]
    S=cities[i][1]
    t=cities[i][2]
    l=cities[i][3]
    n=cities[i][4]
    print(C,S,l,t,n)

import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.basemap import Basemap

num = 79
lat = 5 * np.random.random(num) + 33
lon = 10 * np.random.random(num) - 104

fig, ax = plt.subplots()
m = Basemap(projection='stere',lon_0=-95,lat_0=35.,lat_ts=40,
            llcrnrlat=33,urcrnrlat=38,
            llcrnrlon=-103.8,urcrnrlon=-94,
            resolution='h', ax=ax)

X,Y = m(lon,lat)
m.drawcoastlines()
m.drawstates()
m.drawcountries()
m.drawmapboundary(fill_color='lightblue')
m.drawparallels(np.arange(0.,40.,2.),color='gray',dashes=[1,3],labels=[1,0,0,0])
m.drawmeridians(np.arange(0.,360.,2.),color='gray',dashes=[1,3],labels=[0,0,0,1])

ax.scatter(X,Y)

for i, (x, y) in enumerate(zip(X, Y), start=1):
    ax.annotate(str(i), (x,y), xytext=(5, 5), textcoords='offset points')

plt.show()



from mpl_toolkits.basemap import Basemap
import matplotlib.pyplot as plt

map = Basemap(projection='ortho', 
              lat_0=0, lon_0=0)
map.drawmapboundary(fill_color='aqua')
map.fillcontinents(color='coral',lake_color='aqua')
map.drawcoastlines()

x, y = map(2, 41)
x2, y2 = (-90, 10)

plt.annotate('Barcelona', xy=(x, y),  xycoords='data',
                xytext=(x2, y2), textcoords='offset points',
                color='r',
                arrowprops=dict(arrowstyle="fancy", color='g')
                )

x2, y2 = map(0, 0)
plt.annotate('Barcelona', xy=(x, y),  xycoords='data',
                xytext=(x2, y2), textcoords='data',
                arrowprops=dict(arrowstyle="->")
                )
plt.show()


x, y = m(0,0)
ax.annotate('0', xy=(x, y), xycoords='data', xytext=(x, y), textcoords='data')

from mpl_toolkits.basemap import Basemap
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.cm as cm


#data points
ra = [25,20,21]
dec = [25,20,21]

fig = plt.figure()
ax = fig.add_axes([0.1,0.1,0.8,0.8])

# Get the hammer projection map
m = Basemap(projection='hammer',lon_0 = 0, rsphere = 1.0)
m.drawparallels(np.arange(-90.,90.,30.),labels=[1,0,0,0]) # draw parallels
m.drawmeridians(np.arange(-180.,180.,60.)) # draw meridians

m.plot(ra,dec,marker='o',linestyle='None',markersize=1,latlon=True)
ax.annotate('0', xy=(0, 0), xycoords='data',xytext = (0,0),textcoords='data')

plt.show()

from mpl_toolkits.basemap import Basemap
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.cm as cm


#data points
ra = [25,20,21]
dec = [25,20,21]

fig = plt.figure()
ax = fig.add_axes([0.1,0.1,0.8,0.8])

# Get the hammer projection map
m = Basemap(projection='hammer',lon_0 = 0, rsphere = 1.0)
m.drawparallels(np.arange(-90.,90.,30.),labels=[1,0,0,0]) # draw parallels
m.drawmeridians(np.arange(-180.,180.,60.)) # draw meridians

m.plot(ra,dec,marker='o',linestyle='None',markersize=1,latlon=True)
# Convert from latitude/longitude to x,y
x, y = m(0,0)
ax.annotate('0', xy=(x, y), xycoords='data', xytext=(x, y), textcoords='data')

plt.show()



import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

# Make sure that caffe is on the python path:
caffe_root = '../'  # this file is expected to be in {caffe_root}/examples
import sys
sys.path.insert(0, caffe_root + 'python')

import caffe

plt.rcParams['figure.figsize'] = (10, 10)
plt.rcParams['image.interpolation'] = 'nearest'
plt.rcParams['image.cmap'] = 'gray'

import os
if not os.path.isfile(caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'):
    print("Downloading pre-trained CaffeNet model...")
    !../scripts/download_model_binary.py ../models/bvlc_reference_caffenet

caffe.set_mode_cpu()
net = caffe.Net(caffe_root + 'models/bvlc_reference_caffenet/deploy.prototxt',
                caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel',
                caffe.TEST)

# input preprocessing: 'data' is the name of the input blob == net.inputs[0]
transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})
transformer.set_transpose('data', (2,0,1))
transformer.set_mean('data', np.load(caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy').mean(1).mean(1)) # mean pixel
transformer.set_raw_scale('data', 255)  # the reference model operates on images in [0,255] range instead of [0,1]
transformer.set_channel_swap('data', (2,1,0))  # the reference model has channels in BGR order instead of RGB

# set net to batch size of 50
net.blobs['data'].reshape(50,3,227,227)

net.blobs['data'].data[...] = transformer.preprocess('data', caffe.io.load_image(caffe_root + 'examples/images/cat.jpg'))
out = net.forward()
print("Predicted class is #{}.".format(out['prob'].argmax()))

plt.imshow(transformer.deprocess('data', net.blobs['data'].data[0]))

# load labels
imagenet_labels_filename = caffe_root + 'data/ilsvrc12/synset_words.txt'
try:
    labels = np.loadtxt(imagenet_labels_filename, str, delimiter='\t')
except:
    !../data/ilsvrc12/get_ilsvrc_aux.sh
    labels = np.loadtxt(imagenet_labels_filename, str, delimiter='\t')

# sort top k predictions from softmax output
top_k = net.blobs['prob'].data[0].flatten().argsort()[-1:-6:-1]
print labels[top_k]

# CPU mode
net.forward()  # call once for allocation
%timeit net.forward()

# GPU mode
caffe.set_device(0)
caffe.set_mode_gpu()
net.forward()  # call once for allocation
%timeit net.forward()

[(k, v.data.shape) for k, v in net.blobs.items()]

[(k, v[0].data.shape) for k, v in net.params.items()]

# take an array of shape (n, height, width) or (n, height, width, channels)
# and visualize each (height, width) thing in a grid of size approx. sqrt(n) by sqrt(n)
def vis_square(data, padsize=1, padval=0):
    data -= data.min()
    data /= data.max()
    
    # force the number of filters to be square
    n = int(np.ceil(np.sqrt(data.shape[0])))
    padding = ((0, n ** 2 - data.shape[0]), (0, padsize), (0, padsize)) + ((0, 0),) * (data.ndim - 3)
    data = np.pad(data, padding, mode='constant', constant_values=(padval, padval))
    
    # tile the filters into an image
    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1)))
    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])
    
    plt.imshow(data)

# the parameters are a list of [weights, biases]
filters = net.params['conv1'][0].data
vis_square(filters.transpose(0, 2, 3, 1))

feat = net.blobs['conv1'].data[0, :36]
vis_square(feat, padval=1)

filters = net.params['conv2'][0].data
vis_square(filters[:48].reshape(48**2, 5, 5))

feat = net.blobs['conv2'].data[0, :36]
vis_square(feat, padval=1)

feat = net.blobs['conv3'].data[0]
vis_square(feat, padval=0.5)

feat = net.blobs['conv4'].data[0]
vis_square(feat, padval=0.5)

feat = net.blobs['conv5'].data[0]
vis_square(feat, padval=0.5)

feat = net.blobs['pool5'].data[0]
vis_square(feat, padval=1)

feat = net.blobs['fc6'].data[0]
plt.subplot(2, 1, 1)
plt.plot(feat.flat)
plt.subplot(2, 1, 2)
_ = plt.hist(feat.flat[feat.flat > 0], bins=100)

feat = net.blobs['fc7'].data[0]
plt.subplot(2, 1, 1)
plt.plot(feat.flat)
plt.subplot(2, 1, 2)
_ = plt.hist(feat.flat[feat.flat > 0], bins=100)

feat = net.blobs['prob'].data[0]
plt.plot(feat.flat)

# load labels
imagenet_labels_filename = caffe_root + 'data/ilsvrc12/synset_words.txt'
try:
    labels = np.loadtxt(imagenet_labels_filename, str, delimiter='\t')
except:
    !../data/ilsvrc12/get_ilsvrc_aux.sh
    labels = np.loadtxt(imagenet_labels_filename, str, delimiter='\t')

# sort top k predictions from softmax output
top_k = net.blobs['prob'].data[0].flatten().argsort()[-1:-6:-1]
print labels[top_k]

.05710 * 20054

from GETGMT import *
print(GETGMT())
print(GETYGMT())
help(GETYGMT)

%matplotlib notebook
import mplcursors
from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
from mpld3 import plugins
from PIL import Image
from GETGMT import *
yesterday = GETYGMT()+".csv"
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/"+yesterday


DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
STate = 'Florida'
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-3
B =(max(LG))+3
C =(min(LT))-3
D =(max(LT))+3




longLeft= (min(LG))-3
longRight = (max(LG))+3
lat1 = (min(LT))-3
lat2 = (max(LT))+3

#ax = fig.gca()
T= 'Miami-Dade'
text(0.62, 0.29, T, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)

plt.axis([longLeft,longRight,lat1,lat2])

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")


plt.xlabel('First data sample was: 09/03/2020 04:30:00')
plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
plt.ylabel('Number of Cases')
mplcursors.cursor(hover=True)

plt.show()

%matplotlib notebook
import mplcursors
from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
from mpld3 import plugins
from PIL import Image
from GETGMT import *
yesterday = GETYGMT()+".csv"
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/"+yesterday


DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
STate = 'Florida'
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-3
B =(max(LG))+3
C =(min(LT))-3
D =(max(LT))+3

longLeft= (min(LG))-3
longRight = (max(LG))+3
lat1 = (min(LT))-3
lat2 = (max(LT))+3

ax = fig.gca()
T= 'Miami-Dade'
text(0.62, 0.29, T, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)

plt.axis([longLeft,longRight,lat1,lat2])

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")

plt.xlabel('First data sample was: 09/03/2020 04:30:00')
plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
plt.ylabel('Number of Cases')
mplcursors.cursor(hover=True)

plt.show()

%matplotlib notebook
import matplotlib.pyplot as plt
import numpy as np
import mplcursors


#fig, ax = plt.subplots()
fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")



#ax.scatter(LG, LT)
#ax.set_title("Mouse over a point")

mplcursors.cursor(hover=True)

plt.show()


from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"

from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
%matplotlib inline  
from mpld3 import plugins
from PIL import Image
img=Image.open("mouse-sizing-n-cropping-files/soil600.jpg")
from GETGMT import *
yesterday = GETYGMT()+".csv"
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/"+yesterday
#im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))

DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
STate = 'Florida'
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-3
B =(max(LG))+3
C =(min(LT))-3
D =(max(LT))+3
#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
#fig, ax = plt.subplots(figsize=(8,8), dpi=80, facecolor='salmon')
#im = ax.imshow(img, extent=(A, B, C, D),
#               origin='upper', zorder=0, interpolation='nearest')
#plugins.connect(fig, plugins.MousePosition(fontsize=14))
#mpld3.display()

ax = fig.gca()
T= 'Miami-Dade'
text(0.62, 0.29, T, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)

plt.axis([A, B, C, D])
#plugins.connect(ax, plugins.MousePosition(fontsize=14))

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")
fig, ax = plt.subplots(figsize=(8,8), dpi=80, facecolor='salmon')
plugins.connect(fig, plugins.MousePosition(fontsize=14))
im = ax.imshow(img, extent=(A, B, C, D),
               origin='upper', zorder=0, interpolation='nearest')

mpld3.display()

plt.show()
#from PIL import Image
#im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))
#plugins.connect(fig, plugins.MousePosition(fontsize=14))

mpld3.display()



from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
%matplotlib inline  
from mpld3 import plugins
from PIL import Image
img=Image.open("mouse-sizing-n-cropping-files/soil600.jpg")
from GETGMT import *
yesterday = GETYGMT()+".csv"
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/"+yesterday
#im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))

DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
STate = 'Florida'
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-3
B =(max(LG))+3
C =(min(LT))-3
D =(max(LT))+3
#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
fig, ax = plt.subplots(figsize=(8,8), dpi=80, facecolor='salmon')
im = ax.imshow(img, extent=(A, B, C, D),
               origin='upper', zorder=0, interpolation='nearest')
plugins.connect(fig, plugins.MousePosition(fontsize=14))

longLeft= (min(LG))-3
longRight = (max(LG))+3
lat1 = (min(LT))-3
lat2 = (max(LT))+3

ax = fig.gca()
T= 'Miami-Dade'
text(0.62, 0.29, T, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)

plt.axis([longLeft,longRight,lat1,lat2])

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")

#im = ax.imshow(img, extent=(A, B, C, D),
#               origin='lower', zorder=1, interpolation='nearest')

plt.xlabel('First data sample was: 09/03/2020 04:30:00')
plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
plt.ylabel('Number of Cases')
plt.show()

plugins.connect(fig, plugins.MousePosition(fontsize=14))

mpld3.display()



from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
%matplotlib inline  
from mpld3 import plugins
from PIL import Image
from GETGMT import *
img=Image.open("mouse-sizing-n-cropping-files/soil600.jpg")

yesterday = GETYGMT()+".csv"
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/"+yesterday
#im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))

DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
STate = 'Florida'
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-3
B =(max(LG))+3
C =(min(LT))-3
D =(max(LT))+3
#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
fig, ax = plt.subplots(figsize=(8,8), dpi=80, facecolor='salmon')
im = ax.imshow(img, extent=(A, B, C, D),
               origin='upper', zorder=0, interpolation='nearest')
plugins.connect(fig, plugins.MousePosition(fontsize=14))
mpld3.display()

ax = fig.gca()
T= 'Miami-Dade'
text(0.62, 0.29, T, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)

plt.axis([A, B, C, D])

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")

#im = ax.imshow(img, extent=(A, B, C, D),
#               origin='lower', zorder=1, interpolation='nearest')

#plt.xlabel('First data sample was: 09/03/2020 04:30:00')
#plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
#plt.ylabel('Number of Cases')
plt.show()
from PIL import Image
im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))
plugins.connect(fig, plugins.MousePosition(fontsize=14))

mpld3.display()



from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
%matplotlib inline  
from mpld3 import plugins
from PIL import Image
img=Image.open("mouse-sizing-n-cropping-files/soil600.jpg")
 

fig, ax = plt.subplots()
im = ax.imshow(img, extent=(10, 20, 10, 20),
               origin='upper', zorder=1, interpolation='nearest')

plugins.connect(fig, plugins.MousePosition(fontsize=14))
mpld3.display()
from PIL import Image
im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))
plt.show()
plugins.connect(fig, plugins.MousePosition(fontsize=14))

mpld3.display()


%matplotlib notebook
import matplotlib.pyplot as plt
import numpy as np
import mplcursors
np.random.seed(42)

fig, ax = plt.subplots()
ax.scatter(*np.random.random((2, 26)))
ax.set_title("Mouse over a point")

mplcursors.cursor(hover=True)

plt.show()


%matplotlib notebook
import numpy as np
import matplotlib.pyplot as plt

company=['google','amazon','msft','fb']
revenue=[80,68,54,27]

fig=plt.figure()
ax=plt.subplot()

xpos=np.arange(len(company))

bars = plt.bar(xpos,revenue)


annot = ax.annotate("", xy=(0,0), xytext=(-20,20),textcoords="offset points",
                    bbox=dict(boxstyle="round", fc="black", ec="b", lw=2),
                    arrowprops=dict(arrowstyle="->"))
annot.set_visible(False)

def update_annot(bar):
    x = bar.get_x()+bar.get_width()/2.
    y = bar.get_y()+bar.get_height()
    annot.xy = (x,y)
    text = "({:.2g},{:.2g})".format( x,y )
    annot.set_text(text)
    annot.get_bbox_patch().set_alpha(0.4)


def hover(event):
    vis = annot.get_visible()
    if event.inaxes == ax:
        for bar in bars:
            cont, ind = bar.contains(event)
            if cont:
                update_annot(bar)
                annot.set_visible(True)
                fig.canvas.draw_idle()
                return
    if vis:
        annot.set_visible(False)
        fig.canvas.draw_idle()

fig.canvas.mpl_connect("motion_notify_event", hover)

plt.show()

import mplcursors
help(mplcursors)

%matplotlib notebook
import matplotlib.pyplot as plt
import numpy as np


def plot_unit_circle():
    angs = np.linspace(0, 2 * np.pi, 10**6)
    rs = np.zeros_like(angs) + 1
    xs = rs * np.cos(angs)
    ys = rs * np.sin(angs)
    plt.plot(xs, ys)


def mouse_move(event):
    x, y = event.xdata, event.ydata
    print(x, y)


plt.connect('motion_notify_event', mouse_move)
plot_unit_circle()
plt.axis('equal')
plt.show()

%matplotlib notebook
import matplotlib.pyplot as plt
import numpy as np
import ipywidgets as wdg  # Using the ipython notebook widgets

# Create a random image
a = np.random.poisson(size=(12,15))
fig = plt.figure()
plt.imshow(a)

# Create and display textarea widget
txt = wdg.Textarea(
    value='',
    placeholder='',
    description='event:',
    disabled=False
)
display(txt)

# Define a callback function that will update the textarea
def onclick(event):
    txt.value = str(event)  # Dynamically update the text box above

# Create an hard reference to the callback not to be cleared by the garbage collector
ka = fig.canvas.mpl_connect('button_press_event', onclick)

collector = []
def onclick(event):
    global i, collector
    collector.append((event.xdata, event.ydata))
    # Open the annotations file to continue to write
    target = open('annotation.txt', 'a')
    # Write picture and coordinates
    target.write(line)
    target.write("\n")
    i += 1
    event.canvas.figure.clear()
    event.canvas.figure.gca().imshow(images[i])

fig = plt.figure(figsize=(5,5))
fig.canvas.mpl_connect('button_press_event', onclick)

plt.imshow(images[0])
plt.show()

import matplotlib.pyplot as plt


class LineDrawer(object):
    lines = []
    def draw_line(self, startx,starty):
        ax = plt.gca()
        xy = plt.ginput(1)
        x = [startx,xy[0][0]]
        y = [starty,xy[0][1]]
        line = plt.plot(x,y)
        ax.figure.canvas.draw()

        self.lines.append(line)


def onclick(event):
    if event.dblclick:
        if event.button == 1:
            # Draw line
            ld = LineDrawer()
            ld.draw_line(event.xdata,event.ydata) # here you click on the plot
        elif event.button == 3:
            # Write to figure
            plt.figtext(3, 8, 'boxed italics text in data coords', style='italic', bbox={'facecolor':'red', 'alpha':0.5, 'pad':10})
            circ = plt.Circle((event.xdata, event.ydata), radius=0.07, color='g')
            ax.add_patch(circ)
            ax.figure.canvas.draw()
        else:
            pass # Do nothing


def onpick(event):
    thisline = event.artist
    xdata = thisline.get_xdata()
    ydata = thisline.get_ydata()
    ind = event.ind
    print ('onpick points:', zip(xdata[ind], ydata[ind]))



fig, ax = plt.subplots()

connection_id = fig.canvas.mpl_connect('button_press_event', onclick)
fig.canvas.mpl_connect('pick_event', onpick)


plt.tight_layout()

plt.show()

print(collector)

!ls annotation.txt

from matplotlib import pyplot as plt
import mplcursors
from pandas import DataFrame
collector = []
df = DataFrame(
    [("Alice", 163, 54),
     ("Bob", 174, 67),
     ("Charlie", 177, 73),
     ("Diane", 168, 57)],
    columns=["name", "height", "weight"])
scatter1 = df.plot.scatter("height", "weight")
mplcursors.cursor(scatter1, hover=True).connect("add",
    lambda sel: sel.annotation.set_text(
        f'{df["name"][sel.target.index]}\nHeight: {df["height"][sel.target.index] / 100} m\nWeight: {df["weight"][sel.target.index]} kg'))
plt.show()

import ipywidgets as widgets
import numpy as np
import pandas as pd

vartest = 0

Button = widgets.Button(description='Search', disabled=False, button_style='info', tooltip='Search')
display(Button)

def whenclick2(b):
    global df

    if vartest==0:
        df = pd.DataFrame(np.arange(5))


        class displayDF(object):
            def _create_widgets(self):
                self.button = Button
                self.button.on_click(self._on_button_clicked) # define which function to run when cliked

            def _on_button_clicked(self, change):
                self.out.clear_output() # clean previous outptu (I think ). Not working
                with self.out:# using self.out (the output widget) do the display
                    display(df) #aqui es donde digo que haga display del dataframe que es la variable self.file1

            def display_widgets(self):
                self._create_widgets() # calls the creation of the widgets
                self.out = widgets.Output()  # this is the output widget in which the df is displayed
                display(widgets.VBox([self.out])) # controls layout of widget position  

            def get_df_objects(self):
                return self.df_objects

    # Run class and store output in something
    something = displayDF()
    # output the display
    something.display_widgets()

    #return df    

Button.on_click(whenclick2)



%matplotlib notebook
sav=[]
import numpy as np
import matplotlib.pyplot as plt
fig = plt.figure()
ax = fig.add_subplot(111)
ax.plot(np.random.rand(10))
text=ax.text(0,0, "", va="bottom", ha="left")

def onclick(event):
    tx = 'button=%d, x=%d, y=%d, xdata=%f, ydata=%f' % (event.button, event.x, event.y, event.xdata, event.ydata)
    text.set_text(tx)
    sav.append(tx)

cid = fig.canvas.mpl_connect('button_press_event', onclick)

print(sav)

import numpy as np
import matplotlib.pyplot as plt

x = np.arange(-10,10)
y = x**2

fig = plt.figure()
ax = fig.add_subplot(111)
ax.plot(x,y)

coords = []

def onclick(event):
    global ix, iy
    ix, iy = event.xdata, event.ydata
    print ('x = %d, y = %d'%(ix, iy))

    global coords
    coords.append((ix, iy))

    if len(coords) == 2:
        fig.canvas.mpl_disconnect(cid)

    return coords
cid = fig.canvas.mpl_connect('button_press_event', onclick)

print(coords)

fig, ax = plt.subplots()
ax.plot(np.random.rand(10))

def onclick(event):
    print('%s click: button=%d, x=%d, y=%d, xdata=%f, ydata=%f' %
          ('double' if event.dblclick else 'single', event.button,
           event.x, event.y, event.xdata, event.ydata))

cid = fig.canvas.mpl_connect('button_press_event', onclick)


import matplotlib.pyplot as plt

# function to draw lines - from matplotlib examples.  Note you don't need
# to keep a reference to the lines drawn, so I've removed the class as it
# is overkill for your purposes
def draw_line(startx,starty):
        ax = plt.gca()
        xy = plt.ginput(1)
        x = [startx,xy[0][0]]
        y = [starty,xy[0][1]]
        line = ax.plot(x,y, picker=5) # note that picker=5 means a click within 5 pixels will "pick" the Line2D object
        ax.figure.canvas.draw()        

def onclick(event):
    """
    This implements click functionality.  If it's a double click do something,
    else ignore.
    Once in the double click block, if its a left click, wait for a further 
    click and draw a line between the double click co-ordinates and that click
    (using ginput(1) - the 1 means wait for one mouse input - a higher number
    is used to get multiple clicks to define a polyline)
    If the double click was a right click, draw the fixed radius circle

    """
    if event.dblclick:
        if event.button == 1:
            # Draw line
            draw_line(event.xdata,event.ydata) # here you click on the plot
        elif event.button == 3:
            # Write to figure
            plt.figtext(3, 8, 'boxed italics text in data coords', style='italic', bbox={'facecolor':'red', 'alpha':0.5, 'pad':10})
            circ = plt.Circle((event.xdata, event.ydata), radius=0.07, color='g', picker = True)
            ax.add_patch(circ)
            ax.figure.canvas.draw()
        else:
            pass # Do nothing


def onpick(event):    
    """
    Handles the pick event - if an object has been picked, store a
    reference to it.  We do this by simply adding a reference to it
    named 'stored_pick' to the axes object.  Note that in python we
    can dynamically add an attribute variable (stored_pick) to an 
    existing object - even one that is produced by a library as in this
    case
    """
    this_artist = event.artist #the picked object is available as event.artist
    # print(this_artist) #For debug just to show you which object is picked
    plt.gca().picked_object = this_artist

def on_key(event):
    """
    Function to be bound to the key press event
    If the key pressed is delete and there is a picked object,
    remove that object from the canvas
    """
    if event.key == u'delete':
        ax = plt.gca()
        if ax.picked_object:
            ax.picked_object.remove()
            ax.picked_object = None
            ax.figure.canvas.draw()


fig, ax = plt.subplots()

#First we need to catch three types of event, clicks, "picks" (a specialised
#type of click to select an object on a matplotlib canvas) and key presses.
#The logic is - if it's a right double click, wait for the next click and draw
#a line, if its a right double click draw a fixed radius circle.  If it's a
#pick, store a reference to the picked item until the next keypress.  If it's
#a keypress - test if it's delete and if so, remove the picked object.
#The functions (defined above) bound to the events implement this logic
connection_id = fig.canvas.mpl_connect('button_press_event', onclick)
fig.canvas.mpl_connect('pick_event', onpick)
cid = fig.canvas.mpl_connect('key_press_event', on_key)

#set the size of the matplotlib figure in data units, so that it doesn't
#auto-resize (which it will be default on the first drawn item)
ax.set_xlim([0,2])
ax.set_ylim([0,2])
ax.aspect = 1
plt.tight_layout()

plt.show()

from matplotlib import pyplot as plt

class LineBuilder:
    def __init__(self, line):
        self.line = line
        self.xs = list(line.get_xdata())
        self.ys = list(line.get_ydata())
        self.cid = line.figure.canvas.mpl_connect('button_press_event', self)

    def __call__(self, event):
        print('click', event)
        if event.inaxes!=self.line.axes: return
        self.xs.append(event.xdata)
        self.ys.append(event.ydata)
        self.line.set_data(self.xs, self.ys)
        self.line.figure.canvas.draw()

fig = plt.figure()
ax = fig.add_subplot(111)
ax.set_title('click to build line segments')
line, = ax.plot([0], [0])  # empty line
linebuilder = LineBuilder(line)

plt.show()



fig=plt.figure()

%matplotlib notebook
import mplcursors
from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
from mpld3 import plugins
from PIL import Image

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-14-2020.csv"


DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
STate = 'Florida'
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-3
B =(max(LG))+3
C =(min(LT))-3
D =(max(LT))+3
fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')



longLeft= (min(LG))-3
longRight = (max(LG))+3
lat1 = (min(LT))-3
lat2 = (max(LT))+3

ax = fig.gca()
T= 'Miami-Dade'
text(0.62, 0.29, T, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)

plt.axis([longLeft,longRight,lat1,lat2])

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")


plt.xlabel('First data sample was: 09/03/2020 04:30:00')
plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
plt.ylabel('Number of Cases')
mplcursors.cursor(hover=True)

plt.show()

%matplotlib notebook
import mplcursors
from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
from mpld3 import plugins
from PIL import Image

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-02-2020.csv"

DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
STate = 'Florida'
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-3
B =(max(LG))+3
C =(min(LT))-3
D =(max(LT))+3

longLeft= (min(LG))-3
longRight = (max(LG))+3
lat1 = (min(LT))-3
lat2 = (max(LT))+3

ax = fig.gca()
T= 'Miami-Dade'
text(0.62, 0.29, T, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)

plt.axis([longLeft,longRight,lat1,lat2])

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")

plt.xlabel('First data sample was: 09/03/2020 04:30:00')
plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
plt.ylabel('Number of Cases')
mplcursors.cursor(hover=True)

plt.show()

%matplotlib notebook
import matplotlib.pyplot as plt
import numpy as np
import mplcursors


#fig, ax = plt.subplots()
fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")



#ax.scatter(LG, LT)
#ax.set_title("Mouse over a point")

mplcursors.cursor(hover=True)

plt.show()


from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"

from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
%matplotlib inline  
from mpld3 import plugins
from PIL import Image
img=Image.open("mouse-sizing-n-cropping-files/soil600.jpg")

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-02-2020.csv"
#im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))

DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
STate = 'Florida'
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-3
B =(max(LG))+3
C =(min(LT))-3
D =(max(LT))+3
#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
#fig, ax = plt.subplots(figsize=(8,8), dpi=80, facecolor='salmon')
#im = ax.imshow(img, extent=(A, B, C, D),
#               origin='upper', zorder=0, interpolation='nearest')
#plugins.connect(fig, plugins.MousePosition(fontsize=14))
#mpld3.display()

ax = fig.gca()
T= 'Miami-Dade'
text(0.62, 0.29, T, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)

plt.axis([A, B, C, D])
#plugins.connect(ax, plugins.MousePosition(fontsize=14))

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")
fig, ax = plt.subplots(figsize=(8,8), dpi=80, facecolor='salmon')
plugins.connect(fig, plugins.MousePosition(fontsize=14))
im = ax.imshow(img, extent=(A, B, C, D),
               origin='upper', zorder=0, interpolation='nearest')

mpld3.display()

plt.show()
#from PIL import Image
#im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))
#plugins.connect(fig, plugins.MousePosition(fontsize=14))

mpld3.display()



from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
%matplotlib inline  
from mpld3 import plugins
from PIL import Image
img=Image.open("mouse-sizing-n-cropping-files/soil600.jpg")

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-02-2020.csv"
#im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))

DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
STate = 'Florida'
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-3
B =(max(LG))+3
C =(min(LT))-3
D =(max(LT))+3
#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
fig, ax = plt.subplots(figsize=(8,8), dpi=80, facecolor='salmon')
im = ax.imshow(img, extent=(A, B, C, D),
               origin='upper', zorder=0, interpolation='nearest')
plugins.connect(fig, plugins.MousePosition(fontsize=14))

longLeft= (min(LG))-3
longRight = (max(LG))+3
lat1 = (min(LT))-3
lat2 = (max(LT))+3

ax = fig.gca()
T= 'Miami-Dade'
text(0.62, 0.29, T, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)

plt.axis([longLeft,longRight,lat1,lat2])

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")

#im = ax.imshow(img, extent=(A, B, C, D),
#               origin='lower', zorder=1, interpolation='nearest')

plt.xlabel('First data sample was: 09/03/2020 04:30:00')
plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
plt.ylabel('Number of Cases')
plt.show()

plugins.connect(fig, plugins.MousePosition(fontsize=14))

mpld3.display()



from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
%matplotlib inline  
from mpld3 import plugins
from PIL import Image
img=Image.open("mouse-sizing-n-cropping-files/soil600.jpg")

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-02-2020.csv"
#im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))

DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
STate = 'Florida'
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-3
B =(max(LG))+3
C =(min(LT))-3
D =(max(LT))+3
#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
fig, ax = plt.subplots(figsize=(8,8), dpi=80, facecolor='salmon')
im = ax.imshow(img, extent=(A, B, C, D),
               origin='upper', zorder=0, interpolation='nearest')
plugins.connect(fig, plugins.MousePosition(fontsize=14))
mpld3.display()

ax = fig.gca()
T= 'Miami-Dade'
text(0.62, 0.29, T, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)

plt.axis([A, B, C, D])

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")

#im = ax.imshow(img, extent=(A, B, C, D),
#               origin='lower', zorder=1, interpolation='nearest')

#plt.xlabel('First data sample was: 09/03/2020 04:30:00')
#plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
#plt.ylabel('Number of Cases')
plt.show()
from PIL import Image
im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))
plugins.connect(fig, plugins.MousePosition(fontsize=14))

mpld3.display()



from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
%matplotlib inline  
from mpld3 import plugins
from PIL import Image
img=Image.open("mouse-sizing-n-cropping-files/soil600.jpg")
 

fig, ax = plt.subplots()
im = ax.imshow(img, extent=(10, 20, 10, 20),
               origin='upper', zorder=1, interpolation='nearest')

plugins.connect(fig, plugins.MousePosition(fontsize=14))
mpld3.display()
from PIL import Image
im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))
plt.show()
plugins.connect(fig, plugins.MousePosition(fontsize=14))

mpld3.display()


%matplotlib notebook
import matplotlib.pyplot as plt
import numpy as np
import mplcursors
np.random.seed(42)

fig, ax = plt.subplots()
ax.scatter(*np.random.random((2, 26)))
ax.set_title("Mouse over a point")

mplcursors.cursor(hover=True)

plt.show()


%matplotlib notebook
import numpy as np
import matplotlib.pyplot as plt

company=['google','amazon','msft','fb']
revenue=[80,68,54,27]

fig=plt.figure()
ax=plt.subplot()

xpos=np.arange(len(company))

bars = plt.bar(xpos,revenue)


annot = ax.annotate("", xy=(0,0), xytext=(-20,20),textcoords="offset points",
                    bbox=dict(boxstyle="round", fc="black", ec="b", lw=2),
                    arrowprops=dict(arrowstyle="->"))
annot.set_visible(False)

def update_annot(bar):
    x = bar.get_x()+bar.get_width()/2.
    y = bar.get_y()+bar.get_height()
    annot.xy = (x,y)
    text = "({:.2g},{:.2g})".format( x,y )
    annot.set_text(text)
    annot.get_bbox_patch().set_alpha(0.4)


def hover(event):
    vis = annot.get_visible()
    if event.inaxes == ax:
        for bar in bars:
            cont, ind = bar.contains(event)
            if cont:
                update_annot(bar)
                annot.set_visible(True)
                fig.canvas.draw_idle()
                return
    if vis:
        annot.set_visible(False)
        fig.canvas.draw_idle()

fig.canvas.mpl_connect("motion_notify_event", hover)

plt.show()

import mplcursors
help(mplcursors)

%matplotlib notebook
import matplotlib.pyplot as plt
import numpy as np


def plot_unit_circle():
    angs = np.linspace(0, 2 * np.pi, 10**6)
    rs = np.zeros_like(angs) + 1
    xs = rs * np.cos(angs)
    ys = rs * np.sin(angs)
    plt.plot(xs, ys)


def mouse_move(event):
    x, y = event.xdata, event.ydata
    print(x, y)


plt.connect('motion_notify_event', mouse_move)
plot_unit_circle()
plt.axis('equal')
plt.show()

%matplotlib notebook
import matplotlib.pyplot as plt
import numpy as np
import ipywidgets as wdg  # Using the ipython notebook widgets

# Create a random image
a = np.random.poisson(size=(12,15))
fig = plt.figure()
plt.imshow(a)

# Create and display textarea widget
txt = wdg.Textarea(
    value='',
    placeholder='',
    description='event:',
    disabled=False
)
display(txt)

# Define a callback function that will update the textarea
def onclick(event):
    txt.value = str(event)  # Dynamically update the text box above

# Create an hard reference to the callback not to be cleared by the garbage collector
ka = fig.canvas.mpl_connect('button_press_event', onclick)

collector = []
def onclick(event):
    global i, collector
    collector.append((event.xdata, event.ydata))
    # Open the annotations file to continue to write
    target = open('annotation.txt', 'a')
    # Write picture and coordinates
    target.write(line)
    target.write("\n")
    i += 1
    event.canvas.figure.clear()
    event.canvas.figure.gca().imshow(images[i])

fig = plt.figure(figsize=(5,5))
fig.canvas.mpl_connect('button_press_event', onclick)

plt.imshow(images[0])
plt.show()

%matplotlib notebook
from matplotlib import pyplot as plt
import mplcursors
from pandas import DataFrame
collector = []
def onclick(event):
    global i, collector
    collector.append((event.xdata, event.ydata))
    # Open the annotations file to continue to write
    target = open('annotation.txt', 'a')
    # Write picture and coordinates
    target.write(line)
    target.write("\n")
    i += 1
    event.canvas.figure.clear()
    event.canvas.figure.gca().imshow(images[i])






#fig = plt.figure(figsize=(5,5))
#fig.canvas.mpl_connect('button_press_event', onclick)

df = DataFrame(
    [("Alice", 163, 54),
     ("Bob", 174, 67),
     ("Charlie", 177, 73),
     ("Diane", 168, 57)],
    columns=["name", "height", "weight"])
scatter1 = df.plot.scatter("height", "weight")
mplcursors.cursor(scatter1, hover=True).connect("add",
    lambda sel: sel.annotation.set_text(
        f'{df["name"][sel.target.index]}\nHeight: {df["height"][sel.target.index] / 100} m\nWeight: {df["weight"][sel.target.index]} kg'))


plt.show()

print(collector)

from matplotlib import pyplot as plt
import mplcursors
from pandas import DataFrame
collector = []
df = DataFrame(
    [("Alice", 163, 54),
     ("Bob", 174, 67),
     ("Charlie", 177, 73),
     ("Diane", 168, 57)],
    columns=["name", "height", "weight"])
scatter1 = df.plot.scatter("height", "weight")
mplcursors.cursor(scatter1, hover=True).connect("add",
    lambda sel: sel.annotation.set_text(
        f'{df["name"][sel.target.index]}\nHeight: {df["height"][sel.target.index] / 100} m\nWeight: {df["weight"][sel.target.index]} kg'))
plt.show()

import ipywidgets as widgets
import numpy as np
import pandas as pd

vartest = 0

Button = widgets.Button(description='Search', disabled=False, button_style='info', tooltip='Search')
display(Button)

def whenclick2(b):
    global df

    if vartest==0:
        df = pd.DataFrame(np.arange(5))


        class displayDF(object):
            def _create_widgets(self):
                self.button = Button
                self.button.on_click(self._on_button_clicked) # define which function to run when cliked

            def _on_button_clicked(self, change):
                self.out.clear_output() # clean previous outptu (I think ). Not working
                with self.out:# using self.out (the output widget) do the display
                    display(df) #aqui es donde digo que haga display del dataframe que es la variable self.file1

            def display_widgets(self):
                self._create_widgets() # calls the creation of the widgets
                self.out = widgets.Output()  # this is the output widget in which the df is displayed
                display(widgets.VBox([self.out])) # controls layout of widget position  

            def get_df_objects(self):
                return self.df_objects

    # Run class and store output in something
    something = displayDF()
    # output the display
    something.display_widgets()

    #return df    

Button.on_click(whenclick2)



%matplotlib notebook
sav=[]
import numpy as np
import matplotlib.pyplot as plt
fig = plt.figure()
ax = fig.add_subplot(111)
ax.plot(np.random.rand(10))
text=ax.text(0,0, "", va="bottom", ha="left")

def onclick(event):
    tx = 'button=%d, x=%d, y=%d, xdata=%f, ydata=%f' % (event.button, event.x, event.y, event.xdata, event.ydata)
    text.set_text(tx)
    sav.append(tx)

cid = fig.canvas.mpl_connect('button_press_event', onclick)

print(sav)



fig=plt.figure()

%matplotlib notebook
import mplcursors
from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
from mpld3 import plugins
from PIL import Image

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-14-2020.csv"


DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
STate = 'Florida'
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-3
B =(max(LG))+3
C =(min(LT))-3
D =(max(LT))+3
fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')



longLeft= (min(LG))-3
longRight = (max(LG))+3
lat1 = (min(LT))-3
lat2 = (max(LT))+3

ax = fig.gca()
T= 'Miami-Dade'
text(0.62, 0.29, T, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)

plt.axis([longLeft,longRight,lat1,lat2])

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")


plt.xlabel('First data sample was: 09/03/2020 04:30:00')
plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
plt.ylabel('Number of Cases')
mplcursors.cursor(hover=True)

plt.show()

%matplotlib notebook
import mplcursors
from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
from mpld3 import plugins
from PIL import Image

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-02-2020.csv"

DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
STate = 'Florida'
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-3
B =(max(LG))+3
C =(min(LT))-3
D =(max(LT))+3

longLeft= (min(LG))-3
longRight = (max(LG))+3
lat1 = (min(LT))-3
lat2 = (max(LT))+3

ax = fig.gca()
T= 'Miami-Dade'
text(0.62, 0.29, T, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)

plt.axis([longLeft,longRight,lat1,lat2])

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")

plt.xlabel('First data sample was: 09/03/2020 04:30:00')
plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
plt.ylabel('Number of Cases')
mplcursors.cursor(hover=True)

plt.show()

%matplotlib notebook
import matplotlib.pyplot as plt
import numpy as np
import mplcursors


#fig, ax = plt.subplots()
fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")



#ax.scatter(LG, LT)
#ax.set_title("Mouse over a point")

mplcursors.cursor(hover=True)

plt.show()


from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"

from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
%matplotlib inline  
from mpld3 import plugins
from PIL import Image
img=Image.open("mouse-sizing-n-cropping-files/soil600.jpg")

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-02-2020.csv"
#im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))

DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
STate = 'Florida'
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-3
B =(max(LG))+3
C =(min(LT))-3
D =(max(LT))+3
#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
#fig, ax = plt.subplots(figsize=(8,8), dpi=80, facecolor='salmon')
#im = ax.imshow(img, extent=(A, B, C, D),
#               origin='upper', zorder=0, interpolation='nearest')
#plugins.connect(fig, plugins.MousePosition(fontsize=14))
#mpld3.display()

ax = fig.gca()
T= 'Miami-Dade'
text(0.62, 0.29, T, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)

plt.axis([A, B, C, D])
#plugins.connect(ax, plugins.MousePosition(fontsize=14))

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")
fig, ax = plt.subplots(figsize=(8,8), dpi=80, facecolor='salmon')
plugins.connect(fig, plugins.MousePosition(fontsize=14))
im = ax.imshow(img, extent=(A, B, C, D),
               origin='upper', zorder=0, interpolation='nearest')

mpld3.display()

plt.show()
#from PIL import Image
#im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))
#plugins.connect(fig, plugins.MousePosition(fontsize=14))

mpld3.display()



from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
%matplotlib inline  
from mpld3 import plugins
from PIL import Image
img=Image.open("mouse-sizing-n-cropping-files/soil600.jpg")

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-02-2020.csv"
#im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))

DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
STate = 'Florida'
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-3
B =(max(LG))+3
C =(min(LT))-3
D =(max(LT))+3
#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
fig, ax = plt.subplots(figsize=(8,8), dpi=80, facecolor='salmon')
im = ax.imshow(img, extent=(A, B, C, D),
               origin='upper', zorder=0, interpolation='nearest')
plugins.connect(fig, plugins.MousePosition(fontsize=14))

longLeft= (min(LG))-3
longRight = (max(LG))+3
lat1 = (min(LT))-3
lat2 = (max(LT))+3

ax = fig.gca()
T= 'Miami-Dade'
text(0.62, 0.29, T, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)

plt.axis([longLeft,longRight,lat1,lat2])

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")

#im = ax.imshow(img, extent=(A, B, C, D),
#               origin='lower', zorder=1, interpolation='nearest')

plt.xlabel('First data sample was: 09/03/2020 04:30:00')
plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
plt.ylabel('Number of Cases')
plt.show()

plugins.connect(fig, plugins.MousePosition(fontsize=14))

mpld3.display()



from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
%matplotlib inline  
from mpld3 import plugins
from PIL import Image
img=Image.open("mouse-sizing-n-cropping-files/soil600.jpg")

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-02-2020.csv"
#im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))

DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
STate = 'Florida'
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-3
B =(max(LG))+3
C =(min(LT))-3
D =(max(LT))+3
#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
fig, ax = plt.subplots(figsize=(8,8), dpi=80, facecolor='salmon')
im = ax.imshow(img, extent=(A, B, C, D),
               origin='upper', zorder=0, interpolation='nearest')
plugins.connect(fig, plugins.MousePosition(fontsize=14))
mpld3.display()

ax = fig.gca()
T= 'Miami-Dade'
text(0.62, 0.29, T, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)

plt.axis([A, B, C, D])

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")

#im = ax.imshow(img, extent=(A, B, C, D),
#               origin='lower', zorder=1, interpolation='nearest')

#plt.xlabel('First data sample was: 09/03/2020 04:30:00')
#plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
#plt.ylabel('Number of Cases')
plt.show()
from PIL import Image
im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))
plugins.connect(fig, plugins.MousePosition(fontsize=14))

mpld3.display()



from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
%matplotlib inline  
from mpld3 import plugins
from PIL import Image
img=Image.open("mouse-sizing-n-cropping-files/soil600.jpg")
 

fig, ax = plt.subplots()
im = ax.imshow(img, extent=(10, 20, 10, 20),
               origin='upper', zorder=1, interpolation='nearest')

plugins.connect(fig, plugins.MousePosition(fontsize=14))
mpld3.display()
from PIL import Image
im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))
plt.show()
plugins.connect(fig, plugins.MousePosition(fontsize=14))

mpld3.display()


%matplotlib notebook
import matplotlib.pyplot as plt
import numpy as np
import mplcursors
np.random.seed(42)

fig, ax = plt.subplots()
ax.scatter(*np.random.random((2, 26)))
ax.set_title("Mouse over a point")

mplcursors.cursor(hover=True)

plt.show()


%matplotlib notebook
import numpy as np
import matplotlib.pyplot as plt

company=['google','amazon','msft','fb']
revenue=[80,68,54,27]

fig=plt.figure()
ax=plt.subplot()

xpos=np.arange(len(company))

bars = plt.bar(xpos,revenue)


annot = ax.annotate("", xy=(0,0), xytext=(-20,20),textcoords="offset points",
                    bbox=dict(boxstyle="round", fc="black", ec="b", lw=2),
                    arrowprops=dict(arrowstyle="->"))
annot.set_visible(False)

def update_annot(bar):
    x = bar.get_x()+bar.get_width()/2.
    y = bar.get_y()+bar.get_height()
    annot.xy = (x,y)
    text = "({:.2g},{:.2g})".format( x,y )
    annot.set_text(text)
    annot.get_bbox_patch().set_alpha(0.4)


def hover(event):
    vis = annot.get_visible()
    if event.inaxes == ax:
        for bar in bars:
            cont, ind = bar.contains(event)
            if cont:
                update_annot(bar)
                annot.set_visible(True)
                fig.canvas.draw_idle()
                return
    if vis:
        annot.set_visible(False)
        fig.canvas.draw_idle()

fig.canvas.mpl_connect("motion_notify_event", hover)

plt.show()

import mplcursors
help(mplcursors)

%matplotlib notebook
import matplotlib.pyplot as plt
import numpy as np


def plot_unit_circle():
    angs = np.linspace(0, 2 * np.pi, 10**6)
    rs = np.zeros_like(angs) + 1
    xs = rs * np.cos(angs)
    ys = rs * np.sin(angs)
    plt.plot(xs, ys)


def mouse_move(event):
    x, y = event.xdata, event.ydata
    print(x, y)


plt.connect('motion_notify_event', mouse_move)
plot_unit_circle()
plt.axis('equal')
plt.show()

%matplotlib notebook
import matplotlib.pyplot as plt
import numpy as np
import ipywidgets as wdg  # Using the ipython notebook widgets

# Create a random image
a = np.random.poisson(size=(12,15))
fig = plt.figure()
plt.imshow(a)

# Create and display textarea widget
txt = wdg.Textarea(
    value='',
    placeholder='',
    description='event:',
    disabled=False
)
display(txt)

# Define a callback function that will update the textarea
def onclick(event):
    txt.value = str(event)  # Dynamically update the text box above

# Create an hard reference to the callback not to be cleared by the garbage collector
ka = fig.canvas.mpl_connect('button_press_event', onclick)

collector = []
def onclick(event):
    global i, collector
    collector.append((event.xdata, event.ydata))
    # Open the annotations file to continue to write
    target = open('annotation.txt', 'a')
    # Write picture and coordinates
    target.write(line)
    target.write("\n")
    i += 1
    event.canvas.figure.clear()
    event.canvas.figure.gca().imshow(images[i])

fig = plt.figure(figsize=(5,5))
fig.canvas.mpl_connect('button_press_event', onclick)

plt.imshow(images[0])
plt.show()

%matplotlib notebook
from matplotlib import pyplot as plt
import mplcursors
from pandas import DataFrame
collector = []
def onclick(event):
    global i, collector
    collector.append((event.xdata, event.ydata))
    # Open the annotations file to continue to write
    target = open('annotation.txt', 'a')
    # Write picture and coordinates
    target.write(line)
    target.write("\n")
    i += 1
    event.canvas.figure.clear()
    event.canvas.figure.gca().imshow(images[i])






#fig = plt.figure(figsize=(5,5))
#fig.canvas.mpl_connect('button_press_event', onclick)

df = DataFrame(
    [("Alice", 163, 54),
     ("Bob", 174, 67),
     ("Charlie", 177, 73),
     ("Diane", 168, 57)],
    columns=["name", "height", "weight"])
scatter1 = df.plot.scatter("height", "weight")
mplcursors.cursor(scatter1, hover=True).connect("add",
    lambda sel: sel.annotation.set_text(
        f'{df["name"][sel.target.index]}\nHeight: {df["height"][sel.target.index] / 100} m\nWeight: {df["weight"][sel.target.index]} kg'))


plt.show()

print(collector)

from matplotlib import pyplot as plt
import mplcursors
from pandas import DataFrame
collector = []
df = DataFrame(
    [("Alice", 163, 54),
     ("Bob", 174, 67),
     ("Charlie", 177, 73),
     ("Diane", 168, 57)],
    columns=["name", "height", "weight"])
scatter1 = df.plot.scatter("height", "weight")
mplcursors.cursor(scatter1, hover=True).connect("add",
    lambda sel: sel.annotation.set_text(
        f'{df["name"][sel.target.index]}\nHeight: {df["height"][sel.target.index] / 100} m\nWeight: {df["weight"][sel.target.index]} kg'))
plt.show()

import ipywidgets as widgets
import numpy as np
import pandas as pd

vartest = 0

Button = widgets.Button(description='Search', disabled=False, button_style='info', tooltip='Search')
display(Button)

def whenclick2(b):
    global df

    if vartest==0:
        df = pd.DataFrame(np.arange(5))


        class displayDF(object):
            def _create_widgets(self):
                self.button = Button
                self.button.on_click(self._on_button_clicked) # define which function to run when cliked

            def _on_button_clicked(self, change):
                self.out.clear_output() # clean previous outptu (I think ). Not working
                with self.out:# using self.out (the output widget) do the display
                    display(df) #aqui es donde digo que haga display del dataframe que es la variable self.file1

            def display_widgets(self):
                self._create_widgets() # calls the creation of the widgets
                self.out = widgets.Output()  # this is the output widget in which the df is displayed
                display(widgets.VBox([self.out])) # controls layout of widget position  

            def get_df_objects(self):
                return self.df_objects

    # Run class and store output in something
    something = displayDF()
    # output the display
    something.display_widgets()

    #return df    

Button.on_click(whenclick2)



%matplotlib notebook
sav=[]
import numpy as np
import matplotlib.pyplot as plt
fig = plt.figure()
ax = fig.add_subplot(111)
ax.plot(np.random.rand(10))
text=ax.text(0,0, "", va="bottom", ha="left")

def onclick(event):
    tx = 'button=%d, x=%d, y=%d, xdata=%f, ydata=%f' % (event.button, event.x, event.y, event.xdata, event.ydata)
    text.set_text(tx)
    sav.append(tx)

cid = fig.canvas.mpl_connect('button_press_event', onclick)

print(sav)

%matplotlib notebook
import mplcursors
from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
from mpld3 import plugins
from PIL import Image
import ipywidgets as wdg 
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/05-08-2020.csv"

DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
LOCATION =[]
cases = []
COORD=[]
STate = input("Which State? ")
STate = "Ohio"
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        if cnt ==2:print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
        LOCATION.append([line[7],line[5],line[6],line[8]])
LA = LAT
LO = LON
X = np.array(LAT,dtype=np.float)
Y = np.array(LON,dtype=np.float)
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

fig = plt.figure(num=None, figsize=(12,12), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-1
B =(max(LG))+1
C =(min(LT))-1
D =(max(LT))+1


longLeft= (min(LG))-3
longRight = (max(LG))+3
lat1 = (min(LT))-3
lat2 = (max(LT))+3

ax = fig.gca()
T= STate
text(0.62, 0.29, T, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes, fontsize=20)

# Create and display textarea widget
txt = wdg.Textarea(
    value='',
    placeholder='',
    description='event:',
    disabled=False
)
display(txt)

#COORD.append(txt)
# Define a callback function that will update the textarea
def onclick(event):
    # Uncomment for only one one click at a time
    #COORD=[]

    txt.value = str(event)  # Dynamically update the text box above
    COORD.append(txt.value)

# Create an hard reference to the callback not to be cleared by the garbage collector
ka = fig.canvas.mpl_connect('button_press_event', onclick)

plt.axis([longLeft,longRight,lat1,lat2])
ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(Y, X, s=s, color="black")


plt.xlabel('First data sample was taken: 01/20/2020', fontsize=24)
plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
plt.ylabel('Number of Cases')
mplcursors.cursor(hover=True)

plt.show()

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/05-08-2020.csv"

DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
LOCATION =[]
cases = []
COORD=[]
CITY =[]
#STate = input("Which State? ")
Threshhold = 40
STate = "Ohio"
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        if int(line[8])>Threshhold:
            print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
            cnt=cnt+1
            LAT.append(line[5]) 
            LON.append(line[6])
            cases.append(int(line[7]))
            LOCATION.append([line[1],line[6],line[5],line[8]])
            CITY.append(line[1])

for i in range(0,len(LOCATION)):
    location = LOCATION[i][1:-1]
    print(location[0],location[1])

location = LOCATION[3][1:-1]

import warnings
warnings.filterwarnings("ignore")
import matplotlib.pyplot as plt
from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon
import numpy as np
from PIL import Image,ImageFont,ImageDraw,ImageFilter,ImageChops
from random import randint
from mpl_toolkits.basemap import Basemap

cities =[]
LAT=[]
LONG=[]
LATd=[]
LONGd=[]
STATES=[]
ALL=[]
cases=[]
deaths =[]
yesterday=0
today=0
longitude = ""
cnt=0
CNT=0
Dcnt=0
LASTFILE="csv/_deaths_US.csv"
DataIn = open(LASTFILE).readlines()
for line in DataIn:
    line=line.replace('"','')
    if cnt==0:print (line)
    cnt=cnt+1
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    if cnt<10 and line[5] !="":print (line[7])
    if "Ohio" in line[2]:# and line[6] == "New York":
        #if CNT==7:print(line)
        #if CNT==8:print(line)    
        if CNT<5 and line[5] !="":print(line)
        CNT=CNT+1
        ALL.append(line)
        LAT.append(line[5])
        LONG.append(line[6])
        L=len(line)
        deaths.append(line[L-1])
        #print(L)
        #print(line[L-1],line[L-2])
        if int(line[L-2])+50<int(line[L-1]):
            #print ("if ",int(line[L-2]),'+10',int(line[L-1]))
            #print (text,int(line[L-2]),int(line[L-1]))
            if len(line[8])>3:            
                text=line
                STATES.append(text)
                yesterday=yesterday+int(line[-2])
                today= today+int(line[-1])
                Dcnt=Dcnt+1
                #print(line[8],line[9])
                cities.append([line[5],line[6],line[8],line[9],line[L-1],int(line[L-1])-int(line[L-2])])
                LATd.append(line[8])
                LONGd.append(line[9])
                

                
                
                
LTd = np.array(LATd,dtype=np.float)
LGd = np.array(LONGd,dtype=np.float)
Str = np.array(cities,dtype=np.str)

fig = plt.figure(num=None, figsize=(12, 8) ) 
m = Basemap(width=6000000,height=4500000,resolution='c',projection='aea',lat_1=35.,lat_2=45,lon_0=-100,lat_0=40)
m.drawcoastlines(linewidth=0.5)
m.fillcontinents(color='tan',lake_color='lightblue')
# draw parallels and meridians.
m.drawparallels(np.arange(-90.,91.,15.),labels=[True,True,False,False],dashes=[2,2])
m.drawmeridians(np.arange(-180.,181.,15.),labels=[False,False,False,True],dashes=[2,2])
m.drawmapboundary(fill_color='lightblue')
m.drawcountries(linewidth=2, linestyle='solid', color='k' ) 
m.drawstates(linewidth=0.5, linestyle='solid', color='k')
m.drawrivers(linewidth=0.5, linestyle='solid', color='blue')






S=1
Size=[]
for x in cases:
    S=1+(float(x)*.01)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

Sd=1
Sized=[]
for xd in deaths:
    Sd=0+(float(xd)*.07)
    Sized.append(int(Sd))
    #print(int(S))
sd = np.array(Sized)
#print(Sized)
plt.title("Finding-Hot-Spots.ipynb - https://github.com/JupyterJones/COVID-19-Jupyter-Notebooks")
#plt.text(max(LG-1.2),max(LT), search, color='white', fontsize=24)
#x, y = m(lons, lats)  # transform coordinates
x, y = m(LGd, LTd)
#xx,yy = m(LG, LT)
plt.xlabel('Longitude',color="white", fontsize=24)
plt.ylabel('Latitute',color="white", fontsize=24)

for i in (range(0,len(cities))):
    C=cities[i][0]
    S=cities[i][1]
    t=float(cities[i][2])
    l=float(cities[i][3])
    d=cities[i][4]
    inc=cities[i][5]
    print(C,S,l,t,d,inc)
    plt.annotate(C, m(l,t),color='red',fontsize=20,zorder=15)   
    
m.scatter(x, y, s=sd, color='r', zorder=10,  alpha=0.6)
filename = "BaseMap/april30_Hotspots__.png"
plt.savefig(filename, dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)

import matplotlib.pyplot as plt
from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon
import numpy as np
from PIL import Image,ImageFont,ImageDraw,ImageFilter,ImageChops
from random import randint
from mpl_toolkits.basemap import Basemap
#prevents a warning from using Python3 instaead of Python2
import warnings
warnings.filterwarnings("ignore")
import sys
sys.path.insert(1, "/home/jack/hidden")
import Key
import twython
from twython import Twython

def RndState():
    TX=["Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming"]
    x=randint(1,50)
    return TX[x]


LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-27-2020.csv"
#LASTFILE="csse_covid_19_data/csse_covid_19_daily_reports/03-30-2020.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
LATd=[]
LONGd=[]
STATES=[]
cases=[]
deaths =[]
longitude = ""
search = RndState()
for line in DataIn:
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    if search in line[2] and "-" in (line[6]):
        text=line[2],line[1],line[3],line[4],line[5],line[6],line[7],line[8],line[9],line[10]
        STATES.append(text)
        LAT.append(line[5])
        LONG.append(line[6])
        if int(line[8])>0:
            LATd.append(line[5])
            LONGd.append(line[6])        
        cases.append(line[7])
        deaths.append(line[8])
        longitude = longitude+line[6]+","

print(len(STATES))        
LT = np.array(LAT,dtype=np.float)
LG = np.array(LONG,dtype=np.float)
LTd = np.array(LATd,dtype=np.float)
LGd = np.array(LONGd,dtype=np.float)

# Make the figure
fig = plt.figure(num=None, figsize=(10,8), dpi=80, facecolor='salmon')

urcrnrlat=max(LT)+.5
llcrnrlat=min(LT)-.5
urcrnrlon=max(LG)+.8
llcrnrlon=min(LG)-.5
lat_0 = (urcrnrlat+llcrnrlat)/2
lon_0 =(urcrnrlon+llcrnrlon)/2

# Easiest way to make a basemap is to use the cylidrical projection and 
# define the bottom left lat/lon and top right lat/lon corners
# create the map object, m
m = Basemap(resolution='h', projection='cyl', \
    llcrnrlon=llcrnrlon, llcrnrlat=llcrnrlat, urcrnrlon=urcrnrlon, urcrnrlat=urcrnrlat)

# Note:
# You can define the resolution of the map you just created. Higher - resolutions take longer to create.
#    'c' - crude
#    'l' - low
#    'i' - intermediate
#    'h' - high
#    'f' - full

# Draw some map elements on the map
m.drawmapboundary(fill_color='aqua')
m.fillcontinents(color='#ddaa66',lake_color='aqua')
m.drawcoastlines()
m.drawrivers(linewidth=1.0,color='navy',zorder=8)
m.drawcounties(linewidth=1.0, linestyle='solid', color='gray', antialiased=1, facecolor='lightgreen', ax=None, zorder=2, drawbounds=True)
m.drawstates(linewidth=1.5, linestyle='solid', color='black', antialiased=1,zorder=2, )
plt.text(llcrnrlon,llcrnrlat+.5, search, color='black', fontsize=24.5, zorder=6,bbox=dict(facecolor='salmon'))

# Drawing ArcGIS Basemap (only works with cylc projections??)
# Examples of what each map looks like can be found here:
# http://kbkb-wx-python.blogspot.com/2016/04/python-basemap-background-image-from.html
maps = ['ESRI_Imagery_World_2D',    # 0
        'ESRI_StreetMap_World_2D',  # 1
        'NatGeo_World_Map',         # 2
        'NGS_Topo_US_2D',           # 3
        'Ocean_Basemap',            # 4
        'USA_Topo_Maps',            # 5
        'World_Imagery',            # 6
        'World_Physical_Map',       # 7
        'World_Shaded_Relief',      # 8
        'World_Street_Map',         # 9
        'World_Terrain_Base',       # 10
        'World_Topo_Map'            # 11
        ]
MapStyle = 2
print ("Drawing MapStyle",MapStyle," image from arcGIS server..."),

m.arcgisimage(service=maps[MapStyle], xpixels=2000, verbose=False)
print ("...finished")

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.5)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

Sd=0
Sized=[]
for xd in deaths:
    Sd=0+(float(xd))
    Sized.append(int(Sd))
    #print(int(S))
sd = np.array(Sized)
#print(Sized)
plt.title("COVID-19:\n Cases: (black)\n Deaths(red) \n Location:\n "+search+"\n", fontsize=15, loc='right')
#plt.text(max(LG-1.2),max(LT), search, color='white', fontsize=24)
#x, y = m(lons, lats)  # transform coordinates
x, y = m(LGd, LTd)
xx,yy = m(LG, LT)
plt.xlabel('Longitude',color="white", fontsize=24)
plt.ylabel('Latitute',color="white", fontsize=24)

m.scatter(xx, yy, s=s, color='black', zorder=5, alpha=0.6)
m.scatter(x, y, s=sd, color='r', zorder=10,  alpha=0.6)

plt.savefig("BaseMap/"+search+"arcGIS__.png", dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)

# Add plot title and other plot elements the normal way
filename0 = "BaseMap/"+search+"arcGIS__.png"

def draw_blurred_back(img, position, text, font, col, halo_col):
    halo = Image.new('RGBA', img.size, (0, 0, 0, 0))
    ImageDraw.Draw(halo).text(position, text, font = font, fill = halo_col)
    blurred_halo = halo.filter(ImageFilter.BLUR)
    ImageDraw.Draw(blurred_halo).text(position, text, font = font, fill = col)
    return Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))

if __name__ == '__main__':
    
    basewidth = 720
    inp = Image.open(filename0)
    wpercent = (basewidth / float(inp.size[0]))
    hsize = int((float(inp.size[1]) * float(wpercent)))
    inp = inp.resize((basewidth, hsize), Image.ANTIALIAS)
    #img.save(resized_image.jpg')
    
    #inp = inp.resize((640,640), Image.ANTIALIAS)
    font = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 30)
    text_title = (255, 255,230) # bright green
    blur_title = (0, 0, 0)   # black

    i2 = draw_blurred_back(inp, (15, 30), "Plotting COVID-19 Data", font, text_title, blur_title)
    font0 = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 20)
    font1 = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 14)
    font2 = ImageFont.truetype("/home/jack/fonts/PatrickHand-Regular.ttf", 16)
    #i2 = draw_blurred_back(i2, (15, 65), "Plot Using ArcGIS Basemap - "+search, font0, text_title, blur_title)
    
    i2 = draw_blurred_back(i2, (15, 65), "Drawing MapStyle "+str(MapStyle)+" image from arcGIS server..."+search, font0, text_title, blur_title)
    
    TXT="https://github.com/JupyterJones/COVID-19-Jupyter-Notebooks"
    draw = ImageDraw.Draw(i2) 
    draw.text((15, 5), TXT, font = font2, align ="left",fill="black")
    #i2 = draw(i2, (15, 65),TXT, font1)    
    
    #txt = Image.new('RGBA', i.size, (255,255,255,0))

    # get a font
    fnt = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 20)
    # get a drawing context
    signature_ = "@jacklnorthrup" 
    #get length in pixel of signature_
    sizeS,ln = fnt.getsize(signature_)
    #add 15 pixels to right border
    pt = sizeS+25
    width, height = inp.size
    #marginx starting point of signature_
    marginx = pt
    #bottom margin
    marginy = 30
    x = width - marginx
    y = height - marginy
    

    text_sig = (255, 255,230) # bright green
    blur_sig = (0, 0, 0)   # black
    txt=draw_blurred_back(i2,(x,y), signature_, fnt, text_sig, blur_sig)
    out = Image.alpha_composite(i2, txt)
    out.save("images/TEMP_POST.png")

CONSUMER_KEY = Key.twiter()[0]
CONSUMER_SECRET = Key.twiter()[1]
ACCESS_KEY = Key.twiter()[2]
ACCESS_SECRET = Key.twiter()[3]
twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)

STR = "#"+search+"  #arcGIS server #Basemap #COVID-19 - #Python  Plot data using "+TXT+" #JupyterJones" 

PATH = "images/TEMP_POST.png"
photo = open(PATH,'rb')
#response = twitter.upload_media(media=photo)
#twitter.update_status(status=STR, media_ids=[response['media_id']])

import matplotlib.pyplot as plt
from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon
import numpy as np
from PIL import Image,ImageFont,ImageDraw,ImageFilter,ImageChops
from random import randint
from mpl_toolkits.basemap import Basemap
#prevents a warning from using Python3 instaead of Python2
import warnings
warnings.filterwarnings("ignore")
import sys
sys.path.insert(1, "/home/jack/hidden")
import Key
import twython
from twython import Twython

def RndState():
    TX=["Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming"]
    x=randint(1,50)
    return TX[x]


LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-27-2020.csv"
#LASTFILE="csse_covid_19_data/csse_covid_19_daily_reports/03-30-2020.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
LATd=[]
LONGd=[]
STATES=[]
cases=[]
deaths =[]
longitude = ""
search = RndState()
for line in DataIn:
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    if search in line[2] and "-" in (line[6]):
        text=line[2],line[1],line[3],line[4],line[5],line[6],line[7],line[8],line[9],line[10]
        STATES.append(text)
        LAT.append(line[5])
        LONG.append(line[6])
        if int(line[8])>0:
            LATd.append(line[5])
            LONGd.append(line[6])        
        cases.append(line[7])
        deaths.append(line[8])
        longitude = longitude+line[6]+","

print(len(STATES))        
LT = np.array(LAT,dtype=np.float)
LG = np.array(LONG,dtype=np.float)
LTd = np.array(LATd,dtype=np.float)
LGd = np.array(LONGd,dtype=np.float)

# Make the figure
fig = plt.figure(num=None, figsize=(10,8), dpi=80, facecolor='salmon')

urcrnrlat=max(LT)+.5
llcrnrlat=min(LT)-.5
urcrnrlon=max(LG)+.8
llcrnrlon=min(LG)-.5
lat_0 = (urcrnrlat+llcrnrlat)/2
lon_0 =(urcrnrlon+llcrnrlon)/2

# Easiest way to make a basemap is to use the cylidrical projection and 
# define the bottom left lat/lon and top right lat/lon corners
# create the map object, m
m = Basemap(resolution='h', projection='cyl', \
    llcrnrlon=llcrnrlon, llcrnrlat=llcrnrlat, urcrnrlon=urcrnrlon, urcrnrlat=urcrnrlat)
print("llcrnrlon=",llcrnrlon, "llcrnrlat=",llcrnrlat,"urcrnrlon=",urcrnrlon,"urcrnrlat=",urcrnrlat)
# Note:
# You can define the resolution of the map you just created. Higher - resolutions take longer to create.
#    'c' - crude
#    'l' - low
#    'i' - intermediate
#    'h' - high
#    'f' - full

# Draw some map elements on the map
m.drawmapboundary(fill_color='aqua')
m.fillcontinents(color='#ddaa66',lake_color='aqua')
m.drawcoastlines()
m.drawrivers(linewidth=1.0,color='navy',zorder=8)
m.drawcounties(linewidth=1.0, linestyle='solid', color='gray', antialiased=1, facecolor='lightgreen', ax=None, zorder=2, drawbounds=True)
m.drawstates(linewidth=1.5, linestyle='solid', color='black', antialiased=1,zorder=2, )
plt.text(llcrnrlon,llcrnrlat+.5, search, color='black', fontsize=24.5, zorder=6,bbox=dict(facecolor='salmon'))

# Drawing ArcGIS Basemap (only works with cylc projections??)
# Examples of what each map looks like can be found here:
# http://kbkb-wx-python.blogspot.com/2016/04/python-basemap-background-image-from.html
maps = ['ESRI_Imagery_World_2D',    # 0
        'ESRI_StreetMap_World_2D',  # 1
        'NatGeo_World_Map',         # 2
        'NGS_Topo_US_2D',           # 3
        'Ocean_Basemap',            # 4
        'USA_Topo_Maps',            # 5
        'World_Imagery',            # 6
        'World_Physical_Map',       # 7
        'World_Shaded_Relief',      # 8
        'World_Street_Map',         # 9
        'World_Terrain_Base',       # 10
        'World_Topo_Map'            # 11
        ]
MapStyle = 2
print ("Drawing MapStyle",MapStyle," image from arcGIS server..."),

m.arcgisimage(service=maps[MapStyle], xpixels=2000, verbose=False)
print ("...finished")

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.5)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

Sd=0
Sized=[]
for xd in deaths:
    Sd=0+(float(xd))
    Sized.append(int(Sd))
    #print(int(S))
sd = np.array(Sized)
#print(Sized)
plt.title("COVID-19:\n Cases: (black)\n Deaths(red) \n Location:\n "+search+"\n", fontsize=15, loc='right')
#plt.text(max(LG-1.2),max(LT), search, color='white', fontsize=24)
#x, y = m(lons, lats)  # transform coordinates
x, y = m(LGd, LTd)
xx,yy = m(LG, LT)
plt.xlabel('Longitude',color="white", fontsize=24)
plt.ylabel('Latitute',color="white", fontsize=24)

m.scatter(xx, yy, s=s, color='black', zorder=5, alpha=0.6)
m.scatter(x, y, s=sd, color='r', zorder=10,  alpha=0.6)

plt.savefig("BaseMap/"+search+"arcGIS__.png", dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)

# Add plot title and other plot elements the normal way
filename0 = "BaseMap/"+search+"arcGIS__.png"

def draw_blurred_back(img, position, text, font, col, halo_col):
    halo = Image.new('RGBA', img.size, (0, 0, 0, 0))
    ImageDraw.Draw(halo).text(position, text, font = font, fill = halo_col)
    blurred_halo = halo.filter(ImageFilter.BLUR)
    ImageDraw.Draw(blurred_halo).text(position, text, font = font, fill = col)
    return Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))

if __name__ == '__main__':
    
    basewidth = 720
    inp = Image.open(filename0)
    wpercent = (basewidth / float(inp.size[0]))
    hsize = int((float(inp.size[1]) * float(wpercent)))
    inp = inp.resize((basewidth, hsize), Image.ANTIALIAS)
    #img.save(resized_image.jpg')
    
    #inp = inp.resize((640,640), Image.ANTIALIAS)
    font = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 30)
    text_title = (255, 255,230) # bright green
    blur_title = (0, 0, 0)   # black

    i2 = draw_blurred_back(inp, (15, 30), "Plotting COVID-19 Data", font, text_title, blur_title)
    font0 = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 20)
    font1 = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 14)
    font2 = ImageFont.truetype("/home/jack/fonts/PatrickHand-Regular.ttf", 16)
    #i2 = draw_blurred_back(i2, (15, 65), "Plot Using ArcGIS Basemap - "+search, font0, text_title, blur_title)
    
    i2 = draw_blurred_back(i2, (15, 65), "Drawing MapStyle "+str(MapStyle)+" image from arcGIS server..."+search, font0, text_title, blur_title)
    
    TXT="https://github.com/JupyterJones/COVID-19-Jupyter-Notebooks"
    draw = ImageDraw.Draw(i2) 
    draw.text((15, 5), TXT, font = font2, align ="left",fill="black")
    #i2 = draw(i2, (15, 65),TXT, font1)    
    
    #txt = Image.new('RGBA', i.size, (255,255,255,0))

    # get a font
    fnt = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 20)
    # get a drawing context
    signature_ = "@jacklnorthrup" 
    #get length in pixel of signature_
    sizeS,ln = fnt.getsize(signature_)
    #add 15 pixels to right border
    pt = sizeS+25
    width, height = inp.size
    #marginx starting point of signature_
    marginx = pt
    #bottom margin
    marginy = 30
    x = width - marginx
    y = height - marginy
    

    text_sig = (255, 255,230) # bright green
    blur_sig = (0, 0, 0)   # black
    txt=draw_blurred_back(i2,(x,y), signature_, fnt, text_sig, blur_sig)
    out = Image.alpha_composite(i2, txt)
    out.save("images/TEMP_POST.png")

CONSUMER_KEY = Key.twiter()[0]
CONSUMER_SECRET = Key.twiter()[1]
ACCESS_KEY = Key.twiter()[2]
ACCESS_SECRET = Key.twiter()[3]
twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)

STR = "#"+search+"  #arcGIS server #Basemap #COVID-19 - #Python  Plot data using "+TXT+" #JupyterJones" 

PATH = "images/TEMP_POST.png"
photo = open(PATH,'rb')
#response = twitter.upload_media(media=photo)
#twitter.update_status(status=STR, media_ids=[response['media_id']])

from PIL import Image
IM = Image.open(PATH)
IM



!ls COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv

!pip show basemap | grep Location

import os
import inspect
print(inspect.getfile(Basemap))

import os.path
from mpl_toolkits.basemap import Basemap
import mpl_toolkits.basemap
print(os.path.abspath('mpl_toolkits.basemap'))

!locate etopo20data.gz



from mpl_toolkits.basemap import Basemap


!ls COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/

import matplotlib.pyplot as plt
from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon
import numpy as np
from PIL import Image,ImageFont,ImageDraw,ImageFilter,ImageChops
from random import randint
from mpl_toolkits.basemap import Basemap
#prevents a warning from using Python3 instaead of Python2
import warnings
warnings.filterwarnings("ignore")
import sys
sys.path.insert(1, "/home/jack/hidden")
import Key
import twython
from twython import Twython
# Make the figure
#fig = plt.figure()
#ax = fig.add_subplot(111)

# Easiest way to make a basemap is to use the cylidrical projection and 
# define the bottom left lat/lon and top right lat/lon corners

def RndState():
    TX=["Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming"]
    x=randint(1,50)
    return TX[x]
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-27-2020.csv"
#LASTFILE="csse_covid_19_data/csse_covid_19_daily_reports/03-30-2020.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
LATd=[]
LONGd=[]
STATES=[]
cases=[]
deaths =[]
longitude = ""
search = RndState()
for line in DataIn:
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    if search in line[2] and "-" in (line[6]):
        text=line[2],line[1],line[3],line[4],line[5],line[6],line[7],line[8],line[9],line[10]
        STATES.append(text)
        LAT.append(line[5])
        LONG.append(line[6])
        if int(line[8])>0:
            LATd.append(line[5])
            LONGd.append(line[6])        
        cases.append(line[7])
        deaths.append(line[8])
        longitude = longitude+line[6]+","
print(len(STATES))        
LT = np.array(LAT,dtype=np.float)
LG = np.array(LONG,dtype=np.float)
LTd = np.array(LATd,dtype=np.float)
LGd = np.array(LONGd,dtype=np.float)


fig = plt.figure(num=None, figsize=(10,8), dpi=80, facecolor='salmon')


urcrnrlat=max(LT)+.5
llcrnrlat=min(LT)-.5
urcrnrlon=max(LG)+.8
llcrnrlon=min(LG)-.5
lat_0 = (urcrnrlat+llcrnrlat)/2
lon_0 =(urcrnrlon+llcrnrlon)/2

# create the map object, m
m = Basemap(resolution='i', projection='cyl', \
    llcrnrlon=llcrnrlon, llcrnrlat=llcrnrlat, urcrnrlon=urcrnrlon, urcrnrlat=urcrnrlat)

# Note: You can define the resolution of the map you just created. Higher 
# resolutions take longer to create.
#    'c' - crude
#    'l' - low
#    'i' - intermediate
#    'h' - high
#    'f' - full

# Draw some map elements on the map
m.drawmapboundary(fill_color='aqua')
m.fillcontinents(color='#ddaa66',lake_color='aqua')
m.drawcoastlines()
m.drawrivers(linewidth=1.0,color='navy',zorder=8)
m.drawcounties(linewidth=1.0, linestyle='solid', color='gray', antialiased=1, facecolor='lightgreen', ax=None, zorder=2, drawbounds=True)
m.drawstates(linewidth=1.5, linestyle='solid', color='black', antialiased=1,zorder=2, )
plt.text(llcrnrlon,llcrnrlat+.5, search, color='black', fontsize=24.5, zorder=6,bbox=dict(facecolor='salmon'))

# Drawing ArcGIS Basemap (only works with cylc projections??)
# Examples of what each map looks like can be found here:
# http://kbkb-wx-python.blogspot.com/2016/04/python-basemap-background-image-from.html
maps = ['ESRI_Imagery_World_2D',    # 0
        'ESRI_StreetMap_World_2D',  # 1
        'NatGeo_World_Map',         # 2
        'NGS_Topo_US_2D',           # 3
        'Ocean_Basemap',            # 4
        'USA_Topo_Maps',            # 5
        'World_Imagery',            # 6
        'World_Physical_Map',       # 7
        'World_Shaded_Relief',      # 8
        'World_Street_Map',         # 9
        'World_Terrain_Base',       # 10
        'World_Topo_Map'            # 11
        ]
print ("drawing image from arcGIS server..."),
m.arcgisimage(service=maps[8], xpixels=1000, verbose=False)
print ("...finished")

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.5)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

Sd=0
Sized=[]
for xd in deaths:
    Sd=0+(float(xd))
    Sized.append(int(Sd))
    #print(int(S))
sd = np.array(Sized)
#print(Sized)
plt.title("COVID-19:\n Cases: (black)\n Deaths(red) \n Location:\n "+search+"\n", fontsize=15, loc='right')
#plt.text(max(LG-1.2),max(LT), search, color='white', fontsize=24)
#x, y = m(lons, lats)  # transform coordinates
x, y = m(LGd, LTd)
xx,yy = m(LG, LT)
plt.xlabel('Longitude',color="white", fontsize=24)
plt.ylabel('Latitute',color="white", fontsize=24)

m.scatter(xx, yy, s=s, color='black', zorder=5, alpha=0.6)
m.scatter(x, y, s=sd, color='r', zorder=10,  alpha=0.6)



#plt.scatter(x, y,  s=s, color="black", zorder=3, alpha=0.6)
#plt.scatter(x, y,  s=sd, color="red", zorder=6, alpha=0.6)
#plt.text(urcrnrlon,urcrnrlat, search, color='white', fontsize=24)
plt.savefig("BaseMap/"+search+"arcGIS__.png", dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)

# Add plot title and other plot elements the normal way
filename0 = "BaseMap/"+search+"arcGIS__.png"


def draw_blurred_back(img, position, text, font, col, halo_col):
    halo = Image.new('RGBA', img.size, (0, 0, 0, 0))
    ImageDraw.Draw(halo).text(position, text, font = font, fill = halo_col)
    blurred_halo = halo.filter(ImageFilter.BLUR)
    ImageDraw.Draw(blurred_halo).text(position, text, font = font, fill = col)
    return Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))

if __name__ == '__main__':
    
    basewidth = 720
    inp = Image.open(filename0)
    wpercent = (basewidth / float(inp.size[0]))
    hsize = int((float(inp.size[1]) * float(wpercent)))
    inp = inp.resize((basewidth, hsize), Image.ANTIALIAS)
    #img.save(resized_image.jpg')
    
    #inp = inp.resize((640,640), Image.ANTIALIAS)
    font = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 30)
    text_title = (255, 255,230) # bright green
    blur_title = (0, 0, 0)   # black

    i2 = draw_blurred_back(inp, (15, 30), "Plotting COVID-19 Data", font, text_title, blur_title)
    font0 = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 20)
    font1 = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 14)
    font2 = ImageFont.truetype("/home/jack/fonts/PatrickHand-Regular.ttf", 16)
    i2 = draw_blurred_back(i2, (15, 65), "Plot Using ArcGIS Basemap - "+search, font0, text_title, blur_title)
    TXT="https://github.com/JupyterJones/COVID-19-Jupyter-Notebooks"
    draw = ImageDraw.Draw(i2) 
    draw.text((15, 5), TXT, font = font2, align ="left",fill="black")
    #i2 = draw(i2, (15, 65),TXT, font1)    
    
    #txt = Image.new('RGBA', i.size, (255,255,255,0))

    # get a font
    fnt = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 20)
    # get a drawing context
    signature_ = "@jacklnorthrup" 
    #get length in pixel of signature_
    sizeS,ln = fnt.getsize(signature_)
    #add 15 pixels to right border
    pt = sizeS+25
    width, height = inp.size
    #marginx starting point of signature_
    marginx = pt
    #bottom margin
    marginy = 30
    x = width - marginx
    y = height - marginy
    

    text_sig = (255, 255,230) # bright green
    blur_sig = (0, 0, 0)   # black
    txt=draw_blurred_back(i2,(x,y), signature_, fnt, text_sig, blur_sig)
    out = Image.alpha_composite(i2, txt)
    out.save("images/TEMP_POST.png")

CONSUMER_KEY = Key.twiter()[0]
CONSUMER_SECRET = Key.twiter()[1]
ACCESS_KEY = Key.twiter()[2]
ACCESS_SECRET = Key.twiter()[3]
twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)

STR = "#"+search+"  #arcGIS server #Basemap #COVID-19 - #Python  Plot data using "+TXT+" #JupyterJones" 

PATH = "images/TEMP_POST.png"
photo = open(PATH,'rb')
#response = twitter.upload_media(media=photo)
#twitter.update_status(status=STR, media_ids=[response['media_id']])

import matplotlib.pyplot as plt
from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon
import numpy as np
from PIL import Image,ImageFont,ImageDraw,ImageFilter,ImageChops
from random import randint
from mpl_toolkits.basemap import Basemap
from US_State_Bounding_Boxes import GetCOOR # get coordinates for state(box)
#prevents a warning from using Python3 instaead of Python2
import warnings
warnings.filterwarnings("ignore")
import sys
sys.path.insert(1, "/home/jack/hidden")
import Key
import twython
from twython import Twython
# Make the figure
#fig = plt.figure()
#ax = fig.add_subplot(111)

# Easiest way to make a basemap is to use the cylidrical projection and 
# define the bottom left lat/lon and top right lat/lon corners

def RndState():
    TX=["Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming"]
    x=randint(1,49)
    return TX[x]
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/05-10-2020.csv"
#LASTFILE="csse_covid_19_data/csse_covid_19_daily_reports/03-30-2020.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
LATd=[]
LONGd=[]
STATES=[]
cases=[]
deaths =[]
longitude = ""
search = RndState()
#search = "Florida"
for line in DataIn:
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    if search in line[2] and "-" in (line[6]):
        text=line[2],line[1],line[3],line[4],line[5],line[6],line[7],line[8],line[9],line[10]
        STATES.append(text)
        LAT.append(line[5])
        LONG.append(line[6])
        if int(line[8])>0:
            LATd.append(line[5])
            LONGd.append(line[6])        
        cases.append(line[7])
        deaths.append(line[8])
        longitude = longitude+line[6]+","
print(len(STATES))        
LT = np.array(LAT,dtype=np.float)
LG = np.array(LONG,dtype=np.float)
LTd = np.array(LATd,dtype=np.float)
LGd = np.array(LONGd,dtype=np.float)

fig = plt.figure(num=None, figsize=(12,10), dpi=80, facecolor='salmon')
coor= GetCOOR(search)
urcrnrlat = coor[0]+.5
llcrnrlat = coor[1]-.5
urcrnrlon = coor[2]+.5
llcrnrlon = coor[3]-.5

lat_0 = (urcrnrlat+llcrnrlat)/2
lon_0 =(urcrnrlon+llcrnrlon)/2
# create the map object, m
m = Basemap(resolution='h', projection='cyl', \
    llcrnrlon=llcrnrlon, llcrnrlat=llcrnrlat, urcrnrlon=urcrnrlon, urcrnrlat=urcrnrlat)

# Note: You can define the resolution of the map you just created. Higher 
# resolutions take longer to create.
#    'c' - crude
#    'l' - low
#    'i' - intermediate
#    'h' - high
#    'f' - full


# Draw some map elements on the map
#m.drawmapboundary(fill_color='aqua')
#m.fillcontinents(color='#ddaa66',lake_color='aqua')
#m.drawcoastlines()
#m.drawrivers(linewidth=1.0,color='navy',zorder=8)
#m.drawcounties(linewidth=1.0, linestyle='solid', color='gray', antialiased=1, facecolor=None, ax=None, zorder=2, drawbounds=True)
#m.drawstates(linewidth=1.5, linestyle='solid', color='black', antialiased=1,zorder=2, )
plt.text(llcrnrlon,llcrnrlat, search, color='firebrick', fontsize=24.5, zorder=6,bbox=dict(facecolor='salmon'))

# Drawing ArcGIS Basemap (only works with cylc projections??)
# Examples of what each map looks like can be found here:
# http://kbkb-wx-python.blogspot.com/2016/04/python-basemap-background-image-from.html
maps = ['ESRI_Imagery_World_2D',    # 0
        'ESRI_StreetMap_World_2D',  # 1
        'NatGeo_World_Map',         # 2
        'NGS_Topo_US_2D',           # 3
        'Ocean_Basemap',            # 4
        'USA_Topo_Maps',            # 5
        'World_Imagery',            # 6
        'World_Physical_Map',       # 7
        'World_Shaded_Relief',      # 8
        'World_Street_Map',         # 9
        'World_Terrain_Base',       # 10
        'World_Topo_Map'            # 11
        ]
print ("drawing image from arcGIS server..."),
#m.arcgisimage(service=maps[9], xpixels=1000, verbose=False)
# Rank Styles: 0 Not good for plots
#              1 Nice Map
#              2 Nice Map 
MapStyle= 8
m.arcgisimage(service=maps[MapStyle], xpixels = 3500, dpi=500, verbose= True)
m.drawstates()
print ("...finished")

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.5)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

Sd=0
Sized=[]
for xd in deaths:
    Sd=0+(float(xd))
    Sized.append(int(Sd))
    #print(int(S))
sd = np.array(Sized)
#print(Sized)
plt.title("COVID-19:\n Cases: (black)\n Deaths(red) \n Location:\n "+search+"\n", fontsize=15, loc='right')
#plt.text(max(LG-1.2),max(LT), search, color='white', fontsize=24)
#x, y = m(lons, lats)  # transform coordinates
x, y = m(LGd, LTd)
xx,yy = m(LG, LT)
plt.xlabel('Longitude',color="white", fontsize=24)
plt.ylabel('Latitute',color="white", fontsize=24)

m.scatter(xx, yy, s=s, color='black', zorder=5, alpha=0.6)
m.scatter(x, y, s=sd, color='r', zorder=10,  alpha=0.6)

#plt.text(urcrnrlon,urcrnrlat, search, color='white', fontsize=24)
plt.savefig("BaseMap/"+search+"arcGIS__.png", dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)
#plt.show()
# Plot a scatter point at WBB on the map object
#lon = -111.85
#lat = 40.77
#m.scatter(lon,lat,c='r',s=150)

filename0 = "BaseMap/"+search+"arcGIS__.png"


def draw_blurred_back(img, position, text, font, col, halo_col):
    halo = Image.new('RGBA', img.size, (0, 0, 0, 0))
    ImageDraw.Draw(halo).text(position, text, font = font, fill = halo_col)
    blurred_halo = halo.filter(ImageFilter.BLUR)
    ImageDraw.Draw(blurred_halo).text(position, text, font = font, fill = col)
    return Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))

if __name__ == '__main__':
    
    basewidth = 720
    inp = Image.open(filename0)
    wpercent = (basewidth / float(inp.size[0]))
    hsize = int((float(inp.size[1]) * float(wpercent)))
    inp = inp.resize((basewidth, hsize), Image.ANTIALIAS)
    #img.save(resized_image.jpg')
    
    #inp = inp.resize((640,640), Image.ANTIALIAS)
    font = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 30)
    text_title = (255, 255,230) # bright green
    blur_title = (0, 0, 0)   # black

    i2 = draw_blurred_back(inp, (15, 35), "Plotting COVID-19 Data", font, text_title, blur_title)
    font0 = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 20)
    font1 = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 14)
    font2 = ImageFont.truetype("/home/jack/fonts/PatrickHand-Regular.ttf", 18)
    i2 = draw_blurred_back(i2, (15, 70), "Plot Using ArcGIS Basemap Style "+str(MapStyle)+" - "+search, font0, text_title, blur_title)
    TXT="https://github.com/JupyterJones/COVID-19-Jupyter-Notebooks"
    draw = ImageDraw.Draw(i2) 
    draw.text((15, 10), TXT, font = font2, align ="left",fill="black")
    #i2 = draw(i2, (15, 65),TXT, font1)    
    
    #txt = Image.new('RGBA', i.size, (255,255,255,0))

    # get a font
    fnt = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 20)
    # get a drawing context
    signature_ = "@jacklnorthrup" 
    #get length in pixel of signature_
    sizeS,ln = fnt.getsize(signature_)
    #add 15 pixels to right border
    pt = sizeS+25
    width, height = inp.size
    #marginx starting point of signature_
    marginx = pt
    #bottom margin
    marginy = 30
    x = width - marginx
    y = height - marginy
    

    text_sig = (255, 255,230) # bright green
    blur_sig = (0, 0, 0)   # black
    txt=draw_blurred_back(i2,(x,y), signature_, fnt, text_sig, blur_sig)
    out = Image.alpha_composite(i2, txt)
    out.save("images/TEMP_POST.png")
    out.save("images/"+str(MapStyle)+"_POST.png")

CONSUMER_KEY = Key.twiter()[0]
CONSUMER_SECRET = Key.twiter()[1]
ACCESS_KEY = Key.twiter()[2]
ACCESS_SECRET = Key.twiter()[3]
twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)

STR = "Plot data using MapStyle= "+str(MapStyle)+" "+TXT+" #JupyterJones #"+search+"  #arcGIS server #Basemap #COVID-19 - #Python" 

PATH = "images/TEMP_POST.png"
photo = open(PATH,'rb')
#response = twitter.upload_media(media=photo)
#twitter.update_status(status=STR, media_ids=[response['media_id']])

from PIL import Image
PATH = "images/TEMP_POST.png"
IM = Image.open(PATH)
print(IM.size)
IM

import matplotlib.pyplot as plt
import numpy as np
from mpl_toolkits.basemap import Basemap
from random import randint
from US_State_Bounding_Boxes import GetCOOR
def RndState():
    TX=["Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming"]
    x=randint(1,50)
    return TX[x]


search = RndState()
fig = plt.figure(num=None, figsize=(12,10), dpi=80, facecolor='salmon')
coor= GetCOOR(search)
urcrnrlat = coor[0]+.5
llcrnrlat = coor[1]-.5
urcrnrlon = coor[2]+.5
llcrnrlon = coor[3]-.5

lat_0 = (urcrnrlat+llcrnrlat)/2
lon_0 =(urcrnrlon+llcrnrlon)/2



## Map in cylindrical projection (data points may apear skewed)
m = Basemap(resolution='i',projection='cyl',\
            llcrnrlon=llcrnrlon,llcrnrlat=llcrnrlat,\
            urcrnrlon=urcrnrlon,urcrnrlat=urcrnrlat,)


map_list = [
'ESRI_Imagery_World_2D',    # 0
'ESRI_StreetMap_World_2D',  # 1
'NatGeo_World_Map',         # 2
'NGS_Topo_US_2D',           # 3
#'Ocean_Basemap',            # 4
'USA_Topo_Maps',            # 5
'World_Imagery',            # 6
'World_Physical_Map',       # 7     Still blurry
'World_Shaded_Relief',      # 8
'World_Street_Map',         # 9
'World_Terrain_Base',       # 10
'World_Topo_Map'            # 11
]

for maps in map_list: 
    plt.figure(figsize=[10,20])    
    ## Instead of using WRF terrain fields you can get a high resolution image from ESRI
    m.arcgisimage(service=maps, xpixels = 3500, dpi=500, verbose= True)
    m.drawstates()
    plt.title(maps)
    
    plt.savefig('00'+maps, dpi=120, bbox_inches="tight")

!pip install functions_domains_models

m.arcgisimage(service=maps, xpixels = 3500, dpi=500, verbose= True)

fig=plt.figure()

%matplotlib notebook
import mplcursors
from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
from mpld3 import plugins
from PIL import Image

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-14-2020.csv"


DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
STate = 'Florida'
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-3
B =(max(LG))+3
C =(min(LT))-3
D =(max(LT))+3
fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')



longLeft= (min(LG))-3
longRight = (max(LG))+3
lat1 = (min(LT))-3
lat2 = (max(LT))+3

ax = fig.gca()
T= 'Miami-Dade'
text(0.62, 0.29, T, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)

plt.axis([longLeft,longRight,lat1,lat2])

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")


plt.xlabel('First data sample was: 09/03/2020 04:30:00')
plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
plt.ylabel('Number of Cases')
mplcursors.cursor(hover=True)

plt.show()

%matplotlib notebook
import mplcursors
from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
from mpld3 import plugins
from PIL import Image

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-02-2020.csv"

DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
STate = 'Florida'
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-3
B =(max(LG))+3
C =(min(LT))-3
D =(max(LT))+3

longLeft= (min(LG))-3
longRight = (max(LG))+3
lat1 = (min(LT))-3
lat2 = (max(LT))+3

ax = fig.gca()
T= 'Miami-Dade'
text(0.62, 0.29, T, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)

plt.axis([longLeft,longRight,lat1,lat2])

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")

plt.xlabel('First data sample was: 09/03/2020 04:30:00')
plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
plt.ylabel('Number of Cases')
mplcursors.cursor(hover=True)

plt.show()

%matplotlib notebook
import matplotlib.pyplot as plt
import numpy as np
import mplcursors


#fig, ax = plt.subplots()
fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")



#ax.scatter(LG, LT)
#ax.set_title("Mouse over a point")

mplcursors.cursor(hover=True)

plt.show()


from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"

from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
%matplotlib inline  
from mpld3 import plugins
from PIL import Image
img=Image.open("mouse-sizing-n-cropping-files/soil600.jpg")

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-02-2020.csv"
#im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))

DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
STate = 'Florida'
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-3
B =(max(LG))+3
C =(min(LT))-3
D =(max(LT))+3
#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
#fig, ax = plt.subplots(figsize=(8,8), dpi=80, facecolor='salmon')
#im = ax.imshow(img, extent=(A, B, C, D),
#               origin='upper', zorder=0, interpolation='nearest')
#plugins.connect(fig, plugins.MousePosition(fontsize=14))
#mpld3.display()

ax = fig.gca()
T= 'Miami-Dade'
text(0.62, 0.29, T, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)

plt.axis([A, B, C, D])
#plugins.connect(ax, plugins.MousePosition(fontsize=14))

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")
fig, ax = plt.subplots(figsize=(8,8), dpi=80, facecolor='salmon')
plugins.connect(fig, plugins.MousePosition(fontsize=14))
im = ax.imshow(img, extent=(A, B, C, D),
               origin='upper', zorder=0, interpolation='nearest')

mpld3.display()

plt.show()
#from PIL import Image
#im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))
#plugins.connect(fig, plugins.MousePosition(fontsize=14))

mpld3.display()



from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
%matplotlib inline  
from mpld3 import plugins
from PIL import Image
img=Image.open("mouse-sizing-n-cropping-files/soil600.jpg")

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-02-2020.csv"
#im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))

DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
STate = 'Florida'
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-3
B =(max(LG))+3
C =(min(LT))-3
D =(max(LT))+3
#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
fig, ax = plt.subplots(figsize=(8,8), dpi=80, facecolor='salmon')
im = ax.imshow(img, extent=(A, B, C, D),
               origin='upper', zorder=0, interpolation='nearest')
plugins.connect(fig, plugins.MousePosition(fontsize=14))

longLeft= (min(LG))-3
longRight = (max(LG))+3
lat1 = (min(LT))-3
lat2 = (max(LT))+3

ax = fig.gca()
T= 'Miami-Dade'
text(0.62, 0.29, T, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)

plt.axis([longLeft,longRight,lat1,lat2])

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")

#im = ax.imshow(img, extent=(A, B, C, D),
#               origin='lower', zorder=1, interpolation='nearest')

plt.xlabel('First data sample was: 09/03/2020 04:30:00')
plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
plt.ylabel('Number of Cases')
plt.show()

plugins.connect(fig, plugins.MousePosition(fontsize=14))

mpld3.display()



from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
%matplotlib inline  
from mpld3 import plugins
from PIL import Image
img=Image.open("mouse-sizing-n-cropping-files/soil600.jpg")

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-02-2020.csv"
#im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))

DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
STate = 'Florida'
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-3
B =(max(LG))+3
C =(min(LT))-3
D =(max(LT))+3
#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
fig, ax = plt.subplots(figsize=(8,8), dpi=80, facecolor='salmon')
im = ax.imshow(img, extent=(A, B, C, D),
               origin='upper', zorder=0, interpolation='nearest')
plugins.connect(fig, plugins.MousePosition(fontsize=14))
mpld3.display()

ax = fig.gca()
T= 'Miami-Dade'
text(0.62, 0.29, T, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)

plt.axis([A, B, C, D])

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")

#im = ax.imshow(img, extent=(A, B, C, D),
#               origin='lower', zorder=1, interpolation='nearest')

#plt.xlabel('First data sample was: 09/03/2020 04:30:00')
#plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
#plt.ylabel('Number of Cases')
plt.show()
from PIL import Image
im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))
plugins.connect(fig, plugins.MousePosition(fontsize=14))

mpld3.display()



from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
%matplotlib inline  
from mpld3 import plugins
from PIL import Image
img=Image.open("mouse-sizing-n-cropping-files/soil600.jpg")
 

fig, ax = plt.subplots()
im = ax.imshow(img, extent=(10, 20, 10, 20),
               origin='upper', zorder=1, interpolation='nearest')

plugins.connect(fig, plugins.MousePosition(fontsize=14))
mpld3.display()
from PIL import Image
im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))
plt.show()
plugins.connect(fig, plugins.MousePosition(fontsize=14))

mpld3.display()


%matplotlib notebook
import matplotlib.pyplot as plt
import numpy as np
import mplcursors
np.random.seed(42)

fig, ax = plt.subplots()
ax.scatter(*np.random.random((2, 26)))
ax.set_title("Mouse over a point")

mplcursors.cursor(hover=True)

plt.show()


%matplotlib notebook
import numpy as np
import matplotlib.pyplot as plt

company=['google','amazon','msft','fb']
revenue=[80,68,54,27]

fig=plt.figure()
ax=plt.subplot()

xpos=np.arange(len(company))

bars = plt.bar(xpos,revenue)


annot = ax.annotate("", xy=(0,0), xytext=(-20,20),textcoords="offset points",
                    bbox=dict(boxstyle="round", fc="black", ec="b", lw=2),
                    arrowprops=dict(arrowstyle="->"))
annot.set_visible(False)

def update_annot(bar):
    x = bar.get_x()+bar.get_width()/2.
    y = bar.get_y()+bar.get_height()
    annot.xy = (x,y)
    text = "({:.2g},{:.2g})".format( x,y )
    annot.set_text(text)
    annot.get_bbox_patch().set_alpha(0.4)


def hover(event):
    vis = annot.get_visible()
    if event.inaxes == ax:
        for bar in bars:
            cont, ind = bar.contains(event)
            if cont:
                update_annot(bar)
                annot.set_visible(True)
                fig.canvas.draw_idle()
                return
    if vis:
        annot.set_visible(False)
        fig.canvas.draw_idle()

fig.canvas.mpl_connect("motion_notify_event", hover)

plt.show()

import mplcursors
help(mplcursors)

%matplotlib notebook
import matplotlib.pyplot as plt
import numpy as np


def plot_unit_circle():
    angs = np.linspace(0, 2 * np.pi, 10**6)
    rs = np.zeros_like(angs) + 1
    xs = rs * np.cos(angs)
    ys = rs * np.sin(angs)
    plt.plot(xs, ys)


def mouse_move(event):
    x, y = event.xdata, event.ydata
    print(x, y)


plt.connect('motion_notify_event', mouse_move)
plot_unit_circle()
plt.axis('equal')
plt.show()

%matplotlib notebook
import matplotlib.pyplot as plt
import numpy as np
import ipywidgets as wdg  # Using the ipython notebook widgets

# Create a random image
a = np.random.poisson(size=(12,15))
fig = plt.figure()
plt.imshow(a)

# Create and display textarea widget
txt = wdg.Textarea(
    value='',
    placeholder='',
    description='event:',
    disabled=False
)
display(txt)

# Define a callback function that will update the textarea
def onclick(event):
    txt.value = str(event)  # Dynamically update the text box above

# Create an hard reference to the callback not to be cleared by the garbage collector
ka = fig.canvas.mpl_connect('button_press_event', onclick)



%matplotlib notebook
import mplcursors
from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
from mpld3 import plugins
from PIL import Image
import ipywidgets as wdg 
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/05-08-2020.csv"

DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
COORD=[]
STate = input("Which State? ")
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON
X = np.array(LAT,dtype=np.float)
Y = np.array(LON,dtype=np.float)
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

fig = plt.figure(num=None, figsize=(12,12), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-1
B =(max(LG))+1
C =(min(LT))-1
D =(max(LT))+1


longLeft= (min(LG))-3
longRight = (max(LG))+3
lat1 = (min(LT))-3
lat2 = (max(LT))+3

ax = fig.gca()
T= STate
text(0.62, 0.29, T, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes, fontsize=20)

# Create and display textarea widget
txt = wdg.Textarea(
    value='',
    placeholder='',
    description='event:',
    disabled=False
)
display(txt)

#COORD.append(txt)
# Define a callback function that will update the textarea
def onclick(event):
    # Uncomment for only one one click at a time
    #COORD=[]

    txt.value = str(event)  # Dynamically update the text box above
    COORD.append(txt.value)

# Create an hard reference to the callback not to be cleared by the garbage collector
ka = fig.canvas.mpl_connect('button_press_event', onclick)

plt.axis([longLeft,longRight,lat1,lat2])
ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(Y, X, s=s, color="black")


plt.xlabel('First data sample was taken: 01/20/2020', fontsize=24)
plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
plt.ylabel('Number of Cases')
mplcursors.cursor(hover=True)

plt.show()

import reverse_geocoder as rg 
import pprint 
def Reverse(tuples): 
    new_tup = tuples[::-1] 
    return new_tup   
def reverseGeocode(coordinates): 
    result = rg.search(coordinates) 
      
    # result is a list containing ordered dictionary. 
    pprint.pprint(result)  

for line in COORD:
    coordinates = ((str(line).split('xydata=('))[1].split(') button=1')[0])
    res = tuple(map(float, coordinates.split(', ')))
    dat = Reverse(res)
    reverseGeocode(dat)

%%writefile test.csv
City,Longitude,Latitude
Newburgh Heights,-81.66346,41.45005
Marion,-83.12852,40.58867
Mount Healthy,-84.54578,39.23367

Newburgh Heights,-81.66346,41.45005
Marion,-83.12852,40.58867
Mount Healthy,-84.54578,39.23367

[OrderedDict([('lat', '41.45005'),
              ('lon', '-81.66346'),
              ('name', 'Newburgh Heights'),
              ('admin1', 'Ohio'),
              ('admin2', 'Cuyahoga County'),
              ('cc', 'US')])]
[OrderedDict([('lat', '41.45005'),
              ('lon', '-81.66346'),
              ('name', 'Newburgh Heights'),
              ('admin1', 'Ohio'),
              ('admin2', 'Cuyahoga County'),
              ('cc', 'US')])]
[OrderedDict([('lat', '40.58867'),
              ('lon', '-83.12852'),
              ('name', 'Marion'),
              ('admin1', 'Ohio'),
              ('admin2', 'Marion County'),
              ('cc', 'US')])]
[OrderedDict([('lat', '40.58867'),
              ('lon', '-83.12852'),
              ('name', 'Marion'),
              ('admin1', 'Ohio'),
              ('admin2', 'Marion County'),
              ('cc', 'US')])]
[OrderedDict([('lat', '39.23367'),
              ('lon', '-84.54578'),
              ('name', 'Mount Healthy'),
              ('admin1', 'Ohio'),
              ('admin2', 'Hamilton County'),
              ('cc', 'US')])]
[OrderedDict([('lat', '39.23367'),
              ('lon', '-84.54578'),
              ('name', 'Mount Healthy'),
              ('admin1', 'Ohio'),
              ('admin2', 'Hamilton County'),
              ('cc', 'US')])]

%matplotlib notebook
from matplotlib.pyplot import text
from matplotlib import pyplot as plt
import numpy as np
import mpld3
from mpld3 import plugins
import time
import mplcursors
import ipywidgets as wdg 
#%matplotlib inline
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv"
DataIn = open(LASTFILE).readlines()
cases=[]
for line in DataIn:
    if len(line)>10 and 'US' in line and "Recovered" not in line and "Unassigned" not in line:
        line=line.replace("\n","")
        line = line.lstrip(",")
        line = line.split(",")
        End=len(line)-1
        if len(line)>5 and "Florida" in line[6] and "Out of FL" not in line:
            cases.append(line[End])        

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
CITY=[]
deaths=[]
TEXT=[]
COORD=[]
cnt = -1
Total=0
SEARCH = "Colorado"
for line in DataIn:
    if len(line)>10 and 'US' in line and "Recovered" not in line and "Unassigned" not in line:
        cnt=cnt+1
        line=line.replace("\n","")
        line = line.lstrip(",")
        line = line.split(",")
        End=len(line)-1
        if len(line)>5 and SEARCH in line[6] and "0.0" not in line:
            if cnt>=1 and cnt<=5:print(line[5],line[6],line[8],line[9], line[End] )
            Total=Total+int(line[End])
            CITY.append(line[5])
            LAT.append(line[8])
            LONG.append(line[9])
            deaths.append(line[End])        
            text = str(line[2]+' '+line[1]+' '+line[3]+' '+line[4]+' '+line[5]+' '+line[6]+' '+line[7]+' '+line[8]+' '+line[9]+' '+line[10])
            TEXT.append(text)
            
print("Number of Cities: ",len(CITY)) 
print("Total Deaths: ",Total)

LA = LAT
LO = LONG

print(len(LA))
print(len(LO))

DA = np.array(deaths,dtype=np.int)
LT = np.array(LAT,dtype=np.float)
LG = np.array(LONG,dtype=np.float)
X = np.array(LAT,dtype=np.float)
Y = np.array(LONG,dtype=np.float)
print (max(LG))
print (min(LG))
print (min(LT))
print (max(LT))

A = (min(LG))-1
B = (max(LG))+1
C = (min(LT))-1
D = (max(LT))+1

fig = plt.figure(num=None, figsize=(12,12), dpi=80, facecolor='salmon')
#fig = plt.figure()
ax = fig.gca()

#ax.set_facecolor('xkcd:green')
ax.set_facecolor(('#8eda8b'))

Sd=1
Sized=[]
for xd in deaths:
    Sd=2+(float(xd)*3)
    Sized.append(int(Sd))
    #print(int(S))
sd = np.array(Sized)

S=1
Size=[]
for x in cases:
    S=2+(float(x)*1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)


plt.text(-119, 41, SEARCH, fontsize=26)
#plt.axis([-130,-65,20,55])
ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.scatter(Y, X, s=s, color="black")
plt.axis([A,B,C,D])
# Create and display textarea widget
txt = wdg.Textarea(
    value='',
    placeholder='',
    description='event:',
    disabled=False
)
display(txt)

COORD.append(txt)
# Define a callback function that will update the textarea
def onclick(event):
    txt.value = str(event)  # Dynamically update the text box above
    #COORD=[]
# Create an hard reference to the callback not to be cleared by the garbage collector
ka = fig.canvas.mpl_connect('button_press_event', onclick)

plt.scatter(Y, X, s=sd, color="red")
plt.grid(True)

plt.xlabel('- Longitude -\nFirst Data Record : January 21, 2020', fontsize=18)
plt.title('Using Latitude and Longitude from:\n https://github.com/CSSEGISandData/COVID-19\n Black is Confirmed Cases and the Red are Deaths', fontsize=18)
plt.ylabel('- Latitude -', fontsize=18, color="white")
filename = "images/"+SEARCH+"_"+(time.strftime('%a_%d_%b_%Y_%I_%M_%S_%p_%Z', time.gmtime())+".png")
fig.savefig(filename, facecolor=fig.get_facecolor(), edgecolor='black')
print(filename)

mplcursors.cursor(hover=True)
plt.show()

import reverse_geocoder as rg 
import pprint 
def Reverse(tuples): 
    new_tup = tuples[::-1] 
    return new_tup   
def reverseGeocode(coordinates): 
    result = rg.search(coordinates) 
      
    # result is a list containing ordered dictionary. 
    pprint.pprint(result)  

for line in COORD:
    coordinates = ((str(line).split('xydata=('))[1].split(') button=1')[0])
    res = tuple(map(float, coordinates.split(', ')))
    dat = Reverse(res)
    reverseGeocode(dat)

reset -f

%%writefile DIST.py
#!/usr/bin/env python

# figure distance between two locations given in Lat and long

import math

def distance(Start, End):
    lat0, lon0 = Start
    lat1, lon1 = End
    radius = 6371 # km
    #radius = 3958.756 # miles
    lat = math.radians(lat1-lat0)
    lon = math.radians(lon1-lon0)
    a = math.sin(lat/2) * math.sin(lat/2) + math.cos(math.radians(lat1)) \
        * math.cos(math.radians(lat1)) * math.sin(lon/2) * math.sin(lon/2)
    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))
    d = radius * c
    return d

from DIST import distance

Start = 40.5,-90
End =  42,-93
print(distance(Start, End))

# Taking kilometers input from the user
kilometers = float(input("Enter value in kilometers: "))

# conversion factor
conv_fac = 0.621371

# calculate miles
miles = kilometers * conv_fac
print('%0.2f kilometers is equal to %0.2f miles' %(kilometers,miles))

from math import sin, cos, sqrt, atan2, radians

# approximate radius of earth in miles: 7917
def distance_cal(Lat0,Long0,Lat1,Long1):
    R = 7917 #mi

    lat1 = radians(Lat0)
    lon1 = radians(Long0)
    lat2 = radians(Lat1)
    lon2 = radians(Long1)

    dlon = lon2 - lon1
    dlat = lat2 - lat1
    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2
    c = 2 * atan2(sqrt(a), sqrt(1 - a))
    distance = round(R * c, 2)#*1000
    # print("Result:", distance)
    return distance
Start = 40.5,-90
End =  42,-93

Lat0=40.5
Long0=-90

Lat1=42
Long1=-93

distance_cal(Lat0,Long0,Lat1,Long1)

from math import sin, cos, sqrt, atan2, radians
import pandas as pd

# approximate radius of earth in meters
def distance_cal(LatC,LongC,LatT,LongT):
    R = 6373.0

    lat1 = radians(LatC)
    lon1 = radians(LongC)
    lat2 = radians(LatT)
    lon2 = radians(LongT)

    dlon = lon2 - lon1
    dlat = lat2 - lat1

    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2
    c = 2 * atan2(sqrt(a), sqrt(1 - a))

    distance = R * c*1000

#    print("Result:", distance)
return distance

#COORD=[]
#COORD.append(txt)

print(COORD)
#xydata=(  ) button=1

for line in COORD:
    coordinates = ((line.split('xydata=('))[1].split(') button=1')[0])


TXT="""Textarea(value='button_press_event: xy=(258, 336) xydata=(-84.54645894452702, 39.19144800795269) button=1 dblclick=False inaxes=AxesSubplot(0.125,0.11;0.775x0.77)', description='event:', placeholder='')"""
#OUTPUT = str(TXT).split("#xydata=(",0).split(") button=1",0)
#print(OUTPUT)

#start = 'xydata=('
#end = ') button=1'
coordinates = ((TXT.split('xydata=('))[1].split(') button=1')[0])
print(stats)

start = 'xydata=('
end = ') button=1'
stats = ((TXT.split(start))[1].split(end)[0])
print(stats)

import reverse_geocoder as rg 
import pprint 
  
def reverseGeocode(coordinates): 
    result = rg.search(coordinates) 
      
    # result is a list containing ordered dictionary. 
    pprint.pprint(result)  

for line in COORD:
    coordinates = ((str(line).split('xydata=('))[1].split(') button=1')[0])
    deg=coordinates.split(", ")
    print(deg[0]+","+deg[1])
    reverseGeocode(deg[0]+", "+deg[1])  

import reverse_geocoder as rg 
import pprint 
  
def reverseGeocode(coordinates): 
    result = rg.search(coordinates) 
      
    # result is a list containing ordered dictionary. 
    pprint.pprint(result)  

LatLong =input("LatLong: ")
LatLong=LatLong.split(",")
print(LatLong[0],LatLong[1])
lat=LatLong[1]
lng=LatLong[0]

coordinates =(lat,lng) 
     
reverseGeocode(coordinates)  

https://simplemaps.com/data/us-cities

-80.4875 26.1815

%matplotlib notebook
import mplcursors
from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
from mpld3 import plugins
from PIL import Image

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-14-2020.csv"

DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []

STate = input("Which State? ")
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

fig = plt.figure(num=None, figsize=(12,12), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-1
B =(max(LG))+1
C =(min(LT))-1
D =(max(LT))+1


longLeft= (min(LG))-3
longRight = (max(LG))+3
lat1 = (min(LT))-3
lat2 = (max(LT))+3

ax = fig.gca()
T= STate
text(0.62, 0.29, T, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes, fontsize=20)

plt.axis([longLeft,longRight,lat1,lat2])

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")


plt.xlabel('First data sample was taken: 01/20/2020', fontsize=24)
plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
plt.ylabel('Number of Cases')
mplcursors.cursor(hover=True)

plt.show()

import reverse_geocoder as rg 
import pprint 
def Reverse(tuples): 
    new_tup = tuples[::-1] 
    return new_tup   
def reverseGeocode(coordinates): 
    result = rg.search(coordinates) 
      
    # result is a list containing ordered dictionary. 
    pprint.pprint(result)  

for line in COORD:
    coordinates = ((str(line).split('xydata=('))[1].split(') button=1')[0])
    res = tuple(map(float, coordinates.split(', ')))
    dat = Reverse(res)
    reverseGeocode(dat)

%matplotlib notebook
import mplcursors
from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
from mpld3 import plugins
from PIL import Image

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-02-2020.csv"

DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
STate = input("Which State? ")
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-1
B =(max(LG))+1
C =(min(LT))-1
D =(max(LT))+1

ax = fig.gca()
tx = max(LG)-.5
ty = max(LT)+.5

print(tx,ty)
text(tx, ty, STate, bbox=dict(facecolor='white', alpha=0.5))


plt.axis([A,B,C,D])

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")

plt.xlabel('First data sample was: 09/03/2020 04:30:00')
plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
plt.ylabel('Number of Cases')
mplcursors.cursor(hover=True)

plt.show()

%matplotlib notebook
import matplotlib.pyplot as plt
import numpy as np
import mplcursors


#fig, ax = plt.subplots()
fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")



#ax.scatter(LG, LT)
#ax.set_title("Mouse over a point")

mplcursors.cursor(hover=True)

plt.show()


from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"

from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
%matplotlib inline  
from mpld3 import plugins
from PIL import Image
img=Image.open("mouse-sizing-n-cropping-files/soil600.jpg")

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-02-2020.csv"
#im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))

DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
STate = 'Florida'
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-3
B =(max(LG))+3
C =(min(LT))-3
D =(max(LT))+3
#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
#fig, ax = plt.subplots(figsize=(8,8), dpi=80, facecolor='salmon')
#im = ax.imshow(img, extent=(A, B, C, D),
#               origin='upper', zorder=0, interpolation='nearest')
#plugins.connect(fig, plugins.MousePosition(fontsize=14))
#mpld3.display()

ax = fig.gca()
T= 'Miami-Dade'
text(0.62, 0.29, T, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)

plt.axis([A, B, C, D])
#plugins.connect(ax, plugins.MousePosition(fontsize=14))

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")
fig, ax = plt.subplots(figsize=(8,8), dpi=80, facecolor='salmon')
plugins.connect(fig, plugins.MousePosition(fontsize=14))
im = ax.imshow(img, extent=(A, B, C, D),
               origin='upper', zorder=0, interpolation='nearest')

mpld3.display()
plt.show()
#from PIL import Image
#im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))
#plugins.connect(fig, plugins.MousePosition(fontsize=14))
mpld3.display()




from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
%matplotlib inline  
from mpld3 import plugins
from PIL import Image
img=Image.open("mouse-sizing-n-cropping-files/soil600.jpg")

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-02-2020.csv"
#im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))

DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
STate = 'Florida'
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-3
B =(max(LG))+3
C =(min(LT))-3
D =(max(LT))+3
#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
fig, ax = plt.subplots(figsize=(8,8), dpi=80, facecolor='salmon')
im = ax.imshow(img, extent=(A, B, C, D),
               origin='upper', zorder=0, interpolation='nearest')
plugins.connect(fig, plugins.MousePosition(fontsize=14))

longLeft= (min(LG))-3
longRight = (max(LG))+3
lat1 = (min(LT))-3
lat2 = (max(LT))+3

ax = fig.gca()
T= 'Miami-Dade'
text(0.62, 0.29, T, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)

plt.axis([longLeft,longRight,lat1,lat2])

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")

#im = ax.imshow(img, extent=(A, B, C, D),
#               origin='lower', zorder=1, interpolation='nearest')

plt.xlabel('First data sample was: 09/03/2020 04:30:00')
plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
plt.ylabel('Number of Cases')
plt.show()

plugins.connect(fig, plugins.MousePosition(fontsize=14))

mpld3.display()



from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
%matplotlib inline  
from mpld3 import plugins
from PIL import Image
img=Image.open("mouse-sizing-n-cropping-files/soil600.jpg")

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-02-2020.csv"
#im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))

DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
STate = 'Florida'
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-3
B =(max(LG))+3
C =(min(LT))-3
D =(max(LT))+3
#fig = plt.figure(num=None, figsize=(8,8), dpi=80, facecolor='salmon')
fig, ax = plt.subplots(figsize=(8,8), dpi=80, facecolor='salmon')
im = ax.imshow(img, extent=(A, B, C, D),
               origin='upper', zorder=0, interpolation='nearest')
plugins.connect(fig, plugins.MousePosition(fontsize=14))
mpld3.display()

ax = fig.gca()
T= 'Miami-Dade'
text(0.62, 0.29, T, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)

plt.axis([A, B, C, D])

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")

#im = ax.imshow(img, extent=(A, B, C, D),
#               origin='lower', zorder=1, interpolation='nearest')

#plt.xlabel('First data sample was: 09/03/2020 04:30:00')
#plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
#plt.ylabel('Number of Cases')
plt.show()
from PIL import Image
im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))
plugins.connect(fig, plugins.MousePosition(fontsize=14))

mpld3.display()



from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
%matplotlib inline  
from mpld3 import plugins
from PIL import Image
img=Image.open("mouse-sizing-n-cropping-files/soil600.jpg")
 

fig, ax = plt.subplots()
im = ax.imshow(img, extent=(10, 20, 10, 20),
               origin='upper', zorder=1, interpolation='nearest')

plugins.connect(fig, plugins.MousePosition(fontsize=14))
mpld3.display()
from PIL import Image
im = np.array(Image.open('mouse-sizing-n-cropping-files/soil600.jpg'))
plt.show()
plugins.connect(fig, plugins.MousePosition(fontsize=14))

mpld3.display()


%matplotlib notebook
import matplotlib.pyplot as plt
import numpy as np
import mplcursors
np.random.seed(42)

fig, ax = plt.subplots()
ax.scatter(*np.random.random((2, 26)))
ax.set_title("Mouse over a point")

mplcursors.cursor(hover=True)

plt.show()


%matplotlib notebook
import numpy as np
import matplotlib.pyplot as plt

company=['google','amazon','msft','fb']
revenue=[80,68,54,27]

fig=plt.figure()
ax=plt.subplot()

xpos=np.arange(len(company))

bars = plt.bar(xpos,revenue)


annot = ax.annotate("", xy=(0,0), xytext=(-20,20),textcoords="offset points",
                    bbox=dict(boxstyle="round", fc="black", ec="b", lw=2),
                    arrowprops=dict(arrowstyle="->"))
annot.set_visible(False)

def update_annot(bar):
    x = bar.get_x()+bar.get_width()/2.
    y = bar.get_y()+bar.get_height()
    annot.xy = (x,y)
    text = "({:.2g},{:.2g})".format( x,y )
    annot.set_text(text)
    annot.get_bbox_patch().set_alpha(0.4)


def hover(event):
    vis = annot.get_visible()
    if event.inaxes == ax:
        for bar in bars:
            cont, ind = bar.contains(event)
            if cont:
                update_annot(bar)
                annot.set_visible(True)
                fig.canvas.draw_idle()
                return
    if vis:
        annot.set_visible(False)
        fig.canvas.draw_idle()

fig.canvas.mpl_connect("motion_notify_event", hover)

plt.show()

import mplcursors
help(mplcursors)

%matplotlib notebook
import matplotlib.pyplot as plt
import numpy as np


def plot_unit_circle():
    angs = np.linspace(0, 2 * np.pi, 10**6)
    rs = np.zeros_like(angs) + 1
    xs = rs * np.cos(angs)
    ys = rs * np.sin(angs)
    plt.plot(xs, ys)


def mouse_move(event):
    x, y = event.xdata, event.ydata
    print(x, y)


plt.connect('motion_notify_event', mouse_move)
plot_unit_circle()
plt.axis('equal')
plt.show()

%matplotlib notebook
import matplotlib.pyplot as plt
import numpy as np
import ipywidgets as wdg  # Using the ipython notebook widgets

# Create a random image
a = np.random.poisson(size=(12,15))
fig = plt.figure()
plt.imshow(a)

# Create and display textarea widget
txt = wdg.Textarea(
    value='',
    placeholder='',
    description='event:',
    disabled=False
)
display(txt)

# Define a callback function that will update the textarea
def onclick(event):
    txt.value = str(event)  # Dynamically update the text box above

# Create an hard reference to the callback not to be cleared by the garbage collector
ka = fig.canvas.mpl_connect('button_press_event', onclick)

data = open("/home/jack/Desktop/COVID-19-Jupyter-Notebooks/uscities.csv").readlines()
cnt=0
for line in data:
    line=line.replace("\"","")
    line = line.split(",")
    cnt=cnt+1
    
    if cnt==1:print(line)
    if cnt==1:print(" ")    
    if cnt>1 and cnt<10:print(line[0],line[3],line[5],float(line[8]),float(line[9]))   

from matplotlib.pyplot import text
from matplotlib import pyplot as plt
import numpy as np
import mpld3
from mpld3 import plugins
import time
%matplotlib inline
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv"
DataIn = open(LASTFILE).readlines()
cases=[]
for line in DataIn:
    if len(line)>10 and 'US' in line and "Recovered" not in line and "Unassigned" not in line:
        line=line.replace("\n","")
        line = line.lstrip(",")
        line = line.split(",")
        End=len(line)-1
        if len(line)>5 and "Florida" in line[6] and "Out of FL" not in line:
            cases.append(line[End])        

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
CITY=[]
deaths=[]
TEXT=[]
cnt = -1
Total=0
SEARCH = "California"
for line in DataIn:
    if len(line)>10 and 'US' in line and "Recovered" not in line and "Unassigned" not in line:
        cnt=cnt+1
        line=line.replace("\n","")
        line = line.lstrip(",")
        line = line.split(",")
        End=len(line)-1
        if len(line)>5 and SEARCH in line[6] and "0.0" not in line:
            if cnt>=1 and cnt<=5:print(line[5],line[6],line[8],line[9], line[End] )
            Total=Total+int(line[End])
            CITY.append(line[5])
            LAT.append(line[8])
            LONG.append(line[9])
            deaths.append(line[End])        
            text = str(line[2]+' '+line[1]+' '+line[3]+' '+line[4]+' '+line[5]+' '+line[6]+' '+line[7]+' '+line[8]+' '+line[9]+' '+line[10])
            TEXT.append(text)
            
print("Number of Cities: ",len(CITY)) 
print("Total Deaths: ",Total)

LA = LAT
LO = LONG

print(len(LA))
print(len(LO))

DA = np.array(deaths,dtype=np.int)
LT = np.array(LAT,dtype=np.float)
LG = np.array(LONG,dtype=np.float)
print (max(LG))
print (min(LG))
print (min(LT))
print (max(LT))

A = (min(LG))-1
B = (max(LG))+1
C = (min(LT))-1
D = (max(LT))+1

fig = plt.figure(num=None, figsize=(12,12), dpi=80, facecolor='salmon')
#fig = plt.figure()
ax = fig.gca()

#ax.set_facecolor('xkcd:green')
ax.set_facecolor(('#8eda8b'))

Sd=1
Sized=[]
for xd in deaths:
    Sd=2+(float(xd)*1)
    Sized.append(int(Sd))
    #print(int(S))
sd = np.array(Sized)

S=1
Size=[]
for x in cases:
    S=2+(float(x)*1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)


plt.text(-119, 41, SEARCH, fontsize=26)
#plt.axis([-130,-65,20,55])
plt.axis([A,B,C,D])

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.scatter(LG, LT, s=s, color="black")
plt.scatter(LG, LT, s=sd, color="red")
plt.grid(True)

plt.xlabel('- Longitude -\nFirst Data Record : January 21, 2020', fontsize=18)
plt.title('Using Latitude and Longitude from:\n https://github.com/CSSEGISandData/COVID-19\n Black is Confirmed Cases and the Red are Deaths', fontsize=18)
plt.ylabel('- Latitude -', fontsize=18, color="white")
filename = "images/"+SEARCH+"_"+(time.strftime('%a_%d_%b_%Y_%I_%M_%S_%p_%Z', time.gmtime())+".png")
fig.savefig(filename, facecolor=fig.get_facecolor(), edgecolor='black')
print(filename)
plt.show()

from matplotlib.pyplot import text
from matplotlib import pyplot as plt
import numpy as np
import mpld3
from mpld3 import plugins
import time
%matplotlib inline
#LASTFILE="DATA/Download.csv"
#DataIn = open(LASTFILE).readlines()
cases=[]
#cnt=cnt+1
#for line in DataIn:
#    line = line.split(",")
#    if cnt==0:print(line)

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
CITY=[]
deaths=[]
TEXT=[]
cnt = -1
Total=0
SEARCH = "Florida"
for line in DataIn:
    if len(line)>10 and 'US' in line and "Recovered" not in line and "Unassigned" not in line:
        cnt=cnt+1
        line=line.replace("\n","")
        line = line.lstrip(",")
        line = line.split(",")
        End=len(line)-1
        if len(line)>5 and SEARCH in line[6] and "0.0" not in line:
            
            if cnt>=1 and cnt<=5:print(line[5],line[6],line[8],line[9], line[End] )
            Total=Total+int(line[End])
            CITY.append(line[5])
            LAT.append(line[8])
            LONG.append(line[9])
            cases.append(line[9])
            deaths.append(line[End])        
            TText = str(line[2]+' '+line[1]+' '+line[3]+' '+line[4]+' '+line[5]+' '+line[6]+' '+line[7]+' '+line[8]+' '+line[9]+' '+line[10])
            if cnt==10:print("TTEXT: ",TText)
            TEXT.append(TText)
            
print("Number of Cities: ",len(CITY)) 
print("Total Deaths: ",Total)

LA = LAT
LO = LONG

print(len(LA))
print(len(LO))

DA = np.array(deaths,dtype=np.int)
LT = np.array(LAT,dtype=np.float)
LG = np.array(LONG,dtype=np.float)
print (max(LG))
print (min(LG))
print (min(LT))
print (max(LT))

print(deaths[-1])


A = (min(LG))-1
B = (max(LG))+1
C = (min(LT))-1
D = (max(LT))+1

fig = plt.figure(num=None, figsize=(12,12), dpi=80, facecolor='salmon')
#fig = plt.figure()
ax = fig.gca()

#ax.set_facecolor('xkcd:green')
ax.set_facecolor(('#8eda8b'))

Sd=5
Sized=[]
for xd in deaths:
    Sd=2+(float(xd)*1)
    Sized.append(int(Sd))
    #print(int(S))
sd = np.array(Sized)

S=5
Size=[]
for x in cases:
    S=2+(float(x)*1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)


#plt.text(-119, 41, SEARCH, fontsize=26)
#plt.axis([-130,-65,20,55])
plt.axis([A,B,C,D])

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.scatter(LG, LT, s=sd, color="red")
plt.scatter(LG, LT, s=s, color="black")

plt.grid(True)

plt.xlabel('- Longitude -\nFirst Data Record : January 21, 2020', fontsize=18)
plt.title('Using Latitude and Longitude from:\n https://github.com/CSSEGISandData/COVID-19\n Black is Confirmed Cases and the Red are Deaths', fontsize=18)
plt.ylabel('- Latitude -', fontsize=18, color="white")
filename = "images/"+SEARCH+"_"+(time.strftime('%a_%d_%b_%Y_%I_%M_%S_%p_%Z', time.gmtime())+".png")
fig.savefig(filename, facecolor=fig.get_facecolor(), edgecolor='black')
print(filename)
plt.show()

filename = "images/"+SEARCH+"_"+(time.strftime('%a_%d_%b_%Y_%I_%M_%S_%p_%Z', time.gmtime())+".png")
fig.savefig(filename, facecolor=fig.get_facecolor(), edgecolor='black')
print(filename)
plt.show()

filename = "images/"+SEARCH+"_"+(time.strftime('%a_%d_%b_%Y_%I_%M_%S_%p_%Z', time.gmtime())+".png")
fig.savefig(filename, facecolor=fig.get_facecolor(), edgecolor='black')
print(filename)
plt.show()

data = open("/home/jack/Desktop/COVID-19-Jupyter-Notebooks/uscities.csv").readlines()
cnt=0
LatLong =input("LatLong: ")
LatLong=LatLong.split(" ")
print(LatLong[1],LatLong[0])
lat=LatLong[1]
lng=LatLong[0]
for line in data:
    line=line.replace("\"","")
    line = line.split(",")
    cnt=cnt+1
    if LatLong[1] == line:print(line)
    if LatLong[0] == line:print(line)
        

data = open("/home/jack/Desktop/COVID-19-Jupyter-Notebooks/uscities.csv").readlines()
cnt=0
LatLong =input("LatLong: ")
LatLong=LatLong.split(" ")
print(LatLong[1],LatLong[0])
for line in data:
    line=line.replace("\"","")
    line = line.split(",")
    cnt=cnt+1
    if cnt==2:print(round(float(LatLong[1]),3),round(float(LatLong[0]),3)),round(float(line[8]),3),round(float(line[9]),3)
    if cnt>2 and round(float(LatLong[1]),3)==round(float(line[8]),3):
        print("line",line[0],line[3])
    if cnt>2 and round(float(LatLong[0]),3)==round(float(line[9]),3):
            print("XXX",line[0],line[3])    

LatLong =input("LatLong: ")
LatLong=LatLong.split(",")
print(LatLong[0],LatLong[1])
lat=LatLong[0]
lng=LatLong[1]

import reverse_geocoder as rg 
import pprint 
  
def reverseGeocode(coordinates): 
    result = rg.search(coordinates) 
      
    # result is a list containing ordered dictionary. 
    pprint.pprint(result)  

LatLong =input("LatLong: ")
LatLong=LatLong.split(",")
print(LatLong[0],LatLong[1])
lat=LatLong[0]
lng=LatLong[1]

coordinates =(lat,lng) 
     
reverseGeocode(coordinates)  

%matplotlib notebook
import mplcursors
from matplotlib.pyplot import text
import numpy as np
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import matplotlib.pyplot as plt
import numpy as np
import mpld3
from mpld3 import plugins
from PIL import Image
import ipywidgets as wdg 
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-14-2020.csv"

DataIn = open(LASTFILE).readlines()
cnt=-1
LAT =[]
LON =[]
cases = []
COORD=[]
STate = input("Which State? ")
for lines in DataIn:
    lines = lines.replace("\n","")
    line = lines.split(",")
    if STate in line[2] and len(line[5])>8 and len(line[6])>4:
        cnt=cnt+1
        if cnt<5:
            print(" ")
            #print(line[1],line[2],line[3],line[4],line[5],line[6],line[7],line[8])
        LAT.append(line[5]) 
        LON.append(line[6])
        cases.append(int(line[7]))
LA = LAT
LO = LON
LT = np.array(LAT,dtype=np.float)
LG = np.array(LON,dtype=np.float)

fig = plt.figure(num=None, figsize=(12,12), dpi=80, facecolor='salmon')
ax = fig.gca()
ax.set_facecolor(('#c2efc1'))

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

A =(min(LG))-1
B =(max(LG))+1
C =(min(LT))-1
D =(max(LT))+1


longLeft= (min(LG))-3
longRight = (max(LG))+3
lat1 = (min(LT))-3
lat2 = (max(LT))+3

ax = fig.gca()
T= STate
text(0.62, 0.29, T, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes, fontsize=20)

# Create and display textarea widget
txt = wdg.Textarea(
    value='',
    placeholder='',
    description='event:',
    disabled=False
)
display(txt)

COORD.append(txt)
# Define a callback function that will update the textarea
def onclick(event):
    COORD=[]
    txt.value = str(event)  # Dynamically update the text box above

# Create an hard reference to the callback not to be cleared by the garbage collector
ka = fig.canvas.mpl_connect('button_press_event', onclick)

plt.axis([longLeft,longRight,lat1,lat2])
plt.axis([A,B,C,D])

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
plt.scatter(LG, LT, s=s, color="black")


plt.xlabel('First data sample was taken: 01/20/2020', fontsize=24)
plt.title('Using Latitude and Longitude from https://github.com/CSSEGISandData/COVID-19')
plt.ylabel('Number of Cases')
mplcursors.cursor(hover=True)

plt.show()

import reverse_geocoder as rg 
import pprint 
def Reverse(tuples): 
    new_tup = tuples[::-1] 
    return new_tup   
def reverseGeocode(coordinates): 
    result = rg.search(coordinates) 
      
    # result is a list containing ordered dictionary. 
    pprint.pprint(result)  

for line in COORD:
    coordinates = ((str(line).split('xydata=('))[1].split(') button=1')[0])
    res = tuple(map(float, coordinates.split(', ')))
    dat = Reverse(res)
    reverseGeocode(dat)





import requests as req
import time
DATE = time.strftime("%m-%d-%H_")

# Create an empty list
ALLdata=[]

URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv"

resp = req.get(URL)
content = resp.text

#clean the content, then break the content into lines 
content=content.replace(",,",",Ex,")
content=content.replace("(","")
content=content.replace(")","")
content=content.replace("\"","")
lines= content.splitlines()
print (len(lines))
# loop the lines one line at a time
# split each line at the delimiter ` , ` 
# then append the empty list 'ALLdata' with the line (which is now a list):  [line]  
for line in lines:
    #convert the splitlines to strings
    line= str(line).split(",")
    ALLdata.append(line)

Threshhold = 10
count = 0
# Check each line of data, county by county.
for i in range(1,len(ALLdata)):
    # Increase a counter for every line -  this will allow further investigation into the data
    # as demonstarted in the next four cells.
    count=count+1
    # subtract the last four days of data to see if it has increased by the minimum of the Threshhold each day
    if int(ALLdata[i][-3])-int(ALLdata[i][-4]) >Threshhold and int(ALLdata[i][-2])-int(ALLdata[i][-3]) >Threshhold and int(ALLdata[i][-1])-int(ALLdata[i][-2]) >Threshhold:
        # if they do increase as specified, define the line as a variable called history
        history=[int(ALLdata[i][-3])-int(ALLdata[i][-4]),int(ALLdata[i][-2])-int(ALLdata[i][-3]),int(ALLdata[i][-1])-int(ALLdata[i][-2])]
        # The total amount of deaths in the specific county
        deaths = int(ALLdata[i][-1])
        # The county's name
        county = ALLdata[i][5]
        # The State the county is located in
        state = ALLdata[i][6]
        # The longitude and latitude of the county
        longitude = ALLdata[i][9]
        Latitude = ALLdata[i][8]
        #print the data line by line
        print ("i="+str(count),deaths,county,state,longitude,Latitude,history)

# Using the info above
i=210
history=[int(ALLdata[i][-3])-int(ALLdata[i][-4]),int(ALLdata[i][-2])-int(ALLdata[i][-3]),int(ALLdata[i][-1])-int(ALLdata[i][-2])]
print (history)

i=210
print (ALLdata[i])

i=1885
print (ALLdata[i][5],ALLdata[i][6])
print ("----")
# 8 and 9 are intentionally reversed so loingitude is first
print (ALLdata[i][9],ALLdata[i][8])
print ("\n-- Notice 'deaths' is a list of strings --")
numbers = ALLdata[i][14:]
print (numbers)
print ("\n-- 'deaths' Converted to integers --")
ListOfIntegers = [int(r) for r in numbers]
print (ListOfIntegers)

# Convert the "ListOfIntegers" to a numpy array
import numpy as np
deaths = np.asarray(ListOfIntegers)
print (deaths)
deaths.shape # number of elements in the numpy array

import plotly.graph_objects as go
import time
      
fig = go.Figure()
fig.add_trace(go.Scatter(y=deaths))
fig.add_trace(go.Bar(y=deaths))
fig.update_layout(title = 'CONDID-19 Deaths')
fig.show() 

from __future__ import division
import sys
import glob
import time
import os
import matplotlib
import matplotlib.pyplot as plt
#%matplotlib inline 
import numpy as np 

e = len(deaths)
print (e)
ss = range(0,e)
x= np.asarray(ss)
y = np.array(deaths,dtype=np.int)
print(Ta)

fig, ax = plt.subplots(dpi=100)

ax.plot(x, y)
DT = time.strftime("%Y-%m-%d:%H")
ax.set(xlabel='DATE: '+DT)
ax.grid()
tm = time.strftime("%Y-%m%d%H%M%S")
Filename = tm+".png"
print (Filename)
fig.savefig(Filename)
plt.show()


!ls COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/05-12-2020.csv

import warnings
warnings.filterwarnings("ignore")
from mpl_toolkits.basemap import Basemap
import matplotlib.pyplot as plt
from matplotlib.pyplot import text
from matplotlib import pyplot as plt
import numpy as np
from matplotlib.font_manager import FontProperties
"""
When I tried to draw counties, I got error: basemap 'utf-8' codec can't decode byte 0xf1 in position
Answered on https://stackoverflow.com/questions/45660904/matplotlib-basemap-drawcounties-having-issues

Budi said, for me, i change return v.decode(encoding, encodingErrors) to return v.decode('latin-1') and it's works,, – Budi Mulyo May 27 '19 at 8:12

My file looked different than you described: so I opened /miniconda3/lib/python3.7/site-packages/shapefile.py and replaced all instances of 'utf-8' with 'latin-1' Itt works fine now. 
Thank you very much. – JackNorthrup 3 mins ago

"""
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/05-12-2020.csv"

DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
STATES=[]
cases=[]
deaths =[]
longitude = ""
search = "Illinois"
for line in DataIn:
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    if search in line[2] and "-" in (line[6]):
        #print(line[2],line[1],line[3],line[4],line[5],line[6],line[7],line[8],line[9],line[10])
        STATES.append(text)
        LAT.append(line[5])
        LONG.append(line[6])
        cases.append(line[7])
        deaths.append(line[8])
        longitude = longitude+line[6]+","
print("\n\n",len(STATES))        
LT = np.array(LAT,dtype=np.float)
LG = np.array(LONG,dtype=np.float)
fig = plt.figure(num=None, figsize=(10,8), dpi=80, facecolor='salmon')
urcrnrlat=max(LT)+.5
llcrnrlat=min(LT)-.5
urcrnrlon=max(LG)+.8
llcrnrlon=min(LG)-.5
lat_0 = (urcrnrlat+llcrnrlat)/2
lon_0 =(urcrnrlon+llcrnrlon)/2
# make up some data for scatter plot
lats = LT
lons = LG

fig = plt.gcf()
fig.set_size_inches(8, 6.5)


m = Basemap(llcrnrlon,llcrnrlat,urcrnrlon,urcrnrlat,
             resolution='i', projection='tmerc', lat_0 = lat_0, lon_0 = lon_0)

m.readshapefile(r'/home/jack/Desktop/state-data/state_bounds/state_bounds', 'Neighborhoods')
m.drawmapboundary(fill_color='aqua')
m.fillcontinents(color='#ddaa66',lake_color='aqua')
m.drawcoastlines()
m.drawrivers()
#m.drawcounties(linewidth=0.1, linestyle='solid', color='k', antialiased=1, facecolor='none', ax=None, zorder=None, drawbounds=False)
m.drawcounties(zorder=20)
S=1
Size=[]
for x in cases:
    S=1+(float(x)*.5)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

Sd=0
Sized=[]
for xd in deaths:
    Sd=0+(float(xd))
    Sized.append(int(Sd))
    #print(int(S))
sd = np.array(Sized)
print(Sized)

x, y = m(lons, lats)  # transform coordinates 
plt.scatter(x, y,  s=s, color="black", zorder=3)
plt.scatter(x, y,  s=sd, color="red", zorder=6)
plt.text(urcrnrlon,urcrnrlat, search, color='white', fontsize=24)
plt.savefig("BaseMap/"+search+"Counties__.png", dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)
plt.show()

DATA =[]
import numpy as np
cnt = 0
for rows in ALLdata[1:]:
    
    cnt=cnt+1
    arr = [int(r) for r in rows[13:]]
    DATA.append(arr)

data = [sum(x) for x in zip(*DATA)]
print cnt,data

cnt=0
print ALLdata[233][0],ALLdata[233][1],ALLdata[233][2],ALLdata[233][3],ALLdata[233][4]
print ALLdata[233][5],ALLdata[233][6],ALLdata[233][7],ALLdata[233][8],ALLdata[233][9]
data = map(int, ALLdata[233][14:])
print data

DATA =[]
import numpy as np
cnt = 0
state = "Ohio"
for i in range(1,len(ALLdata)):
    if ALLdata[i][6] == state:
        arr = [int(r) for r in ALLdata[i][14:]]
        DATA.append(arr)
        print "\n",ALLdata[i][5],ALLdata[i][6],ALLdata[i][7],ALLdata[i][8],"\n",arr
        
data = [sum(x) for x in zip(*DATA)]
print "\nData:",data        

DATA =[]
import numpy as np
cnt = 0
state = "Ohio"
for i in range(1,len(ALLdata)):
    if ALLdata[i][6] == state:
        for rows in ALLdata[i][6]:
            cnt=cnt+1
            arr = [int(r) for r in rows[14:]]
            DATA.append(arr)


data = [sum(x) for x in zip(*DATA)]
#print data[-1],rows[5],rows[6],rows[7],rows[8],data
print data

print DATA

DATA =[]
import numpy as np
cnt = 0
i =233

for rows in ALLdata[i:]:
    cnt=cnt+1
    arr = [int(r) for r in rows[14:]]
    DATA.append(arr)

data = [sum(x) for x in zip(*DATA)]
print data[-1],rows[5],rows[6],rows[7],rows[8],data

DATA =[]
import numpy as np
cnt = 0
for rows in ALLdata[1:]:
    cnt=cnt+1
    #if rows[6] == "Florida":
    if cnt<1:  
        arr = [int(r) for r in rows[14:]]
        DATA.append(arr)

data = [sum(x) for x in zip(*DATA)]
print data[-1],rows[6],data

STATE=[]
DATA =[]
import numpy as np
cnt = 0
for rows in ALLdata:
    cnt=cnt+1
    if rows[6] == "Florida":
        arr = [int(r) for r in rows[14:]]
        DATA.append(arr)

data = [sum(x) for x in zip(*DATA)]
#print rows[6],data
STATE.append([[str(rows[6])],data])
print STATE

TX=["Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming"]

print TX[2]

import requests as req
URL="https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv"
resp = req.get(URL)
OWID = []
text = resp.content
data=text.splitlines()
cnt=0
for line in data:
    cnt=cnt+1
    if cnt<5:
        # remove the b' before the line
        line = line.decode('utf-8') 
        OWID.append([line])

print OWID[0]

STATE=[]
DATA =[]
import numpy as np
cnt = 0
TX=["Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming"]


for i in range(0,len(TX)):
    #print TX[i]
    cnt=0
    for rows in ALLdata[1:]:
        DATA=[]
        if rows[6] == TX[i]:
            cnt=cnt+1
            arr = [int(r) for r in rows[14:]]
            DATA.append(arr)
            line = rows[5],rows[6],arr
        data = [sum(x) for x in zip(*DATA)]   

STATE=[]
DATA =[]
import numpy as np
cnt = 0
TX=["Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming"]


for i in range(0,len(TX)):
    for rows in ALLdata[1:]:
        cnt=cnt+1
        if rows[6] == TX[i]:
            arr = [int(r) for r in rows[14:]]
            DATA.append(arr)

    data = [sum(x) for x in zip(*DATA)]
    #print rows[6],data
    STATE.append([[str(rows[6])],data])
    print STATE

STATE=[]
DATA =[]
import numpy as np
cnt = 0
for rows in ALLdata[1:]:
    cnt=cnt+1
    arr = [int(r) for r in rows[14:]]
    DATA.append(arr)

data = [sum(x) for x in zip(*DATA)]
#print rows[6],data
STATE.append([[str(rows[6])],data])
print STATE

STATE=[]
DATA =[]
import numpy as np
cnt = 0
for rows in ALLdata:
    cnt=cnt+1
    if cnt>1:
        arr = [int(r) for r in rows[14:]]
        print "-",
        DATA.append(arr)

    data = [sum(x) for x in zip(*DATA)]
    print " . ",
    STATE.append([str(rows[6])]+data)


print STATE[233][0]
print STATE[233][1:]
print STATE[233][-1]

for i in range(0,len(STATE)):
    if "Ohio" == STATE[i][0]:
        print i,STATE[i][0:]

cnt = 0
for rows in ALLdata:
    cnt=cnt+1
    if cnt<5:
        print cnt,rows
        print " "

cnt = 0
for rows in ALLdata:
    cnt=cnt+1
    if cnt>50 and cnt<55:
        print cnt,rows[6],rows[13:]
        print " "

cnt = 0
WholeState=[]
for rows in ALLdata:
    cnt=cnt+1
    if rows[6] == "Florida":
        INT = map(int, rows[14:])
        WholeState.append(INT)
        print WholeState

res = [sum(x) for x in zip(*WholeState)]
print res

import requests as req
import time
DATE = time.strftime("%m-%d-%H_")
ALLdata=[]
STATE = "Florida"
URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv"

STATE = "Florida"

resp = req.get(URL)
content = resp.text

#clean the content, then break the content into lines 
content=content.replace(",,",",Ex,")
content=content.replace("(","")
content=content.replace(")","")
content=content.replace("\"","")
lines= content.splitlines()
# loop the lines one line at a time
# split each line at the delimiter ` , ` 
# then append the empty list 'ALLdata' with the line (which is now a list):  [line]  
for line in lines:
    line= line.split(",")
    ALLdata.append(line)


WholeState=[]
for rows in ALLdata:
    if rows[6] == STATE:
        INT = map(int, rows[14:])
        WholeState.append(INT)
        
LOCATION = []        
for rows in ALLdata:
    if rows[6] == STATE:
        LOCATION.append([float(rows[9]),float(rows[8])])        

data = [sum(x) for x in zip(*WholeState)]
print(data)
print(LOCATION)

StateData=[]
STATE="Ohio"
for rows in ALLdata:
    if rows[6] == STATE:
        INT = map(int, rows[14:])
        # Notice the Deaths are in First Column ( Easy to sort high to low )
        StateData.append([int(rows[-1]),rows[5],rows[6],float(rows[9]),float(rows[8]),INT])

cnt=0
for row in sorted(StateData, reverse=True):
    if cnt==0:print row[0],row[1],row[2],row[3],row[4],row[5]
    if cnt==1:print row[0],row[1],row[2],row[3],row[4],row[5]
    if cnt==2:print row[0],row[1],row[2],row[3],row[4],row[5]
    cnt=cnt+1

print len(StateData)
print(StateData[1])
print "---------------"
print(StateData[1][0])
print "---------------"
print(StateData[1][1])
print "---------------"
print(StateData[1][2])
print "---------------"
print(StateData[1][3])
print "---------------"
print(StateData[1][4])
print "---------------"
print(StateData[1][5])


StateData=[]
for rows in ALLdata[1:]:
    INT = map(int, rows[14:])
    # Notice the Deaths are in First Column ( Easy to sort high to low )
    StateData.append([int(rows[-1]),rows[5],rows[6],float(rows[9]),float(rows[8]),INT])

cnt=0
for row in sorted(StateData, reverse=True):
    if cnt<20:print row[0],row[1],row[2],row[3],row[4],row[5]
    cnt=cnt+1

HighestCounts=[]
CNT=0
cnt=0
StateData=[]
for rows in ALLdata[1:]:
    print str(rows[14:])
    INT = map(int, rows[14:])
    # Notice the Deaths are in First Column ( Easy to sort high to low )
    StateData.append([int(rows[-1]),rows[5],rows[6],float(rows[9]),float(rows[8]),INT])

cnt=0
for row in sorted(StateData, reverse=True):
    if cnt<50:HighestCounts.append([row[0],row[1],row[2],row[3],row[4],row[5]])
    cnt=cnt+1
    
cnt=0
for row in sorted(HighestCounts, reverse=True):
    cnt=cnt+1
    print str(cnt)+": ",row

cnt=0
for i in range(0,len(HighestCounts)):
    deaths = HighestCounts[i][0]
    county = HighestCounts[i][1]
    state = HighestCounts[i][2]
    longitude = HighestCounts[i][3]
    latitude = HighestCounts[i][4]
    print deaths,county,state,longitude,latitude
    

HighestCounts=[]
CNT=0
for i in range(0,len(ALLdata[1:])):
    StateData=[]
    for rows in ALLdata[1:i]:
        #print(rows[0:])
        INT = map(int, rows[14:])
        # Notice the Deaths are in First Column ( Easy to sort high to low )
        StateData.append([INT[-1],rows[5],rows[6],float(rows[9]),float(rows[8]),INT])

cnt=0
for row in sorted(StateData, reverse=True):
    if cnt==0:HighestCounts.append([row[0],row[1],row[2],row[3],row[4],row[5]])
    cnt=cnt+1

import warnings
warnings.filterwarnings("ignore")
import matplotlib.pyplot as plt
from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon
import numpy as np
from PIL import Image,ImageFont,ImageDraw,ImageFilter,ImageChops
from random import randint
from mpl_toolkits.basemap import Basemap
fig = plt.figure(num=None, figsize=(12, 8) ) 
m = Basemap(width=6000000,height=4500000,resolution='h',projection='aea',lat_1=35.,lat_2=45,lon_0=-100,lat_0=40)
m.drawcoastlines(linewidth=0.5)
m.fillcontinents(color='tan',lake_color='lightblue')
# draw parallels and meridians.
m.drawparallels(np.arange(-90.,91.,10.),labels=[True,True,False,False],dashes=[2,2])
m.drawmeridians(np.arange(-180.,181.,10.),labels=[False,False,False,True],dashes=[2,2])
m.drawmapboundary(fill_color='lightblue')
m.drawcountries(linewidth=2, linestyle='solid', color='k' ) 
m.drawstates(linewidth=0.5, linestyle='solid', color='k')
m.drawrivers(linewidth=0.5, linestyle='solid', color='blue')

'''
S=1
Size=[]
for x in deaths:
    S=1+(float(x)*.05)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)
'''
plt.title("COVID-19:\n Cases: (black)\n Deaths(red) \n Location:\n ", fontsize=15, loc='right')
#plt.text(max(LG-1.2),max(LT), search, color='white', fontsize=24)
#x, y = m(lons, lats)  # transform coordinates


plt.xlabel('Longitude',color="white", fontsize=24)
plt.ylabel('Latitute',color="white", fontsize=24)
x, y = m(-80.55170587, 25.6112362)
m.scatter(x, y, s=20, color='red', zorder=5, alpha=0.6)
#m.scatter(40.21053671, -75.36652296,  s=20, color='blue', zorder=5, alpha=0.6)
#m.scatter(x, y, s=sd, color='r', zorder=10,  alpha=0.6)

plt.savefig("BaseMap/EXP.png", dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)


import warnings
warnings.filterwarnings("ignore")
import matplotlib.pyplot as plt
from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon
import numpy as np
from PIL import Image,ImageFont,ImageDraw,ImageFilter,ImageChops
from random import randint
from mpl_toolkits.basemap import Basemap
fig = plt.figure(num=None, figsize=(12, 8) ) 
m = Basemap(width=6000000,height=4500000,resolution='h',projection='aea',lat_1=35.,lat_2=45,lon_0=-100,lat_0=40)
m.drawcoastlines(linewidth=0.5)
m.fillcontinents(color='tan',lake_color='lightblue')
# draw parallels and meridians.
m.drawparallels(np.arange(-90.,91.,10.),labels=[True,True,False,False],dashes=[2,2])
m.drawmeridians(np.arange(-180.,181.,10.),labels=[False,False,False,True],dashes=[2,2])
m.drawmapboundary(fill_color='lightblue')
m.drawcountries(linewidth=2, linestyle='solid', color='k' ) 
m.drawstates(linewidth=0.5, linestyle='solid', color='k')
m.drawrivers(linewidth=0.5, linestyle='solid', color='blue')
def RndState():
    TX=["Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming"]
    x=randint(1,49)
    return TX[x]

search = RndState()
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/05-08-2020.csv"
#LASTFILE="csse_covid_19_data/csse_covid_19_daily_reports/03-30-2020.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
LATd=[]
LONGd=[]
STATES=[]
cases=[]
deaths =[]
longitude = ""
search = RndState()
for line in DataIn:
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    if search in line[2] and "-" in (line[6]):
        text=line[2],line[1],line[3],line[4],line[5],line[6],line[7],line[8],line[9],line[10]
        STATES.append(text)
        LAT.append(line[5])
        LONG.append(line[6])
        if int(line[8])>0:
            LATd.append(line[5])
            LONGd.append(line[6])        
        cases.append(line[7])
        deaths.append(line[8])
        longitude = longitude+line[6]+","
print(len(STATES))        
LT = np.array(LAT,dtype=np.float)
LG = np.array(LONG,dtype=np.float)
LTd = np.array(LATd,dtype=np.float)
LGd = np.array(LONGd,dtype=np.float)

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.05)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

Sd=0
Sized=[]
for xd in deaths:
    Sd=0+(float(xd)+.05)
    Sized.append(int(Sd))
    #print(int(S))
sd = np.array(Sized)
#print(Sized)
plt.title("COVID-19:\n Cases: (black)\n Deaths(red) \n Location:\n "+search+"\n", fontsize=15, loc='right')
#plt.text(max(LG-1.2),max(LT), search, color='white', fontsize=24)
#x, y = m(lons, lats)  # transform coordinates
x, y = m(LGd, LTd)
xx,yy = m(LG, LT)
plt.xlabel('Longitude',color="white", fontsize=24)
plt.ylabel('Latitute',color="white", fontsize=24)

m.scatter(xx, yy, s=s, color='black', zorder=5, alpha=0.6)
m.scatter(x, y, s=sd, color='r', zorder=10,  alpha=0.6)

plt.savefig("BaseMap/"+search+"Hotspots1__.png", dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)


StateData=[]
STATE="Ohio"
for rows in ALLdata:
    if rows[6] == STATE:
        INT = map(int, rows[14:])
        StateData.append([rows[5],rows[6],int(rows[-1]),float(rows[9]),float(rows[8]),INT])
print StateData        

import requests as req
import time
DATE = time.strftime("%m-%d-%H_")
URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv"

resp = req.get(URL)
content = resp.text

#create a date oriented filename and print it
filename=str(DATE)+"_"+URL[-21:]
print(filename)
content=content.replace(",,",",Ex,")
content=content.replace("(","")
content=content.replace(")","")
content=content.replace("\"","")
print(content)
# Open a file using the new filename and write the content of the 'gitfile' to it.
# Update one time daily
TEMP = open(filename,"w")
TEMP.write(content)
TEMP.close()

LASTFILE="05-11-13__covid19_deaths_US.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
LATd=[]
LONGd=[]
STATES=[]
cases=[]
deaths =[]
longitude = ""
search = RndState()
for line in DataIn:
    print(line)
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    if search in line[2] and "-" in (line[6]):
        text=line[2],line[1],line[3],line[4],line[5],line[6],line[7],line[8],line[9],line[10]
        STATES.append(text)
        LAT.append(line[5])
        LONG.append(line[6])
        if int(line[8])>0:
            LATd.append(line[5])
            LONGd.append(line[6])        
        cases.append(line[7])
        deaths.append(line[8])
        longitude = longitude+line[6]+","
print(len(STATES))        

import matplotlib.pyplot as plt
from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon
import numpy as np
from PIL import Image,ImageFont,ImageDraw,ImageFilter,ImageChops
from random import randint
from mpl_toolkits.basemap import Basemap
#prevents a warning from using Python3 instaead of Python2
import warnings
from RandomState import *
warnings.filterwarnings("ignore")
import sys
sys.path.insert(1, "/home/jack/hidden")
import Key
import twython
from twython import Twython
# Make the figure
#fig = plt.figure()
#ax = fig.add_subplot(111)

# Easiest way to make a basemap is to use the cylidrical projection and 
# define the bottom left lat/lon and top right lat/lon corners

def RndState():
    TX=["Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming"]
    x=randint(1,49)
    return TX[x]


LASTFILE="05-11-13__covid19_deaths_US.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
LATd=[]
LONGd=[]
STATES=[]
cases=[]
deaths =[]

search = RndState()
for line in DataIn:
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    if search in line[6] and "-" in (line[9]):
        text=line[2],line[1],line[3],line[4],line[5],line[6],line[7],line[8],line[9],line[10],line[11],line[12],line[13]
        #print(line)
        STATES.append(text)
        LAT.append(line[8])
        LONG.append(line[9])
        if int(float(line[8]))>0:
            LATd.append(float(line[8]))
            LONGd.append(float(line[9]))        
        cases.append(line[-1])
        deaths.append(line[-1])

print(len(STATES))



LT = np.array(LAT,dtype=np.float)
LG = np.array(LONG,dtype=np.float)
LTd = np.array(LATd,dtype=np.float)
LGd = np.array(LONGd,dtype=np.float)


fig = plt.figure(num=None, figsize=(10,8), dpi=80, facecolor='salmon')


urcrnrlat=max(LT)+.5
llcrnrlat=min(LT)-.5
urcrnrlon=max(LG)+.8
llcrnrlon=min(LG)-.5
lat_0 = (urcrnrlat+llcrnrlat)/2
lon_0 =(urcrnrlon+llcrnrlon)/2

# create the map object, m
m = Basemap(resolution='h', projection='cyl', \
    llcrnrlon=llcrnrlon, llcrnrlat=llcrnrlat, urcrnrlon=urcrnrlon, urcrnrlat=urcrnrlat)

# Note: You can define the resolution of the map you just created. Higher 
# resolutions take longer to create.
#    'c' - crude
#    'l' - low
#    'i' - intermediate
#    'h' - high
#    'f' - full

# Draw some map elements on the map
m.drawmapboundary(fill_color='aqua')
m.fillcontinents(color='#ddaa66',lake_color='aqua')
m.drawcoastlines()
m.drawrivers(linewidth=1.0,color='navy',zorder=8)
m.drawcounties(linewidth=1.0, linestyle='solid', color='gray', antialiased=1, facecolor='lightgreen', ax=None, zorder=2, drawbounds=True)
m.drawstates(linewidth=1.5, linestyle='solid', color='black', antialiased=1,zorder=2, )
plt.text(llcrnrlon,llcrnrlat+.5, search, color='black', fontsize=24.5, zorder=6,bbox=dict(facecolor='salmon'))

# Drawing ArcGIS Basemap (only works with cylc projections??)
# Examples of what each map looks like can be found here:
# http://kbkb-wx-python.blogspot.com/2016/04/python-basemap-background-image-from.html
maps = ['ESRI_Imagery_World_2D',    # 0
        'ESRI_StreetMap_World_2D',  # 1
        'NatGeo_World_Map',         # 2
        'NGS_Topo_US_2D',           # 3
        'Ocean_Basemap',            # 4
        'USA_Topo_Maps',            # 5
        'World_Imagery',            # 6
        'World_Physical_Map',       # 7
        'World_Shaded_Relief',      # 8
        'World_Street_Map',         # 9
        'World_Terrain_Base',       # 10
        'World_Topo_Map'            # 11
        ]
print ("drawing image from arcGIS server..."),
#m.arcgisimage(service=maps[8], xpixels=1000, verbose=False)
m.arcgisimage(service=maps[9], xpixels=3500, verbose=False)
print ("...finished")

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.5)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

Sd=0
Sized=[]
for xd in deaths:
    Sd=0+(float(xd))
    Sized.append(int(Sd))
    #print(int(S))
sd = np.array(Sized)
#print(Sized)
plt.title("COVID-19:\n Cases: (black)\n Deaths(red) \n Location:\n "+search+"\n", fontsize=15, loc='right')
#plt.text(max(LG-1.2),max(LT), search, color='white', fontsize=24)
#x, y = m(lons, lats)  # transform coordinates
x, y = m(LGd, LTd)
xx,yy = m(LG, LT)
plt.xlabel('Longitude',color="white", fontsize=24)
plt.ylabel('Latitute',color="white", fontsize=24)

m.scatter(xx, yy, s=s, color='black', zorder=5, alpha=0.6)
m.scatter(x, y, s=sd, color='r', zorder=10,  alpha=0.6)

#plt.text(urcrnrlon,urcrnrlat, search, color='white', fontsize=24)
plt.savefig("BaseMap/"+search+"arcGIS__.png", dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)

filename0 = "BaseMap/"+search+"arcGIS__.png"


def draw_blurred_back(img, position, text, font, col, halo_col):
    halo = Image.new('RGBA', img.size, (0, 0, 0, 0))
    ImageDraw.Draw(halo).text(position, text, font = font, fill = halo_col)
    blurred_halo = halo.filter(ImageFilter.BLUR)
    ImageDraw.Draw(blurred_halo).text(position, text, font = font, fill = col)
    return Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))

if __name__ == '__main__':
    
    basewidth = 720
    inp = Image.open(filename0)
    wpercent = (basewidth / float(inp.size[0]))
    hsize = int((float(inp.size[1]) * float(wpercent)))
    inp = inp.resize((basewidth, hsize), Image.ANTIALIAS)
    #img.save(resized_image.jpg')
    
    #inp = inp.resize((640,640), Image.ANTIALIAS)
    font = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 30)
    text_title = (255, 255,230) # bright green
    blur_title = (0, 0, 0)   # black

    i2 = draw_blurred_back(inp, (15, 30), "Plotting COVID-19 Data", font, text_title, blur_title)
    font0 = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 20)
    font1 = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 14)
    font2 = ImageFont.truetype("/home/jack/fonts/PatrickHand-Regular.ttf", 16)
    i2 = draw_blurred_back(i2, (15, 65), "Plot Using ArcGIS Basemap - "+search, font0, text_title, blur_title)
    TXT="https://github.com/JupyterJones/COVID-19-Jupyter-Notebooks"
    draw = ImageDraw.Draw(i2) 
    draw.text((15, 5), TXT, font = font2, align ="left",fill="black")
    #i2 = draw(i2, (15, 65),TXT, font1)    
    
    #txt = Image.new('RGBA', i.size, (255,255,255,0))

    # get a font
    fnt = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 20)
    # get a drawing context
    signature_ = "@jacklnorthrup" 
    #get length in pixel of signature_
    sizeS,ln = fnt.getsize(signature_)
    #add 15 pixels to right border
    pt = sizeS+25
    width, height = inp.size
    #marginx starting point of signature_
    marginx = pt
    #bottom margin
    marginy = 30
    x = width - marginx
    y = height - marginy
    

    text_sig = (255, 255,230) # bright green
    blur_sig = (0, 0, 0)   # black
    txt=draw_blurred_back(i2,(x,y), signature_, fnt, text_sig, blur_sig)
    out = Image.alpha_composite(i2, txt)
    out.save("images/TEMP_POST.png")

CONSUMER_KEY = Key.twiter()[0]
CONSUMER_SECRET = Key.twiter()[1]
ACCESS_KEY = Key.twiter()[2]
ACCESS_SECRET = Key.twiter()[3]
twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)

STR = "#"+search+"  #arcGIS server #Basemap #COVID-19 - #Python  Plot data using "+TXT+" #JupyterJones" 

PATH = "images/TEMP_POST.png"
photo = open(PATH,'rb')
#response = twitter.upload_media(media=photo)
#twitter.update_status(status=STR, media_ids=[response['media_id']])

from PIL import Image
IM = Image.open(PATH)
IM

longitude = HighestCounts[i][3]
latitude = HighestCounts[i][4]

print latitude



import warnings
warnings.filterwarnings("ignore")
import matplotlib.pyplot as plt
from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon
import numpy as np
from PIL import Image,ImageFont,ImageDraw,ImageFilter,ImageChops
from random import randint
from mpl_toolkits.basemap import Basemap
fig = plt.figure(num=None, figsize=(12, 8) ) 
m = Basemap(width=6000000,height=4500000,resolution='h',projection='aea',lat_1=35.,lat_2=45,lon_0=-100,lat_0=40)
m.drawcoastlines(linewidth=0.5)
m.fillcontinents(color='tan',lake_color='lightblue')
# draw parallels and meridians.
m.drawparallels(np.arange(-90.,91.,10.),labels=[True,True,False,False],dashes=[2,2])
m.drawmeridians(np.arange(-180.,181.,10.),labels=[False,False,False,True],dashes=[2,2])
m.drawmapboundary(fill_color='lightblue')
m.drawcountries(linewidth=2, linestyle='solid', color='k' ) 
m.drawstates(linewidth=0.5, linestyle='solid', color='k')
m.drawrivers(linewidth=0.5, linestyle='solid', color='blue')
def RndState():
    TX=["Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming"]
    x=randint(1,49)
    return TX[x]

search = RndState()
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/05-08-2020.csv"
#LASTFILE="csse_covid_19_data/csse_covid_19_daily_reports/03-30-2020.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
LATd=[]
LONGd=[]
STATES=[]
cases=[]
deaths =[]
longitude = ""
search = RndState()
for line in DataIn:
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    if search in line[2] and "-" in (line[6]):
        text=line[2],line[1],line[3],line[4],line[5],line[6],line[7],line[8],line[9],line[10]
        STATES.append(text)
        LAT.append(line[5])
        LONG.append(line[6])
        if int(line[8])>0:
            LATd.append(line[5])
            LONGd.append(line[6])        
        cases.append(line[7])
        deaths.append(line[8])
        longitude = longitude+line[6]+","
print(len(STATES))        
LT = np.array(LAT,dtype=np.float)
LG = np.array(LONG,dtype=np.float)
LTd = np.array(LATd,dtype=np.float)
LGd = np.array(LONGd,dtype=np.float)

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.05)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

Sd=0
Sized=[]
for xd in deaths:
    Sd=0+(float(xd)+.05)
    Sized.append(int(Sd))
    #print(int(S))
sd = np.array(Sized)
#print(Sized)
plt.title("COVID-19:\n Cases: (black)\n Deaths(red) \n Location:\n "+search+"\n", fontsize=15, loc='right')
#plt.text(max(LG-1.2),max(LT), search, color='white', fontsize=24)
#x, y = m(lons, lats)  # transform coordinates
x, y = m(LGd, LTd)
xx,yy = m(LG, LT)
plt.xlabel('Longitude',color="white", fontsize=24)
plt.ylabel('Latitute',color="white", fontsize=24)

m.scatter(xx, yy, s=s, color='black', zorder=5, alpha=0.6)
m.scatter(x, y, s=sd, color='r', zorder=10,  alpha=0.6)

plt.savefig("BaseMap/"+search+"Hotspots1__.png", dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)


import warnings
warnings.filterwarnings("ignore")
import matplotlib.pyplot as plt
from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon
import numpy as np
from PIL import Image,ImageFont,ImageDraw,ImageFilter,ImageChops
from random import randint
from mpl_toolkits.basemap import Basemap
fig = plt.figure(num=None, figsize=(12, 8) ) 
m = Basemap(width=6000000,height=4500000,resolution='h',projection='aea',lat_1=35.,lat_2=45,lon_0=-100,lat_0=40)
m.drawcoastlines(linewidth=0.5)
m.fillcontinents(color='tan',lake_color='lightblue')
# draw parallels and meridians.
m.drawparallels(np.arange(-90.,91.,10.),labels=[True,True,False,False],dashes=[2,2])
m.drawmeridians(np.arange(-180.,181.,10.),labels=[False,False,False,True],dashes=[2,2])
m.drawmapboundary(fill_color='lightblue')
m.drawcountries(linewidth=2, linestyle='solid', color='k' ) 
m.drawstates(linewidth=0.5, linestyle='solid', color='k')
m.drawrivers(linewidth=0.5, linestyle='solid', color='blue')
def RndState():
    TX=["Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming"]
    x=randint(1,49)
    return TX[x]

search = RndState()
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/05-08-2020.csv"
#LASTFILE="csse_covid_19_data/csse_covid_19_daily_reports/03-30-2020.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
LATd=[]
LONGd=[]
STATES=[]
cases=[]
deaths =[]
longitude = ""
search = RndState()
for line in DataIn:
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    if search in line[2] and "-" in (line[6]):
        text=line[2],line[1],line[3],line[4],line[5],line[6],line[7],line[8],line[9],line[10]
        STATES.append(text)
        LAT.append(line[5])
        LONG.append(line[6])
        if int(line[8])>0:
            LATd.append(line[5])
            LONGd.append(line[6])        
        cases.append(line[7])
        deaths.append(line[8])
        longitude = longitude+line[6]+","
print(len(STATES))        
LT = np.array(LAT,dtype=np.float)
LG = np.array(LONG,dtype=np.float)
LTd = np.array(LATd,dtype=np.float)
LGd = np.array(LONGd,dtype=np.float)

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.05)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

Sd=0
Sized=[]
for xd in deaths:
    Sd=0+(float(xd)+.05)
    Sized.append(int(Sd))
    #print(int(S))
sd = np.array(Sized)
#print(Sized)
plt.title("COVID-19:\n Cases: (black)\n Deaths(red) \n Location:\n "+search+"\n", fontsize=15, loc='right')
#plt.text(max(LG-1.2),max(LT), search, color='white', fontsize=24)
#x, y = m(lons, lats)  # transform coordinates
x, y = m(LGd, LTd)
xx,yy = m(LG, LT)
plt.xlabel('Longitude',color="white", fontsize=24)
plt.ylabel('Latitute',color="white", fontsize=24)

m.scatter(xx, yy, s=s, color='black', zorder=5, alpha=0.6)
m.scatter(x, y, s=sd, color='r', zorder=10,  alpha=0.6)

plt.savefig("BaseMap/"+search+"Hotspots1__.png", dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)


from PIL import Image
IM = Image.open("BaseMap/"+search+"Hotspots1__.png")
IM

import requests as req

#URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"
URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv"


print (URL[-33:])
STAT =URL[57:-4]
resp = req.get(URL)

#LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"
#STAT =LASTFILE[57:-4]
#DataIn = open(LASTFILE).readlines()

content = resp.text

TEMP = open(URL[-25:],"w")
TEMP.write(content)
TEMP.close()


LASTFILE0="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/time_series_covid19_confirmed_US.csv"
LASTFILE="ies_covid19_deaths_US.csv"
DataIn = open(LASTFILE).readlines()
cnt=0
for line in DataIn:
    if cnt<10:print (line)
    cnt=cnt+1
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    #if cnt<10 and line[5] !="":print (line[6])
    if "US" == line[7]:
        #if CNT<5 and line[5] !="":print line
        CNT=CNT+1
        ALL.append(line)
        text=line[5],line[6],line[8],line[9]
        if CNT<20:print(text)
        STATES.append(text)
        LAT.append(line[5])
        LONG.append(line[6])
        if int(line[-1])>0:
            if line[-2]<line[-1]:
                #prints all lines with increases
                #print (text,line[-2],line[-1] )
                yesterday=yesterday+int(line[-2])
                today= today+int(line[-1])
                Dcnt=Dcnt+1
                LATd.append(text)
                LONGd.append(text)
print(len(STATES))

#LASTFILE0="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/time_series_covid19_confirmed_US.csv"
#LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
LATd=[]
LONGd=[]
STATES=[]
ALL=[]
cases=[]
deaths =[]
yesterday=0
today=0
longitude = ""
cnt=0
CNT=0
Dcnt=0
for line in DataIn:
    line=line.replace('"','')
    if cnt==0:print (line)
    cnt=cnt+1
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    #if cnt<10 and line[5] !="":print (line[6])
    if "US" == line[7]:
        #if CNT<5 and line[5] !="":print line
        CNT=CNT+1
        ALL.append(line)
        text=line[5],line[6],line[8],line[9]
        if CNT<20:print(text)
        STATES.append(text)
        LAT.append(line[5])
        LONG.append(line[6])
        if int(line[-1])>0:
            if line[-2]<line[-1]:
                #prints all lines with increases
                #print (text,line[-2],line[-1] )
                yesterday=yesterday+int(line[-2])
                today= today+int(line[-1])
                Dcnt=Dcnt+1
                LATd.append(text)
                LONGd.append(text)
print(len(STATES))

cnt=0
data=open("STATE.data","w")
data.write("City,State,Latitude,Longitude\n")
for line in STATES:
    cnt=cnt+1
    line =str(line)
    line=line.replace("(","")
    line=line.replace(")","")
    line=line.replace(")","")
    line=line.replace(")","")
    data.write(line+"\n")
data.close    

#LASTFILE0="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/time_series_covid19_confirmed_US.csv"
#LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
LATd=[]
LONGd=[]
STATES=[]
ALL=[]
cases=[]
deaths =[]
yesterday=0
today=0
longitude = ""
cnt=0
CNT=0
Dcnt=0
for line in DataIn:
    line=line.replace('"','')
    #if cnt==0:print (line)
    cnt=cnt+1
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    #if cnt<10 and line[5] !="":print (line[6])
    if "US" == line[7]:# and line[6] == "New York":
        #if CNT<5 and line[5] !="":print line
        CNT=CNT+1
        ALL.append(line)
        text=line[5],line[6],line[8],line[9]
        #print(text)
        STATES.append(text)
        LAT.append(line[5])
        LONG.append(line[6])
        L=len(line)
        #print(L)
        #print(line[L-1],line[L-2])
        if int(line[L-2])+10<int(line[L-1]):
            print ("if ",int(line[L-2]),'+10',int(line[L-1]))
            print (text,int(line[L-2]),int(line[L-1]))
            yesterday=yesterday+int(line[-2])
            today= today+int(line[-1])
            Dcnt=Dcnt+1
            LATd.append(text)
            LONGd.append(text)
print ('------------')
print ('Counties',CNT) 
print ('Counties with new deaths',Dcnt)
print (len(LONGd))
print (Dcnt)
print ("yesterday",yesterday)
print ("today",today)
print ("today-yesterday",today-yesterday)

import warnings
warnings.filterwarnings("ignore")
import matplotlib.pyplot as plt
from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon
import numpy as np
from PIL import Image,ImageFont,ImageDraw,ImageFilter,ImageChops
from random import randint
from mpl_toolkits.basemap import Basemap
fig = plt.figure(num=None, figsize=(12, 8) ) 
m = Basemap(width=6000000,height=4500000,resolution='c',projection='aea',lat_1=35.,lat_2=45,lon_0=-100,lat_0=40)
m.drawcoastlines(linewidth=0.5)
m.fillcontinents(color='tan',lake_color='lightblue')
# draw parallels and meridians.
m.drawparallels(np.arange(-90.,91.,15.),labels=[True,True,False,False],dashes=[2,2])
m.drawmeridians(np.arange(-180.,181.,15.),labels=[False,False,False,True],dashes=[2,2])
m.drawmapboundary(fill_color='lightblue')
m.drawcountries(linewidth=2, linestyle='solid', color='k' ) 
m.drawstates(linewidth=0.5, linestyle='solid', color='k')
m.drawrivers(linewidth=0.5, linestyle='solid', color='blue')


cities =[]
LAT=[]
LONG=[]
LATd=[]
LONGd=[]
STATES=[]
ALL=[]
cases=[]
deaths =[]
yesterday=0
today=0
longitude = ""
cnt=0
CNT=0
Dcnt=0
LASTFILE="ies_covid19_deaths_US.csv"
DataIn = open(LASTFILE).readlines()
for line in DataIn:
    line=line.replace('"','')
    #if cnt==0:print (line)
    cnt=cnt+1
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    #if cnt<10 and line[5] !="":print (line[6])
    if "US" == line[7]:# and line[6] == "New York":
        if CNT==7:print(line)
        if CNT==8:print(line)    
        #if CNT<5 and line[5] !="":print line
        CNT=CNT+1
        ALL.append(line)
        STATES.append(text)
        LAT.append(line[5])
        LONG.append(line[6])
        L=len(line)
        #print(L)
        #print(line[L-1],line[L-2])
        if int(line[L-2])+10<int(line[L-1]):
            #print ("if ",int(line[L-2]),'+10',int(line[L-1]))
            #print (text,int(line[L-2]),int(line[L-1]))
            yesterday=yesterday+int(line[-2])
            today= today+int(line[-1])
            Dcnt=Dcnt+1
            if len(line[8])>3:
                #print(line[8],line[9])
                cities.append([line[5],line[6],line[8],line[9],int(line[L-1])])
                LATd.append(line[8])
                LONGd.append(line[9])
                deaths.append(int(line[L-1]))
LTd = np.array(LATd,dtype=np.float)
LGd = np.array(LONGd,dtype=np.float)
Str = np.array(cities,dtype=np.str)

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.01)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

Sd=1
Sized=[]
for xd in deaths:
    Sd=0+(float(xd)*.07)
    Sized.append(int(Sd))
    #print(int(S))
sd = np.array(Sized)
#print(Sized)
plt.title("Finding-Hot-Spots.ipynb - https://github.com/JupyterJones/COVID-19-Jupyter-Notebooks")
#plt.text(max(LG-1.2),max(LT), search, color='white', fontsize=24)
#x, y = m(lons, lats)  # transform coordinates
x, y = m(LGd, LTd)
#xx,yy = m(LG, LT)
plt.xlabel('Longitude',color="white", fontsize=24)
plt.ylabel('Latitute',color="white", fontsize=24)

#m.scatter(xx, yy, s=s, color='black', zorder=5, alpha=0.6)
m.scatter(x, y, s=sd, color='r', zorder=10,  alpha=0.6)
filename = "BaseMap/april30_Hotspots__.png"
plt.savefig(filename, dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)


for i in (range(0,len(cities))):
    print(cities[i][0])
    print(cities[i][1])
    print(cities[i][2])
    print(cities[i][3])
    print("-----------")

from PIL import Image
IM = Image.open("BaseMap/april30_Hotspots__.png")
IM

print(cities)

LASTFILE="ies_covid19_deaths_US.csv"
DataIn = open(LASTFILE).readlines()
for line in DataIn:
    line=line.replace('"','')
    if cnt==0:print (line)
    cnt=cnt+1
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    #if cnt<10 and line[5] !="":print (line[6])
    if "US" == line[7]:# and line[6] == "New York":
        #if CNT<5 and line[5] !="":print line
        CNT=CNT+1
        ALL.append(line)
        STATES.append(text)
        LAT.append(line[5])
        LONG.append(line[6])
        L=len(line)
        #print(L)
        #print(line[L-1],line[L-2])
        if int(line[L-2])+10<int(line[L-1]):
            #print ("if ",int(line[L-2]),'+10',int(line[L-1]))
            #print (text,int(line[L-2]),int(line[L-1]))
            yesterday=yesterday+int(line[-2])
            today= today+int(line[-1])
            Dcnt=Dcnt+1
            if len(line[8])>3:
                print(line[8],line[9],line[8],line[9])
                LATd.append(line[8])
                LONGd.append(line[9])
            



import matplotlib.pyplot as plt
from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon
import numpy as np
from PIL import Image,ImageFont,ImageDraw,ImageFilter,ImageChops
from random import randint
from mpl_toolkits.basemap import Basemap
#prevents a warning from using Python3 instaead of Python2
import warnings
warnings.filterwarnings("ignore")
import sys
sys.path.insert(1, "/home/jack/hidden")
import Key
import twython
from twython import Twython
# Make the figure
#fig = plt.figure()
#ax = fig.add_subplot(111)

# Easiest way to make a basemap is to use the cylidrical projection and 
# define the bottom left lat/lon and top right lat/lon corners

def RndState():
    TX=["Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming"]
    x=randint(1,50)
    return TX[x]
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/04-27-2020.csv"
#LASTFILE="csse_covid_19_data/csse_covid_19_daily_reports/03-30-2020.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
LATd=[]
LONGd=[]
STATES=[]
cases=[]
deaths =[]
longitude = ""
search = RndState()
for line in DataIn:
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    if search in line[2] and "-" in (line[6]):
        text=line[2],line[1],line[3],line[4],line[5],line[6],line[7],line[8],line[9],line[10]
        STATES.append(text)
        LAT.append(line[5])
        LONG.append(line[6])
        if int(line[8])>0:
            LATd.append(line[5])
            LONGd.append(line[6])        
        cases.append(line[7])
        deaths.append(line[8])
        longitude = longitude+line[6]+","
print(len(STATES))        
LT = np.array(LAT,dtype=np.float)
LG = np.array(LONG,dtype=np.float)
LTd = np.array(LATd,dtype=np.float)
LGd = np.array(LONGd,dtype=np.float)


fig = plt.figure(num=None, figsize=(10,8), dpi=80, facecolor='salmon')


urcrnrlat=max(LT)+.5
llcrnrlat=min(LT)-.5
urcrnrlon=max(LG)+.8
llcrnrlon=min(LG)-.5
lat_0 = (urcrnrlat+llcrnrlat)/2
lon_0 =(urcrnrlon+llcrnrlon)/2

# create the map object, m
m = Basemap(resolution='i', projection='cyl', \
    llcrnrlon=llcrnrlon, llcrnrlat=llcrnrlat, urcrnrlon=urcrnrlon, urcrnrlat=urcrnrlat)

# Note: You can define the resolution of the map you just created. Higher 
# resolutions take longer to create.
#    'c' - crude
#    'l' - low
#    'i' - intermediate
#    'h' - high
#    'f' - full

# Draw some map elements on the map
m.drawmapboundary(fill_color='aqua')
m.fillcontinents(color='#ddaa66',lake_color='aqua')
m.drawcoastlines()
m.drawrivers(linewidth=1.0,color='navy',zorder=8)
m.drawcounties(linewidth=1.0, linestyle='solid', color='gray', antialiased=1, facecolor='lightgreen', ax=None, zorder=2, drawbounds=True)
m.drawstates(linewidth=1.5, linestyle='solid', color='black', antialiased=1,zorder=2, )
plt.text(llcrnrlon,llcrnrlat+.5, search, color='black', fontsize=24.5, zorder=6,bbox=dict(facecolor='salmon'))

# Drawing ArcGIS Basemap (only works with cylc projections??)
# Examples of what each map looks like can be found here:
# http://kbkb-wx-python.blogspot.com/2016/04/python-basemap-background-image-from.html
maps = ['ESRI_Imagery_World_2D',    # 0
        'ESRI_StreetMap_World_2D',  # 1
        'NatGeo_World_Map',         # 2
        'NGS_Topo_US_2D',           # 3
        'Ocean_Basemap',            # 4
        'USA_Topo_Maps',            # 5
        'World_Imagery',            # 6
        'World_Physical_Map',       # 7
        'World_Shaded_Relief',      # 8
        'World_Street_Map',         # 9
        'World_Terrain_Base',       # 10
        'World_Topo_Map'            # 11
        ]
print ("drawing image from arcGIS server..."),
m.arcgisimage(service=maps[8], xpixels=1000, verbose=False)
print ("...finished")

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.5)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

Sd=0
Sized=[]
for xd in deaths:
    Sd=0+(float(xd))
    Sized.append(int(Sd))
    #print(int(S))
sd = np.array(Sized)
#print(Sized)
plt.title("COVID-19:\n Cases: (black)\n Deaths(red) \n Location:\n "+search+"\n", fontsize=15, loc='right')
#plt.text(max(LG-1.2),max(LT), search, color='white', fontsize=24)
#x, y = m(lons, lats)  # transform coordinates
x, y = m(LGd, LTd)
xx,yy = m(LG, LT)
plt.xlabel('Longitude',color="white", fontsize=24)
plt.ylabel('Latitute',color="white", fontsize=24)

m.scatter(xx, yy, s=s, color='black', zorder=5, alpha=0.6)
m.scatter(x, y, s=sd, color='r', zorder=10,  alpha=0.6)



#plt.scatter(x, y,  s=s, color="black", zorder=3, alpha=0.6)
#plt.scatter(x, y,  s=sd, color="red", zorder=6, alpha=0.6)
#plt.text(urcrnrlon,urcrnrlat, search, color='white', fontsize=24)
plt.savefig("BaseMap/"+search+"arcGIS__.png", dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)


# Add plot title and other plot elements the normal way
filename0 = "BaseMap/april29_Hotspots__.png"


def draw_blurred_back(img, position, text, font, col, halo_col):
    halo = Image.new('RGBA', img.size, (0, 0, 0, 0))
    ImageDraw.Draw(halo).text(position, text, font = font, fill = halo_col)
    blurred_halo = halo.filter(ImageFilter.BLUR)
    ImageDraw.Draw(blurred_halo).text(position, text, font = font, fill = col)
    return Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))

if __name__ == '__main__':
    
    basewidth = 720
    inp = Image.open(filename0)
    wpercent = (basewidth / float(inp.size[0]))
    hsize = int((float(inp.size[1]) * float(wpercent)))
    inp = inp.resize((basewidth, hsize), Image.ANTIALIAS)
    #img.save(resized_image.jpg')
    
    #inp = inp.resize((640,640), Image.ANTIALIAS)
    font = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 30)
    text_title = (255, 255,230) # bright green
    blur_title = (0, 0, 0)   # black

    i2 = draw_blurred_back(inp, (65, 60), "Plotting COVID-19 Data", font, text_title, blur_title)
    font0 = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 20)
    font1 = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 14)
    font2 = ImageFont.truetype("/home/jack/fonts/PatrickHand-Regular.ttf", 16)
    i2 = draw_blurred_back(i2, (65, 95), "Finding-Hot-Spots.ipynb", font0, text_title, blur_title)
    TXT="https://github.com/JupyterJones/COVID-19-Jupyter-Notebooks"
    draw = ImageDraw.Draw(i2) 
    draw.text((65, 45), TXT, font = font2, align ="left",fill="black")
    #i2 = draw(i2, (15, 65),TXT, font1)    
    
    #txt = Image.new('RGBA', i.size, (255,255,255,0))

    # get a font
    fnt = ImageFont.truetype("/home/jack/fonts/Exo-Black.ttf", 20)
    # get a drawing context
    signature_ = "@jacklnorthrup" 
    #get length in pixel of signature_
    sizeS,ln = fnt.getsize(signature_)
    #add 15 pixels to right border
    pt = sizeS+25
    width, height = inp.size
    #marginx starting point of signature_
    marginx = pt
    #bottom margin
    marginy = 30
    x = width - marginx
    y = height - marginy
    

    text_sig = (255, 255,230) # bright green
    blur_sig = (0, 0, 0)   # black
    txt=draw_blurred_back(i2,(x,y), signature_, fnt, text_sig, blur_sig)
    out = Image.alpha_composite(i2, txt)
    out.save("images/TEMP_POST.png")

CONSUMER_KEY = Key.twiter()[0]
CONSUMER_SECRET = Key.twiter()[1]
ACCESS_KEY = Key.twiter()[2]
ACCESS_SECRET = Key.twiter()[3]
twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)

STR = "Finding-Hot-Spots.ipynb https://github.com/JupyterJones/COVID-19-Jupyter-Notebooks" 

PATH = "images/TEMP_POST.png"
#PATH="BaseMap/april29_Hotspots__.png"
photo = open(PATH,'rb')
#response = twitter.upload_media(media=photo)
#twitter.update_status(status=STR, media_ids=[response['media_id']])

from PIL import Image
IM = Image.open(PATH)
print(IM.size)
IM

from GlobalData import *
print(GlobalData("help"))

from mpl_toolkits.basemap import Basemap
import matplotlib.pyplot as plt


map = Basemap(projection='ortho', 
              lat_0=0, lon_0=0)

map.drawmapboundary(fill_color='aqua')
map.fillcontinents(color='coral',lake_color='aqua')
map.drawcoastlines()


x, y = map(2, 41)
x2, y2 = (-90, 10)

plt.annotate('Barcelona', xy=(x, y),  xycoords='data',
                xytext=(x2, y2), textcoords='offset points',
                color='r',
                arrowprops=dict(arrowstyle="fancy", color='g')
                )

x2, y2 = map(0, 0)
plt.annotate('Barcelona', xy=(x, y),  xycoords='data',
                xytext=(x2, y2), textcoords='data',
                arrowprops=dict(arrowstyle="->")
                )
plt.show()


import warnings
warnings.filterwarnings("ignore")
import matplotlib.pyplot as plt
from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon
import numpy as np
from PIL import Image,ImageFont,ImageDraw,ImageFilter,ImageChops
from random import randint
from mpl_toolkits.basemap import Basemap
fig = plt.figure(num=None, figsize=(12, 8) ) 
m = Basemap(width=6000000,height=4500000,resolution='h',projection='aea',lat_1=35.,lat_2=45,lon_0=-100,lat_0=40)
m.drawcoastlines(linewidth=0.5)
m.fillcontinents(color='tan',lake_color='lightblue')
# draw parallels and meridians.
m.drawparallels(np.arange(-90.,91.,10.),labels=[True,True,False,False],dashes=[2,2])
m.drawmeridians(np.arange(-180.,181.,10.),labels=[False,False,False,True],dashes=[2,2])
m.drawmapboundary(fill_color='lightblue')
m.drawcountries(linewidth=2, linestyle='solid', color='k' ) 
m.drawstates(linewidth=0.5, linestyle='solid', color='k')
m.drawrivers(linewidth=0.5, linestyle='solid', color='blue')
def RndState():
    TX=["Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming"]
    x=randint(1,49)
    return TX[x]

search = RndState()
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/05-08-2020.csv"
#LASTFILE="csse_covid_19_data/csse_covid_19_daily_reports/03-30-2020.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
LATd=[]
LONGd=[]
STATES=[]
cases=[]
deaths =[]
longitude = ""
search = RndState()
for line in DataIn:
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    if search in line[2] and "-" in (line[6]):
        text=line[2],line[1],line[3],line[4],line[5],line[6],line[7],line[8],line[9],line[10]
        STATES.append(text)
        LAT.append(line[5])
        LONG.append(line[6])
        if int(line[8])>0:
            LATd.append(line[5])
            LONGd.append(line[6])        
        cases.append(line[7])
        deaths.append(line[8])
        longitude = longitude+line[6]+","
print(len(STATES))        
LT = np.array(latitude,dtype=np.float)
LG = np.array(longitude,dtype=np.float)
LTd = np.array(LATd,dtype=np.float)
LGd = np.array(LONGd,dtype=np.float)

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.05)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

Sd=0
Sized=[]
for xd in deaths:
    Sd=0+(float(xd)+.05)
    Sized.append(int(Sd))
    #print(int(S))
sd = np.array(Sized)
#print(Sized)
plt.title("COVID-19:\n Cases: (black)\n Deaths(red) \n Location:\n "+search+"\n", fontsize=15, loc='right')
#plt.text(max(LG-1.2),max(LT), search, color='white', fontsize=24)
#x, y = m(lons, lats)  # transform coordinates
longitude = HighestCounts[i][3]
latitude = HighestCounts[i][4]


#x, y = m(longitude,latitude)
x,y = m(LG, LT)
plt.xlabel('Longitude',color="white", fontsize=24)
plt.ylabel('Latitute',color="white", fontsize=24)

#m.scatter(xx, yy, s=s, color='black', zorder=5, alpha=0.6)
m.scatter(x, y, s=20, color='r', zorder=10,  alpha=0.6)

plt.savefig("BaseMap/"+search+"Hotspots1__.png", dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)




%matplotlib inline

# sphinx_gallery_thumbnail_number = 3
import geopandas

# sphinx_gallery_thumbnail_number = 3
import geopandas
geopandas.datasets.available

from geopy.geocoders import Nominatim
geolocator = Nominatim(user_agent="my-application")
loc = geolocator.geocode("New York, NY")
loc


from geopy.geocoders import Nominatim
geolocator = Nominatim(user_agent="my-application")
loc = geolocator.geocode("Eureka Springs, AR")
loc


from geopy.geocoders import Nominatim
geolocator = Nominatim(user_agent="my-application")
loc = geolocator.geocode("Manila, PH")
loc

from geopy.geocoders import Nominatim
geolocator = Nominatim(user_agent="my-application")
loc = geolocator.geocode("Gaya Gaya, Bulacan")
loc

import geopandas
gdf = geopandas.read_file(geopandas.datasets.get_path("naturalearth_cities"))
gdf.crs

import pyproj
crs = pyproj.CRS("EPSG:31370")
crs

%matplotlib inline
import contextily as ctx
df = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))
ax = df.plot(figsize=(12, 12), alpha=0.5, edgecolor='k')
ctx.add_basemap(ax, source=ctx.providers.Stamen.TonerLite, zoom=12)
ax.set_axis_off()


import contextily as ctx
df = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))
ax = df.plot(figsize=(10, 10), alpha=0.5, edgecolor='k')
ctx.add_basemap(ax, zoom=12)

df = geopandas.read_file(geopandas.datasets.get_path('naturalearth_cities'))
ax = df.plot(figsize=(16, 16), alpha=0.5, edgecolor='k')
ctx.add_basemap(ax, zoom=12)

df = geopandas.read_file(geopandas.datasets.get_path('nybb'))
ax = df.plot(figsize=(10, 10), alpha=0.5, edgecolor='k')

df = df.to_crs(epsg=3857)

import contextily as ctx

ax = df.plot(figsize=(10, 10), alpha=0.5, edgecolor='k')
ctx.add_basemap(ax)

ax = df.plot(figsize=(10, 10), alpha=0.5, edgecolor='k')
ctx.add_basemap(ax, zoom=12)

ax = df.plot(figsize=(10, 10), alpha=0.5, edgecolor='k')
ctx.add_basemap(ax, source=ctx.providers.Stamen.TonerLite)
ax.set_axis_off()



!pip install contextily

!pip install descartes

!pip install geopandas



# Create an empty list
ALLdata=[]

URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv"

resp = req.get(URL)
content = resp.text

#clean the content, then break the content into lines 
content=content.replace(",,",",Ex,")
content=content.replace("(","")
content=content.replace(")","")
content=content.replace("\"","")
lines= content.splitlines()
print (len(lines))
# loop the lines one line at a time
# split each line at the delimiter ` , ` 
# then append the empty list 'ALLdata' with the line (which is now a list):  [line]  
for line in lines:
    #convert the splitlines to strings
    line= str(line).split(",")
    ALLdata.append(line)
    
"""
Finding counties with a "threshhold" increase in deaths
Take the last four entries of data to see if the number of deaths has increased for the last three days:
To make it easy to understand lets use dates instead of data.
May10 May11 May12 May13
subract May10 from May11 check if the result is above the 'Threshhold'
subract May11 from May12 check if the result is above the 'Threshhold'
subract May12 from May13 check if the result is above the 'Threshhold'
if all three conditions are met, print the location and information.
"""    
    
Threshhold = 10
count = 0
STATE =[]
COUNTY =[]
Points =[]
HISTORY=[]
lat=[]
long=[]
# Check each line of data, county by county.
for i in range(1,len(ALLdata)):
    # Increase a counter for every line -  this will allow further investigation into the data
    # as demonstarted in the next four cells.
    count=count+1
    # subtract the last four days of data to see if it has increased by the minimum of the Threshhold each day
    if int(ALLdata[i][-3])-int(ALLdata[i][-4]) >Threshhold and int(ALLdata[i][-2])-int(ALLdata[i][-3]) >Threshhold and int(ALLdata[i][-1])-int(ALLdata[i][-2]) >Threshhold:
        # if they do increase as specified, define the line as a variable called history
        history=[int(ALLdata[i][-3])-int(ALLdata[i][-4]),int(ALLdata[i][-2])-int(ALLdata[i][-3]),int(ALLdata[i][-1])-int(ALLdata[i][-2])]
        HISTORY.append(history)
        # The total amount of deaths in the specific county
        deaths = int(ALLdata[i][-1])
        # The county's name
        county = ALLdata[i][5]
        # The State the county is located in
        state = ALLdata[i][6]
        STATE.append(state)
        COUNTY.append(county)
        # The longitude and latitude of the county
        longitude = ALLdata[i][9]
        latitude = ALLdata[i][8]
        long.append(float(longitude))
        lat.append(float(latitude))
        Points.append([float(longitude),float(latitude)])
        #print the data line by line
        print ("i="+str(count),deaths,county,state,longitude,latitude,history)

import matplotlib.pyplot as plt
from matplotlib.legend_handler import HandlerLine2D, HandlerTuple


for i in range(0,len(lat)):
    #p1, = plt.scatter(long,lat, s=1, color='blue')
    p2, = plt.plot(long[i],lat[i], s=20, color='red')

l = plt.legend([(p1, p2)], ['Two keys'], numpoints=1,
               handler_map={tuple: HandlerTuple(ndivide=None)})

import matplotlib.pyplot as plt
import numpy as np

c = np.char.array(COUNTY)
S = np.char.array(STATE)
y = np.array(long)
x =np.array(lat)

inc= len(COUNTY)
colorZ = ['yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan','yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan','navy']
colors = colorZ[-inc:]


plt.scatter(x,y, s=40, color=colors)

labels = ['{0}, {1}'.format(i,j) for i,j in zip(c, S)]



sortlegend0 = [colors[0], labels[0],]
sortlegend1 = [colors[1], labels[1],]
print (sortlegend0,sortlegend1)
plt.legend([(sortlegend0,sortlegend1)], loc='left center', bbox_to_anchor=(-0.1, 1.),
           fontsize=8)

"""
plt.legend(handles=sortlegend, loc='left center', bbox_to_anchor=(-0.1, 1.),
           fontsize=8)
"""
plt.savefig('piechart.png', bbox_inches='tight')


#plt.legend(handles=[line_up, line_down])

text0 = COUNTY
text = STATE
for i in range(len(Points)):
    x = Points[i][0]
    y = Points[i][1]
    tx = text0[i]+", "+text[i]
    xx, yy = m(x,y)
    print(xx, yy)
    #plt.plot(xx, yy, 'bo')
    plt.scatter(xx, yy, s=20, color='red', zorder=5, alpha=0.6)
    plt.text(xx, yy, tx, fontsize=16, color="white")


import warnings
warnings.filterwarnings("ignore")
import matplotlib.pyplot as plt
from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon
import numpy as np
from PIL import Image,ImageFont,ImageDraw,ImageFilter,ImageChops
from random import randint
from mpl_toolkits.basemap import Basemap
import requests as req
import time
DATE = time.strftime("%m-%d-%H_")

# Create an empty list
ALLdata=[]

URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv"

resp = req.get(URL)
content = resp.text

#clean the content, then break the content into lines 
content=content.replace(",,",",Ex,")
content=content.replace("(","")
content=content.replace(")","")
content=content.replace("\"","")
lines= content.splitlines()
print (len(lines))
# loop the lines one line at a time
# split each line at the delimiter ` , ` 
# then append the empty list 'ALLdata' with the line (which is now a list):  [line]  
for line in lines:
    #convert the splitlines to strings
    line= str(line).split(",")
    ALLdata.append(line)
    
"""
Finding counties with a "threshhold" increase in deaths
Take the last four entries of data to see if the number of deaths has increased for the last three days:
To make it easy to understand lets use dates instead of data.
May10 May11 May12 May13
subract May10 from May11 check if the result is above the 'Threshhold'
subract May11 from May12 check if the result is above the 'Threshhold'
subract May12 from May13 check if the result is above the 'Threshhold'
if all three conditions are met, print the location and information.
"""    
    
Threshhold = 10
count = 0
STATE =[]
COUNTY =[]
Points =[]
lat=[]
long=[]
# Check each line of data, county by county.
for i in range(1,len(ALLdata)):
    # Increase a counter for every line -  this will allow further investigation into the data
    # as demonstarted in the next four cells.
    count=count+1
    # subtract the last four days of data to see if it has increased by the minimum of the Threshhold each day
    if int(ALLdata[i][-3])-int(ALLdata[i][-4]) >Threshhold and int(ALLdata[i][-2])-int(ALLdata[i][-3]) >Threshhold and int(ALLdata[i][-1])-int(ALLdata[i][-2]) >Threshhold:
        # if they do increase as specified, define the line as a variable called history
        history=[int(ALLdata[i][-3])-int(ALLdata[i][-4]),int(ALLdata[i][-2])-int(ALLdata[i][-3]),int(ALLdata[i][-1])-int(ALLdata[i][-2])]
        # The total amount of deaths in the specific county
        deaths = int(ALLdata[i][-1])
        # The county's name
        county = ALLdata[i][5]
        # The State the county is located in
        state = ALLdata[i][6]
        STATE.append(state)
        COUNTY.append(county)
        # The longitude and latitude of the county
        longitude = ALLdata[i][9]
        latitude = ALLdata[i][8]
        long.append(float(longitude))
        lat.append(float(latitude))
        Points.append([float(longitude),float(latitude)])
        #print the data line by line
        print ("i="+str(count),deaths,county,state,longitude,latitude,history)
"""
Plot the data on a basemape with annotations of the County namea
""" 

fig = plt.figure(num=None, figsize=(12, 8), dpi=120 ) 
m = Basemap(width=6000000,height=4500000,resolution='h',projection='aea',lat_1=35.,lat_2=45,lon_0=-100,lat_0=40)
m.drawcoastlines(linewidth=0.5)
m.fillcontinents(color='tan',lake_color='lightblue')
# draw parallels and meridians.
m.drawparallels(np.arange(-90.,91.,10.),labels=[True,True,False,False],dashes=[2,2])
m.drawmeridians(np.arange(-180.,181.,10.),labels=[False,False,False,True],dashes=[2,2])
m.drawmapboundary(fill_color='lightblue')
m.drawcountries(linewidth=2, linestyle='solid', color='k' ) 
m.drawstates(linewidth=0.5, linestyle='solid', color='k')
m.drawrivers(linewidth=0.5, linestyle='solid', color='blue')

#-- Place the text in the upper left hand corner of the axes
# The basemap instance doesn't have an annotate method, so we'll use the pyplot
# interface instead.  (This is one of the many reasons to use cartopy instead.)
#plt.annotate('Jul-24-2012', xy=(0, 1), xycoords='axes fraction')
text0 = COUNTY
text = STATE
for i in range(len(Points)):
    x = Points[i][0]
    y = Points[i][1]
    tx = str(text0[i])+", "+str(text[i])
    xx, yy = m(x,y)
    print(xx, yy)
    #plt.plot(xx, yy, 'bo')
    plt.scatter(xx, yy, s=20, color='red', zorder=5, alpha=0.6)
    plt.text(xx, yy, tx, fontsize=16, color="white")

filename = "BaseMap/Hotspots__.png"
plt.savefig(filename, dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)
    
plt.show()



import matplotlib.pyplot as plt
%matplotlib inline
import numpy as np

x = np.linspace(0, 10, 1000)
fig, ax = plt.subplots()
plt.plot(x, np.sin(x), '-b', label='Sine')
plt.plot(x, np.cos(x), '--r', label='Cosine')
plt.axis('equal')
leg = plt.legend();


import requests as req
# Create an empty list
ALLdata=[]

URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv"

resp = req.get(URL)
content = resp.text

#clean the content, then break the content into lines 
content=content.replace(",,",",Ex,")
content=content.replace("(","")
content=content.replace(")","")
content=content.replace("\"","")
lines= content.splitlines()
print (len(lines))
# loop the lines one line at a time
# split each line at the delimiter ` , ` 
# then append the empty list 'ALLdata' with the line (which is now a list):  [line]  
for line in lines:
    #convert the splitlines to strings
    line= str(line).split(",")
    ALLdata.append(line)
    
"""
Finding counties with a "threshhold" increase in deaths for the last three consecutive days.
How to inspect last four entries of data to see if the number of deaths has increased:
To make it easy to understand lets use the following three dates instead of data.
May10 May11 May12 May13
Subract May10 from May11 check if the result is above the 'Threshhold'
Subract May11 from May12 check if the result is above the 'Threshhold'
Subract May12 from May13 check if the result is above the 'Threshhold'
If all three conditions are met, print the location and information.
"""    
    
Threshhold = 25
count = 0
STATE =[]
COUNTY =[]
Points =[]
HISTORY=[]
SUM =[]
SORTED =[]
lat=[]
long=[]
# Check each line of data, county by county.
for i in range(1,len(ALLdata)):
    # Increase a counter for every line -  this will allow further investigation into the data
    # as demonstarted in the next four cells.
    count=count+1
    # subtract the last four days of data to see if it has increased by the minimum of the Threshhold each day
    if int(ALLdata[i][-3])-int(ALLdata[i][-4]) >Threshhold and int(ALLdata[i][-2])-int(ALLdata[i][-3]) >Threshhold and int(ALLdata[i][-1])-int(ALLdata[i][-2]) >Threshhold:
        # if they do increase as specified, define the line as a variable called history
        history=[int(ALLdata[i][-3])-int(ALLdata[i][-4]),int(ALLdata[i][-2])-int(ALLdata[i][-3]),int(ALLdata[i][-1])-int(ALLdata[i][-2])]
        HISTORY.append(history)
        Sum=(int(ALLdata[i][-3])-int(ALLdata[i][-4]))+(int(ALLdata[i][-2])-int(ALLdata[i][-3]))+(int(ALLdata[i][-1])-int(ALLdata[i][-2]))
        SUM.append(Sum)
        # The total amount of deaths in the specific county
        deaths = int(ALLdata[i][-1])
        # The county's name
        county = ALLdata[i][5]
        # The State the county is located in
        state = ALLdata[i][6]
        STATE.append(state)
        COUNTY.append(county)
        # The longitude and latitude of the county
        longitude = ALLdata[i][9]
        latitude = ALLdata[i][8]
        long.append(float(longitude))
        lat.append(float(latitude))
        Points.append([float(longitude),float(latitude)])
        #print the data line by line
        print ("i="+str(count),deaths,county,state,longitude,latitude,history,Sum)
        SORTED.append([Sum,"i="+str(count),deaths,county,state,longitude,latitude,history])

i=315
print(ALLdata[i][5:7])
DataAsString = ALLdata[i][14:]
print (DataAsString)
DataAsInteger = list(map(int, DataAsString))
x = str(ALLdata[i][5:7]).replace(",","").replace("'","")
filename = ''.join(filter(str.isalnum, x))+".png"
print(filename)
print(". . . .")
print(DataAsInteger)

i=314
print(ALLdata[i][5:7])
DataAsString = ALLdata[i][14:]
print (DataAsString)
DataAsInteger = list(map(int, DataAsString))
x = str(ALLdata[i][5:7]).replace(",","").replace("'","")
filename = ''.join(filter(str.isalnum, x))+".png"
print(filename)
print(". . . .")
print(DataAsInteger)

print(ALLdata[i][5:7])

import matplotlib.pyplot as plt
%matplotlib inline
import numpy as np
import time
data = DataAsInteger
variation=[]
previous=0
for i in range(1,len(data)):
    print(data[i]-data[i-1], end = " ")
    variation.append(data[i]-data[i-1])
    
Xv=np.asarray(variation)
Yv = np.asarray(range(0,len(Xv)))

XX = np.asarray(DataAsInteger)
Y = np.asarray(range(0,len(XX)))
fig = plt.figure(num=None, figsize=(5,5), dpi=80, facecolor='salmon')
fig, ax = plt.subplots(2)
fig.suptitle('Vertically stacked subplots')
ax[0].grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
ax[0].plot(Yv,Xv,  '-b', label='Day by Day Variation in Deaths')
ax[1].grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
ax[1].plot(Y,XX, '-r', label='Day by Day Variation in Deaths')
leg = ax[0].legend();
leg = ax[1].legend();
#filename = "images/2"+(time.strftime('%a_%d_%b_%Y_%I_%M_%S_%p.png'))
filename1 = "images/1"+filename+(time.strftime('%I_%M_%S_%p.png'))
fig.savefig(filename, facecolor=fig.get_facecolor(), edgecolor='black')
plt.rcParams['axes.facecolor']='yellow'
#plt.rcParams['savefig.facecolor']='red'
ax[0].set_facecolor((1,1,1,0))
ax[1].set_facecolor("grey")
fig.savefig(filename1, facecolor=(1,1,1,0))
print(filename)
print(filename1)

from PIL import Image
IM=Image.open("images/1HartfordConnecticut.png01_15_03_PM.png")
IM

from PIL import Image
IM=Image.open("FairfieldConnecticut.png")
IM

x = str(ALLdata[i][5:7]).replace(",","").replace("'","")
s = ''.join(filter(str.isalnum, x))
print(s)

x_values = Yv
y_values = Xv
plt.plot(x_values, y_values)
fig = plt.figure(1)
rect = fig.patch
rect.set_facecolor("salmon")

plt.savefig("figure_with_background.png", facecolor=fig.get_facecolor())

import matplotlib.pyplot as plt
%matplotlib inline
import numpy as np


X = np.log10(DataAsInteger)
Y = np.asarray(range(0,len(X)))

XX = np.asarray(DataAsInteger)
YY = np.asarray(range(0,len(XX)))

fig, axs = plt.subplots(2)
fig.suptitle('Vertically stacked subplots')
axs[0].grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
axs[0].plot(Y,X,  '-b', label='Day by Day Variation in Deaths')
axs[1].grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
axs[1].plot(YY,XX, '-r', label='Day by Day Variation in Deaths')

leg = axs.legend();


def normalize(column):
    upper = column.max()
    lower = column.min()
    y = (column - lower)/(upper-lower)
    return y

data = DataAsInteger
variation=[]
previous=0
for i in range(1,len(data)):
    print(data[i]-data[i-1], end = " ")
    variation.append(data[i]-data[i-1])
Xv=np.asarray(variation)
Yv = np.asarray(range(0,len(Xv)))
fig = plt.figure(num=None, figsize=(5,5), dpi=80, facecolor='salmon')
fig, axs = plt.subplots(2)
fig.suptitle('Vertically stacked subplots')
axs[0].grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
axs[0].plot(Yv,Xv,  '-b', label='Day by Day Variation in Deaths')
axs[1].grid(color='lightgray', linestyle='-', linewidth=1)
plt.grid(True)
axs[1].plot(Y,XX, '-r', label='Day by Day Variation in Deaths')

filename = "images/2"+(time.strftime('%a_%d_%b_%Y_%I_%M_%S_%p.png'))
fig.savefig(filename, facecolor=fig.get_facecolor(), edgecolor='black')
print(filename)

filename="images/2Fri_15_May_2020_05_22_44_PM.png"
from PIL import Image
IM=Image.open(filename)
print(IM.size)
IM

import matplotlib.pyplot as plt
%matplotlib inline
import numpy as np

data = DataAsInteger
variation=[]
previous=0
for i in range(1,len(data)):
    print(data[i]-data[i-1], end = " ")
    variation.append(data[i]-data[i-1])
Xv=np.asarray(variation)


#new_list = [x+1 for x in variation]
#Xx=np.log(new_list)

#Y=np.asarray(range(0,len(variation)))
Y = np.linspace(0, 1000, len(X))
fig, ax = plt.subplots()
ax.plot(Y,X, '-b', label='Day by Day Variation in Deaths')
#ax.plot(X, np.cos(X), '--r', label='Cosine')
#ax.axis('equal')
leg = ax.legend();


import numpy as np
import matplotlib.pyplot as plt
import time
list_x = np.asarray(range(0,len(variation)))
list_y = np.asarray(variation)
inc = len(variation)/10
print(inc)

fig = plt.figure(num=None, figsize=(12,12), dpi=120, facecolor='salmon')
#fig = plt.figure()
ax = fig.gca()

#plt.figure()
poly = np.polyfit(list_x,list_y,inc)
poly_y = np.poly1d(poly)(list_x)
plt.plot(list_x,poly_y)
plt.plot(list_x,list_y)

ax.grid(color='lightgray', linestyle='-', linewidth=1)

plt.grid(True)

def listToString(s):  
    # initialize an empty string 
    str1 = " " 
    # return string   
    return (str1.join(s)) 
i=315
print("i: ",i)        
TExt = listToString(ALLdata[i][5:7])
total = "Total Deaths to Date: "+str(ALLdata[i][-1])
plt.text(0,70, TExt, fontsize=30, color="red")
plt.text(0,65, total, fontsize=30, color="red")
plt.xlabel('- Time Span -\nFirst Data Record : January 21, 2020\nhttps://raw.githubusercontent.com/CSSEGISandData/COVID-19/master\n/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv', fontsize=18)
plt.title('Plotting Day by Day Death Variations from:\n https://github.com/JupyterJones/COVID-19-Jupyter-Notebooks\n Orange is actual, Blue is smoothed', fontsize=18)
plt.ylabel('- Variation -', fontsize=18, color="white")
filename = "images/"+(time.strftime('%a_%d_%b_%Y_%I_%M_%S_%p_%Z', time.gmtime())+".png")
fig.savefig(filename, facecolor=fig.get_facecolor(), edgecolor='black')
print(filename)
plt.show()

import numpy as np
import matplotlib.pyplot as plt

list_x = np.asarray(range(0,len(variation)))
list_y = np.asarray(variation)
inc = len(variation)/10
print(inc)

fig = plt.figure(num=None, figsize=(12,12), dpi=80, facecolor='salmon')
#fig = plt.figure()
ax = fig.gca()

#plt.figure()
poly = np.polyfit(list_x,list_y,inc)
poly_y = np.poly1d(poly)(list_x)
plt.plot(list_x,poly_y)
plt.plot(list_x,list_y)
plt.show()

from matplotlib.pyplot import text
from matplotlib import pyplot as plt
import numpy as np
import mpld3
from mpld3 import plugins
import time
%matplotlib inline
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv"
DataIn = open(LASTFILE).readlines()
cases=[]
for line in DataIn:
    if len(line)>10 and 'US' in line and "Recovered" not in line and "Unassigned" not in line:
        line=line.replace("\n","")
        line = line.lstrip(",")
        line = line.split(",")
        End=len(line)-1
        if len(line)>5 and "Florida" in line[6] and "Out of FL" not in line:
            cases.append(line[End])        

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
CITY=[]
deaths=[]
TEXT=[]
cnt = -1
Total=0
SEARCH = "California"
for line in DataIn:
    if len(line)>10 and 'US' in line and "Recovered" not in line and "Unassigned" not in line:
        cnt=cnt+1
        line=line.replace("\n","")
        line = line.lstrip(",")
        line = line.split(",")
        End=len(line)-1
        if len(line)>5 and SEARCH in line[6] and "0.0" not in line:
            if cnt>=1:print(line[5],line[6],line[8],line[9], line[End] )
            Total=Total+int(line[End])
            CITY.append(line[5])
            LAT.append(line[8])
            LONG.append(line[9])
            deaths.append(line[End])        
            text = str(line[2]+' '+line[1]+' '+line[3]+' '+line[4]+' '+line[5]+' '+line[6]+' '+line[7]+' '+line[8]+' '+line[9]+' '+line[10])
            TEXT.append(text)
            
print("Number of Cities: ",len(CITY)) 
print("Total Deaths: ",Total)

LA = LAT
LO = LONG

print(len(LA))
print(len(LO))

DA = np.array(deaths,dtype=np.int)
LT = np.array(LAT,dtype=np.float)
LG = np.array(LONG,dtype=np.float)
print (max(LG))
print (min(LG))
print (min(LT))
print (max(LT))

A = (min(LG))-1
B = (max(LG))+1
C = (min(LT))-1
D = (max(LT))+1

fig = plt.figure(num=None, figsize=(12,12), dpi=80, facecolor='salmon')
#fig = plt.figure()
ax = fig.gca()

#ax.set_facecolor('xkcd:green')
ax.set_facecolor(('#8eda8b'))

Sd=1
Sized=[]
for xd in deaths:
    Sd=2+(float(xd)*1)
    Sized.append(int(Sd))
    #print(int(S))
sd = np.array(Sized)

S=1
Size=[]
for x in cases:
    S=2+(float(x)*1)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)


plt.text(-119, 41, SEARCH, fontsize=26)
#plt.axis([-130,-65,20,55])
plt.axis([A,B,C,D])

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.scatter(LG, LT, s=s, color="black")
plt.scatter(LG, LT, s=sd, color="red")
plt.grid(True)

plt.xlabel('- Longitude -\nFirst Data Record : January 21, 2020', fontsize=18)
plt.title('Using Latitude and Longitude from:\n https://github.com/CSSEGISandData/COVID-19\n Black is Confirmed Cases and the Red are Deaths', fontsize=18)
plt.ylabel('- Latitude -', fontsize=18, color="white")
filename = "images/"+SEARCH+"_"+(time.strftime('%a_%d_%b_%Y_%I_%M_%S_%p_%Z', time.gmtime())+".png")
fig.savefig(filename, facecolor=fig.get_facecolor(), edgecolor='black')
print(filename)
plt.show()

import matplotlib.pyplot as plt
import numpy as np

T = np.array([6, 7, 8, 9, 10, 11, 12])
power = np.array([1.53E+03, 5.92E+02, 2.04E+02, 7.24E+01, 2.72E+01, 1.10E+01, 4.70E+00])

plt.plot(T,power)
plt.show()

from scipy.interpolate import make_interp_spline, BSpline
import numpy as np

#list_x=variation
list_y = np.asarray(range(0,len(variation)))
list_x = np.asarray(variation)

list_x_new = np.linspace(min(list_x), max(list_x), 1000)
list_y_smooth = make_interp_spline(list_x, list_y, list_x_new)

plt.plot(list_x_new, list_y_smooth)
plt.show() 

from scipy.interpolate import make_interp_spline, BSpline

# 300 represents number of points to make between T.min and T.max
xnew = np.linspace(min(variation), max(variation), 300) 
#xnew=np.asarray(variation)
spl = make_interp_spline(variation, power, k=3)  # type: BSpline
power_smooth = spl(xnew)

plt.plot(xnew, power_smooth)
plt.show()

import matplotlib.pyplot as plt
%matplotlib inline
import numpy as np

data = DataAsInteger
variation=[]
previous=0
for i in range(1,len(data)):
    print(data[i]-data[i-1], end = " ")
    variation.append(data[i]-data[i-1])
X=np.asarray(variation)
#Y=np.asarray(range(0,len(variation)))
Y = np.linspace(0, 1000, len(X))
fig, ax = plt.subplots()
ax.plot(Y,X, '-b', label='Day by Day Variation in Deaths')
#ax.plot(X, np.cos(X), '--r', label='Cosine')
ax.axis('equal')
leg = ax.legend();


print("SumLastThreeDays, ItemLine, TotalDeaths, Country, State, Long, Lat, IncreasePerDay(LastThreeDays)\n")
for line in sorted(SORTED, reverse=True):
    print (line)

# To view the header use ALLdata[0] that is the first line:
print ("This is the first line or `The header`.\n",ALLdata[0])

# Use the `i` value ( i=616 ) to view the entire line of data.
# Example:  To see i=616 enter:  616
i =input("Enter a value for `i`: ")
i = int(i)
print ("\nThe data at position ALLdata["+str(i)+"]\n----------\n",ALLdata[i])



for i in range(0,len(COUNTY)):
    #print(COUNTY[i],STATE[i])
    print('{:<12} {:>12}'.format(COUNTY[i],STATE[i]))
    
#Los Angeles  California        

data = DataAsInteger
variation=[]
previous=0
for i in range(1,len(data)):
    print(data[i]-data[i-1], end = " ")
    variation.append(data[i]-data[i-1])




import matplotlib.pyplot as plt
from matplotlib.legend_handler import HandlerLine2D, HandlerTuple
import numpy as np
inc= len(Y)
colorZ = ['yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan','yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan','navy']
colors = colorZ[-inc:]

y=np.asarray(long)
x=np.asarray(lat)


#plt.scatter(y,x, s=40, color=colors)

for i in range(0,len(lat)-1):
    #p1, = plt.plot(float(long[i]),float(lat[i]), color=colors[i])
    plt.scatter(float(long[i]),float(lat[i]), color=colors[i])
    #p3, = plt.text(float(long[i]),float(lat[i]), COUNTY[i])
    #p3, = plt.scatter(float(long[i]),float(lat[i]), color=colors[i])
    print(long[i],lat[i])
    '''
    l = plt.legend([(p2)], ['Two keys'], numpoints=1,
               handler_map={tuple: HandlerTuple(ndivide=None)})
    '''

print(y[1])

colorZ = ['yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan','yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan','navy']

inc= len(y)

colors = colorZ[-inc:]
colorS = colorZ[0:inc]
print(colors)
print(len(colors))
print(colorS)
print(len(colorS))

print(len(y))

negative=plt.scatter(x,y,s=12, color=colors, label='negative')
positive= plt.scatter(y,x,s=6, color=colors,label = 'positive')
plt.legend(handles=[negative,positive])

negative=plt.plot(x,y,linestyle ='dashed', label='negative')
positive= plt.plot(y,x,label = 'positive')
plt.legend(handles=[negative[0],positive[0],])

negative=plt.plot(x,lat,linestyle ='dashed', label='negative')
positive= plt.plot(x,long,label = 'positive')
plt.legend(handles=[negative[0],positive[0]])

import matplotlib.pyplot as plt
import numpy as np

c = np.char.array(COUNTY)
S = np.char.array(STATE)
y = np.array(long)
x =np.array(lat)

inc= len(COUNTY)
colorZ = ['yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan','yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan','navy']
colors = colorZ[-inc:]


plt.scatter(x,y, s=40, color=colors)

labels = ['{0}, {1}'.format(i,j) for i,j in zip(c, S)]



sortlegend0 = [colors[0], labels[0],]
sortlegend1 = [colors[1], labels[1],]
print (sortlegend0,sortlegend1)
#plt.legend([(sortlegend0,sortlegend1)], loc='left center', bbox_to_anchor=(-0.1, 1.),
#           fontsize=8)


#l = plt.legend([(sortlegend0,sortlegend1)], ['Two keys'], numpoints=1,
#               handler_map={tuple: HandlerTuple(ndivide=None)})



"""
plt.legend(handles=sortlegend, loc='left center', bbox_to_anchor=(-0.1, 1.),
           fontsize=8)
"""
plt.savefig('piechart.png', bbox_inches='tight')


#plt.legend(handles=[line_up, line_down])

inc= len(Points)
colorZ = ['yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan','yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan','navy']
colors = colorZ[-inc:]


text0 = COUNTY
text = STATE
for i in range(len(Points)):
    x = Points[i][0]
    y = Points[i][1]
    tx = text0[i]+", "+text[i]
    #xx, yy = m(x,y)
    #print(xx, yy)
    print(x, y)
    print(colors[i])
    c=colors[i]
    #plt.plot(xx, yy, 'bo')
    #plt.scatter(xx, yy, s=20, color=c, zorder=5, alpha=0.6)
    #t = plt.text(xx, yy, tx, fontsize=16, color=c)
    plt.scatter(x, y, s=20, color=c, zorder=5, alpha=0.6)
    t = plt.text(x, y, tx, fontsize=16, color=c)

import warnings
warnings.filterwarnings("ignore")
import matplotlib.pyplot as plt
from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon
import numpy as np
from PIL import Image,ImageFont,ImageDraw,ImageFilter,ImageChops
from random import randint
from mpl_toolkits.basemap import Basemap
import requests as req
import time
DATE = time.strftime("%m-%d-%H_")

# Create an empty list
ALLdata=[]

URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv"

resp = req.get(URL)
content = resp.text

#clean the content, then break the content into lines 
content=content.replace(",,",",Ex,")
content=content.replace("(","")
content=content.replace(")","")
content=content.replace("\"","")
lines= content.splitlines()
print (len(lines))
# loop the lines one line at a time
# split each line at the delimiter ` , ` 
# then append the empty list 'ALLdata' with the line (which is now a list):  [line]  
for line in lines:
    #convert the splitlines to strings
    line= str(line).split(",")
    ALLdata.append(line)
    
"""
Finding counties with a "threshhold" increase in deaths
Take the last four entries of data to see if the number of deaths has increased for the last three days:
To make it easy to understand lets use dates instead of data.
May10 May11 May12 May13
subract May10 from May11 check if the result is above the 'Threshhold'
subract May11 from May12 check if the result is above the 'Threshhold'
subract May12 from May13 check if the result is above the 'Threshhold'
if all three conditions are met, print the location and information.
"""    
    
Threshhold = 10
count = 0
STATE =[]
COUNTY =[]
Points =[]
lat=[]
long=[]
# Check each line of data, county by county.
for i in range(1,len(ALLdata)):
    # Increase a counter for every line -  this will allow further investigation into the data
    # as demonstarted in the next four cells.
    count=count+1
    # subtract the last four days of data to see if it has increased by the minimum of the Threshhold each day
    if int(ALLdata[i][-3])-int(ALLdata[i][-4]) >Threshhold and int(ALLdata[i][-2])-int(ALLdata[i][-3]) >Threshhold and int(ALLdata[i][-1])-int(ALLdata[i][-2]) >Threshhold:
        # if they do increase as specified, define the line as a variable called history
        history=[int(ALLdata[i][-3])-int(ALLdata[i][-4]),int(ALLdata[i][-2])-int(ALLdata[i][-3]),int(ALLdata[i][-1])-int(ALLdata[i][-2])]
        # The total amount of deaths in the specific county
        deaths = int(ALLdata[i][-1])
        # The county's name
        county = ALLdata[i][5]
        # The State the county is located in
        state = ALLdata[i][6]
        STATE.append(state)
        COUNTY.append(county)
        # The longitude and latitude of the county
        longitude = ALLdata[i][9]
        latitude = ALLdata[i][8]
        long.append(float(longitude))
        lat.append(float(latitude))
        Points.append([float(longitude),float(latitude)])
        #print the data line by line
        print ("i="+str(count),deaths,county,state,longitude,latitude,history)
"""
Plot the data on a basemape with annotations of the County namea
""" 

fig = plt.figure(num=None, figsize=(12, 8), dpi=120 ) 
m = Basemap(width=6000000,height=4500000,resolution='h',projection='aea',lat_1=35.,lat_2=45,lon_0=-100,lat_0=40)
m.drawcoastlines(linewidth=0.5)
m.fillcontinents(color='tan',lake_color='lightblue')
# draw parallels and meridians.
m.drawparallels(np.arange(-90.,91.,10.),labels=[True,True,False,False],dashes=[2,2])
m.drawmeridians(np.arange(-180.,181.,10.),labels=[False,False,False,True],dashes=[2,2])
m.drawmapboundary(fill_color='lightblue')
m.drawcountries(linewidth=2, linestyle='solid', color='k' ) 
m.drawstates(linewidth=0.5, linestyle='solid', color='k')
m.drawrivers(linewidth=0.5, linestyle='solid', color='blue')

#-- Place the text in the upper left hand corner of the axes
# The basemap instance doesn't have an annotate method, so we'll use the pyplot
# interface instead.  (This is one of the many reasons to use cartopy instead.)
#plt.annotate('Jul-24-2012', xy=(0, 1), xycoords='axes fraction')
text0 = COUNTY
text = STATE
for i in range(len(Points)):
    x = Points[i][0]
    y = Points[i][1]
    tx = str(text0[i])+", "+str(text[i])
    xx, yy = m(x,y)
    print(xx, yy)
    #plt.plot(xx, yy, 'bo')
    plt.scatter(xx, yy, s=20, color='red', zorder=5, alpha=0.6)
    plt.text(xx, yy, tx, fontsize=10, color="white")

filename = "BaseMap/Hotspots__.png"
plt.savefig(filename, dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)
    
plt.show()



import warnings
warnings.filterwarnings("ignore")
import matplotlib.pyplot as plt
from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon
import numpy as np
from PIL import Image,ImageFont,ImageDraw,ImageFilter,ImageChops
from random import randint
from mpl_toolkits.basemap import Basemap
import requests as req
import time
DATE = time.strftime("%m-%d-%H_")

# Create an empty list
ALLdata=[]

URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv"

resp = req.get(URL)
content = resp.text

#clean the content, then break the content into lines 
content=content.replace(",,",",Ex,")
content=content.replace("(","")
content=content.replace(")","")
content=content.replace("\"","")
lines= content.splitlines()
print (len(lines))
# loop the lines one line at a time
# split each line at the delimiter ` , ` 
# then append the empty list 'ALLdata' with the line (which is now a list):  [line]  
for line in lines:
    #convert the splitlines to strings
    line= str(line).split(",")
    ALLdata.append(line)
    
"""
Finding counties with a "threshhold" increase in deaths
Take the last four entries of data to see if the number of deaths has increased for the last three days:
To make it easy to understand lets use dates instead of data.
May10 May11 May12 May13
subract May10 from May11 check if the result is above the 'Threshhold'
subract May11 from May12 check if the result is above the 'Threshhold'
subract May12 from May13 check if the result is above the 'Threshhold'
if all three conditions are met, print the location and information.
"""    
    
Threshhold = 10
count = 0
STATE =[]
COUNTY =[]
Points =[]
lat=[]
long=[]
# Check each line of data, county by county.
for i in range(1,len(ALLdata)):
    # Increase a counter for every line -  this will allow further investigation into the data
    # as demonstarted in the next four cells.
    count=count+1
    # subtract the last four days of data to see if it has increased by the minimum of the Threshhold each day
    if int(ALLdata[i][-3])-int(ALLdata[i][-4]) >Threshhold and int(ALLdata[i][-2])-int(ALLdata[i][-3]) >Threshhold and int(ALLdata[i][-1])-int(ALLdata[i][-2]) >Threshhold:
        # if they do increase as specified, define the line as a variable called history
        history=[int(ALLdata[i][-3])-int(ALLdata[i][-4]),int(ALLdata[i][-2])-int(ALLdata[i][-3]),int(ALLdata[i][-1])-int(ALLdata[i][-2])]
        # The total amount of deaths in the specific county
        deaths = int(ALLdata[i][-1])
        # The county's name
        county = ALLdata[i][5]
        # The State the county is located in
        state = ALLdata[i][6]
        STATE.append(state)
        COUNTY.append(county)
        # The longitude and latitude of the county
        longitude = ALLdata[i][9]
        latitude = ALLdata[i][8]
        long.append(float(longitude))
        lat.append(float(latitude))
        Points.append([float(longitude),float(latitude)])
        #print the data line by line
        print ("i="+str(count),deaths,county,state,longitude,latitude,history)
"""
Plot the data on a basemape with annotations of the County namea
""" 

fig = plt.figure(num=None, figsize=(12, 8), dpi=120 ) 
m = Basemap(width=6000000,height=4500000,resolution='h',projection='aea',lat_1=35.,lat_2=45,lon_0=-100,lat_0=40)
m.drawcoastlines(linewidth=0.5)
m.fillcontinents(color='tan',lake_color='lightblue')
# draw parallels and meridians.
m.drawparallels(np.arange(-90.,91.,10.),labels=[True,True,False,False],dashes=[2,2])
m.drawmeridians(np.arange(-180.,181.,10.),labels=[False,False,False,True],dashes=[2,2])
m.drawmapboundary(fill_color='lightblue')
m.drawcountries(linewidth=2, linestyle='solid', color='k' ) 
m.drawstates(linewidth=0.5, linestyle='solid', color='k')
m.drawrivers(linewidth=0.5, linestyle='solid', color='blue')

#-- Place the text in the upper left hand corner of the axes
# The basemap instance doesn't have an annotate method, so we'll use the pyplot
# interface instead.  (This is one of the many reasons to use cartopy instead.)
#plt.annotate('Jul-24-2012', xy=(0, 1), xycoords='axes fraction')
text0 = COUNTY
text = STATE
for i in range(len(Points)):
    x = Points[i][0]
    y = Points[i][1]
    tx = str(text0[i])+", "+str(text[i])
    xx, yy = m(x,y)
    print(xx, yy)
    #plt.plot(xx, yy, 'bo')
    plt.scatter(xx, yy, s=20, color='red', zorder=5, alpha=0.6)
    plt.text(xx, yy, tx, fontsize=16, color="white")

filename = "BaseMap/Hotspots__.png"
plt.savefig(filename, dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)
    
plt.show()

from PIL import Image
IM = Image.open(filename)
print (IM.size)
IM

print(history)

text0 = COUNTY
text = STATE
for i in range(len(Points)):
    x = Points[i][0]
    y = Points[i][1]
    tx = text0[i]+", "+text[i]
    xx, yy = m(x,y)
    print(xx, yy)
    #plt.plot(xx, yy, 'bo')
    plt.scatter(xx, yy, s=20, color='red', zorder=5, alpha=0.6)
    plt.text(xx, yy, tx, fontsize=16, color="white")


inc= len(COUNTY)
colors = ['yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan','yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan']

color = colors[-inc:]
print (color)

text0 = COUNTY
text = STATE
for i in range(len(Points)):
    x = Points[i][0]
    y = Points[i][1]
    tx = text0[i]+", "+text[i]
    colorz =color[i]
    xx, yy = m(x,y)
    print(xx, yy)
    #plt.plot(xx, yy, 'bo')
    plt.scatter(xx, yy, s=20, color=colorz, zorder=5, alpha=0.6)
    plt.text(xx, yy, tx, fontsize=16, color="white")


import matplotlib.pyplot as plt
import numpy as np

c = np.char.array(COUNTY)
S = np.char.array(STATE)
y = np.array(long)
x =np.array(lat)

inc= len(COUNTY)
colorZ = ['yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan','yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan','navy']
colors = colorZ[-inc:]


plt.scatter(x,y, s=40, color=colors)

labels = ['{0}, {1}'.format(i,j) for i,j in zip(c, S)]



sortlegend0 = [colors[0], labels[0],]
sortlegend1 = [colors[1], labels[1],]
print (sortlegend)
plt.legend([(sortlegend0,sortlegend1)], loc='left center', bbox_to_anchor=(-0.1, 1.),
           fontsize=8)

"""
plt.legend(handles=sortlegend, loc='left center', bbox_to_anchor=(-0.1, 1.),
           fontsize=8)
"""
plt.savefig('piechart.png', bbox_inches='tight')


#plt.legend(handles=[line_up, line_down])

import matplotlib.pyplot as plt
import numpy as np

c = np.char.array(COUNTY)
S = np.char.array(STATE)
y = np.array(long)
x =np.array(lat)

inc= len(COUNTY)
colorZ = ['yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan','yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan','navy']
colors = colorZ[-inc:]


plt.scatter(x,y, s=40, color=colors)

labels = ['{0}, {1}'.format(i,j) for i,j in zip(c, S)]



sortlegend0 = [colors[0], labels[0],]
sortlegend1 = [colors[1], labels[1],]
print (sortlegend)
plt.legend([(sortlegend0,sortlegend1)], loc='left center', bbox_to_anchor=(-0.1, 1.),
           fontsize=8)

"""
plt.legend(handles=sortlegend, loc='left center', bbox_to_anchor=(-0.1, 1.),
           fontsize=8)
"""
plt.savefig('piechart.png', bbox_inches='tight')


#plt.legend(handles=[line_up, line_down])

import matplotlib.patches as mpatches
import matplotlib.pyplot as plt

red_patch = mpatches.Patch(color=colors, label=labels)
plt.legend(handles=[red_patch])

plt.show()

A,B = [colors, labels]
print(A)

import matplotlib.pyplot as plt
import numpy as np
#Legend, = color, label =  [colors, labels]
A,B = [colors, labels]

Legend= [A, B]
plt.legend(handles=Legend, loc='left center', bbox_to_anchor=(-0.1, 1.),fontsize=8)

sort_legend = True
if sort_legend:
    colors, labels =  zip(*colors, labels,
                                          key=lambda x: x[1],
                                          reverse=True)
print(colors, labels)

import matplotlib.pyplot as plt
import numpy as np

c = np.char.array(COUNTY)
S = np.char.array(STATE)
y = np.array(long)
x =np.array(lat)

inc= len(COUNTY)
colors = ['yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan','yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan']
colorz = colors[-inc:]
#Cc = np.char.array(colors)

plt.scatter(x,y, s=40, color=colorz)


labels = ['{0}, {1}'.format(i,j) for i,j in zip(c, S)]

sort_legend = True
if sort_legend:
    colors, labels =  zip(*sorted(zip(colorz, labels),
                                          key=lambda x: x[1],
                                          reverse=True))
    print(colorz, labels)
plt.legend(colors, labels, loc='left center', bbox_to_anchor=(-0.1, 1.),
           fontsize=8)

plt.savefig('piechart.png', bbox_inches='tight')

import matplotlib.pyplot as plt
import numpy as np

x = np.char.array(COUNTRY)
y = np.array([234, 64, 54,10, 0, 1, 0, 9, 2, 1, 7, 7])
colors = ['yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan']
porcent = 100.*y/y.sum()

patches, texts = plt.pie(y, colors=colors, startangle=90, radius=1.2)
labels = ['{0} - {1:1.2f} %'.format(i,j) for i,j in zip(x, porcent)]

sort_legend = True
if sort_legend:
    patches, labels, dummy =  zip(*sorted(zip(patches, labels, y),
                                          key=lambda x: x[2],
                                          reverse=True))

plt.legend(patches, labels, loc='left center', bbox_to_anchor=(-0.1, 1.),
           fontsize=8)

plt.savefig('piechart.png', bbox_inches='tight')

import matplotlib.pyplot as plt
import numpy as np

x = np.char.array(['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct', 'Nov','Dec'])
y = np.array([234, 64, 54,10, 0, 1, 0, 9, 2, 1, 7, 7])
colors = ['yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan']
porcent = 100.*y/y.sum()

patches, texts = plt.pie(y, colors=colors, startangle=90, radius=1.2)
labels = ['{0} - {1:1.2f} %'.format(i,j) for i,j in zip(x, porcent)]

sort_legend = True
if sort_legend:
    patches, labels, dummy =  zip(*sorted(zip(patches, labels, y),
                                          key=lambda x: x[2],
                                          reverse=True))

plt.legend(patches, labels, loc='left center', bbox_to_anchor=(-0.1, 1.),
           fontsize=8)

plt.savefig('piechart.png', bbox_inches='tight')

from mpl_toolkits.basemap import Basemap
import matplotlib.pyplot as plt
m = Basemap(width=120000,height=90000,projection='aeqd',
            resolution=None,lat_0=30.,lon_0=80.)
lats=[30.0,30.1,30.2,30.0,30.1,30.2]
lons=[80.0,80.1,80.2,80.3,80.4,80.5]
m.bluemarble()
x, y = m(lons,lats)
labels=['Point1','Point2','Point3','Point4','Point5','Point6']
m.scatter(x,y,10,marker='o',color='k')
for label, xpt, ypt in zip(labels, x, y):
    plt.text(xpt + 10, ypt + 10, label, size=20)
plt.show()

import requests as req
import time
DATE = time.strftime("%m-%d-%H_")

# Create an empty list
ALLdata=[]

URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv"

resp = req.get(URL)
content = resp.text

#clean the content, then break the content into lines 
content=content.replace(",,",",Ex,")
content=content.replace("(","")
content=content.replace(")","")
content=content.replace("\"","")
lines= content.splitlines()
print (len(lines))
# loop the lines one line at a time
# split each line at the delimiter ` , ` 
# then append the empty list 'ALLdata' with the line (which is now a list):  [line]  
for line in lines:
    #convert the splitlines to strings
    line= str(line).split(",")
    ALLdata.append(line)
    
    

Threshhold = 15
count = 0
STATE =[]
Points =[]
# Check each line of data, county by county.
for i in range(1,len(ALLdata)):
    # Increase a counter for every line -  this will allow further investigation into the data
    # as demonstarted in the next four cells.
    count=count+1
    # subtract the last four days of data to see if it has increased by the minimum of the Threshhold each day
    if int(ALLdata[i][-3])-int(ALLdata[i][-4]) >Threshhold and int(ALLdata[i][-2])-int(ALLdata[i][-3]) >Threshhold and int(ALLdata[i][-1])-int(ALLdata[i][-2]) >Threshhold:
        # if they do increase as specified, define the line as a variable called history
        history=[int(ALLdata[i][-3])-int(ALLdata[i][-4]),int(ALLdata[i][-2])-int(ALLdata[i][-3]),int(ALLdata[i][-1])-int(ALLdata[i][-2])]
        # The total amount of deaths in the specific county
        deaths = int(ALLdata[i][-1])
        # The county's name
        county = ALLdata[i][5]
        # The State the county is located in
        state = ALLdata[i][6]
        STATE.append(state)
        # The longitude and latitude of the county
        longitude = ALLdata[i][9]
        latitude = ALLdata[i][8]
        Points.append([float(longitude),float(latitude)])
        #print the data line by line
        print ("i="+str(count),deaths,county,state,longitude,latitude,history)
        

print (Points)
#points = [[-118.22824109999999,34.30828379],[-87.81658794,41.84144849],[-72.8012172,40.88320119]]
print (STATE)

print(Points[0][1])

import matplotlib.pyplot as plt


#text = [['Los Angeles'],['Cook'],['Suffolk']]
text = STATE
for i in range(len(Points)):
    x = Points[i][0]
    y = Points[i][1]
    xx = text[i]
    plt.plot(x, y, 'bo')
    plt.text(x , y , xx, fontsize=12)

plt.xlim((-120, -50))
plt.ylim((30, 50))
plt.show()

MAX=[max(points[0]),max(points[1]),max(points[2])]
MIN=[min(points[0]),min(points[1]),min(points[2])]

print(min(MIN),max(MIN))
print(min(MAX),max(MAX))

import matplotlib.pyplot as plt

points = [[-118.22824109999999,34.30828379],[-87.81658794,41.84144849],[-72.8012172,40.88320119]]
text = ['Los Angeles','Cook','Suffolk']
for i in range(len(points)):
    x = points[i][0]
    y = points[i][1]
    xx = text[i]
    plt.plot(x, y, 'bo')
    plt.text(x , y , xx, fontsize=12)

#plt.xlim((-120, -50))
#plt.ylim((30, 50))
plt.xlim(min(MIN),max(MIN))
plt.ylim(min(MAX),max(MAX))

plt.show()

import warnings
warnings.filterwarnings("ignore")
import matplotlib.pyplot as plt
from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon
import numpy as np
from PIL import Image,ImageFont,ImageDraw,ImageFilter,ImageChops
from random import randint
from mpl_toolkits.basemap import Basemap
fig = plt.figure(num=None, figsize=(12, 8), dpi=300 ) 
m = Basemap(width=6000000,height=4500000,resolution='h',projection='aea',lat_1=35.,lat_2=45,lon_0=-100,lat_0=40)
m.drawcoastlines(linewidth=0.5)
m.fillcontinents(color='tan',lake_color='lightblue')
# draw parallels and meridians.
m.drawparallels(np.arange(-90.,91.,10.),labels=[True,True,False,False],dashes=[2,2])
m.drawmeridians(np.arange(-180.,181.,10.),labels=[False,False,False,True],dashes=[2,2])
m.drawmapboundary(fill_color='lightblue')
m.drawcountries(linewidth=2, linestyle='solid', color='k' ) 
m.drawstates(linewidth=0.5, linestyle='solid', color='k')
m.drawrivers(linewidth=0.5, linestyle='solid', color='blue')

#-- Place the text in the upper left hand corner of the axes
# The basemap instance doesn't have an annotate method, so we'll use the pyplot
# interface instead.  (This is one of the many reasons to use cartopy instead.)
#plt.annotate('Jul-24-2012', xy=(0, 1), xycoords='axes fraction')
text = STATE
for i in range(len(Points)):
    x = Points[i][0]
    y = Points[i][1]
    tx = text[i]
    xx, yy = m(x,y)
    print(xx, yy)
    #plt.plot(xx, yy, 'bo')
    plt.scatter(xx, yy, s=20, color='red', zorder=5, alpha=0.6)
    plt.text(xx, yy, tx, fontsize=12)


plt.savefig("BaseMap/Hotspots__.png", dpi=300, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)
    
plt.show()

import warnings
warnings.filterwarnings("ignore")
import matplotlib.pyplot as plt
from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon
import numpy as np
from PIL import Image,ImageFont,ImageDraw,ImageFilter,ImageChops
from random import randint
from mpl_toolkits.basemap import Basemap
fig = plt.figure(num=None, figsize=(12, 8) ) 
m = Basemap(width=6000000,height=4500000,resolution='h',projection='aea',lat_1=35.,lat_2=45,lon_0=-100,lat_0=40)
m.drawcoastlines(linewidth=0.5)
m.fillcontinents(color='tan',lake_color='lightblue')
# draw parallels and meridians.
m.drawparallels(np.arange(-90.,91.,10.),labels=[True,True,False,False],dashes=[2,2])
m.drawmeridians(np.arange(-180.,181.,10.),labels=[False,False,False,True],dashes=[2,2])
m.drawmapboundary(fill_color='lightblue')
m.drawcountries(linewidth=2, linestyle='solid', color='k' ) 
m.drawstates(linewidth=0.5, linestyle='solid', color='k')
m.drawrivers(linewidth=0.5, linestyle='solid', color='blue')
def RndState():
    TX=["Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming"]
    x=randint(1,49)
    return TX[x]

search = RndState()
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/05-12-2020.csv"
#LASTFILE="csse_covid_19_data/csse_covid_19_daily_reports/03-30-2020.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
LATd=[]
LONGd=[]
STATES=[]
cases=[]
deaths =[]
longitude = ""
search = RndState()
for line in DataIn:
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    #if search in line[2] and "-" in (line[6]):
    if len(line[2])>0 and "-" in (line[6]):    
        text=line[2],line[1],line[3],line[4],line[5],line[6],line[7],line[8],line[9],line[10]
        STATES.append(text)
        LAT.append(line[5])
        LONG.append(line[6])
        if int(line[8])>0:
            LATd.append(line[5])
            LONGd.append(line[6])        
        cases.append(line[7])
        deaths.append(line[8])
        longitude = longitude+line[6]+","
print(len(STATES))        
LT = np.array(LAT,dtype=np.float)
LG = np.array(LONG,dtype=np.float)
LTd = np.array(LATd,dtype=np.float)
LGd = np.array(LONGd,dtype=np.float)

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.05)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

Sd=0
Sized=[]
for xd in deaths:
    Sd=0+(float(xd)+.05)
    Sized.append(int(Sd))
    #print(int(S))
sd = np.array(Sized)
#print(Sized)
plt.title("COVID-19:\n Cases: (black)\n Deaths(red) \n Location:\n "+search+"\n", fontsize=15, loc='right')
#plt.text(max(LG-1.2),max(LT), search, color='white', fontsize=24)
#x, y = m(lons, lats)  # transform coordinates
x, y = m(LGd, LTd)
xx,yy = m(LG, LT)
plt.xlabel('Longitude',color="white", fontsize=24)
plt.ylabel('Latitute',color="white", fontsize=24)

m.scatter(xx, yy, s=s, color='black', zorder=5, alpha=0.6)
m.scatter(x, y, s=sd, color='r', zorder=10,  alpha=0.6)

plt.savefig("BaseMap/"+search+"Hotspots1__.png", dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)




from matplotlib.pyplot import text
from matplotlib import pyplot as plt
import numpy as np
import mpld3
from mpld3 import plugins
import time
%matplotlib inline
#LASTFILE="DATA/Download.csv"
#DataIn = open(LASTFILE).readlines()
cases=[]
#cnt=cnt+1
#for line in DataIn:
#    line = line.split(",")
#    if cnt==0:print(line)

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
CITY=[]
deaths=[]
TEXT=[]
cnt = -1
Total=0
SEARCH = "Mississippi"
for line in DataIn:
    if len(line)>10 and 'US' in line and "Recovered" not in line and "Unassigned" not in line:
        cnt=cnt+1
        line=line.replace("\n","")
        line = line.lstrip(",")
        line = line.split(",")
        End=len(line)-1
        if len(line)>5 and SEARCH in line[6] and "0.0" not in line:
            
            if cnt>=1 and cnt<=5:print(line[5],line[6],line[8],line[9], line[End] )
            Total=Total+int(line[End])
            CITY.append(line[5])
            LAT.append(line[8])
            LONG.append(line[9])
            cases.append(line[9])
            deaths.append(line[End])        
            TText = str(line[2]+' '+line[1]+' '+line[3]+' '+line[4]+' '+line[5]+' '+line[6]+' '+line[7]+' '+line[8]+' '+line[9]+' '+line[10])
            if cnt==10:print("TTEXT: ",TText)
            TEXT.append(TText)
            
print("Number of Cities: ",len(CITY)) 
print("Total Deaths: ",Total)

LA = LAT
LO = LONG

print(len(LA))
print(len(LO))

DA = np.array(deaths,dtype=np.int)
LT = np.array(LAT,dtype=np.float)
LG = np.array(LONG,dtype=np.float)
print (max(LG))
print (min(LG))
print (min(LT))
print (max(LT))

print(deaths[-1])


A = (min(LG))-1
B = (max(LG))+1
C = (min(LT))-1
D = (max(LT))+1

fig = plt.figure(num=None, figsize=(12,12), dpi=80, facecolor='salmon')
#fig = plt.figure()
ax = fig.gca()
ax.set_facecolor(('#8eda8b'))

Sd=5
Sized=[]
for xd in deaths:
    Sd=2+(float(xd)*1)
    Sized.append(int(Sd))
    #print(int(S))
sd = np.array(Sized)

S=5
Size=[]
for x in cases:
    S=2+(float(x)*2)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

plt.text(A+.5, D-.5, SEARCH, fontsize=26)
#plt.axis([-130,-65,20,55])
plt.axis([A,B,C,D])

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.scatter(LG, LT, s=sd, color="red")
plt.scatter(LG, LT, s=s, color="black")

plt.grid(True)

plt.xlabel('- Longitude -\nFirst Data Record : January 21, 2020', fontsize=18)
plt.title('Using Latitude and Longitude from:\n https://github.com/CSSEGISandData/COVID-19\n Black is Confirmed Cases and the Red are Deaths', fontsize=18)
plt.ylabel('- Latitude -', fontsize=18, color="white")
filename = "images/"+SEARCH+"_"+(time.strftime('%a_%d_%b_%Y_%I_%M_%S_%p_%Z', time.gmtime())+".png")
fig.savefig(filename, facecolor=fig.get_facecolor(), edgecolor='black')
print(filename)
plt.show()



!find /home/jack/miniconda3 -name gshhs_h.dat

!sudo updatedb

!locate gshhs_h.dat 

!conda install basemap-data-hires

!locate share/proj

!mkdir BaseMap

import sys
sys.path.append("/home/jack/miniconda3/envs/deep/lib/python3.7/site-packages/") # go to parent dir
#from customFunctions import *

import os
import sys
os.environ['PROJ_LIB'] = '/home/jack/miniconda3/envs/deep/share/proj'
sys.path.append("/home/jack/miniconda3/envs/deep/lib/python3.7/site-packages/") # go to parent dir

!wget https://anaconda.org/conda-forge/basemap-data-hires/1.2.1/download/linux-64/basemap-data-hires-1.2.1-0.tar.bz2

!conda install --offline ./basemap-data-hires-1.2.2-0.tar.bz2

!wget https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv

datafile = open("time_series_covid19_deaths_US.csv", "r")
count = 0
for data in datafile:
    count=count+1
    if "Ohio" in data:
        print ("XXXXX",count,data)

import os
os.environ['PROJ_LIB'] = '/home/jack/miniconda3/envs/deep/share/proj'
import warnings
warnings.filterwarnings("ignore")
import matplotlib.pyplot as plt
from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon
import numpy as np
from PIL import Image,ImageFont,ImageDraw,ImageFilter,ImageChops
from random import randint
from mpl_toolkits.basemap import Basemap
import requests as req
import time
DATE = time.strftime("%m-%d-%H_")

# Create an empty list
ALLdata=[]

URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv"
#https://raw.githubusercontent.com/CSSEGISandData/COVID-19/
#master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv
resp = req.get(URL)
content = resp.text

#clean the content, then break the content into lines 
content=content.replace(",,",",Ex,")
content=content.replace("(","")
content=content.replace(")","")
content=content.replace("\"","")
lines= content.splitlines()
print (len(lines))
# loop the lines one line at a time
# split each line at the delimiter ` , ` 
# then append the empty list 'ALLdata' with the line (which is now a list):  [line]  
for line in lines:
    #convert the splitlines to strings
    line= str(line).split(",")
    ALLdata.append(line)
    
"""
Finding counties with a "threshhold" increase in deaths
Take the last four entries of data to see if the number of deaths has increased for the last three days:
To make it easy to understand lets use dates instead of data.
May10 May11 May12 May13
subract May10 from May11 check if the result is above the 'Threshhold'
subract May11 from May12 check if the result is above the 'Threshhold'
subract May12 from May13 check if the result is above the 'Threshhold'
if all three conditions are met, print the location and information.
"""    
    
Threshhold = 10
count = 0
STATE =[]
COUNTY =[]
Points =[]
lat=[]
long=[]
# Check each line of data, county by county.
for i in range(1,len(ALLdata)):
    # Increase a counter for every line -  this will allow further investigation into the data
    # as demonstarted in the next four cells.
    count=count+1
    # subtract the last four days of data to see if it has increased by the minimum of the Threshhold each day
    if int(ALLdata[i][-3])-int(ALLdata[i][-4]) >Threshhold and int(ALLdata[i][-2])-int(ALLdata[i][-3]) >Threshhold and int(ALLdata[i][-1])-int(ALLdata[i][-2]) >Threshhold:
        # if they do increase as specified, define the line as a variable called history
        history=[int(ALLdata[i][-3])-int(ALLdata[i][-4]),int(ALLdata[i][-2])-int(ALLdata[i][-3]),int(ALLdata[i][-1])-int(ALLdata[i][-2])]
        # The total amount of deaths in the specific county
        deaths = int(ALLdata[i][-1])
        # The county's name
        county = ALLdata[i][5]
        # The State the county is located in
        state = ALLdata[i][6]
        STATE.append(state)
        COUNTY.append(county)
        # The longitude and latitude of the county
        longitude = ALLdata[i][9]
        latitude = ALLdata[i][8]
        long.append(float(longitude))
        lat.append(float(latitude))
        Points.append([float(longitude),float(latitude)])
        #print the data line by line
        print ("i="+str(count),deaths,county,state,longitude,latitude,history)
"""
Plot the data on a basemape with annotations of the County namea
""" 

fig = plt.figure(num=None, figsize=(12, 8), dpi=120 ) 
m = Basemap(width=6000000,height=4500000,resolution='h',projection='aea',lat_1=35.,lat_2=45,lon_0=-100,lat_0=40)
m.drawcoastlines(linewidth=0.5)
m.fillcontinents(color='tan',lake_color='lightblue')
# draw parallels and meridians.
m.drawparallels(np.arange(-90.,91.,10.),labels=[True,True,False,False],dashes=[2,2])
m.drawmeridians(np.arange(-180.,181.,10.),labels=[False,False,False,True],dashes=[2,2])
m.drawmapboundary(fill_color='lightblue')
m.drawcountries(linewidth=2, linestyle='solid', color='k' ) 
m.drawstates(linewidth=0.5, linestyle='solid', color='k')
m.drawrivers(linewidth=0.5, linestyle='solid', color='blue')

#-- Place the text in the upper left hand corner of the axes
# The basemap instance doesn't have an annotate method, so we'll use the pyplot
# interface instead.  (This is one of the many reasons to use cartopy instead.)
#plt.annotate('Jul-24-2012', xy=(0, 1), xycoords='axes fraction')
text0 = COUNTY
text = STATE
for i in range(len(Points)):
    x = Points[i][0]
    y = Points[i][1]
    tx = str(text0[i])+", "+str(text[i])
    xx, yy = m(x,y)
    print(xx, yy)
    #plt.plot(xx, yy, 'bo')
    plt.scatter(xx, yy, s=20, color='red', zorder=5, alpha=0.6)
    plt.text(xx, yy, tx, fontsize=16, color="white")

filename = "BaseMap/Hotspots__.png"
plt.savefig(filename, dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)
    
plt.show()

from PIL import Image
IM = Image.open(filename)
print (IM.size)
IM

text0 = COUNTY
text = STATE
for i in range(len(Points)):
    x = Points[i][0]
    y = Points[i][1]
    tx = text0[i]+", "+text[i]
    xx, yy = m(x,y)
    print(xx, yy)
    #plt.plot(xx, yy, 'bo')
    plt.scatter(xx, yy, s=20, color='red', zorder=5, alpha=0.6)
    plt.text(xx, yy, tx, fontsize=16, color="white")


inc= len(COUNTY)
colors = ['yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan','yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan']

color = colors[-inc:]
print (color)

print(Points)

text0 = COUNTY
text = STATE
for i in range(len(Points)):
    x = Points[i][0]
    y = Points[i][1]
    tx = text0[i]+", "+text[i]
    colorz =color[i]
    xx, yy = m(x,y)
    print(xx, yy)
    #plt.plot(xx, yy, 'bo')
    plt.scatter(xx, yy, s=20, color=colorz, zorder=5, alpha=0.6)
    plt.text(xx, yy, tx, fontsize=16, color="white")


import matplotlib.pyplot as plt
import numpy as np

c = np.char.array(COUNTY)
S = np.char.array(STATE)
y = np.array(long)
x =np.array(lat)

inc= len(COUNTY)
colorZ = ['yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan','yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan','navy']
colors = colorZ[-inc:]


plt.scatter(x,y, s=40, color=colors)

labels = ['{0}, {1}'.format(i,j) for i,j in zip(c, S)]



sortlegend0 = [colors[0], labels[0],]
sortlegend1 = [colors[1], labels[1],]
print (sortlegend)
plt.legend([(sortlegend0,sortlegend1)], loc='left center', bbox_to_anchor=(-0.1, 1.),
           fontsize=8)

"""
plt.legend(handles=sortlegend, loc='left center', bbox_to_anchor=(-0.1, 1.),
           fontsize=8)
"""
plt.savefig('piechart.png', bbox_inches='tight')


#plt.legend(handles=[line_up, line_down])

import matplotlib.pyplot as plt
import numpy as np

c = np.char.array(COUNTY)
S = np.char.array(STATE)
y = np.array(long)
x =np.array(lat)

inc= len(COUNTY)
colorZ = ['yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan','yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan','navy']
colors = colorZ[-inc:]


plt.scatter(x,y, s=40, color=colors)

labels = ['{0}, {1}'.format(i,j) for i,j in zip(c, S)]



sortlegend0 = [colors[0], labels[0],]
sortlegend1 = [colors[1], labels[1],]
print (sortlegend)
plt.legend([(sortlegend0,sortlegend1)], loc='left center', bbox_to_anchor=(-0.1, 1.),
           fontsize=8)

"""
plt.legend(handles=sortlegend, loc='left center', bbox_to_anchor=(-0.1, 1.),
           fontsize=8)
"""
plt.savefig('piechart.png', bbox_inches='tight')


#plt.legend(handles=[line_up, line_down])

import matplotlib.patches as mpatches
import matplotlib.pyplot as plt

red_patch = mpatches.Patch(color=colors, label=labels)
plt.legend(handles=[red_patch])

plt.show()

A,B = [colors, labels]
print(A)

import matplotlib.pyplot as plt
import numpy as np
#Legend, = color, label =  [colors, labels]
A,B = [colors, labels]

Legend= [A, B]
plt.legend(handles=Legend, loc='left center', bbox_to_anchor=(-0.1, 1.),fontsize=8)

sort_legend = True
if sort_legend:
    colors, labels =  zip(*colors, labels,
                                          key=lambda x: x[1],
                                          reverse=True)
print(colors, labels)

import matplotlib.pyplot as plt
import numpy as np

c = np.char.array(COUNTY)
S = np.char.array(STATE)
y = np.array(long)
x =np.array(lat)

inc= len(COUNTY)
colors = ['yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan','yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan']
colorz = colors[-inc:]
#Cc = np.char.array(colors)

plt.scatter(x,y, s=40, color=colorz)


labels = ['{0}, {1}'.format(i,j) for i,j in zip(c, S)]

sort_legend = True
if sort_legend:
    colors, labels =  zip(*sorted(zip(colorz, labels),
                                          key=lambda x: x[1],
                                          reverse=True))
    print(colorz, labels)
plt.legend(colors, labels, loc='left center', bbox_to_anchor=(-0.1, 1.),
           fontsize=8)

plt.savefig('piechart.png', bbox_inches='tight')

import matplotlib.pyplot as plt
import numpy as np

x = np.char.array(COUNTRY)
y = np.array([234, 64, 54,10, 0, 1, 0, 9, 2, 1, 7, 7])
colors = ['yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan']
porcent = 100.*y/y.sum()

patches, texts = plt.pie(y, colors=colors, startangle=90, radius=1.2)
labels = ['{0} - {1:1.2f} %'.format(i,j) for i,j in zip(x, porcent)]

sort_legend = True
if sort_legend:
    patches, labels, dummy =  zip(*sorted(zip(patches, labels, y),
                                          key=lambda x: x[2],
                                          reverse=True))

plt.legend(patches, labels, loc='left center', bbox_to_anchor=(-0.1, 1.),
           fontsize=8)

plt.savefig('piechart.png', bbox_inches='tight')

import matplotlib.pyplot as plt
import numpy as np

x = np.char.array(['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct', 'Nov','Dec'])
y = np.array([234, 64, 54,10, 0, 1, 0, 9, 2, 1, 7, 7])
colors = ['yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan']
porcent = 100.*y/y.sum()

patches, texts = plt.pie(y, colors=colors, startangle=90, radius=1.2)
labels = ['{0} - {1:1.2f} %'.format(i,j) for i,j in zip(x, porcent)]

sort_legend = True
if sort_legend:
    patches, labels, dummy =  zip(*sorted(zip(patches, labels, y),
                                          key=lambda x: x[2],
                                          reverse=True))

plt.legend(patches, labels, loc='left center', bbox_to_anchor=(-0.1, 1.),
           fontsize=8)

plt.savefig('piechart.png', bbox_inches='tight')

from mpl_toolkits.basemap import Basemap
import matplotlib.pyplot as plt
m = Basemap(width=120000,height=90000,projection='aeqd',
            resolution=None,lat_0=30.,lon_0=80.)
lats=[30.0,30.1,30.2,30.0,30.1,30.2]
lons=[80.0,80.1,80.2,80.3,80.4,80.5]
m.bluemarble()
x, y = m(lons,lats)
labels=['Point1','Point2','Point3','Point4','Point5','Point6']
m.scatter(x,y,10,marker='o',color='k')
for label, xpt, ypt in zip(labels, x, y):
    plt.text(xpt + 10, ypt + 10, label, size=20)
plt.show()

import requests as req
import time
DATE = time.strftime("%m-%d-%H_")

# Create an empty list
ALLdata=[]

URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv"

resp = req.get(URL)
content = resp.text

#clean the content, then break the content into lines 
content=content.replace(",,",",Ex,")
content=content.replace("(","")
content=content.replace(")","")
content=content.replace("\"","")
lines= content.splitlines()
print (len(lines))
# loop the lines one line at a time
# split each line at the delimiter ` , ` 
# then append the empty list 'ALLdata' with the line (which is now a list):  [line]  
for line in lines:
    #convert the splitlines to strings
    line= str(line).split(",")
    ALLdata.append(line)
    
    

Threshhold = 15
count = 0
STATE =[]
Points =[]
# Check each line of data, county by county.
for i in range(1,len(ALLdata)):
    # Increase a counter for every line -  this will allow further investigation into the data
    # as demonstarted in the next four cells.
    count=count+1
    # subtract the last four days of data to see if it has increased by the minimum of the Threshhold each day
    if int(ALLdata[i][-3])-int(ALLdata[i][-4]) >Threshhold and int(ALLdata[i][-2])-int(ALLdata[i][-3]) >Threshhold and int(ALLdata[i][-1])-int(ALLdata[i][-2]) >Threshhold:
        # if they do increase as specified, define the line as a variable called history
        history=[int(ALLdata[i][-3])-int(ALLdata[i][-4]),int(ALLdata[i][-2])-int(ALLdata[i][-3]),int(ALLdata[i][-1])-int(ALLdata[i][-2])]
        # The total amount of deaths in the specific county
        deaths = int(ALLdata[i][-1])
        # The county's name
        county = ALLdata[i][5]
        # The State the county is located in
        state = ALLdata[i][6]
        STATE.append(state)
        # The longitude and latitude of the county
        longitude = ALLdata[i][9]
        latitude = ALLdata[i][8]
        Points.append([float(longitude),float(latitude)])
        #print the data line by line
        print ("i="+str(count),deaths,county,state,longitude,latitude,history)
        

print (Points)
#points = [[-118.22824109999999,34.30828379],[-87.81658794,41.84144849],[-72.8012172,40.88320119]]
print (STATE)

print(Points[0][1])

import matplotlib.pyplot as plt


#text = [['Los Angeles'],['Cook'],['Suffolk']]
text = STATE
for i in range(len(Points)):
    x = Points[i][0]
    y = Points[i][1]
    xx = text[i]
    plt.plot(x, y, 'bo')
    plt.text(x , y , xx, fontsize=12)

plt.xlim((-120, -50))
plt.ylim((30, 50))
plt.show()

MAX=[max(points[0]),max(points[1]),max(points[2])]
MIN=[min(points[0]),min(points[1]),min(points[2])]

print(min(MIN),max(MIN))
print(min(MAX),max(MAX))

import matplotlib.pyplot as plt

points = [[-118.22824109999999,34.30828379],[-87.81658794,41.84144849],[-72.8012172,40.88320119]]
text = ['Los Angeles','Cook','Suffolk']
for i in range(len(points)):
    x = points[i][0]
    y = points[i][1]
    xx = text[i]
    plt.plot(x, y, 'bo')
    plt.text(x , y , xx, fontsize=12)

#plt.xlim((-120, -50))
#plt.ylim((30, 50))
plt.xlim(min(MIN),max(MIN))
plt.ylim(min(MAX),max(MAX))

plt.show()

import warnings
warnings.filterwarnings("ignore")
import matplotlib.pyplot as plt
from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon
import numpy as np
from PIL import Image,ImageFont,ImageDraw,ImageFilter,ImageChops
from random import randint
from mpl_toolkits.basemap import Basemap
fig = plt.figure(num=None, figsize=(12, 8), dpi=300 ) 
m = Basemap(width=6000000,height=4500000,resolution='h',projection='aea',lat_1=35.,lat_2=45,lon_0=-100,lat_0=40)
m.drawcoastlines(linewidth=0.5)
m.fillcontinents(color='tan',lake_color='lightblue')
# draw parallels and meridians.
m.drawparallels(np.arange(-90.,91.,10.),labels=[True,True,False,False],dashes=[2,2])
m.drawmeridians(np.arange(-180.,181.,10.),labels=[False,False,False,True],dashes=[2,2])
m.drawmapboundary(fill_color='lightblue')
m.drawcountries(linewidth=2, linestyle='solid', color='k' ) 
m.drawstates(linewidth=0.5, linestyle='solid', color='k')
m.drawrivers(linewidth=0.5, linestyle='solid', color='blue')

#-- Place the text in the upper left hand corner of the axes
# The basemap instance doesn't have an annotate method, so we'll use the pyplot
# interface instead.  (This is one of the many reasons to use cartopy instead.)
#plt.annotate('Jul-24-2012', xy=(0, 1), xycoords='axes fraction')
text = STATE
for i in range(len(Points)):
    x = Points[i][0]
    y = Points[i][1]
    tx = text[i]
    xx, yy = m(x,y)
    print(xx, yy)
    #plt.plot(xx, yy, 'bo')
    plt.scatter(xx, yy, s=20, color='red', zorder=5, alpha=0.6)
    plt.text(xx, yy, tx, fontsize=12)


plt.savefig("BaseMap/Hotspots__.png", dpi=300, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)
    
plt.show()

import warnings
warnings.filterwarnings("ignore")
import matplotlib.pyplot as plt
from matplotlib.collections import PatchCollection
from matplotlib.patches import Polygon
import numpy as np
from PIL import Image,ImageFont,ImageDraw,ImageFilter,ImageChops
from random import randint
from mpl_toolkits.basemap import Basemap
fig = plt.figure(num=None, figsize=(12, 8) ) 
m = Basemap(width=6000000,height=4500000,resolution='h',projection='aea',lat_1=35.,lat_2=45,lon_0=-100,lat_0=40)
m.drawcoastlines(linewidth=0.5)
m.fillcontinents(color='tan',lake_color='lightblue')
# draw parallels and meridians.
m.drawparallels(np.arange(-90.,91.,10.),labels=[True,True,False,False],dashes=[2,2])
m.drawmeridians(np.arange(-180.,181.,10.),labels=[False,False,False,True],dashes=[2,2])
m.drawmapboundary(fill_color='lightblue')
m.drawcountries(linewidth=2, linestyle='solid', color='k' ) 
m.drawstates(linewidth=0.5, linestyle='solid', color='k')
m.drawrivers(linewidth=0.5, linestyle='solid', color='blue')
def RndState():
    TX=["Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming"]
    x=randint(1,49)
    return TX[x]

search = RndState()
LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/05-12-2020.csv"
#LASTFILE="csse_covid_19_data/csse_covid_19_daily_reports/03-30-2020.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
LATd=[]
LONGd=[]
STATES=[]
cases=[]
deaths =[]
longitude = ""
search = RndState()
for line in DataIn:
    line=line.replace("\n","")
    line = line.lstrip(",")
    line = line.split(",")
    #if search in line[2] and "-" in (line[6]):
    if len(line[2])>0 and "-" in (line[6]):    
        text=line[2],line[1],line[3],line[4],line[5],line[6],line[7],line[8],line[9],line[10]
        STATES.append(text)
        LAT.append(line[5])
        LONG.append(line[6])
        if int(line[8])>0:
            LATd.append(line[5])
            LONGd.append(line[6])        
        cases.append(line[7])
        deaths.append(line[8])
        longitude = longitude+line[6]+","
print(len(STATES))        
LT = np.array(LAT,dtype=np.float)
LG = np.array(LONG,dtype=np.float)
LTd = np.array(LATd,dtype=np.float)
LGd = np.array(LONGd,dtype=np.float)

S=1
Size=[]
for x in cases:
    S=1+(float(x)*.05)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

Sd=0
Sized=[]
for xd in deaths:
    Sd=0+(float(xd)+.05)
    Sized.append(int(Sd))
    #print(int(S))
sd = np.array(Sized)
#print(Sized)
plt.title("COVID-19:\n Cases: (black)\n Deaths(red) \n Location:\n "+search+"\n", fontsize=15, loc='right')
#plt.text(max(LG-1.2),max(LT), search, color='white', fontsize=24)
#x, y = m(lons, lats)  # transform coordinates
x, y = m(LGd, LTd)
xx,yy = m(LG, LT)
plt.xlabel('Longitude',color="white", fontsize=24)
plt.ylabel('Latitute',color="white", fontsize=24)

m.scatter(xx, yy, s=s, color='black', zorder=5, alpha=0.6)
m.scatter(x, y, s=sd, color='r', zorder=10,  alpha=0.6)

plt.savefig("BaseMap/"+search+"Hotspots1__.png", dpi=120, facecolor='salmon', edgecolor='b',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches="tight", pad_inches=0.2,
        frameon=None, metadata=None)




from matplotlib.pyplot import text
from matplotlib import pyplot as plt
import numpy as np
import mpld3
from mpld3 import plugins
import time
%matplotlib inline
#LASTFILE="DATA/Download.csv"
#DataIn = open(LASTFILE).readlines()
cases=[]
#cnt=cnt+1
#for line in DataIn:
#    line = line.split(",")
#    if cnt==0:print(line)

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv"
DataIn = open(LASTFILE).readlines()
LAT=[]
LONG=[]
CITY=[]
deaths=[]
TEXT=[]
cnt = -1
Total=0
SEARCH = "Mississippi"
for line in DataIn:
    if len(line)>10 and 'US' in line and "Recovered" not in line and "Unassigned" not in line:
        cnt=cnt+1
        line=line.replace("\n","")
        line = line.lstrip(",")
        line = line.split(",")
        End=len(line)-1
        if len(line)>5 and SEARCH in line[6] and "0.0" not in line:
            
            if cnt>=1 and cnt<=5:print(line[5],line[6],line[8],line[9], line[End] )
            Total=Total+int(line[End])
            CITY.append(line[5])
            LAT.append(line[8])
            LONG.append(line[9])
            cases.append(line[9])
            deaths.append(line[End])        
            TText = str(line[2]+' '+line[1]+' '+line[3]+' '+line[4]+' '+line[5]+' '+line[6]+' '+line[7]+' '+line[8]+' '+line[9]+' '+line[10])
            if cnt==10:print("TTEXT: ",TText)
            TEXT.append(TText)
            
print("Number of Cities: ",len(CITY)) 
print("Total Deaths: ",Total)

LA = LAT
LO = LONG

print(len(LA))
print(len(LO))

DA = np.array(deaths,dtype=np.int)
LT = np.array(LAT,dtype=np.float)
LG = np.array(LONG,dtype=np.float)
print (max(LG))
print (min(LG))
print (min(LT))
print (max(LT))

print(deaths[-1])


A = (min(LG))-1
B = (max(LG))+1
C = (min(LT))-1
D = (max(LT))+1

fig = plt.figure(num=None, figsize=(12,12), dpi=80, facecolor='salmon')
#fig = plt.figure()
ax = fig.gca()
ax.set_facecolor(('#8eda8b'))

Sd=5
Sized=[]
for xd in deaths:
    Sd=2+(float(xd)*1)
    Sized.append(int(Sd))
    #print(int(S))
sd = np.array(Sized)

S=5
Size=[]
for x in cases:
    S=2+(float(x)*2)
    Size.append(int(S))
    #print(int(S))
s = np.array(Size)

plt.text(A+.5, D-.5, SEARCH, fontsize=26)
#plt.axis([-130,-65,20,55])
plt.axis([A,B,C,D])

ax.grid(color='lightgray', linestyle='-', linewidth=1)
plt.scatter(LG, LT, s=sd, color="red")
plt.scatter(LG, LT, s=s, color="black")

plt.grid(True)

plt.xlabel('- Longitude -\nFirst Data Record : January 21, 2020', fontsize=18)
plt.title('Using Latitude and Longitude from:\n https://github.com/CSSEGISandData/COVID-19\n Black is Confirmed Cases and the Red are Deaths', fontsize=18)
plt.ylabel('- Latitude -', fontsize=18, color="white")
filename = "images/"+SEARCH+"_"+(time.strftime('%a_%d_%b_%Y_%I_%M_%S_%p_%Z', time.gmtime())+".png")
fig.savefig(filename, facecolor=fig.get_facecolor(), edgecolor='black')
print(filename)
plt.show()



https://catalog.data.gov/dataset/tiger-line-shapefile-2017-nation-u-s-current-county-and-equivalent-national-shapefile

https://github.com/unitedstates/python-us

import us

help(us)

help(us.states)

help(us.unitedstatesofamerica)

help(us)

https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/05-15-2020.csv

import pandas as pd
url = "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"
df = pd.read_csv(url)   
df.to_csv('test_global.csv')
df.head()


df = pd.read_csv('test_global.csv')
# Locate the row the US is in:
df[df['Country/Region'].str.match('US')]

df.iloc[225, 4:-1]

# Total number of deaths un the USA ( index locate )
df.iloc[225, -2:-1]

# Total number of deaths un the USA
df.loc[225, '5/14/20']

import pandas as pd
import requests
from io import StringIO

url = "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"
headers = {"User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:66.0) Gecko/20100101 Firefox/66.0"}
req = requests.get(url, headers=headers)
data = StringIO(req.text)

df = pd.read_csv(data)

print(df)

print(df.loc[[225]])



import pandas as pd
import requests
from io import StringIO

url = "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"
headers = {"User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:66.0) Gecko/20100101 Firefox/66.0"}
req = requests.get(url, headers=headers)
#data = StringIO(req.text)
data = req.text
COUNTRIES = []
cnt=0
#if data[0] =","
#print(data)
#ndata = str(data).replace(",,","null")
ndata = data.splitlines()
for line in ndata:
    if cnt ==0:print(line,"\n----\n")
    cnt=cnt+1    
    if len(line)>5 and cnt>1:
        line= line.replace('"','')
        line = line.replace(",,",",NaN,")
        nline= line.split(",")
        if nline[0]=="":
            nline.pop(0)
            nline.insert(0,'NaN')
        dist = nline[0]
        country = nline[1]
        long=float(nline[3])
        lat=float(nline[2])
        ndata = nline[4:]
        intdata = list(map(int,ndata))
        '''
        try:
            intdata = list(map(int,nline[4:]))
        except Exception as ex:
            print(ex)
            print ("Error: %s.\n" % str(ex))
            print(cnt,nline[1])
            pass
        '''    
        #print(nline[0],nline[1],nline[2],nline[3],intdata)
        #print("cnt,space,dist,country,long,lat,intdata")
        print(dist,country,long,lat,intdata)
        COUNTRIES.append([dist,country,long,lat,intdata])

AllCountryList = []

cnt=0
for line in COUNTRIES:
    cnt=cnt+1
print("Total Countries Listed:",cnt)
cnt=0
AllCountryList = []
for line in COUNTRIES:
    cnt=cnt+1
    print (line,"\n")
    AllCountryList.append([line])
    

i = 143
for line in AllCountryList:
    print(line)

print(len(AllCountryList))





import os
os.chdir('..')

import sys
sys.path.insert(0, './python')
import caffe

from pylab import *
%matplotlib inline

# Download and prepare data
!data/mnist/get_mnist.sh
!examples/mnist/create_mnist.sh

from caffe import layers as L
from caffe import params as P

def lenet(lmdb, batch_size):
    # our version of LeNet: a series of linear and simple nonlinear transformations
    n = caffe.NetSpec()
    n.data, n.label = L.Data(batch_size=batch_size, backend=P.Data.LMDB, source=lmdb,
                             transform_param=dict(scale=1./255), ntop=2)
    n.conv1 = L.Convolution(n.data, kernel_size=5, num_output=20, weight_filler=dict(type='xavier'))
    n.pool1 = L.Pooling(n.conv1, kernel_size=2, stride=2, pool=P.Pooling.MAX)
    n.conv2 = L.Convolution(n.pool1, kernel_size=5, num_output=50, weight_filler=dict(type='xavier'))
    n.pool2 = L.Pooling(n.conv2, kernel_size=2, stride=2, pool=P.Pooling.MAX)
    n.ip1 = L.InnerProduct(n.pool2, num_output=500, weight_filler=dict(type='xavier'))
    n.relu1 = L.ReLU(n.ip1, in_place=True)
    n.ip2 = L.InnerProduct(n.relu1, num_output=10, weight_filler=dict(type='xavier'))
    n.loss = L.SoftmaxWithLoss(n.ip2, n.label)
    return n.to_proto()
    
with open('examples/mnist/lenet_auto_train.prototxt', 'w') as f:
    f.write(str(lenet('examples/mnist/mnist_train_lmdb', 64)))
    
with open('examples/mnist/lenet_auto_test.prototxt', 'w') as f:
    f.write(str(lenet('examples/mnist/mnist_test_lmdb', 100)))

!cat examples/mnist/lenet_auto_train.prototxt

!cat examples/mnist/lenet_auto_solver.prototxt

caffe.set_device(0)
caffe.set_mode_gpu()
solver = caffe.SGDSolver('examples/mnist/lenet_auto_solver.prototxt')

# each output is (batch size, feature dim, spatial dim)
[(k, v.data.shape) for k, v in solver.net.blobs.items()]

# just print the weight sizes (not biases)
[(k, v[0].data.shape) for k, v in solver.net.params.items()]

solver.net.forward()  # train net
solver.test_nets[0].forward()  # test net (there can be more than one)

# we use a little trick to tile the first eight images
imshow(solver.net.blobs['data'].data[:8, 0].transpose(1, 0, 2).reshape(28, 8*28), cmap='gray')
print solver.net.blobs['label'].data[:8]

imshow(solver.test_nets[0].blobs['data'].data[:8, 0].transpose(1, 0, 2).reshape(28, 8*28), cmap='gray')
print solver.test_nets[0].blobs['label'].data[:8]

solver.step(1)

imshow(solver.net.params['conv1'][0].diff[:, 0].reshape(4, 5, 5, 5)
       .transpose(0, 2, 1, 3).reshape(4*5, 5*5), cmap='gray')

%%time
niter = 200
test_interval = 25
# losses will also be stored in the log
train_loss = zeros(niter)
test_acc = zeros(int(np.ceil(niter / test_interval)))
output = zeros((niter, 8, 10))

# the main solver loop
for it in range(niter):
    solver.step(1)  # SGD by Caffe
    
    # store the train loss
    train_loss[it] = solver.net.blobs['loss'].data
    
    # store the output on the first test batch
    # (start the forward pass at conv1 to avoid loading new data)
    solver.test_nets[0].forward(start='conv1')
    output[it] = solver.test_nets[0].blobs['ip2'].data[:8]
    
    # run a full test every so often
    # (Caffe can also do this for us and write to a log, but we show here
    #  how to do it directly in Python, where more complicated things are easier.)
    if it % test_interval == 0:
        print 'Iteration', it, 'testing...'
        correct = 0
        for test_it in range(100):
            solver.test_nets[0].forward()
            correct += sum(solver.test_nets[0].blobs['ip2'].data.argmax(1)
                           == solver.test_nets[0].blobs['label'].data)
        test_acc[it // test_interval] = correct / 1e4

_, ax1 = subplots()
ax2 = ax1.twinx()
ax1.plot(arange(niter), train_loss)
ax2.plot(test_interval * arange(len(test_acc)), test_acc, 'r')
ax1.set_xlabel('iteration')
ax1.set_ylabel('train loss')
ax2.set_ylabel('test accuracy')

for i in range(8):
    figure(figsize=(2, 2))
    imshow(solver.test_nets[0].blobs['data'].data[i, 0], cmap='gray')
    figure(figsize=(10, 2))
    imshow(output[:50, i].T, interpolation='nearest', cmap='gray')
    xlabel('iteration')
    ylabel('label')

for i in range(8):
    figure(figsize=(2, 2))
    imshow(solver.test_nets[0].blobs['data'].data[i, 0], cmap='gray')
    figure(figsize=(10, 2))
    imshow(exp(output[:50, i].T) / exp(output[:50, i].T).sum(0), interpolation='nearest', cmap='gray')
    xlabel('iteration')
    ylabel('label')

import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

import os
os.chdir('..')

import sys
sys.path.insert(0, './python')
import caffe


import os
import h5py
import shutil
import tempfile

import sklearn
import sklearn.datasets
import sklearn.linear_model

import pandas as pd

X, y = sklearn.datasets.make_classification(
    n_samples=10000, n_features=4, n_redundant=0, n_informative=2, 
    n_clusters_per_class=2, hypercube=False, random_state=0
)

# Split into train and test
X, Xt, y, yt = sklearn.cross_validation.train_test_split(X, y)

# Visualize sample of the data
ind = np.random.permutation(X.shape[0])[:1000]
df = pd.DataFrame(X[ind])
_ = pd.scatter_matrix(df, figsize=(9, 9), diagonal='kde', marker='o', s=40, alpha=.4, c=y[ind])

%%timeit
# Train and test the scikit-learn SGD logistic regression.
clf = sklearn.linear_model.SGDClassifier(
    loss='log', n_iter=1000, penalty='l2', alpha=1e-3, class_weight='auto')

clf.fit(X, y)
yt_pred = clf.predict(Xt)
print('Accuracy: {:.3f}'.format(sklearn.metrics.accuracy_score(yt, yt_pred)))

# Write out the data to HDF5 files in a temp directory.
# This file is assumed to be caffe_root/examples/hdf5_classification.ipynb
dirname = os.path.abspath('./examples/hdf5_classification/data')
if not os.path.exists(dirname):
    os.makedirs(dirname)

train_filename = os.path.join(dirname, 'train.h5')
test_filename = os.path.join(dirname, 'test.h5')

# HDF5DataLayer source should be a file containing a list of HDF5 filenames.
# To show this off, we'll list the same data file twice.
with h5py.File(train_filename, 'w') as f:
    f['data'] = X
    f['label'] = y.astype(np.float32)
with open(os.path.join(dirname, 'train.txt'), 'w') as f:
    f.write(train_filename + '\n')
    f.write(train_filename + '\n')
    
# HDF5 is pretty efficient, but can be further compressed.
comp_kwargs = {'compression': 'gzip', 'compression_opts': 1}
with h5py.File(test_filename, 'w') as f:
    f.create_dataset('data', data=Xt, **comp_kwargs)
    f.create_dataset('label', data=yt.astype(np.float32), **comp_kwargs)
with open(os.path.join(dirname, 'test.txt'), 'w') as f:
    f.write(test_filename + '\n')

from caffe import layers as L
from caffe import params as P

def logreg(hdf5, batch_size):
    # logistic regression: data, matrix multiplication, and 2-class softmax loss
    n = caffe.NetSpec()
    n.data, n.label = L.HDF5Data(batch_size=batch_size, source=hdf5, ntop=2)
    n.ip1 = L.InnerProduct(n.data, num_output=2, weight_filler=dict(type='xavier'))
    n.accuracy = L.Accuracy(n.ip1, n.label)
    n.loss = L.SoftmaxWithLoss(n.ip1, n.label)
    return n.to_proto()
    
with open('examples/hdf5_classification/logreg_auto_train.prototxt', 'w') as f:
    f.write(str(logreg('examples/hdf5_classification/data/train.txt', 10)))
    
with open('examples/hdf5_classification/logreg_auto_test.prototxt', 'w') as f:
    f.write(str(logreg('examples/hdf5_classification/data/test.txt', 10)))

%%timeit
caffe.set_mode_cpu()
solver = caffe.get_solver('examples/hdf5_classification/solver.prototxt')
solver.solve()

accuracy = 0
batch_size = solver.test_nets[0].blobs['data'].num
test_iters = int(len(Xt) / batch_size)
for i in range(test_iters):
    solver.test_nets[0].forward()
    accuracy += solver.test_nets[0].blobs['accuracy'].data
accuracy /= test_iters

print("Accuracy: {:.3f}".format(accuracy))

!./build/tools/caffe train -solver examples/hdf5_classification/solver.prototxt

from caffe import layers as L
from caffe import params as P

def nonlinear_net(hdf5, batch_size):
    # one small nonlinearity, one leap for model kind
    n = caffe.NetSpec()
    n.data, n.label = L.HDF5Data(batch_size=batch_size, source=hdf5, ntop=2)
    # define a hidden layer of dimension 40
    n.ip1 = L.InnerProduct(n.data, num_output=40, weight_filler=dict(type='xavier'))
    # transform the output through the ReLU (rectified linear) non-linearity
    n.relu1 = L.ReLU(n.ip1, in_place=True)
    # score the (now non-linear) features
    n.ip2 = L.InnerProduct(n.ip1, num_output=2, weight_filler=dict(type='xavier'))
    # same accuracy and loss as before
    n.accuracy = L.Accuracy(n.ip2, n.label)
    n.loss = L.SoftmaxWithLoss(n.ip2, n.label)
    return n.to_proto()
    
with open('examples/hdf5_classification/nonlinear_auto_train.prototxt', 'w') as f:
    f.write(str(nonlinear_net('examples/hdf5_classification/data/train.txt', 10)))
    
with open('examples/hdf5_classification/nonlinear_auto_test.prototxt', 'w') as f:
    f.write(str(nonlinear_net('examples/hdf5_classification/data/test.txt', 10)))

%%timeit
caffe.set_mode_cpu()
solver = caffe.get_solver('examples/hdf5_classification/nonlinear_solver.prototxt')
solver.solve()

accuracy = 0
batch_size = solver.test_nets[0].blobs['data'].num
test_iters = int(len(Xt) / batch_size)
for i in range(test_iters):
    solver.test_nets[0].forward()
    accuracy += solver.test_nets[0].blobs['accuracy'].data
accuracy /= test_iters

print("Accuracy: {:.3f}".format(accuracy))

!./build/tools/caffe train -solver examples/hdf5_classification/nonlinear_solver.prototxt

# Clean up (comment this out if you want to examine the hdf5_classification/data directory).
shutil.rmtree(dirname)

import os
os.chdir('..')
import sys
sys.path.insert(0, './python')

import caffe
import numpy as np
from pylab import *
%matplotlib inline

# This downloads the ilsvrc auxiliary data (mean file, etc),
# and a subset of 2000 images for the style recognition task.
!data/ilsvrc12/get_ilsvrc_aux.sh
!scripts/download_model_binary.py models/bvlc_reference_caffenet
!python examples/finetune_flickr_style/assemble_data.py \
    --workers=-1 --images=2000 --seed=1701 --label=5

!diff models/bvlc_reference_caffenet/train_val.prototxt models/finetune_flickr_style/train_val.prototxt

niter = 200
# losses will also be stored in the log
train_loss = np.zeros(niter)
scratch_train_loss = np.zeros(niter)

caffe.set_device(0)
caffe.set_mode_gpu()
# We create a solver that fine-tunes from a previously trained network.
solver = caffe.SGDSolver('models/finetune_flickr_style/solver.prototxt')
solver.net.copy_from('models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel')
# For reference, we also create a solver that does no finetuning.
scratch_solver = caffe.SGDSolver('models/finetune_flickr_style/solver.prototxt')

# We run the solver for niter times, and record the training loss.
for it in range(niter):
    solver.step(1)  # SGD by Caffe
    scratch_solver.step(1)
    # store the train loss
    train_loss[it] = solver.net.blobs['loss'].data
    scratch_train_loss[it] = scratch_solver.net.blobs['loss'].data
    if it % 10 == 0:
        print 'iter %d, finetune_loss=%f, scratch_loss=%f' % (it, train_loss[it], scratch_train_loss[it])
print 'done'

plot(np.vstack([train_loss, scratch_train_loss]).T)

plot(np.vstack([train_loss, scratch_train_loss]).clip(0, 4).T)

test_iters = 10
accuracy = 0
scratch_accuracy = 0
for it in arange(test_iters):
    solver.test_nets[0].forward()
    accuracy += solver.test_nets[0].blobs['accuracy'].data
    scratch_solver.test_nets[0].forward()
    scratch_accuracy += scratch_solver.test_nets[0].blobs['accuracy'].data
accuracy /= test_iters
scratch_accuracy /= test_iters
print 'Accuracy for fine-tuning:', accuracy
print 'Accuracy for training from scratch:', scratch_accuracy

import requests as req
URL="https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv"
response = req.get(URL)
content = response.content

content=str(content)
DataIn = content.splitlines()

print DataIn[0]

cnt=0
ALLdata = []
for line in DataIn[1:]:
    cnt=cnt+1
    #print cnt,line
    line= line.replace(",,",",nan,")
    line= line.split(",")
    ALLdata.append(line)

print ALLdata[200][1]

history = []
for i in range(0,len(ALLdata)):
    #if "USA" == ALLdata[i][0]:
    if "United States" == ALLdata[i][1]:   
        history.append(ALLdata[i][3:7])
print len(history)        

print history[0:]

Summary.reverse()

for line in Summary:
    print line



cnt=0
filename = "36B9q1Ws.csv"
with open(filename) as f:
    lines = f.read().splitlines()
    for line in lines:
        cnt=cnt+1
        if cnt==1:print line
        if cnt==1:print "-----------------------------"
Summary=[]
cnt=0
Cases = []
Deaths = []
Population = []
with open(filename) as f:
    lines = f.read().splitlines()    
    for line in lines:
        item = line.split(",")
        if "United_States_of_America" == item[6]:
            Cases.append(int(item[4]))
            Deaths.append(int(item[5]))
            Population.append(int(item[9]))
            Summary.append([int(item[4]),int(item[5]),int(item[9]),str(item[0])])            

install.packages("randomForest")

install.packages("aRtsy")

https://hub.docker.com/_/r-base/tags

installing: ‘blob’, ‘data.table’, ‘cellranger’, ‘ids’, ‘vroom’, ‘tzdb’,
‘progress’, ‘broom’, ‘crayon’, ‘dbplyr’, ‘dtplyr’, ‘forcats’, ‘googledrive’, ‘googlesheets4’, 
‘haven’, ‘hms’, ‘jsonlite’, ‘lubridate’, ‘modelr’, ‘readr’, ‘readxl’, ‘reprex’, ‘tidyr’

library(tidyverse)
library(Rcpp)
library(colourlovers)
library(reshape2)
library(cowplot)

# Import C++ code
sourceCpp('cyclic_funs.cpp')

#################################################################
# Functions
#################################################################

# This function creates a w x h matrix of random states
initial_grid <- function(s, w, h){
  matrix(sample(x = seq_len(s)-1,
               size = w *h,
               replace = TRUE),
         nrow = h,
         ncol = w)}

# This function implements neighborhoods
# You can add your own
convolution_indexes <- function(r, n){
  crossing(x = -r:r, y = -r:r) %>% 
    mutate(M = ((x != 0) | (y != 0)) * 1 ,
           N = (abs(x) + abs(y) <= r) * M,
           Mr = ((abs(x) == r) | (abs(y) == r)) * M,
           Nr = (abs(x) + abs(y) == r) * M,
           Cr = ((x == 0) | (y == 0)) * M,
           S1 = (((x > 0) & (y > 0))|((x < 0) & (y < 0))) * 1,
           Bl = (abs(x) == abs(y)) * M,
           D1 = (abs(x) > abs(y)) * M,
           D2 = ((abs(x) == abs(y)) | abs(x) == r) * M,
           C2 = M - N,
           Z = ((abs(y) == r) | (x == y)) * M,
           t = ((y == r) | (x == 0)) * M,
           U = ((abs(x) == r) | (y == -r)) * M,
           H = (abs(x) == r | y == 0) * M,
           TM = ((abs(x) == abs(y)) | abs(x) == r | abs(y) == r) * M,
           S2 = ((y==0) | ((x == r) & (y > 0)) |((x == -r) & (y < 0))) * M,
           M2 = ((abs(x) == r) | (abs(x) == abs(y) & y > 0)) * M) %>% 
    select(x, y, matches(n)) %>% 
    filter_at(3, all_vars(. > 0)) %>% 
    select(x,y)
}

#################################################################
# Initialization
#################################################################
range <- 5
thresold <- 29
states <- 5
neighborhood <- "M"
iter <- 600

width  <- 1500
height <- 1500
  
X <- initial_grid(s = states,
                  w = width,
                  h = height)

L <- convolution_indexes(r = range, n = neighborhood)
  
for (i in 1:iter){
    X <- iterate_cyclic(X, L, states, thresold)  
}
  
# Transform resulting environment matrix into data frame
df <- melt(X)
colnames(df) <- c("x","y","v") # to name columns
  
# Pick a top palette from colourlovers
palette <- sample(clpalettes('top'), 1)[[1]] 
colors <- palette %>% swatch %>% .[[1]]

# Do the plot
ggplot(data = df, aes(x = x, y = y, fill = v)) + 
  geom_raster(interpolate = TRUE) +
  coord_equal() +
  scale_fill_gradientn(colours = colors) +
  scale_y_continuous(expand = c(0,0)) + 
  scale_x_continuous(expand = c(0,0)) +
  theme_nothing() 


library(RcppArmadillo)
library(imager)
plot(boats)

library(generativeart)

# set the paths
IMG_DIR <- "img/"
IMG_SUBDIR <- "everything/"
IMG_SUBDIR2 <- "handpicked/"
IMG_PATH <- paste0(IMG_DIR, IMG_SUBDIR)

LOGFILE_DIR <- "logfile/"
LOGFILE <- "logfile.csv"
LOGFILE_PATH <- paste0(LOGFILE_DIR, LOGFILE)

# create the directory structure
generativeart::setup_directories(IMG_DIR, IMG_SUBDIR, IMG_SUBDIR2, LOGFILE_DIR)

# include a specific formula, for example:
my_formula <- list(
  x = quote(runif(1, -1, 1) * x_i^2 - sin(y_i^2)),
  y = quote(runif(1, -1, 1) * y_i^3 - cos(x_i^2))
)

# call the main function to create five images with a polar coordinate system
generativeart::generate_img(formula = my_formula, nr_of_img = 25, polar = TRUE, filetype = "png", color = "gold", background_color = "darkred")


RcppArmadillo.h
Error: Package 'RcppArmadillo' referenced from Rcpp::depends in source file cyclic_funs.cpp is not available.
Traceback:

https://cran.r-project.org/web/packages/imager/vignettes/gettingstarted.html

library(imager)
plot(boats)

install.packages("imager")

install.packages("imager")

install.packages("tidyverse")
install.packages("Rcpp")
install.packages("reshape2")
install.packages("colourlovers")
install.packages("cowplot")

https://generative.substack.com/p/generative-art-and-r

install.packages("/home/jack/Desktop/R-Studio/generativeart/", repos = NULL, type="source")

install.packages("/home/jack/Desktop/R-Studio/httr2_0.2.2.tar.gz", repos = NULL, type="source")

library(generativeart)

# include a specific formula, for example:
my_formula <- list(
  x = quote(runif(1, -1, 1) * x_i^2 - sin(y_i^2)),
  y = quote(runif(1, -1, 1) * y_i^3 - cos(x_i^2))
)

# call the main function to create five images with a polar coordinate system
generativeart::generate_img(formula = my_formula, nr_of_img = 20, polar = TRUE, 
                            filetype = "png", color = "gold", background_color = "blue4")


# generativeart

## Announcement

This package collects more and more stars here on Github and is widely used for NFTs. Just browse on NFT platforms - it won't take you long to discover  patterns be that might be decandents of this repository.

I would like to clarify: I am **not a fan** of Blockchain, NFT and Web3. 

Why? Read this text: ["The Third Web"](https://tante.cc/2021/12/17/the-third-web/) by [@tante](https://twitter.com/tante).

--- 

Create Generative Art with R.

![](img/generativeart.png)

[More on Instagram](https://www.instagram.com/cutterkom/)

## Description

> One overly simple but useful definition is that generative art is art programmed using a computer that intentionally introduces randomness as part of its creation process.
-- [Why Love Generative Art? - Artnome](https://www.artnome.com/news/2018/8/8/why-love-generative-art)

The `R` package `generativeart` let's you create images based on many thousand points.
The position of every single point is calculated by a formula, which has random parameters.
Because of the random numbers, every image looks different.

In order to make an image reproducible, `generative art` implements a log file that saves the `file_name`, the `seed` and the `formula`.

## Install

You can install the package with the `devtools` package directly from Github:

```r
devtools::install_github("cutterkom/generativeart")
```

`generativeart` uses the packages `ggplot2`, `magrittr`, `purrr` and `dplyr`.

## Usage

The package works with a specific directory structure that fits my needs best.
The first step is to create it with `setup_directories()`.
All images are saved by default in `img/everything/`. I use `img/handpicked/` to choose the best ones.
In `logfile/` you will find a `csv` file that saves the `file_name`, the `seed` and the used `formula`.

```r
library(generativeart)

# set the paths
IMG_DIR <- "img/"
IMG_SUBDIR <- "everything/"
IMG_SUBDIR2 <- "handpicked/"
IMG_PATH <- paste0(IMG_DIR, IMG_SUBDIR)

LOGFILE_DIR <- "logfile/"
LOGFILE <- "logfile.csv"
LOGFILE_PATH <- paste0(LOGFILE_DIR, LOGFILE)

# create the directory structure
generativeart::setup_directories(IMG_DIR, IMG_SUBDIR, IMG_SUBDIR2, LOGFILE_DIR)

# include a specific formula, for example:
my_formula <- list(
  x = quote(runif(1, -1, 1) * x_i^2 - sin(y_i^2)),
  y = quote(runif(1, -1, 1) * y_i^3 - cos(x_i^2))
)

# call the main function to create five images with a polar coordinate system
generativeart::generate_img(formula = my_formula, nr_of_img = 5, polar = TRUE, \
                            filetype = "png", color = "black", background_color = "white")

```

* You can create as many images as you want by setting `nr_of_img`.
* For every image a seed is drawn from a number between 1 and 10000.
* This seed determines the random numbers in the formula.
* You can choose between cartesian and polar coordinate systems by setting `polar = TRUE` or `polar = FALSE`
* You can choose the colors with `color = 'black'` and `background_color = 'hotpink'`
* You can save the output image in various formats.
Default is `png`, the alternatives are defined by the `device` options of [`ggplot::ggsave()`](https://ggplot2.tidyverse.org/reference/ggsave.html).
* the formula is a `list()`

## Examples

#It is a good idea to use the sine and cosine in the formula, since it guarantees nice shapes, especially when combined with a polar coordinate system. One simple example:
r
my_formula <- list(
  x = quote(runif(1, -1, 1) * x_i^2 - sin(y_i^2)),
  y = quote(runif(1, -1, 1) * y_i^3 - cos(x_i^2))
)

generativeart::generate_img(formula = my_formula, nr_of_img = 5, polar = TRUE, color = "black", background_color = "white")

```

Two possible images:

`seed = 1821`, `polar = TRUE`:
![](img/2018-11-16-17-13_seed_1821.png)

`seed = 5451`, `polar = FALSE`:
![](img/2018-11-16-17-12_seed_5451.png)

The corresponding log file looks like that:

| file_name                      | seed | formula_x                            | formula_y                            | 
|--------------------------------|------|--------------------------------------|--------------------------------------| 
| 2018-11-16-17-13_seed_1821.png | 1821 | runif(1, -1, 1) * x_i^2 - sin(y_i^2) | runif(1, -1, 1) * y_i^3 - cos(x_i^2) | 
| 2018-11-16-17-12_seed_5451.png | 5451 | runif(1, -1, 1) * x_i^2 - sin(y_i^2) | runif(1, -1, 1) * y_i^3 - cos(x_i^2) | 


## Inspiration

The basic concept is heavily inspired by [Fronkonstin's great blog](https://fronkonstin.com/).


library(httr2)

#install.packages("/home/jack/Desktop/R-Studio/rjson_0.2.13.tar.gz", repos=NULL, type="source")
#install.packages("twitteR")
library(twitteR)
setup_twitter_oauth(consumer_key = 'APIkey()[0]',
                    access_token = 'APIkey()[2]',
                    consumer_secret = 'APIkey()[1]',
                    access_secret = 'APIkey()[3]')


#tw <- updateStatus("Now I need to read Tweets using R in my Jupyter Notebook! #Jupyternotebook #rstudio #RStudio") 
#Download version 2.13 from http://cran.rstudio.com/src/contrib/Archive/rjson/rjson_0.2.13.tar.gz In R, run install.packages('path to the downloaded gz file>', repos=NULL, type='source')")
#https://cran.rstudio.com/

tw <- updateStatus("#Jupyternotebook #rstudio #RStudio Now I'll try to post an Image", mediaPath = "post-this.png")

library(twitteR)
setup_twitter_oauth(consumer_key = 'XXXXXXXXX',
                    access_token = 'YYYYYYYYYYYYY',
                    consumer_secret = 'ZZZZZZZZZZZZZZZZZZZZZ',
                    access_secret = 'WWWWWWWWWWWWWWWWWWWWWW')
tw <- updateStatus('#Jupyternotebook #rstudio #RStudio Now I'll try to post an Image', mediaPath = 'post-this.png')

library(twitteR)
library(httr)


ckey <- "X"
csecret <- "X"
atoken <- "X"
asecret <- "X"

setup_twitter_oauth(ckey, csecret, atoken, asecret)

tweet("")
There is a parameter in tweet() and updateStatus() called mediaPath which you can use to submit images. Try something like:

tweet("some status", mediaPath = "url-to-image.jpg")
tw <- updateStatus("some status", mediaPath = "url-to-image.jpg")

install.packages("/home/jack/Desktop/R-Studio/devtools_2.4.5.tar.gz", repos = NULL, type="source")

install.packages(path_to_file, repos = NULL, type="source")

R --version
R version 3.6.1 (2019-07-05) -- "Action of the Toes"
Copyright (C) 2019 The R Foundation for Statistical Computing
Platform: x86_64-conda_cos6-linux-gnu (64-bit)


https://cran.rstudio.com/
https://developer.twitter.com/en/docs/api-reference-index
https://www.tensorflow.org/lite/examples/style_transfer/overview

https://www.r-bloggers.com/2018/05/send-tweets-from-r-a-very-short-walkthrough/
http://zevross.com/blog/2017/06/19/tips-and-tricks-for-working-with-images-and-figures-in-r-markdown-documents/
https://bookdown.org/yihui/rmarkdown/notebook.html#using-notebooks
https://towardsdatascience.com/getting-started-with-generative-art-in-r-3bc50067d34b
https://www.earthdatascience.org/courses/earth-analytics/get-data-using-apis/use-twitter-api-r/
https://www.jumpingrivers.com/blog/r-knitr-markdown-png-pdf-graphics/
https://dgarcia-eu.github.io/SocialDataScience/4_SNA/047_TwitterNetwork/TwitterNetwork.html
https://dgarcia-eu.github.io/SocialDataScience/2_SocialDynamics/027_rtweet/rtweet.html
https://datatofish.com/r-jupyter-notebook/
https://github.com/plotly/plotly.R/issues/239

install.packages(plotly) # if you haven't installed the package
library(plotly)

df <- data.frame(Product = c('Oven', 'Microwave', 'Toaster'),
                 Price = c(850, 300, 120)
                 )
print (df)

# Function definition
# To check n is divisible by 5 or not
divisbleBy5 <- function(n){
  if(n %% 5 == 0)
  {
    return("number is divisible by 5")
  }
  else 
  {
    return("number is not divisible by 5")
  }
}
   
# Function call
divisbleBy5(100)
divisbleBy5(4)
divisbleBy5(20.0)


 R Programming

# load twitter library - the rtweet library is recommended now over twitteR
library(rtweet)
# plotting and pipes - tidyverse!
library(ggplot2)
library(dplyr)
# text mining library
library(tidytext)


#install.packages("/home/jack/Desktop/R-Studio/rjson_0.2.13.tar.gz", repos=NULL, type="source")
#install.packages("twitteR")
library(twitteR)
setup_twitter_oauth(consumer_key = 'APIkey()[0]',
                    access_token = 'APIkey()[2]',
                    consumer_secret = 'APIkey()[1]',
                    access_secret = 'APIkey()[3]')


tw <- updateStatus("#rstudio #RStudio #twitteR This is an old library, it only allows a Tweet of under 140 characters") 
#Download version 2.13 from http://cran.rstudio.com/src/contrib/Archive/rjson/rjson_0.2.13.tar.gz In R, run install.packages('path to the downloaded gz file>', repos=NULL, type='source')")
#https://cran.rstudio.com/

#' Generate data
#'
#' The generative images are based on values in a dataframe. This function creates the data by transforming the base values `seq(-pi, pi)` with a `formula`.
#' @param formula a list that contains formulas for transforming the x- and y-values.
#' @return data frame
#' @seealso \code{\link{generate_plot}} the returned data frame is the input to generate the plot
#' @export
#' @examples
#' \dontrun{
#' generate_data(formula)
#' }
#' # an example for a formula:
#' formula <- list(
#'   x = quote(runif(1, -1, 1) * pi_x^2 -sin(pi_y^2)),
#'   y = quote(runif(1, -1, 1) * pi_y^3-cos(pi_x^2))
#'  )
#' @importFrom dplyr mutate
#' @importFrom magrittr %>%

### create dataframe with starting points and transformed x and y depending on a formula
generate_data <- function(formula) {
  print("generate data")
  df <- seq(from = -pi, to = pi, by = 0.01) %>%
    expand.grid(x_i = ., y_i = .) %>%
    dplyr::mutate(!!!formula)
  return(df)
}


generate_data

formula

generate_data(formula)
 formula <- list(
   x = quote(runif(1, -1, 1) * pi_x^2 -sin(pi_y^2)),
   y = quote(runif(1, -1, 1) * pi_y^3-cos(pi_x^2))
  )
#@importFrom dplyr mutate
#@importFrom magrittr %>%


library(devtools)

install.packages("devtools", dependencies = TRUE)

https://cran.r-project.org/src/contrib/httr2_0.2.2.tar.gz

Downloading and Extracting Packages
r-lubridate-1.7.4    | 1.1 MB    | #################################### | 100% 
r-mass-7.3_51.3      | 1.1 MB    | #################################### | 100% 
r-stringr-1.4.0      | 221 KB    | #################################### | 100% 
r-tibble-2.1.1       | 316 KB    | #################################### | 100% 
r-markdown-0.9       | 143 KB    | #################################### | 100% 
r-readr-1.3.1        | 814 KB    | #################################### | 100% 
r-dbi-1.0.0          | 916 KB    | #################################### | 100% 
r-reshape2-1.4.3     | 129 KB    | #################################### | 100% 
r-ps-1.3.0           | 221 KB    | #################################### | 100% 
r-processx-3.3.0     | 190 KB    | #################################### | 100% 
r-whisker-0.3_2      | 82 KB     | #################################### | 100% 
r-openssl-1.3        | 1.2 MB    | #################################### | 100% 
r-munsell-0.5.0      | 254 KB    | #################################### | 100% 
r-plogr-0.2.0        | 20 KB     | #################################### | 100% 
r-callr-3.2.0        | 270 KB    | #################################### | 100% 
r-yaml-2.2.0         | 113 KB    | #################################### | 100% 
r-bh-1.69.0_1        | 10.9 MB   | #################################### | 100% 
r-r6-2.4.0           | 68 KB     | #################################### | 100% 
r-purrr-0.3.2        | 397 KB    | #################################### | 100% 
r-pillar-1.3.1       | 180 KB    | #################################### | 100% 
r-stringi-1.4.3      | 773 KB    | #################################### | 100% 
r-gtable-0.3.0       | 425 KB    | #################################### | 100% 
r-highr-0.8          | 60 KB     | #################################### | 100% 
r-broom-0.5.2        | 2.0 MB    | #################################### | 100% 
r-colorspace-1.4_1   | 2.5 MB    | #################################### | 100% 
r-xfun-0.6           | 189 KB    | #################################### | 100% 
r-fs-1.2.7           | 510 KB    | #################################### | 100% 
r-utf8-1.1.4         | 159 KB    | #################################### | 100% 
r-rstudioapi-0.10    | 240 KB    | #################################### | 100% 
r-glue-1.3.1         | 165 KB    | #################################### | 100% 
r-xml2-1.2.0         | 340 KB    | #################################### | 100% 
r-rvest-0.3.3        | 928 KB    | #################################### | 100% 
r-rematch-1.0.1      | 19 KB     | #################################### | 100% 
r-knitr-1.22         | 1.3 MB    | #################################### | 100% 
r-nlme-3.1_139       | 2.2 MB    | #################################### | 100% 
r-dplyr-0.8.0.1      | 1.9 MB    | #################################### | 100% 
r-fansi-0.4.0        | 193 KB    | #################################### | 100% 
r-haven-2.1.0        | 331 KB    | #################################### | 100% 
r-dbplyr-1.4.0       | 622 KB    | #################################### | 100% 
r-labeling-0.3       | 71 KB     | #################################### | 100% 
r-sys-3.2            | 47 KB     | #################################### | 100% 
r-clipr-0.6.0        | 66 KB     | #################################### | 100% 
r-forcats-0.4.0      | 373 KB    | #################################### | 100% 
r-httr-1.4.0         | 513 KB    | #################################### | 100% 
r-tidyverse-1.2.1    | 95 KB     | #################################### | 100% 
r-backports-1.1.4    | 65 KB     | #################################### | 100% 
r-modelr-0.1.4       | 226 KB    | #################################### | 100% 
r-dichromat-2.0_0    | 163 KB    | #################################### | 100% 
r-pkgconfig-2.0.2    | 25 KB     | #################################### | 100% 
r-askpass-1.0        | 27 KB     | #################################### | 100% 
r-progress-1.2.0     | 89 KB     | #################################### | 100% 
r-lazyeval-0.2.2     | 164 KB    | #################################### | 100% 
r-tidyselect-0.2.5   | 138 KB    | #################################### | 100% 
r-assertthat-0.2.1   | 74 KB     | #################################### | 100% 
r-ggplot2-3.1.1      | 3.6 MB    | #################################### | 100% 
r-matrix-1.2_17      | 3.8 MB    | #################################### | 100% 
r-cli-1.1.0          | 189 KB    | #################################### | 100% 
r-readxl-1.3.1       | 855 KB    | #################################### | 100% 
r-withr-2.1.2        | 181 KB    | #################################### | 100% 
r-rlang-0.3.4        | 1.0 MB    | #################################### | 100% 
r-rmarkdown-1.12     | 3.0 MB    | #################################### | 100% 
r-generics-0.0.2     | 82 KB     | #################################### | 100% 
r-ellipsis-0.1.0     | 35 KB     | #################################### | 100% 
r-mime-0.6           | 50 KB     | #################################### | 100% 
r-rcolorbrewer-1.1_2 | 62 KB     | #################################### | 100% 
r-tinytex-0.12       | 106 KB    | #################################### | 100% 
r-curl-3.3           | 406 KB    | #################################### | 100% 
r-viridislite-0.3.0  | 66 KB     | #################################### | 100% 
r-cellranger-1.1.0   | 116 KB    | #################################### | 100% 
r-selectr-0.4_1      | 474 KB    | #################################### | 100% 
r-hms-0.4.2          | 74 KB     | #################################### | 100% 
r-scales-1.0.0       | 580 KB    | #################################### | 100% 
r-magrittr-1.5       | 173 KB    | #################################### | 100% 
r-plyr-1.8.4         | 815 KB    | #################################### | 100% 
r-tidyr-0.8.3        | 446 KB    | #################################### | 100% 
r-mgcv-1.8_28        | 2.6 MB    | #################################### | 100% 
r-lattice-0.20_38    | 1.1 MB    | #################################### | 100% 
r-reprex-0.2.1       | 410 KB    | #################################### | 100% 
r-prettyunits-1.0.2  | 38 KB     | #################################### | 100% 
Preparing transaction: done


install.packages("randomForest")
install.packages("aRtsy")

install.packages("aRtsy")

https://hub.docker.com/_/r-base/tags

installing: ‘blob’, ‘data.table’, ‘cellranger’, ‘ids’, ‘vroom’, ‘tzdb’,
‘progress’, ‘broom’, ‘crayon’, ‘dbplyr’, ‘dtplyr’, ‘forcats’, ‘googledrive’, ‘googlesheets4’, 
‘haven’, ‘hms’, ‘jsonlite’, ‘lubridate’, ‘modelr’, ‘readr’, ‘readxl’, ‘reprex’, ‘tidyr’

library(generativeart)

# set the paths
IMG_DIR <- "img/"
IMG_SUBDIR <- "everything/"
IMG_SUBDIR2 <- "handpicked/"
IMG_PATH <- paste0(IMG_DIR, IMG_SUBDIR)

LOGFILE_DIR <- "logfile/"
LOGFILE <- "logfile.csv"
LOGFILE_PATH <- paste0(LOGFILE_DIR, LOGFILE)

# create the directory structure
generativeart::setup_directories(IMG_DIR, IMG_SUBDIR, IMG_SUBDIR2, LOGFILE_DIR)

# include a specific formula, for example:
my_formula <- list(
  x = quote(runif(1, -1, 1) * x_i^2 - sin(y_i^2)),
  y = quote(runif(1, -1, 1) * y_i^3 - cos(x_i^2))
)

# call the main function to create five images with a polar coordinate system
generativeart::generate_img(formula = my_formula, nr_of_img = 25, polar = TRUE, filetype = "png", color = "gold", background_color = "darkred")


RcppArmadillo.h
Error: Package 'RcppArmadillo' referenced from Rcpp::depends in source file cyclic_funs.cpp is not available.
Traceback:

https://cran.r-project.org/web/packages/imager/vignettes/gettingstarted.html

library(imager)
plot(boats)

install.packages("imager")

install.packages("imager")

install.packages("tidyverse")
install.packages("Rcpp")
install.packages("reshape2")
install.packages("colourlovers")
install.packages("cowplot")

https://generative.substack.com/p/generative-art-and-r

install.packages("/home/jack/Desktop/R-Studio/generativeart/", repos = NULL, type="source")

install.packages("/home/jack/Desktop/R-Studio/httr2_0.2.2.tar.gz", repos = NULL, type="source")

library(generativeart)

# include a specific formula, for example:
my_formula <- list(
  x = quote(runif(1, -1, 1) * x_i^2 - sin(y_i^2)),
  y = quote(runif(1, -1, 1) * y_i^3 - cos(x_i^2))
)

# call the main function to create five images with a polar coordinate system
generativeart::generate_img(formula = my_formula, nr_of_img = 20, polar = TRUE, 
                            filetype = "png", color = "gold", background_color = "blue4")


# generativeart

## Announcement

This package collects more and more stars here on Github and is widely used for NFTs. Just browse on NFT platforms - it won't take you long to discover  patterns be that might be decandents of this repository.

I would like to clarify: I am **not a fan** of Blockchain, NFT and Web3. 

Why? Read this text: ["The Third Web"](https://tante.cc/2021/12/17/the-third-web/) by [@tante](https://twitter.com/tante).

--- 

Create Generative Art with R.

![](img/generativeart.png)

[More on Instagram](https://www.instagram.com/cutterkom/)

## Description

> One overly simple but useful definition is that generative art is art programmed using a computer that intentionally introduces randomness as part of its creation process.
-- [Why Love Generative Art? - Artnome](https://www.artnome.com/news/2018/8/8/why-love-generative-art)

The `R` package `generativeart` let's you create images based on many thousand points.
The position of every single point is calculated by a formula, which has random parameters.
Because of the random numbers, every image looks different.

In order to make an image reproducible, `generative art` implements a log file that saves the `file_name`, the `seed` and the `formula`.

## Install

You can install the package with the `devtools` package directly from Github:

```r
devtools::install_github("cutterkom/generativeart")
```

`generativeart` uses the packages `ggplot2`, `magrittr`, `purrr` and `dplyr`.

## Usage

The package works with a specific directory structure that fits my needs best.
The first step is to create it with `setup_directories()`.
All images are saved by default in `img/everything/`. I use `img/handpicked/` to choose the best ones.
In `logfile/` you will find a `csv` file that saves the `file_name`, the `seed` and the used `formula`.

```r
library(generativeart)

# set the paths
IMG_DIR <- "img/"
IMG_SUBDIR <- "everything/"
IMG_SUBDIR2 <- "handpicked/"
IMG_PATH <- paste0(IMG_DIR, IMG_SUBDIR)

LOGFILE_DIR <- "logfile/"
LOGFILE <- "logfile.csv"
LOGFILE_PATH <- paste0(LOGFILE_DIR, LOGFILE)

# create the directory structure
generativeart::setup_directories(IMG_DIR, IMG_SUBDIR, IMG_SUBDIR2, LOGFILE_DIR)

# include a specific formula, for example:
my_formula <- list(
  x = quote(runif(1, -1, 1) * x_i^2 - sin(y_i^2)),
  y = quote(runif(1, -1, 1) * y_i^3 - cos(x_i^2))
)

# call the main function to create five images with a polar coordinate system
generativeart::generate_img(formula = my_formula, nr_of_img = 5, polar = TRUE, \
                            filetype = "png", color = "black", background_color = "white")

```

* You can create as many images as you want by setting `nr_of_img`.
* For every image a seed is drawn from a number between 1 and 10000.
* This seed determines the random numbers in the formula.
* You can choose between cartesian and polar coordinate systems by setting `polar = TRUE` or `polar = FALSE`
* You can choose the colors with `color = 'black'` and `background_color = 'hotpink'`
* You can save the output image in various formats.
Default is `png`, the alternatives are defined by the `device` options of [`ggplot::ggsave()`](https://ggplot2.tidyverse.org/reference/ggsave.html).
* the formula is a `list()`

## Examples

#It is a good idea to use the sine and cosine in the formula, since it guarantees nice shapes, especially when combined with a polar coordinate system. One simple example:
r
my_formula <- list(
  x = quote(runif(1, -1, 1) * x_i^2 - sin(y_i^2)),
  y = quote(runif(1, -1, 1) * y_i^3 - cos(x_i^2))
)

generativeart::generate_img(formula = my_formula, nr_of_img = 5, polar = TRUE, color = "black", background_color = "white")

```

Two possible images:

`seed = 1821`, `polar = TRUE`:
![](img/2018-11-16-17-13_seed_1821.png)

`seed = 5451`, `polar = FALSE`:
![](img/2018-11-16-17-12_seed_5451.png)

The corresponding log file looks like that:

| file_name                      | seed | formula_x                            | formula_y                            | 
|--------------------------------|------|--------------------------------------|--------------------------------------| 
| 2018-11-16-17-13_seed_1821.png | 1821 | runif(1, -1, 1) * x_i^2 - sin(y_i^2) | runif(1, -1, 1) * y_i^3 - cos(x_i^2) | 
| 2018-11-16-17-12_seed_5451.png | 5451 | runif(1, -1, 1) * x_i^2 - sin(y_i^2) | runif(1, -1, 1) * y_i^3 - cos(x_i^2) | 


## Inspiration

The basic concept is heavily inspired by [Fronkonstin's great blog](https://fronkonstin.com/).


library(httr2)

#install.packages("/home/jack/Desktop/R-Studio/rjson_0.2.13.tar.gz", repos=NULL, type="source")
#install.packages("twitteR")
library(twitteR)
setup_twitter_oauth(consumer_key = 'APIkey()[0]',
                    access_token = 'APIkey()[2]',
                    consumer_secret = 'APIkey()[1]',
                    access_secret = 'APIkey()[3]')


#tw <- updateStatus("Now I need to read Tweets using R in my Jupyter Notebook! #Jupyternotebook #rstudio #RStudio") 
#Download version 2.13 from http://cran.rstudio.com/src/contrib/Archive/rjson/rjson_0.2.13.tar.gz In R, run install.packages('path to the downloaded gz file>', repos=NULL, type='source')")
#https://cran.rstudio.com/

tw <- updateStatus("#Jupyternotebook #rstudio #RStudio Now I'll try to post an Image", mediaPath = "post-this.png")

library(twitteR)
setup_twitter_oauth(consumer_key = 'XXXXXXXXX',
                    access_token = 'YYYYYYYYYYYYY',
                    consumer_secret = 'ZZZZZZZZZZZZZZZZZZZZZ',
                    access_secret = 'WWWWWWWWWWWWWWWWWWWWWW')
tw <- updateStatus('#Jupyternotebook #rstudio #RStudio Now I'll try to post an Image', mediaPath = 'post-this.png')

library(twitteR)
library(httr)


ckey <- "X"
csecret <- "X"
atoken <- "X"
asecret <- "X"

setup_twitter_oauth(ckey, csecret, atoken, asecret)

tweet("")
There is a parameter in tweet() and updateStatus() called mediaPath which you can use to submit images. Try something like:

tweet("some status", mediaPath = "url-to-image.jpg")
tw <- updateStatus("some status", mediaPath = "url-to-image.jpg")

install.packages("/home/jack/Desktop/R-Studio/devtools_2.4.5.tar.gz", repos = NULL, type="source")

install.packages(path_to_file, repos = NULL, type="source")

R --version
R version 3.6.1 (2019-07-05) -- "Action of the Toes"
Copyright (C) 2019 The R Foundation for Statistical Computing
Platform: x86_64-conda_cos6-linux-gnu (64-bit)


https://cran.rstudio.com/
https://developer.twitter.com/en/docs/api-reference-index
https://www.tensorflow.org/lite/examples/style_transfer/overview

https://www.r-bloggers.com/2018/05/send-tweets-from-r-a-very-short-walkthrough/
http://zevross.com/blog/2017/06/19/tips-and-tricks-for-working-with-images-and-figures-in-r-markdown-documents/
https://bookdown.org/yihui/rmarkdown/notebook.html#using-notebooks
https://towardsdatascience.com/getting-started-with-generative-art-in-r-3bc50067d34b
https://www.earthdatascience.org/courses/earth-analytics/get-data-using-apis/use-twitter-api-r/
https://www.jumpingrivers.com/blog/r-knitr-markdown-png-pdf-graphics/
https://dgarcia-eu.github.io/SocialDataScience/4_SNA/047_TwitterNetwork/TwitterNetwork.html
https://dgarcia-eu.github.io/SocialDataScience/2_SocialDynamics/027_rtweet/rtweet.html
https://datatofish.com/r-jupyter-notebook/
https://github.com/plotly/plotly.R/issues/239

install.packages(plotly) # if you haven't installed the package
library(plotly)

df <- data.frame(Product = c('Oven', 'Microwave', 'Toaster'),
                 Price = c(850, 300, 120)
                 )
print (df)

# Function definition
# To check n is divisible by 5 or not
divisbleBy5 <- function(n){
  if(n %% 5 == 0)
  {
    return("number is divisible by 5")
  }
  else 
  {
    return("number is not divisible by 5")
  }
}
   
# Function call
divisbleBy5(100)
divisbleBy5(4)
divisbleBy5(20.0)


 R Programming

# load twitter library - the rtweet library is recommended now over twitteR
library(rtweet)
# plotting and pipes - tidyverse!
library(ggplot2)
library(dplyr)
# text mining library
library(tidytext)


#install.packages("/home/jack/Desktop/R-Studio/rjson_0.2.13.tar.gz", repos=NULL, type="source")
#install.packages("twitteR")
library(twitteR)
setup_twitter_oauth(consumer_key = 'APIkey()[0]',
                    access_token = 'APIkey()[2]',
                    consumer_secret = 'APIkey()[1]',
                    access_secret = 'APIkey()[3]')


tw <- updateStatus("#rstudio #RStudio #twitteR This is an old library, it only allows a Tweet of under 140 characters") 
#Download version 2.13 from http://cran.rstudio.com/src/contrib/Archive/rjson/rjson_0.2.13.tar.gz In R, run install.packages('path to the downloaded gz file>', repos=NULL, type='source')")
#https://cran.rstudio.com/

#' Generate data
#'
#' The generative images are based on values in a dataframe. This function creates the data by transforming the base values `seq(-pi, pi)` with a `formula`.
#' @param formula a list that contains formulas for transforming the x- and y-values.
#' @return data frame
#' @seealso \code{\link{generate_plot}} the returned data frame is the input to generate the plot
#' @export
#' @examples
#' \dontrun{
#' generate_data(formula)
#' }
#' # an example for a formula:
#' formula <- list(
#'   x = quote(runif(1, -1, 1) * pi_x^2 -sin(pi_y^2)),
#'   y = quote(runif(1, -1, 1) * pi_y^3-cos(pi_x^2))
#'  )
#' @importFrom dplyr mutate
#' @importFrom magrittr %>%

### create dataframe with starting points and transformed x and y depending on a formula
generate_data <- function(formula) {
  print("generate data")
  df <- seq(from = -pi, to = pi, by = 0.01) %>%
    expand.grid(x_i = ., y_i = .) %>%
    dplyr::mutate(!!!formula)
  return(df)
}


generate_data

formula

generate_data(formula)
 formula <- list(
   x = quote(runif(1, -1, 1) * pi_x^2 -sin(pi_y^2)),
   y = quote(runif(1, -1, 1) * pi_y^3-cos(pi_x^2))
  )
#@importFrom dplyr mutate
#@importFrom magrittr %>%


library(devtools)

install.packages("devtools", dependencies = TRUE)

https://cran.r-project.org/src/contrib/httr2_0.2.2.tar.gz

Downloading and Extracting Packages
r-lubridate-1.7.4    | 1.1 MB    | #################################### | 100% 
r-mass-7.3_51.3      | 1.1 MB    | #################################### | 100% 
r-stringr-1.4.0      | 221 KB    | #################################### | 100% 
r-tibble-2.1.1       | 316 KB    | #################################### | 100% 
r-markdown-0.9       | 143 KB    | #################################### | 100% 
r-readr-1.3.1        | 814 KB    | #################################### | 100% 
r-dbi-1.0.0          | 916 KB    | #################################### | 100% 
r-reshape2-1.4.3     | 129 KB    | #################################### | 100% 
r-ps-1.3.0           | 221 KB    | #################################### | 100% 
r-processx-3.3.0     | 190 KB    | #################################### | 100% 
r-whisker-0.3_2      | 82 KB     | #################################### | 100% 
r-openssl-1.3        | 1.2 MB    | #################################### | 100% 
r-munsell-0.5.0      | 254 KB    | #################################### | 100% 
r-plogr-0.2.0        | 20 KB     | #################################### | 100% 
r-callr-3.2.0        | 270 KB    | #################################### | 100% 
r-yaml-2.2.0         | 113 KB    | #################################### | 100% 
r-bh-1.69.0_1        | 10.9 MB   | #################################### | 100% 
r-r6-2.4.0           | 68 KB     | #################################### | 100% 
r-purrr-0.3.2        | 397 KB    | #################################### | 100% 
r-pillar-1.3.1       | 180 KB    | #################################### | 100% 
r-stringi-1.4.3      | 773 KB    | #################################### | 100% 
r-gtable-0.3.0       | 425 KB    | #################################### | 100% 
r-highr-0.8          | 60 KB     | #################################### | 100% 
r-broom-0.5.2        | 2.0 MB    | #################################### | 100% 
r-colorspace-1.4_1   | 2.5 MB    | #################################### | 100% 
r-xfun-0.6           | 189 KB    | #################################### | 100% 
r-fs-1.2.7           | 510 KB    | #################################### | 100% 
r-utf8-1.1.4         | 159 KB    | #################################### | 100% 
r-rstudioapi-0.10    | 240 KB    | #################################### | 100% 
r-glue-1.3.1         | 165 KB    | #################################### | 100% 
r-xml2-1.2.0         | 340 KB    | #################################### | 100% 
r-rvest-0.3.3        | 928 KB    | #################################### | 100% 
r-rematch-1.0.1      | 19 KB     | #################################### | 100% 
r-knitr-1.22         | 1.3 MB    | #################################### | 100% 
r-nlme-3.1_139       | 2.2 MB    | #################################### | 100% 
r-dplyr-0.8.0.1      | 1.9 MB    | #################################### | 100% 
r-fansi-0.4.0        | 193 KB    | #################################### | 100% 
r-haven-2.1.0        | 331 KB    | #################################### | 100% 
r-dbplyr-1.4.0       | 622 KB    | #################################### | 100% 
r-labeling-0.3       | 71 KB     | #################################### | 100% 
r-sys-3.2            | 47 KB     | #################################### | 100% 
r-clipr-0.6.0        | 66 KB     | #################################### | 100% 
r-forcats-0.4.0      | 373 KB    | #################################### | 100% 
r-httr-1.4.0         | 513 KB    | #################################### | 100% 
r-tidyverse-1.2.1    | 95 KB     | #################################### | 100% 
r-backports-1.1.4    | 65 KB     | #################################### | 100% 
r-modelr-0.1.4       | 226 KB    | #################################### | 100% 
r-dichromat-2.0_0    | 163 KB    | #################################### | 100% 
r-pkgconfig-2.0.2    | 25 KB     | #################################### | 100% 
r-askpass-1.0        | 27 KB     | #################################### | 100% 
r-progress-1.2.0     | 89 KB     | #################################### | 100% 
r-lazyeval-0.2.2     | 164 KB    | #################################### | 100% 
r-tidyselect-0.2.5   | 138 KB    | #################################### | 100% 
r-assertthat-0.2.1   | 74 KB     | #################################### | 100% 
r-ggplot2-3.1.1      | 3.6 MB    | #################################### | 100% 
r-matrix-1.2_17      | 3.8 MB    | #################################### | 100% 
r-cli-1.1.0          | 189 KB    | #################################### | 100% 
r-readxl-1.3.1       | 855 KB    | #################################### | 100% 
r-withr-2.1.2        | 181 KB    | #################################### | 100% 
r-rlang-0.3.4        | 1.0 MB    | #################################### | 100% 
r-rmarkdown-1.12     | 3.0 MB    | #################################### | 100% 
r-generics-0.0.2     | 82 KB     | #################################### | 100% 
r-ellipsis-0.1.0     | 35 KB     | #################################### | 100% 
r-mime-0.6           | 50 KB     | #################################### | 100% 
r-rcolorbrewer-1.1_2 | 62 KB     | #################################### | 100% 
r-tinytex-0.12       | 106 KB    | #################################### | 100% 
r-curl-3.3           | 406 KB    | #################################### | 100% 
r-viridislite-0.3.0  | 66 KB     | #################################### | 100% 
r-cellranger-1.1.0   | 116 KB    | #################################### | 100% 
r-selectr-0.4_1      | 474 KB    | #################################### | 100% 
r-hms-0.4.2          | 74 KB     | #################################### | 100% 
r-scales-1.0.0       | 580 KB    | #################################### | 100% 
r-magrittr-1.5       | 173 KB    | #################################### | 100% 
r-plyr-1.8.4         | 815 KB    | #################################### | 100% 
r-tidyr-0.8.3        | 446 KB    | #################################### | 100% 
r-mgcv-1.8_28        | 2.6 MB    | #################################### | 100% 
r-lattice-0.20_38    | 1.1 MB    | #################################### | 100% 
r-reprex-0.2.1       | 410 KB    | #################################### | 100% 
r-prettyunits-1.0.2  | 38 KB     | #################################### | 100% 
Preparing transaction: done


Data sets
Package	Item	Title
datasets 	AirPassengers 	Monthly Airline Passenger Numbers 1949-1960
datasets 	BJsales 	Sales Data with Leading Indicator
datasets 	BJsales.lead (BJsales) 	Sales Data with Leading Indicator
datasets 	BOD 	Biochemical Oxygen Demand
datasets 	CO2 	Carbon Dioxide Uptake in Grass Plants
datasets 	ChickWeight 	Weight versus age of chicks on different diets
datasets 	DNase 	Elisa assay of DNase
datasets 	EuStockMarkets 	Daily Closing Prices of Major European Stock Indices, 1991-1998
datasets 	Formaldehyde 	Determination of Formaldehyde
datasets 	HairEyeColor 	Hair and Eye Color of Statistics Students
datasets 	Harman23.cor 	Harman Example 2.3
datasets 	Harman74.cor 	Harman Example 7.4
datasets 	Indometh 	Pharmacokinetics of Indomethacin
datasets 	InsectSprays 	Effectiveness of Insect Sprays
datasets 	JohnsonJohnson        	Quarterly Earnings per Johnson & Johnson Share                 
datasets 	LakeHuron 	Level of Lake Huron 1875-1972
datasets 	LifeCycleSavings 	Intercountry Life-Cycle Savings Data
datasets 	Loblolly 	Growth of Loblolly pine trees
datasets 	Nile 	Flow of the River Nile
datasets 	Orange 	Growth of Orange Trees
datasets 	OrchardSprays 	Potency of Orchard Sprays
datasets 	PlantGrowth 	Results from an Experiment on Plant Growth
datasets 	Puromycin 	Reaction Velocity of an Enzymatic Reaction
datasets 	Seatbelts 	Road Casualties in Great Britain 1969-84
datasets 	Theoph 	Pharmacokinetics of Theophylline
datasets 	Titanic 	Survival of passengers on the Titanic
datasets 	ToothGrowth 	The Effect of Vitamin C on Tooth Growth in Guinea Pigs
datasets 	UCBAdmissions 	Student Admissions at UC Berkeley
datasets 	UKDriverDeaths 	Road Casualties in Great Britain 1969-84
datasets 	UKgas 	UK Quarterly Gas Consumption
datasets 	USAccDeaths 	Accidental Deaths in the US 1973-1978
datasets 	USArrests 	Violent Crime Rates by US State
datasets 	USJudgeRatings 	Lawyers' Ratings of State Judges in the US Superior Court
datasets 	USPersonalExpenditure 	Personal Expenditure Data
datasets 	UScitiesD 	Distances Between European Cities and Between US Cities
datasets 	VADeaths 	Death Rates in Virginia (1940)
datasets 	WWWusage 	Internet Usage per Minute
datasets 	WorldPhones 	The World's Telephones
datasets 	ability.cov 	Ability and Intelligence Tests
datasets 	airmiles 	Passenger Miles on Commercial US Airlines, 1937-1960
datasets 	airquality 	New York Air Quality Measurements
datasets 	anscombe 	Anscombe's Quartet of 'Identical' Simple Linear Regressions
datasets 	attenu 	The Joyner-Boore Attenuation Data
datasets 	attitude 	The Chatterjee-Price Attitude Data
datasets 	austres 	Quarterly Time Series of the Number of Australian Residents
datasets 	beaver1 (beavers) 	Body Temperature Series of Two Beavers
datasets 	beaver2 (beavers) 	Body Temperature Series of Two Beavers
datasets 	cars 	Speed and Stopping Distances of Cars
datasets 	chickwts 	Chicken Weights by Feed Type
datasets 	co2 	Mauna Loa Atmospheric CO2 Concentration
datasets 	crimtab 	Student's 3000 Criminals Data
datasets 	discoveries 	Yearly Numbers of Important Discoveries
datasets 	esoph 	Smoking, Alcohol and (O)esophageal Cancer
datasets 	euro 	Conversion Rates of Euro Currencies
datasets 	euro.cross (euro) 	Conversion Rates of Euro Currencies
datasets 	eurodist 	Distances Between European Cities and Between US Cities
datasets 	faithful 	Old Faithful Geyser Data
datasets 	fdeaths (UKLungDeaths) 	Monthly Deaths from Lung Diseases in the UK
datasets 	freeny 	Freeny's Revenue Data
datasets 	freeny.x (freeny) 	Freeny's Revenue Data
datasets 	freeny.y (freeny) 	Freeny's Revenue Data
datasets 	infert 	Infertility after Spontaneous and Induced Abortion
datasets 	iris 	Edgar Anderson's Iris Data
datasets 	iris3 	Edgar Anderson's Iris Data
datasets 	islands 	Areas of the World's Major Landmasses
datasets 	ldeaths (UKLungDeaths) 	Monthly Deaths from Lung Diseases in the UK
datasets 	lh 	Luteinizing Hormone in Blood Samples
datasets 	longley 	Longley's Economic Regression Data
datasets 	lynx 	Annual Canadian Lynx trappings 1821-1934
datasets 	mdeaths (UKLungDeaths) 	Monthly Deaths from Lung Diseases in the UK
datasets 	morley 	Michelson Speed of Light Data
datasets 	mtcars 	Motor Trend Car Road Tests
datasets 	nhtemp 	Average Yearly Temperatures in New Haven
datasets 	nottem 	Average Monthly Temperatures at Nottingham, 1920-1939
datasets 	npk 	Classical N, P, K Factorial Experiment
datasets 	occupationalStatus 	Occupational Status of Fathers and their Sons
datasets 	precip 	Annual Precipitation in US Cities
datasets 	presidents 	Quarterly Approval Ratings of US Presidents
datasets 	pressure 	Vapor Pressure of Mercury as a Function of Temperature
datasets 	quakes 	Locations of Earthquakes off Fiji
datasets 	randu 	Random Numbers from Congruential Generator RANDU
datasets 	rivers 	Lengths of Major North American Rivers
datasets 	rock 	Measurements on Petroleum Rock Samples
datasets 	sleep 	Student's Sleep Data
datasets 	stack.loss (stackloss) 	Brownlee's Stack Loss Plant Data
datasets 	stack.x (stackloss) 	Brownlee's Stack Loss Plant Data
datasets 	stackloss 	Brownlee's Stack Loss Plant Data
datasets 	state.abb (state) 	US State Facts and Figures
datasets 	state.area (state) 	US State Facts and Figures
datasets 	state.center (state) 	US State Facts and Figures
datasets 	state.division (state) 	US State Facts and Figures
datasets 	state.name (state) 	US State Facts and Figures
datasets 	state.region (state) 	US State Facts and Figures
datasets 	state.x77 (state) 	US State Facts and Figures
datasets 	sunspot.month 	Monthly Sunspot Data, from 1749 to "Present"
datasets 	sunspot.year 	Yearly Sunspot Data, 1700-1988
datasets 	sunspots 	Monthly Sunspot Numbers, 1749-1983
datasets 	swiss 	Swiss Fertility and Socioeconomic Indicators (1888) Data
datasets 	treering 	Yearly Treering Data, -6000-1979
datasets 	trees 	Diameter, Height and Volume for Black Cherry Trees
datasets 	uspop 	Populations Recorded by the US Census
datasets 	volcano 	Topographic Information on Auckland's Maunga Whau Volcano
datasets 	warpbreaks 	The Number of Breaks in Yarn during Weaving
datasets 	women 	Average Heights and Weights for American Women

Use ‘data(package = .packages(all.available = TRUE))’ to list the data sets in all *available* packages.


packageurl <- "http://cran.r-project.org/src/contrib/Archive/XXXX/XXXX_A.B.C.tar.gz"
install.packages(packageurl, contriburl=NULL, type="source")

ls("package:twitteR")

library(twitteR)
setup_twitter_oauth(consumer_key = 'APIkey()[0]',
                    access_token = 'APIkey()[2]',
                    consumer_secret = 'APIkey()[1]',
                    access_secret = 'APIkey()[3]')


#tw <- updateStatus("#rstudio #RStudio #twitteR This is an old library, it only allows a Tweet of under 140 characters") 
#Download version 2.13 from http://cran.rstudio.com/src/contrib/Archive/rjson/rjson_0.2.13.tar.gz In R, run install.packages('path to the downloaded gz file>', repos=NULL, type='source')")
#https://cran.rstudio.com/

sen_df <- searchTwitter("SenateFloor", 300)

print (sen_df)

# load package
library(twitteR)

# set oauth
setup_twitter_oauth(consumer_key = 'APIkey()[0]',
                    access_token = 'APIkey()[2]',
                    consumer_secret = 'APIkey()[1]',
                    access_secret = 'APIkey()[3]')


# get user timeline
k<-userTimeline("SenateFloor", n = 50, includeRts = T)

# to data frame
k<-twListToDF(k)

# print tweet text
print(k$text[1:5])


# load package
library(twitteR)

# set oauth
setup_twitter_oauth(consumer_key = 'APIkey()[0]',
                    access_token = 'APIkey()[2]',
                    consumer_secret = 'APIkey()[1]',
                    access_secret = 'APIkey()[3]')


# get user timeline
k<-userTimeline("Climate", n = 50, includeRts = T)

# to data frame
k<-twListToDF(k)

# print tweet text
print(k$text[1:50])


df <- data.frame(Product = c('Oven', 'Microwave', 'Toaster'),
                 Price = c(850, 300, 120)
                 )
print (df)

a<-installed.packages()
packages<-a[,1] 
is.element("MASS", packages)

help(package="MASS")

Documentation for package ‘MASS’
Information on package ‘MASS’

Description:

Package:            MASS
Version:            7.3-51.3
Date:               2019-03-31
Revision:           $Rev: 3492 $
Depends:            R (>= 3.1.0), grDevices, graphics, stats, utils
Imports:            methods
Suggests:           lattice, nlme, nnet, survival
Authors@R:          c(person("Brian", "Ripley", role = c("aut", "cre",
                    "cph"), email = "ripley@stats.ox.ac.uk"),
                    person("Bill", "Venables", role = "ctb"),
                    person(c("Douglas", "M."), "Bates", role = "ctb"),
                    person("Kurt", "Hornik", role = "trl", comment =
                    "partial port ca 1998"), person("Albrecht",
                    "Gebhardt", role = "trl", comment = "partial port
                    ca 1998"), person("David", "Firth", role = "ctb"))
Description:        Functions and datasets to support Venables and
                    Ripley, "Modern Applied Statistics with S" (4th
                    edition, 2002).
Title:              Support Functions and Datasets for Venables and
                    Ripley's MASS
LazyData:           yes
ByteCompile:        yes
License:            GPL-2 | GPL-3
URL:                http://www.stats.ox.ac.uk/pub/MASS4/
Contact:            <MASS@stats.ox.ac.uk>
NeedsCompilation:   yes
Packaged:           2019-03-31 07:52:37 UTC; ripley
Author:             Brian Ripley [aut, cre, cph], Bill Venables [ctb],
                    Douglas M. Bates [ctb], Kurt Hornik [trl] (partial
                    port ca 1998), Albrecht Gebhardt [trl] (partial
                    port ca 1998), David Firth [ctb]
Maintainer:         Brian Ripley <ripley@stats.ox.ac.uk>
Repository:         CRAN
Date/Publication:   2019-03-31 07:54:32 UTC
Built:              R 3.6.0; x86_64-conda_cos6-linux-gnu; 2019-05-17
                    09:30:42 UTC; unix

Index:

Functions:
=========

Null                    Null Spaces of Matrices
addterm                 Try All One-Term Additions to a Model
anova.negbin            Likelihood Ratio Tests for Negative Binomial GLMs
area                    Adaptive Numerical Integration
bandwidth.nrd           Bandwidth for density() via Normal Reference
                          Distribution
bcv                     Biased Cross-Validation for Bandwidth Selection
boxcox                  Box-Cox Transformations for Linear Models
con2tr                  Convert Lists to Data Frames for use by lattice
confint-MASS            Confidence Intervals for Model Parameters
contr.sdif              Successive Differences Contrast Coding
corresp                 Simple Correspondence Analysis
cov.rob                 Resistant Estimation of Multivariate Location and
                          Scatter
cov.trob                Covariance Estimation for Multivariate t Distribution
denumerate              Transform an Allowable Formula for 'loglm'
                          into one for 'terms'
dose.p                  Predict Doses for Binomial Assay model
dropterm                Try All One-Term Deletions from a Model
eqscplot                Plots with Geometrically Equal Scales
fitdistr                Maximum-likelihood Fitting of Univariate Distributions
fractions               Rational Approximation
gamma.dispersion        Calculate the MLE of the Gamma Dispersion Parameter
			  in a GLM Fit
gamma.shape             Estimate the Shape Parameter of the Gamma Distribution 
			  in a GLM Fit
ginv                    Generalized Inverse of a Matrix
glm.convert             Change a Negative Binomial fit to a GLM fit
glm.nb                  Fit a Negative Binomial Generalized Linear Model
glmmPQL                 Fit Generalized Linear Mixed Models via PQL
hist.scott              Plot a Histogram with Automatic Bin Width Selection
huber                   Huber M-estimator of Location with MAD Scale
hubers                  Huber Proposal 2 Robust Estimator of Location
                          and/or Scale
isoMDS                  Kruskal's Non-metric Multidimensional Scaling
kde2d                   Two-Dimensional Kernel Density Estimation
lda                     Linear Discriminant Analysis
ldahist                 Histograms or Density Plots of Multiple Groups
lm.gls                  Fit Linear Models by Generalized Least Squares
lm.ridge                Ridge Regression
loglm                   Fit Log-Linear Models by Iterative
                        Proportional Scaling
logtrans                Estimate log Transformation Parameter
lqs			Resistant Regression
mca                     Multiple Correspondence Analysis
mvrnorm                 Simulate from a Multivariate Normal Distribution
negative.binomial       Family function for Negative Binomial GLMs
newcomb                 Newcomb's Measurements of the Passage Time of Light
pairs.lda               Produce Pairwise Scatterplots from an 'lda' Fit
parcoord                Parallel Coordinates Plot
plot.lda                Plot Method for Class 'lda'
plot.mca                Plot Method for Objects of Class 'mca'
polr                    Proportional Odds Logistic Regression
predict.lda             Classify Multivariate Observations by Linear
                          Discrimination
predict.lqs             Predict from an lqs Fit
predict.mca             Predict Method for Class 'mca'
predict.qda             Classify from Quadratic Discriminant Analysis
profile.glm             Method for Profiling glm Objects
qda                     Quadratic Discriminant Analysis
rational                Rational Approximation
renumerate              Convert a Formula Transformed by 'denumerate'
rlm                     Robust Fitting of Linear Models
rms.curv                Relative Curvature Measures for Non-Linear Regression
rnegbin                 Simulate Negative Binomial Variates
sammon                  Sammon's Non-Linear Mapping
stdres                  Extract Standardized Residuals from a Linear Model
stepAIC                 Choose a model by AIC in a Stepwise Algorithm
studres                 Extract Studentized Residuals from a Linear Model
summary.loglm           Summary Method Function for Objects of Class 'loglm'
summary.negbin          Summary Method Function for Objects of Class 'negbin'
summary.rlm             Summary Method for Robust Linear Models
theta.md                Estimate theta of the Negative Binomial by Deviance
theta.ml                Estimate theta of the Negative Binomial by Maximum
			  Likelihood
theta.mm                Estimate theta of the Negative Binomial by Moments
truehist                Plot a Histogram
ucv                     Unbiased Cross-Validation for Bandwidth Selection
width.SJ                Bandwidth Selection by Pilot Estimation of Derivatives
write.matrix            Write a Matrix or Data Frame


Datasets:
========

Aids2                   Australian AIDS Survival Data
Animals                 Brain and Body Weights for 28 Species
Boston                  Housing Values in Suburbs of Boston
Cars93                  Data from 93 Cars on Sale in the USA in 1993
Cushings                Diagnostic Tests on Patients with Cushing's Syndrome
DDT                     DDT in Kale
GAGurine                Level of GAG in Urine of Children
Insurance               Numbers of Car Insurance claims
Melanoma                Survival from Malignant Melanoma
OME                     Tests of Auditory Perception in Children with OME
Pima.tr                 Diabetes in Pima Indian Women
Rabbit                  Blood Pressure in Rabbits
Rubber                  Accelerated Testing of Tyre Rubber
SP500                   Returns of the Standard and Poors 500
Sitka                   Growth Curves for Sitka Spruce Trees in 1988
Sitka89                 Growth Curves for Sitka Spruce Trees in 1989
Skye                    AFM Compositions of Aphyric Skye Lavas
Traffic                 Effect of Swedish Speed Limits on Accidents
UScereal                Nutritional and Marketing Information on US Cereals
UScrime                 The Effect of Punishment Regimes on Crime Rates
VA                      Veteran's Administration Lung Cancer Trial
abbey                   Determinations of Nickel Content
accdeaths               Accidental Deaths in the US 1973-1978
anorexia                Anorexia Data on Weight Change
bacteria                Presence of Bacteria after Drug Treatments
beav1                   Body Temperature Series of Beaver 1
beav2                   Body Temperature Series of Beaver 2
biopsy                  Biopsy Data on Breast Cancer Patients
birthwt                 Risk Factors Associated with Low Infant Birth Weight
cabbages                Data from a cabbage field trial
caith                   Colours of Eyes and Hair of People in Caithness
cats                    Anatomical Data from Domestic Cats
cement                  Heat Evolved by Setting Cements
chem                    Copper in Wholemeal Flour
coop                    Co-operative Trial in Analytical Chemistry
cpus                    Performance of Computer CPUs
crabs                   Morphological Measurements on Leptograpsus Crabs
deaths                  Monthly Deaths from Lung Diseases in the UK
drivers                 Deaths of Car Drivers in Great Britain 1969-84
eagles                  Foraging Ecology of Bald Eagles
epil                    Seizure Counts for Epileptics
farms                   Ecological Factors in Farm Management
fgl                     Measurements of Forensic Glass Fragments
forbes                  Forbes' Data on Boiling Points in the Alps
galaxies                Velocities for 82 Galaxies
gehan                   Remission Times of Leukaemia Patients
genotype                Rat Genotype Data
geyser                  Old Faithful Geyser Data
gilgais                 Line Transect of Soil in Gilgai Territory
hills                   Record Times in Scottish Hill Races
housing                 Frequency Table from a Copenhagen Housing Conditions 
			  Survey
immer                   Yields from a Barley Field Trial
leuk                    Survival Times and White Blood Counts for
                          Leukaemia Patients
mammals                 Brain and Body Weights for 62 Species of Land Mammals
mcycle                  Data from a Simulated Motorcycle Accident
menarche                Age of Menarche in Warsaw
michelson               Michelson's Speed of Light Data
minn38                  Minnesota High School Graduates of 1938
motors                  Accelerated Life Testing of Motorettes
muscle                  Effect of Calcium Chloride on Muscle Contraction
			  in Rat Hearts
newcomb                 Newcomb's Measurements of the Passage Time of Light
nlschools               Eighth-Grade Pupils in the Netherlands
npk                     Classical N, P, K Factorial Experiment
npr1                    US Naval Petroleum Reserve No. 1 data
oats                    Data from an Oats Field Trial
painters                The Painter's Data of de Piles
petrol                  N. L. Prater's Petrol Refinery Data
phones                  Belgium Phone Calls 1950-1973
quine                   Absenteeism from School in Rural New South Wales
road                    Road Accident Deaths in US States
rotifer                 Numbers of Rotifers by Fluid Density
ships                   Ships Damage Data
shoes                   Shoe wear data of Box, Hunter and Hunter
shrimp                  Percentage of Shrimp in Shrimp Cocktail
shuttle                 Space Shuttle Autolander Problem
snails                  Snail Mortality Data
steam                   The Saturated Steam Pressure Data
stormer                 The Stormer Viscometer Data
survey                  Student Survey Data
synth.tr                Synthetic Classification Problem
topo                    Spatial Topographic Data
waders                  Counts of Waders at 15 Sites in South Africa
whiteside               House Insulation: Whiteside's Data
wtloss                  Weight Loss Data from an Obese Patient

library("MASS")

help(galaxies)

galaxies {MASS}	R Documentation
Velocities for 82 Galaxies
Description
A numeric vector of velocities in km/sec of 82 galaxies from 6 well-separated conic sections of an unfilled survey of the Corona Borealis region. Multimodality in such surveys is evidence for voids and superclusters in the far universe.
Usage
galaxies

Note
There is an 83rd measurement of 5607 km/sec in the Postman et al. paper which is omitted in Roeder (1990) and from the dataset here.
There is also a typo: this dataset has 78th observation 26690 which should be 26960.
Source
Roeder, K. (1990) Density estimation with confidence sets exemplified by superclusters and voids in galaxies. Journal of the American Statistical Association 85, 617–624.
Postman, M., Huchra, J. P. and Geller, M. J. (1986) Probes of large-scale structures in the Corona Borealis region. Astronomical Journal 92, 1238–1247.
References
Venables, W. N. and Ripley, B. D. (2002) Modern Applied Statistics with S. Fourth edition. Springer.

Examples:
gal <- galaxies/1000
c(width.SJ(gal, method = "dpi"), width.SJ(gal))
plot(x = c(0, 40), y = c(0, 0.3), type = "n", bty = "l",
     xlab = "velocity of galaxy (1000km/s)", ylab = "density")
rug(gal)
lines(density(gal, width = 3.25, n = 200), lty = 1)
lines(density(gal, width = 2.56, n = 200), lty = 3)

[Package MASS version 7.3-51.3 ]

gal <- galaxies/1000
c(width.SJ(gal, method = "dpi"), width.SJ(gal))
plot(x = c(0, 40), y = c(0, 0.3), type = "n", bty = "l",
     xlab = "velocity of galaxy (1000km/s)", ylab = "density")
rug(gal)
lines(density(gal, width = 3.25, n = 200), lty = 1)
lines(density(gal, width = 2.56, n = 200), lty = 3)


p <- available.packages()

dim(p)

Data sets
Package	Item	Title
datasets 	AirPassengers 	Monthly Airline Passenger Numbers 1949-1960
datasets 	BJsales 	Sales Data with Leading Indicator
datasets 	BJsales.lead (BJsales) 	Sales Data with Leading Indicator
datasets 	BOD 	Biochemical Oxygen Demand
datasets 	CO2 	Carbon Dioxide Uptake in Grass Plants
datasets 	ChickWeight 	Weight versus age of chicks on different diets
datasets 	DNase 	Elisa assay of DNase
datasets 	EuStockMarkets 	Daily Closing Prices of Major European Stock Indices, 1991-1998
datasets 	Formaldehyde 	Determination of Formaldehyde
datasets 	HairEyeColor 	Hair and Eye Color of Statistics Students
datasets 	Harman23.cor 	Harman Example 2.3
datasets 	Harman74.cor 	Harman Example 7.4
datasets 	Indometh 	Pharmacokinetics of Indomethacin
datasets 	InsectSprays 	Effectiveness of Insect Sprays
datasets 	JohnsonJohnson        	Quarterly Earnings per Johnson & Johnson Share                 
datasets 	LakeHuron 	Level of Lake Huron 1875-1972
datasets 	LifeCycleSavings 	Intercountry Life-Cycle Savings Data
datasets 	Loblolly 	Growth of Loblolly pine trees
datasets 	Nile 	Flow of the River Nile
datasets 	Orange 	Growth of Orange Trees
datasets 	OrchardSprays 	Potency of Orchard Sprays
datasets 	PlantGrowth 	Results from an Experiment on Plant Growth
datasets 	Puromycin 	Reaction Velocity of an Enzymatic Reaction
datasets 	Seatbelts 	Road Casualties in Great Britain 1969-84
datasets 	Theoph 	Pharmacokinetics of Theophylline
datasets 	Titanic 	Survival of passengers on the Titanic
datasets 	ToothGrowth 	The Effect of Vitamin C on Tooth Growth in Guinea Pigs
datasets 	UCBAdmissions 	Student Admissions at UC Berkeley
datasets 	UKDriverDeaths 	Road Casualties in Great Britain 1969-84
datasets 	UKgas 	UK Quarterly Gas Consumption
datasets 	USAccDeaths 	Accidental Deaths in the US 1973-1978
datasets 	USArrests 	Violent Crime Rates by US State
datasets 	USJudgeRatings 	Lawyers' Ratings of State Judges in the US Superior Court
datasets 	USPersonalExpenditure 	Personal Expenditure Data
datasets 	UScitiesD 	Distances Between European Cities and Between US Cities
datasets 	VADeaths 	Death Rates in Virginia (1940)
datasets 	WWWusage 	Internet Usage per Minute
datasets 	WorldPhones 	The World's Telephones
datasets 	ability.cov 	Ability and Intelligence Tests
datasets 	airmiles 	Passenger Miles on Commercial US Airlines, 1937-1960
datasets 	airquality 	New York Air Quality Measurements
datasets 	anscombe 	Anscombe's Quartet of 'Identical' Simple Linear Regressions
datasets 	attenu 	The Joyner-Boore Attenuation Data
datasets 	attitude 	The Chatterjee-Price Attitude Data
datasets 	austres 	Quarterly Time Series of the Number of Australian Residents
datasets 	beaver1 (beavers) 	Body Temperature Series of Two Beavers
datasets 	beaver2 (beavers) 	Body Temperature Series of Two Beavers
datasets 	cars 	Speed and Stopping Distances of Cars
datasets 	chickwts 	Chicken Weights by Feed Type
datasets 	co2 	Mauna Loa Atmospheric CO2 Concentration
datasets 	crimtab 	Student's 3000 Criminals Data
datasets 	discoveries 	Yearly Numbers of Important Discoveries
datasets 	esoph 	Smoking, Alcohol and (O)esophageal Cancer
datasets 	euro 	Conversion Rates of Euro Currencies
datasets 	euro.cross (euro) 	Conversion Rates of Euro Currencies
datasets 	eurodist 	Distances Between European Cities and Between US Cities
datasets 	faithful 	Old Faithful Geyser Data
datasets 	fdeaths (UKLungDeaths) 	Monthly Deaths from Lung Diseases in the UK
datasets 	freeny 	Freeny's Revenue Data
datasets 	freeny.x (freeny) 	Freeny's Revenue Data
datasets 	freeny.y (freeny) 	Freeny's Revenue Data
datasets 	infert 	Infertility after Spontaneous and Induced Abortion
datasets 	iris 	Edgar Anderson's Iris Data
datasets 	iris3 	Edgar Anderson's Iris Data
datasets 	islands 	Areas of the World's Major Landmasses
datasets 	ldeaths (UKLungDeaths) 	Monthly Deaths from Lung Diseases in the UK
datasets 	lh 	Luteinizing Hormone in Blood Samples
datasets 	longley 	Longley's Economic Regression Data
datasets 	lynx 	Annual Canadian Lynx trappings 1821-1934
datasets 	mdeaths (UKLungDeaths) 	Monthly Deaths from Lung Diseases in the UK
datasets 	morley 	Michelson Speed of Light Data
datasets 	mtcars 	Motor Trend Car Road Tests
datasets 	nhtemp 	Average Yearly Temperatures in New Haven
datasets 	nottem 	Average Monthly Temperatures at Nottingham, 1920-1939
datasets 	npk 	Classical N, P, K Factorial Experiment
datasets 	occupationalStatus 	Occupational Status of Fathers and their Sons
datasets 	precip 	Annual Precipitation in US Cities
datasets 	presidents 	Quarterly Approval Ratings of US Presidents
datasets 	pressure 	Vapor Pressure of Mercury as a Function of Temperature
datasets 	quakes 	Locations of Earthquakes off Fiji
datasets 	randu 	Random Numbers from Congruential Generator RANDU
datasets 	rivers 	Lengths of Major North American Rivers
datasets 	rock 	Measurements on Petroleum Rock Samples
datasets 	sleep 	Student's Sleep Data
datasets 	stack.loss (stackloss) 	Brownlee's Stack Loss Plant Data
datasets 	stack.x (stackloss) 	Brownlee's Stack Loss Plant Data
datasets 	stackloss 	Brownlee's Stack Loss Plant Data
datasets 	state.abb (state) 	US State Facts and Figures
datasets 	state.area (state) 	US State Facts and Figures
datasets 	state.center (state) 	US State Facts and Figures
datasets 	state.division (state) 	US State Facts and Figures
datasets 	state.name (state) 	US State Facts and Figures
datasets 	state.region (state) 	US State Facts and Figures
datasets 	state.x77 (state) 	US State Facts and Figures
datasets 	sunspot.month 	Monthly Sunspot Data, from 1749 to "Present"
datasets 	sunspot.year 	Yearly Sunspot Data, 1700-1988
datasets 	sunspots 	Monthly Sunspot Numbers, 1749-1983
datasets 	swiss 	Swiss Fertility and Socioeconomic Indicators (1888) Data
datasets 	treering 	Yearly Treering Data, -6000-1979
datasets 	trees 	Diameter, Height and Volume for Black Cherry Trees
datasets 	uspop 	Populations Recorded by the US Census
datasets 	volcano 	Topographic Information on Auckland's Maunga Whau Volcano
datasets 	warpbreaks 	The Number of Breaks in Yarn during Weaving
datasets 	women 	Average Heights and Weights for American Women

Use ‘data(package = .packages(all.available = TRUE))’ to list the data sets in all *available* packages.


packageurl <- "http://cran.r-project.org/src/contrib/Archive/XXXX/XXXX_A.B.C.tar.gz"
install.packages(packageurl, contriburl=NULL, type="source")

ls("package:twitteR")

library(twitteR)
setup_twitter_oauth(consumer_key = 'APIkey()[0]',
                    access_token = 'APIkey()[2]',
                    consumer_secret = 'APIkey()[1]',
                    access_secret = 'APIkey()[3]')


#tw <- updateStatus("#rstudio #RStudio #twitteR This is an old library, it only allows a Tweet of under 140 characters") 
#Download version 2.13 from http://cran.rstudio.com/src/contrib/Archive/rjson/rjson_0.2.13.tar.gz In R, run install.packages('path to the downloaded gz file>', repos=NULL, type='source')")
#https://cran.rstudio.com/

sen_df <- searchTwitter("SenateFloor", 300)

print (sen_df)

# load package
library(twitteR)

# set oauth
setup_twitter_oauth(consumer_key = 'APIkey()[0]',
                    access_token = 'APIkey()[2]',
                    consumer_secret = 'APIkey()[1]',
                    access_secret = 'APIkey()[3]')


# get user timeline
k<-userTimeline("SenateFloor", n = 50, includeRts = T)

# to data frame
k<-twListToDF(k)

# print tweet text
print(k$text[1:5])


# load package
library(twitteR)

# set oauth
setup_twitter_oauth(consumer_key = 'APIkey()[0]',
                    access_token = 'APIkey()[2]',
                    consumer_secret = 'APIkey()[1]',
                    access_secret = 'APIkey()[3]')


# get user timeline
k<-userTimeline("Climate", n = 50, includeRts = T)

# to data frame
k<-twListToDF(k)

# print tweet text
print(k$text[1:50])


df <- data.frame(Product = c('Oven', 'Microwave', 'Toaster'),
                 Price = c(850, 300, 120)
                 )
print (df)

a<-installed.packages()
packages<-a[,1] 
is.element("MASS", packages)

help(package="MASS")

Documentation for package ‘MASS’
Information on package ‘MASS’

Description:

Package:            MASS
Version:            7.3-51.3
Date:               2019-03-31
Revision:           $Rev: 3492 $
Depends:            R (>= 3.1.0), grDevices, graphics, stats, utils
Imports:            methods
Suggests:           lattice, nlme, nnet, survival
Authors@R:          c(person("Brian", "Ripley", role = c("aut", "cre",
                    "cph"), email = "ripley@stats.ox.ac.uk"),
                    person("Bill", "Venables", role = "ctb"),
                    person(c("Douglas", "M."), "Bates", role = "ctb"),
                    person("Kurt", "Hornik", role = "trl", comment =
                    "partial port ca 1998"), person("Albrecht",
                    "Gebhardt", role = "trl", comment = "partial port
                    ca 1998"), person("David", "Firth", role = "ctb"))
Description:        Functions and datasets to support Venables and
                    Ripley, "Modern Applied Statistics with S" (4th
                    edition, 2002).
Title:              Support Functions and Datasets for Venables and
                    Ripley's MASS
LazyData:           yes
ByteCompile:        yes
License:            GPL-2 | GPL-3
URL:                http://www.stats.ox.ac.uk/pub/MASS4/
Contact:            <MASS@stats.ox.ac.uk>
NeedsCompilation:   yes
Packaged:           2019-03-31 07:52:37 UTC; ripley
Author:             Brian Ripley [aut, cre, cph], Bill Venables [ctb],
                    Douglas M. Bates [ctb], Kurt Hornik [trl] (partial
                    port ca 1998), Albrecht Gebhardt [trl] (partial
                    port ca 1998), David Firth [ctb]
Maintainer:         Brian Ripley <ripley@stats.ox.ac.uk>
Repository:         CRAN
Date/Publication:   2019-03-31 07:54:32 UTC
Built:              R 3.6.0; x86_64-conda_cos6-linux-gnu; 2019-05-17
                    09:30:42 UTC; unix

Index:

Functions:
=========

Null                    Null Spaces of Matrices
addterm                 Try All One-Term Additions to a Model
anova.negbin            Likelihood Ratio Tests for Negative Binomial GLMs
area                    Adaptive Numerical Integration
bandwidth.nrd           Bandwidth for density() via Normal Reference
                          Distribution
bcv                     Biased Cross-Validation for Bandwidth Selection
boxcox                  Box-Cox Transformations for Linear Models
con2tr                  Convert Lists to Data Frames for use by lattice
confint-MASS            Confidence Intervals for Model Parameters
contr.sdif              Successive Differences Contrast Coding
corresp                 Simple Correspondence Analysis
cov.rob                 Resistant Estimation of Multivariate Location and
                          Scatter
cov.trob                Covariance Estimation for Multivariate t Distribution
denumerate              Transform an Allowable Formula for 'loglm'
                          into one for 'terms'
dose.p                  Predict Doses for Binomial Assay model
dropterm                Try All One-Term Deletions from a Model
eqscplot                Plots with Geometrically Equal Scales
fitdistr                Maximum-likelihood Fitting of Univariate Distributions
fractions               Rational Approximation
gamma.dispersion        Calculate the MLE of the Gamma Dispersion Parameter
			  in a GLM Fit
gamma.shape             Estimate the Shape Parameter of the Gamma Distribution 
			  in a GLM Fit
ginv                    Generalized Inverse of a Matrix
glm.convert             Change a Negative Binomial fit to a GLM fit
glm.nb                  Fit a Negative Binomial Generalized Linear Model
glmmPQL                 Fit Generalized Linear Mixed Models via PQL
hist.scott              Plot a Histogram with Automatic Bin Width Selection
huber                   Huber M-estimator of Location with MAD Scale
hubers                  Huber Proposal 2 Robust Estimator of Location
                          and/or Scale
isoMDS                  Kruskal's Non-metric Multidimensional Scaling
kde2d                   Two-Dimensional Kernel Density Estimation
lda                     Linear Discriminant Analysis
ldahist                 Histograms or Density Plots of Multiple Groups
lm.gls                  Fit Linear Models by Generalized Least Squares
lm.ridge                Ridge Regression
loglm                   Fit Log-Linear Models by Iterative
                        Proportional Scaling
logtrans                Estimate log Transformation Parameter
lqs			Resistant Regression
mca                     Multiple Correspondence Analysis
mvrnorm                 Simulate from a Multivariate Normal Distribution
negative.binomial       Family function for Negative Binomial GLMs
newcomb                 Newcomb's Measurements of the Passage Time of Light
pairs.lda               Produce Pairwise Scatterplots from an 'lda' Fit
parcoord                Parallel Coordinates Plot
plot.lda                Plot Method for Class 'lda'
plot.mca                Plot Method for Objects of Class 'mca'
polr                    Proportional Odds Logistic Regression
predict.lda             Classify Multivariate Observations by Linear
                          Discrimination
predict.lqs             Predict from an lqs Fit
predict.mca             Predict Method for Class 'mca'
predict.qda             Classify from Quadratic Discriminant Analysis
profile.glm             Method for Profiling glm Objects
qda                     Quadratic Discriminant Analysis
rational                Rational Approximation
renumerate              Convert a Formula Transformed by 'denumerate'
rlm                     Robust Fitting of Linear Models
rms.curv                Relative Curvature Measures for Non-Linear Regression
rnegbin                 Simulate Negative Binomial Variates
sammon                  Sammon's Non-Linear Mapping
stdres                  Extract Standardized Residuals from a Linear Model
stepAIC                 Choose a model by AIC in a Stepwise Algorithm
studres                 Extract Studentized Residuals from a Linear Model
summary.loglm           Summary Method Function for Objects of Class 'loglm'
summary.negbin          Summary Method Function for Objects of Class 'negbin'
summary.rlm             Summary Method for Robust Linear Models
theta.md                Estimate theta of the Negative Binomial by Deviance
theta.ml                Estimate theta of the Negative Binomial by Maximum
			  Likelihood
theta.mm                Estimate theta of the Negative Binomial by Moments
truehist                Plot a Histogram
ucv                     Unbiased Cross-Validation for Bandwidth Selection
width.SJ                Bandwidth Selection by Pilot Estimation of Derivatives
write.matrix            Write a Matrix or Data Frame


Datasets:
========

Aids2                   Australian AIDS Survival Data
Animals                 Brain and Body Weights for 28 Species
Boston                  Housing Values in Suburbs of Boston
Cars93                  Data from 93 Cars on Sale in the USA in 1993
Cushings                Diagnostic Tests on Patients with Cushing's Syndrome
DDT                     DDT in Kale
GAGurine                Level of GAG in Urine of Children
Insurance               Numbers of Car Insurance claims
Melanoma                Survival from Malignant Melanoma
OME                     Tests of Auditory Perception in Children with OME
Pima.tr                 Diabetes in Pima Indian Women
Rabbit                  Blood Pressure in Rabbits
Rubber                  Accelerated Testing of Tyre Rubber
SP500                   Returns of the Standard and Poors 500
Sitka                   Growth Curves for Sitka Spruce Trees in 1988
Sitka89                 Growth Curves for Sitka Spruce Trees in 1989
Skye                    AFM Compositions of Aphyric Skye Lavas
Traffic                 Effect of Swedish Speed Limits on Accidents
UScereal                Nutritional and Marketing Information on US Cereals
UScrime                 The Effect of Punishment Regimes on Crime Rates
VA                      Veteran's Administration Lung Cancer Trial
abbey                   Determinations of Nickel Content
accdeaths               Accidental Deaths in the US 1973-1978
anorexia                Anorexia Data on Weight Change
bacteria                Presence of Bacteria after Drug Treatments
beav1                   Body Temperature Series of Beaver 1
beav2                   Body Temperature Series of Beaver 2
biopsy                  Biopsy Data on Breast Cancer Patients
birthwt                 Risk Factors Associated with Low Infant Birth Weight
cabbages                Data from a cabbage field trial
caith                   Colours of Eyes and Hair of People in Caithness
cats                    Anatomical Data from Domestic Cats
cement                  Heat Evolved by Setting Cements
chem                    Copper in Wholemeal Flour
coop                    Co-operative Trial in Analytical Chemistry
cpus                    Performance of Computer CPUs
crabs                   Morphological Measurements on Leptograpsus Crabs
deaths                  Monthly Deaths from Lung Diseases in the UK
drivers                 Deaths of Car Drivers in Great Britain 1969-84
eagles                  Foraging Ecology of Bald Eagles
epil                    Seizure Counts for Epileptics
farms                   Ecological Factors in Farm Management
fgl                     Measurements of Forensic Glass Fragments
forbes                  Forbes' Data on Boiling Points in the Alps
galaxies                Velocities for 82 Galaxies
gehan                   Remission Times of Leukaemia Patients
genotype                Rat Genotype Data
geyser                  Old Faithful Geyser Data
gilgais                 Line Transect of Soil in Gilgai Territory
hills                   Record Times in Scottish Hill Races
housing                 Frequency Table from a Copenhagen Housing Conditions 
			  Survey
immer                   Yields from a Barley Field Trial
leuk                    Survival Times and White Blood Counts for
                          Leukaemia Patients
mammals                 Brain and Body Weights for 62 Species of Land Mammals
mcycle                  Data from a Simulated Motorcycle Accident
menarche                Age of Menarche in Warsaw
michelson               Michelson's Speed of Light Data
minn38                  Minnesota High School Graduates of 1938
motors                  Accelerated Life Testing of Motorettes
muscle                  Effect of Calcium Chloride on Muscle Contraction
			  in Rat Hearts
newcomb                 Newcomb's Measurements of the Passage Time of Light
nlschools               Eighth-Grade Pupils in the Netherlands
npk                     Classical N, P, K Factorial Experiment
npr1                    US Naval Petroleum Reserve No. 1 data
oats                    Data from an Oats Field Trial
painters                The Painter's Data of de Piles
petrol                  N. L. Prater's Petrol Refinery Data
phones                  Belgium Phone Calls 1950-1973
quine                   Absenteeism from School in Rural New South Wales
road                    Road Accident Deaths in US States
rotifer                 Numbers of Rotifers by Fluid Density
ships                   Ships Damage Data
shoes                   Shoe wear data of Box, Hunter and Hunter
shrimp                  Percentage of Shrimp in Shrimp Cocktail
shuttle                 Space Shuttle Autolander Problem
snails                  Snail Mortality Data
steam                   The Saturated Steam Pressure Data
stormer                 The Stormer Viscometer Data
survey                  Student Survey Data
synth.tr                Synthetic Classification Problem
topo                    Spatial Topographic Data
waders                  Counts of Waders at 15 Sites in South Africa
whiteside               House Insulation: Whiteside's Data
wtloss                  Weight Loss Data from an Obese Patient

library("MASS")

help(galaxies)

galaxies {MASS}	R Documentation
Velocities for 82 Galaxies
Description
A numeric vector of velocities in km/sec of 82 galaxies from 6 well-separated conic sections of an unfilled survey of the Corona Borealis region. Multimodality in such surveys is evidence for voids and superclusters in the far universe.
Usage
galaxies

Note
There is an 83rd measurement of 5607 km/sec in the Postman et al. paper which is omitted in Roeder (1990) and from the dataset here.
There is also a typo: this dataset has 78th observation 26690 which should be 26960.
Source
Roeder, K. (1990) Density estimation with confidence sets exemplified by superclusters and voids in galaxies. Journal of the American Statistical Association 85, 617–624.
Postman, M., Huchra, J. P. and Geller, M. J. (1986) Probes of large-scale structures in the Corona Borealis region. Astronomical Journal 92, 1238–1247.
References
Venables, W. N. and Ripley, B. D. (2002) Modern Applied Statistics with S. Fourth edition. Springer.

Examples:
gal <- galaxies/1000
c(width.SJ(gal, method = "dpi"), width.SJ(gal))
plot(x = c(0, 40), y = c(0, 0.3), type = "n", bty = "l",
     xlab = "velocity of galaxy (1000km/s)", ylab = "density")
rug(gal)
lines(density(gal, width = 3.25, n = 200), lty = 1)
lines(density(gal, width = 2.56, n = 200), lty = 3)

[Package MASS version 7.3-51.3 ]

gal <- galaxies/1000
c(width.SJ(gal, method = "dpi"), width.SJ(gal))
plot(x = c(0, 40), y = c(0, 0.3), type = "n", bty = "l",
     xlab = "velocity of galaxy (1000km/s)", ylab = "density")
rug(gal)
lines(density(gal, width = 3.25, n = 200), lty = 1)
lines(density(gal, width = 2.56, n = 200), lty = 3)


p <- available.packages()

dim(p)

# %load ImageBot
#!/bin/bash

while true; do
  python ImageBot1.py
  echo "posted :"
  date
  sleep 1800s
done

#%%writefile ImageBot1.py
#!/home/jack/anaconda2/bin
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import numpy as np
import random
from random import randint
from PIL import Image, ImageDraw, ImageFont, ImageChops 
import os
import sys
import markovify
sys.path.insert(0,"/home/jack/anaconda2/envs/py27/lib/python2.7/site-packages")
import twython
from twython import Twython
import time
#nap=randint(10,400)
#time.sleep(nap)
path = r"publish/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
filename0=(path+base_image)

#base_image ="/home/jack/Desktop/deep-dream-generator/notebooks/new/2/"
square_size = 10
offset_factor = 20
darken_factor = 0.1
image = Image.open(filename0)
size = image.size

# create numpy array from the opened image 
im = np.array(image, dtype=np.uint8)

# Plot figure and axes
fig,ax = plt.subplots(1)

# Display the image
ax.imshow(im)

# Add random offset to tuple based on offset_factor
def add_offet(t):
    t[0] = random.randint(t[0], (t[0] + offset_factor))
    t[1] = random.randint(t[1], (t[1] + offset_factor))

    return t


# Create a Rectangle patch
for w in xrange(0, size[0], square_size):
    for h in xrange(0, size[1], square_size):
        #print str(w) + ':' + str(h)
        #square_size = randint(10,35)
        #offset_factor = randint(10,35)
    
        # Get the average color of the section
        rect = im[h:h+square_size, w:w+square_size]
        mean = rect.mean(axis=(0,1))

        # Convert to hex value
        face_color = '#%02x%02x%02x' % (int(mean[0]), int(mean[1]), int(mean[2]))
        edge_color = '#%02x%02x%02x' % (int(mean[0] - (mean[0] * darken_factor)), int(mean[1]  - (mean[1] * darken_factor)), int(mean[2] - (mean[2] * darken_factor)))

        # Dont draw outline with the dominant color
        z_order = 2
        if '#e' in face_color or '#f' in face_color:
            line_width = 0.0
        else:
            line_width = 0.1
            z_order = 3

        points = [add_offet([w, h]), add_offet([w + square_size, h]), add_offet([w, h + square_size])]
        triangle1 = patches.Polygon(points, edgecolor=edge_color, linewidth=line_width, facecolor=face_color, zorder=z_order)

        # Second triangle
        points2 = [add_offet([w, h + square_size]), add_offet([w + square_size, h + square_size]), add_offet([w + square_size, h])]
        triangle2 = patches.Polygon(points2, edgecolor=edge_color, linewidth=line_width, facecolor=face_color, zorder=z_order)

        # Square in background
        rec = patches.Rectangle((w,h),square_size,square_size,linewidth=0.0, edgecolor=edge_color, facecolor=face_color, zorder=1)

        # Add the patch to the Axes
        ax.add_patch(triangle1)
        ax.add_patch(triangle2)
        ax.add_patch(rec)

plt.axis('off')
plt.savefig("images/Sranger-Tri-001a.jpg", bbox_inches='tight', dpi=200)
img = Image.open("images/Sranger-Tri-001a.jpg")
nonwhite_positions = [(x,y) for x in range(img.size[0]) for y in range(img.size[1]) if img.getdata()[x+y*img.size[0]] != (255,255,255)]
rect = (min([x for x,y in nonwhite_positions]), min([y for x,y in nonwhite_positions]), max([x for x,y in nonwhite_positions]), max([y for x,y in nonwhite_positions]))
img.crop(rect).save('images/Sranger-Tri-001-crop2a.jpg')
#Create a second image
square_size = 10
offset_factor = 20
darken_factor = 0.1
image = Image.open(filename0)
size = image.size

# Create image np array
im = np.array(image, dtype=np.uint8)

# Create figure and axes
fig,ax = plt.subplots(1)

# Display the image
ax.imshow(im)

# Add random offset to tuple based on offset_factor
def add_offet(t):
    t[0] = random.randint(t[0], (t[0] + offset_factor))
    t[1] = random.randint(t[1], (t[1] + offset_factor))

    return t


def generate_the_word(infile):
        with open(infile) as f:
            contents_of_file = f.read()
        lines = contents_of_file.splitlines()
        line_number = random.randrange(0, len(lines))
        return lines[line_number]
        #textin = (generate_the_word("wordcloud.txt"))

# Create a Rectangle patch
for w in xrange(0, size[0], square_size):
    for h in xrange(0, size[1], square_size):
        #print str(w) + ':' + str(h)
        #square_size = randint(10,35)
        #offset_factor = randint(10,35)
    
        # Get the average color of the section
        rect = im[h:h+square_size, w:w+square_size]
        mean = rect.mean(axis=(0,1))

        # Convert to hex value
        face_color = '#%02x%02x%02x' % (int(mean[0]), int(mean[1]), int(mean[2]))
        edge_color = '#%02x%02x%02x' % (int(mean[0] - (mean[0] * darken_factor)), int(mean[1]  - (mean[1] * darken_factor)), int(mean[2] - (mean[2] * darken_factor)))

        # Dont draw outline with the dominant color
        z_order = 2
        if '#e' in face_color or '#f' in face_color:
            line_width = 0.0
        else:
            line_width = 0.1
            z_order = 3

        points = [add_offet([w, h]), add_offet([w + square_size, h]), add_offet([w, h + square_size])]
        triangle1 = patches.Polygon(points, edgecolor=edge_color, linewidth=line_width, facecolor=face_color, zorder=z_order)

        # Second triangle
        points2 = [add_offet([w, h + square_size]), add_offet([w + square_size, h + square_size]), add_offet([w + square_size, h])]
        triangle2 = patches.Polygon(points2, edgecolor=edge_color, linewidth=line_width, facecolor=face_color, zorder=z_order)

        # Square in background
        rec = patches.Rectangle((w,h),square_size,square_size,linewidth=0.0, edgecolor=edge_color, facecolor=face_color, zorder=1)

        # Add the patch to the Axes
        ax.add_patch(triangle1)
        ax.add_patch(triangle2)
        ax.add_patch(rec)

plt.axis('off')
plt.savefig("images/Sranger-Tri-001a.jpg", bbox_inches='tight', dpi=200)
img = Image.open("images/Sranger-Tri-001a.jpg")
nonwhite_positions = [(x,y) for x in range(img.size[0]) for y in range(img.size[1]) if img.getdata()[x+y*img.size[0]] != (255,255,255)]
rect = (min([x for x,y in nonwhite_positions]), min([y for x,y in nonwhite_positions]), max([x for x,y in nonwhite_positions]), max([y for x,y in nonwhite_positions]))
img.crop(rect).save('images/Sranger-Tri-001-crop2b.jpg')


img0 = Image.open("images/Sranger-Tri-001-crop2a.jpg")
img1 = Image.open("images/Sranger-Tri-001-crop2b.jpg")
blen = ImageChops.blend(img0, img1, .9)
blen.save('images/Sranger-Tri-001-crop2b.jpg')

#---------------


base = Image.open('images/Sranger-Tri-001-crop2b.jpg').convert('RGBA')
 
#8 5 4 6 3 2
# make a blank image for the text, initialized to transparent text color
txt = Image.new('RGBA', base.size, (255,255,255,0))
def generate_the_word(infile):
    with open(infile) as f:
            contents_of_file = f.read()
    lines = contents_of_file.splitlines()
    line_number = random.randrange(0, len(lines))
    return lines[line_number]
    

#base = Image.open('images/NewFolder/lightning01.jpg').convert('RGBA')
#8 5 4 6 3 2
# make a blank image for the text, initialized to transparent text color
txt = Image.new('RGBA', base.size, (255,255,255,0))

# get a font
fnt = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 20)
# get a drawing context
d = ImageDraw.Draw(txt)

width, height = base.size
# calculate the x,y coordinates of the text
#marginx = 325
#marginy = 75
marginx = 225
marginy = 50
x = width - marginx
y = height - marginy
signature_ = "The TwitterBot Project" 
d.text((x,y), signature_, font=fnt, fill=(0,0,0,256))

out = Image.alpha_composite(base, txt)
out.save("images/tmp.jpg", "JPEG")
# save the image then reopen to put a title
base = Image.open('images/tmp.jpg').convert('RGBA')
#8 5 4 6 3 2
# make a blank image for the text, initialized to transparent text color
txt = Image.new('RGBA', base.size, (255,255,255,0))

# get a font
fnt = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 50)
# get a drawing context
d = ImageDraw.Draw(txt)

width, height = base.size
# calculate the x,y coordinates of the text
#marginx = 325
#marginy = 75
x = 90
y = 10
#generate a title
title = (generate_the_word("titles.txt"))
d.text((x,y), title , font=fnt, fill=(0,0,0,250))
out2 = Image.alpha_composite(base, txt)
out2.save("images/TM_POST.jpg", "JPEG")


#removed keys for privacy reasons
CONSUMER_KEY = 'xxxxx'
CONSUMER_SECRET = 'xxxx'
ACCESS_KEY = 'xxxxxx'
ACCESS_SECRET = 'xxxxxxx'

twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)
#path = 'images/NewFolder'
f = open("art.txt")
text = f.read()
# Build the model.
text_model = markovify.Text(text)
# Print randomly-generated sentences of no more than 140 characters
#http://paulbourke.net/fractals/
STR = (text_model.make_short_sentence(140))
#STR = ("#All_in_One - #WordCloud #Create - Added ability to randomly choose an image background  #Automated")
#PATH = "/home/jack/Desktop/deep-dream-generator/notebooks/STUFF/experiment/experiment8.jpg"
PATH = "images/TM_POST.jpg"
# 1 , 2, 3, 12, 5, 15, 8, 6
#photo = open('/home/jack/Desktop/deep-dream-generator/notebooks/images/'+file_list[rnd]+'.jpg','rb')

photo = open(PATH,'rb')
response = twitter.upload_media(media=photo)
twitter.update_status(status=STR, media_ids=[response['media_id']])




import numpy as np
import skimage.io
import skimage.viewer
import matplotlib.pyplot as plt
import ipympl

import skimage                 # form 1, load whole skimage library
import skimage.io              # form 2, load skimage.io module only
from skimage.io import imread  # form 3, load only the imread function
import numpy as np             # form 4, load all of numpy into an object called np


%matplotlib widget
import mahotas



import numpy as np
import skimage.io
import skimage.viewer
import matplotlib.pyplot as plt
import ipympl

from skimage.io import imsave as saveitas

import skimage                 # form 1, load whole skimage library
import skimage.io              # form 2, load skimage.io module only
from skimage.io import imread  # form 3, load only the imread function
import numpy as np             # form 4, load all of numpy into an object called np
from skimage.io import imsave as saveit

%matplotlib widget
import mahotas

import mahotas
%matplotlib inline
import mahotas.demos
import numpy as np
from pylab import imshow, gray, show
from os import path

#photo = mahotas.imread('/home/jack/Desktop/dockercommands/images/useresult.png', as_grey=True)
photo = mahotas.imread('/home/jack/Desktop/dockercommands/images/useresult.png', as_grey=False)
photo = photo.astype(np.uint8)

#gray()
imshow(photo)
#show()
#photo

# importing required libraries
import numpy as np
import mahotas
from pylab import imshow, show

# loading image
img = mahotas.imread('/home/jack/Desktop/dockercommands/images/20221010-160527.jpg')

# showing the original image
imshow(img)
show()


!mkdir mahotastest

# input/Output with Mahotas

import mahotas as mh
image = mh.imread('file.png')
mh.imsave('copy.png', image)

#test-001
import cv2
import numpy as np
import imageio
image = cv2.imread('/home/jack/Desktop/dockercommands/AI/u-09294misc.jpg')
original = image.copy()
mask = np.zeros(image.shape, dtype=np.uint8)
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]
kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))
opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=3)

cnts = cv2.findContours(opening, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
cnts = cnts[0] if len(cnts) == 2 else cnts[1]
cnts = sorted(cnts, key=cv2.contourArea, reverse=True)
for c in cnts:
    cv2.drawContours(mask, [c], -1, (255,255,255), -1)
    break

close = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=4)
close = cv2.cvtColor(close, cv2.COLOR_BGR2GRAY)
result = cv2.bitwise_and(original, original, mask=close)
result[close==0] = (255,255,255)

img_uint8 = close.astype(np.uint8)
# and then
imageio.imwrite('mahotastest/test-001.jpg', img_uint8)

# importing required libraries
import numpy as np
import mahotas
from pylab import imshow, show

# loading image
#img = mahotas.imread('/home/jack/Desktop/dockercommands/AI/u-09294misc.jpg')
img = mahotas.imread('/home/jack/Desktop/dockercommands/styles/FeIdoA5VIAIuUFR.jpg')
	
# filtering the image
img = img[:, :, 0]
	
# setting gaussian filter
gaussian = mahotas.gaussian_filter(img, 15)

# setting threshold value
gaussian = (gaussian > gaussian.mean())

# creating a labeled image
labeled, n_nucleus = mahotas.label(gaussian)


print("Image")
# showing the gaussian filter
imshow(labeled)
show()


# getting distance map
dmap = mahotas.distance(labeled)

print("Distance Map")
imshow(dmap)
show()



import scipy.misc
#scipy.misc.imsave('mahotastest/001.png', dmap)
saveit('mahotastest/uUFR-1.jpg', dmap)

import numpy as np
import imageio

# suppose that img's dtype is 'float64'
img_uint8 = dmap.astype(np.uint8)
# and then
imageio.imwrite('mahotastest/uUFR-2.jpg', img_uint8)

!cp /home/jack/Desktop/dockercommands/AI/u-09294misc.jpg mahotastest
!cp /home/jack/Desktop/dockercommands/styles/FeIdoA5VIAIuUFR.jpg mahotastest

from PIL import Image
#filename = '/home/jack/Desktop/dockercommands/AI/u-09294misc.jpg'
filename = '/home/jack/Desktop/dockercommands/styles/FeIdoA5VIAIuUFR.jpg'
img = Image.open(filename)
img

# Turn an image upside down and backwords
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import numpy as np
filename = '/home/jack/Desktop/dockercommands/styles/FeIdoA5VIAIuUFR.jpg'
img = mpimg.imread(filename)
plt.imsave("mahotastest/upsidedown-uUFR-2.jpg", img, cmap = 'gray', origin = 'lower')

img_usd = Image.open("mahotastest/upsidedown-uUFR-2.jpg")
img_usd

import numpy
import matplotlib
from matplotlib import pylab, mlab, pyplot
np = numpy
plt = pyplot

from IPython.display import display
from IPython.core.pylabtools import figsize, getfigs

from pylab import *
from numpy import *

# load the image
filename = '/home/jack/Desktop/dockercommands/styles/FeIdoA5VIAIuUFR.jpg'
image = skimage.io.imread(filename)

fig, ax = plt.subplots()
plt.imshow(image)

import numpy as np
import glob
import matplotlib.pyplot as plt
import skimage.io
import skimage.color
import skimage.filters
%matplotlib inline

# load the image
filename = '/home/jack/Desktop/dockercommands/styles/FeIdoA5VIAIuUFR.jpg'
image = skimage.io.imread(filename)

fig, ax = plt.subplots()
plt.imsave("mahotastest/black-2.jpg", image, cmap = 'gray', origin = 'lower')
plt.imshow(image)

# convert the image to grayscale

filename = "mahotastest/black-2.jpg"
image = skimage.io.imread(filename)
gray_image = skimage.color.rgb2gray(image)

# blur the image to denoise
blurred_image = skimage.filters.gaussian(gray_image, sigma = 1.0)

fig, ax = plt.subplots()
plt.imshow(blurred_image, cmap = "gray")

import cv2
import numpy as np

# Load image as Numpy array in BGR order
na = cv2.imread('I5jKW.png')

# Make a True/False mask of pixels whose BGR values sum to more than zero
alpha = np.sum(na, axis=-1) > 0

# Convert True/False to 0/255 and change type to "uint8" to match "na"
alpha = np.uint8(alpha * 255)

# Stack new alpha layer with existing image to go from BGR to BGRA, i.e. 3 channels to 4 channels
res = np.dstack((na, alpha))

# Save result
cv2.imwrite('result.png', res)

# create a histogram of the blurred grayscale image
histogram, bin_edges = np.histogram(blurred_image, bins = 256, range = (0.0, 1.0))

fig, ax = plt.subplots()
plt.plot(bin_edges[0: -1], histogram)
plt.title("Grayscale Histogram")
plt.xlabel("grayscale value")
plt.ylabel("pixels")
plt.xlim(0, 1.0)

# create a mask based on the threshold
t = 0.8
binary_mask = blurred_image < t

fig, ax = plt.subplots()
plt.imshow(binary_mask, cmap = "gray")

from skimage.io import imsave as saveitas
# use the binary_mask to select the "interesting" part of the image
selection = image.copy()
selection[~binary_mask] = 0

fig, ax = plt.subplots()
saveitas('mahotastest/selection-uUFR-1.jpg', selection)
plt.imshow(selection)

gray_image = skimage.io.imread(filename, as_gray = True)
histogram, bin_edges = np.histogram(gray_image, bins = 256, range = (0.0, 1.0))

fig, ax = plt.subplots()
plt.plot(bin_edges[0: -1], histogram)
plt.title("Graylevel histogram")
plt.xlabel("gray value")
plt.ylabel("pixel count")
plt.xlim(0, 1.0)

# Works Great !
import cv2
import numpy as np
import matplotlib.image
# Load image as Numpy array in BGR order
na = cv2.imread('mahotastest/selection-uUFR-1.jpg')

# Make a True/False mask of pixels whose BGR values sum to more than zero
alpha = np.sum(na, axis=-1) > 0

# Convert True/False to 0/255 and change type to "uint8" to match "na"
#alpha = np.uint8(alpha * 255)
#alpha = np.uint8(alpha * 200)
alpha = np.uint8(alpha * 100)
# Stack new alpha layer with existing image to go from BGR to BGRA, i.e. 3 channels to 4 channels
res = np.dstack((na, alpha))


matplotlib.image.imsave('mahotastest/matplotlib-name100.png', res)

# Save result
cv2.imwrite('mahotastest/selection-uUFR-1-jpg-alpha100.png', res)

#test-2 Not Good Only for a bad mask
import cv2
import numpy as np

# load image
img = cv2.imread('mahotastest/selection-uUFR-1.jpg')

# threshold on black to make a mask
color = (0,0,0)
mask = np.where((img==color).all(axis=2), 0, 255).astype(np.uint8)

# put mask into alpha channel
result = img.copy()
result = cv2.cvtColor(result, cv2.COLOR_BGR2BGRA)
result[:, :, 3] = mask

# save resulting masked image
cv2.imwrite('mahotastest/selection-tranaparent-test-2.jpg', result)
cv2.imwrite('mahotastest/selection-tranaparent-mask-test-2.jpg', mask)
# display result, though it won't show transparency


import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import numpy as np
import mahotas as mh
filename = '/home/jack/Desktop/dockercommands/styles/FeIdoA5VIAIuUFR.jpg'
img = mpimg.imread(filename)
feId = mh.colors.rgb2grey(img)
imshow(feId)

import numpy as np
import glob
import matplotlib.pyplot as plt
import skimage.io
import skimage.color
import skimage.filters %
   matplotlib widget

# load the image
image = skimage.io.imread("data/shapes-01.jpg")

fig, ax = plt.subplots()
plt.imshow(image)

import matplotlib
matplotlib.__version__

pylab.cumsum?

Signature: pylab.cumsum(a, axis=None, dtype=None, out=None)
Docstring:
Return the cumulative sum of the elements along a given axis.

Parameters
----------
a : array_like
    Input array.
axis : int, optional
    Axis along which the cumulative sum is computed. The default
    (None) is to compute the cumsum over the flattened array.
dtype : dtype, optional
    Type of the returned array and of the accumulator in which the
    elements are summed.  If `dtype` is not specified, it defaults
    to the dtype of `a`, unless `a` has an integer dtype with a
    precision less than that of the default platform integer.  In
    that case, the default platform integer is used.
out : ndarray, optional
    Alternative output array in which to place the result. It must
    have the same shape and buffer length as the expected output
    but the type will be cast if necessary. See :ref:`ufuncs-output-type` for
    more details.

Returns
-------
cumsum_along_axis : ndarray.
    A new array holding the result is returned unless `out` is
    specified, in which case a reference to `out` is returned. The
    result has the same size as `a`, and the same shape as `a` if
    `axis` is not None or `a` is a 1-d array.

See Also
--------
sum : Sum array elements.
trapz : Integration of array values using the composite trapezoidal rule.
diff : Calculate the n-th discrete difference along given axis.

Notes
-----
Arithmetic is modular when using integer types, and no error is
raised on overflow.

``cumsum(a)[-1]`` may not be equal to ``sum(a)`` for floating-point
values since ``sum`` may use a pairwise summation routine, reducing
the roundoff-error. See `sum` for more information.

Examples
--------
>>> a = np.array([[1,2,3], [4,5,6]])
>>> a
array([[1, 2, 3],
       [4, 5, 6]])
>>> np.cumsum(a)
array([ 1,  3,  6, 10, 15, 21])
>>> np.cumsum(a, dtype=float)     # specifies type of output value(s)
array([  1.,   3.,   6.,  10.,  15.,  21.])

>>> np.cumsum(a,axis=0)      # sum over rows for each of the 3 columns
array([[1, 2, 3],
       [5, 7, 9]])
>>> np.cumsum(a,axis=1)      # sum over columns for each of the 2 rows
array([[ 1,  3,  6],
       [ 4,  9, 15]])

``cumsum(b)[-1]`` may not be equal to ``sum(b)``

>>> b = np.array([1, 2e-9, 3e-9] * 1000000)
>>> b.cumsum()[-1]
1000000.0050045159
>>> b.sum()
1000000.0050000029
File:      ~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/numpy/core/fromnumeric.py
Type:      function


import pylab
import scipy
p=set(dir(pylab))
s=set(dir(scipy))
k=p.intersection(s)
conflicts = [f for f in k if getattr(scipy, f) is not getattr(pylab, f)]
import matplotlib
matplotlib.__version__
conflicts
results:
['cumsum', 'ptp', 'fix', 'ravel', '__file__', 'ones', 'rank', 'tri',
 'insert', 'arange', 'indices', 'loads', 'where', 'mean', 'argmax', 'nonzero',
 'asarray', 'sum', 'polyfit', 'prod', 'log2', 'power', 'cumproduct', 'corrcoef',
 'meshgrid', '__name__', 'cov', 'cumprod', 'vander', 'arccos', 'load', 'array',
 'iterable', 'eye', 'log', 'sometrue', 'alltrue', 'zeros', 'log10', '__doc__',
 'empty', 'polyval', 'arcsin', 'arctanh', 'linspace', 'typecodes', 'copy',
 'std', 'fromfunction', 'argmin', 'trapz', 'binary_repr', 'sqrt', 'take',
 'product', 'repeat', 'trace', 'compress', 'array2string', 'amax', 'identity',
 'amin', 'fromstring', 'average', 'base_repr', 'reshape']    

numpy.cumsum?
conflicts

pylab.cumsum?

result:
Signature: pylab.cumsum(a, axis=None, dtype=None, out=None)
Docstring:
Return the cumulative sum of the elements along a given axis.

Parameters
----------
a : array_like
    Input array.
axis : int, optional
    Axis along which the cumulative sum is computed. The default
    (None) is to compute the cumsum over the flattened array.
dtype : dtype, optional
    Type of the returned array and of the accumulator in which the
    elements are summed.  If `dtype` is not specified, it defaults
    to the dtype of `a`, unless `a` has an integer dtype with a
    precision less than that of the default platform integer.  In
    that case, the default platform integer is used.
out : ndarray, optional
    Alternative output array in which to place the result. It must
    have the same shape and buffer length as the expected output
    but the type will be cast if necessary. See :ref:`ufuncs-output-type` for
    more details.

Returns
-------
cumsum_along_axis : ndarray.
    A new array holding the result is returned unless `out` is
    specified, in which case a reference to `out` is returned. The
    result has the same size as `a`, and the same shape as `a` if
    `axis` is not None or `a` is a 1-d array.

See Also
--------
sum : Sum array elements.
trapz : Integration of array values using the composite trapezoidal rule.
diff : Calculate the n-th discrete difference along given axis.

Notes
-----
Arithmetic is modular when using integer types, and no error is
raised on overflow.

``cumsum(a)[-1]`` may not be equal to ``sum(a)`` for floating-point
values since ``sum`` may use a pairwise summation routine, reducing
the roundoff-error. See `sum` for more information.

Examples
--------
>>> a = np.array([[1,2,3], [4,5,6]])
>>> a
array([[1, 2, 3],
       [4, 5, 6]])
>>> np.cumsum(a)
array([ 1,  3,  6, 10, 15, 21])
>>> np.cumsum(a, dtype=float)     # specifies type of output value(s)
array([  1.,   3.,   6.,  10.,  15.,  21.])

>>> np.cumsum(a,axis=0)      # sum over rows for each of the 3 columns
array([[1, 2, 3],
       [5, 7, 9]])
>>> np.cumsum(a,axis=1)      # sum over columns for each of the 2 rows
array([[ 1,  3,  6],
       [ 4,  9, 15]])

``cumsum(b)[-1]`` may not be equal to ``sum(b)``

>>> b = np.array([1, 2e-9, 3e-9] * 1000000)
>>> b.cumsum()[-1]
1000000.0050045159
>>> b.sum()
1000000.0050000029
File:      ~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/numpy/core/fromnumeric.py
Type:      function
    
    