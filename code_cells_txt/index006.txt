-!locate *.ttf

!ls /usr/share/fonts/truetype/

!ls /mnt/40ec525c-34bc-44ef-99c8-53f5524ad88b/Images/All-images/

print(FONT[2])

FONT =[]
def randomfont(pathf):
    imgf = random.choice(os.listdir(pathf))
    file_path =pathf+imgf+".ttf"
    file_path0 =path0+img0
    return file_path
for i in range(20):
    pathf = '/usr/share/fonts/truetype/'
    print (randomfont(pathf))
    FONT.append(randomfont(pathf))

from PIL import ImageFilter, ImageDraw, ImageFont
import time
import shutil
import os
import random
from PIL import Image
from random import randint
path = '/home/jack/Documents/'
img = random.choice(os.listdir(path))
path0 = '/home/jack/Documents/'
img0 = random.choice(os.listdir(path0))
file_path =path+img
file_path0 =path0+img0
IMG = Image.open(file_path)
IMG0 = Image.open(file_path0)
IMG0 =IMG0.resize((640,640), Image.NEAREST)
w,h = IMG0.size
IMG1 = IMG0.convert('RGBA')
im =IMG.resize((1280,720), Image.NEAREST)
foreground = Image.new('RGBA', (w+5,h+5), (0, 0, 0, 150))
im.paste(foreground, (580, 60), foreground)
im1 = im.filter(ImageFilter.MinFilter(7))
background = im1.filter(ImageFilter.BLUR)
foreground1 = Image.new('RGBA', (1280,720), (255, 255, 255, 100))
background.paste(foreground1, (0, 0), foreground1)
background.paste(IMG1, (600, 50), IMG1)
background
text0 = "CREATED by"
text1 = "LBRY-Toolbox"
text2 = "ImageBot"
x= randint(1,4)
r=randint(125,200)
g=randint(125,200)
b=randint(125,200)
colour = (r, g, b)
colours = (0,0,0)

path0 = '/home/jack/Documents/'
img0 = random.choice(os.listdir(path0))
file_path =path+img
file_path0 =path0+img0

font_file = FONT[2]
font_file = FONT[2]
font_file = FONT[2]
font_file = FONT[2]
print(font_file)
font_size = 70
font = ImageFont.truetype(font_file, font_size)
w, h = font.getsize(text)
draw = ImageDraw.Draw(background)
H=x*8
draw.text((30+H, 170+H),text0, colours, font=font)
draw.text((30+H, 270+H),text1, colours, font=font)
draw.text((30+H, 370+H),text2, colours, font=font)
draw.text((30+H-5, 170+H+5),text0, colour, font=font)
draw.text((30+H-5, 270+H+5),text1, colour, font=font)
draw.text((30+H-5, 370+H+5),text2, colour, font=font)
DT = time.strftime("images/%Y-%m-%d-%H-%M.png")
background.save(DT)

from PIL import Image
file_path = DT
IMG = Image.open(file_path)
IMG

from PIL import ImageFont, ImageDraw, Image
import time
import os
import random
from random import randint
def pick(font_path):    
        
        font=random.choice([x for x in os.listdir(font_path) if os.path.isfile(os.path.join(font_path, x))])
        return font_path+font
def mkimage(path1):
    
    img = random.choice(os.listdir(path1))
    file_path =path1+img 
    return file_path

def mkbatch(mkimage,pick):
    image = Image.open(mkimage)
    image = image.resize((1280,720), Image.NEAREST)
    W,H = image.size
    draw = ImageDraw.Draw(image)
    txt = "Python Generated /Processed Images"
    fontsize = 6 # starting font size

    W, H = image.size

    # portion of image width you want text width to be
    blank = Image.new('RGB',(W, H))

    FONT = pick
    font = ImageFont.truetype(FONT, fontsize)
    #print image.size

    W,H = blank.size
    blank = blank.resize((W-100, H-30,), Image.NEAREST)
    #print blank.size
    while (font.getsize(txt)[0] < blank.size[0]) and (font.getsize(txt)[1] < blank.size[1]):
        # iterate until the text size is just larger than the criteria
        fontsize += 1
        font = ImageFont.truetype(FONT, fontsize)

    # optionally de-increment to be sure it is less than criteria
    fontsize -= 1
    font = ImageFont.truetype(FONT, fontsize)

    w, h = draw.textsize(txt, font=font)

    #print 'final font size',fontsize, FONT
    draw.text((15,625), txt, font=font, fill="black") # put the text on the image
    draw.text((20,620), txt, font=font, fill="white") # put the text on the image
    DT = time.strftime("base/%Y-%m-%d-%H-%M-%S.png")
    image.save(DT) # save it
    #image
for i in range(1,500):
    path1 = '/mnt/40ec525c-34bc-44ef-99c8-53f5524ad88b/Images/All-images/'
    font_path = '/home/jack/fonts/'
    mkbatch(mkimage(path1),pick(font_path))
    time.sleep(3)
    print ".",

!locate STIXGeneralBol.ttf

!locate *.ttf

from PIL import ImageFont, ImageDraw, Image
import time
image = Image.open("/home/jack/Documents/use-to-seed003.jpg")
image = image.resize((1280,720), Image.NEAREST)
W,H = image.size
draw = ImageDraw.Draw(image)
txt = "Python Generated Processed Images"
fontsize = 6 # starting font size

W, H = image.size

# portion of image width you want text width to be
blank = Image.new('RGB',(W, H))

FONT = "/home/jack/miniconda3/pkgs/matplotlib-base-3.5.2-py310hf590b9c_0/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf"
font = ImageFont.truetype(FONT, fontsize)
print (image.size)

W,H = blank.size
blank = blank.resize((W-100, H-30,), Image.NEAREST)
#print blank.size
while (font.getsize(txt)[0] < blank.size[0]) and (font.getsize(txt)[1] < blank.size[1]):
    # iterate until the text size is just larger than the criteria
    fontsize += 1
    font = ImageFont.truetype(FONT, fontsize)

# optionally de-increment to be sure it is less than criteria
fontsize -= 1
font = ImageFont.truetype(FONT, fontsize)

w, h = draw.textsize(txt, font=font)

print ('final font size',fontsize, FONT)
draw.text((15,625), txt, font=font, fill="black") # put the text on the image
draw.text((20,620), txt, font=font, fill="white") # put the text on the image
DT = time.strftime("base/%Y-%m-%d-%H-%M-%S.png")
print (DT)
image.save(DT) # save it
image

from PIL import ImageFont, ImageDraw, Image
def pick():    
        font_path = '/home/jack/miniconda3/pkgs/matplotlib-base-3.5.2-py310hf590b9c_0/lib/python3.10/site-packages/matplotlib/mpl-data/fonts/ttf/'
        font=random.choice([x for x in os.listdir(font_path) if os.path.isfile(os.path.join(font_path, x))])
        return font_path+font
def mkimage():
    path = '/home/jack/Documents/jpg/720/'
    img = random.choice(os.listdir(path))
    file_path =path+img 
    return file_path

image = Image.open(mkimage())
image = image.resize((1280,720), Image.NEAREST)
W,H = image.size
draw = ImageDraw.Draw(image)
txt = "Python Generated Processed Images"
fontsize = 6 # starting font size

W, H = image.size

# portion of image width you want text width to be
blank = Image.new('RGB',(W, H))

FONT = pick()
font = ImageFont.truetype(FONT, fontsize)
print (image.size)

W,H = blank.size
blank = blank.resize((W-100, H-30,), Image.NEAREST)
print (blank.size)
while (font.getsize(txt)[0] < blank.size[0]) and (font.getsize(txt)[1] < blank.size[1]):
    # iterate until the text size is just larger than the criteria
    fontsize += 1
    font = ImageFont.truetype(FONT, fontsize)

# optionally de-increment to be sure it is less than criteria
fontsize -= 1
font = ImageFont.truetype(FONT, fontsize)

w, h = draw.textsize(txt, font=font)

print ('final font size',fontsize, FONT)
draw.text((15,625), txt, font=font, fill="black") # put the text on the image
draw.text((20,620), txt, font=font, fill="white") # put the text on the image
DT = time.strftime("base/%Y-%m-%d-%H-%M-%S.png")
image.save(DT) # save it
image

/home/jack/fonts/Quatl.ttf
/home/jack/fonts/Exo-Black.ttf
/home/jack/fonts/Rafika.ttf
/home/jack/fonts/georgiab.ttf
/home/jack/fonts/Biryani-Light.ttf
/home/jack/fonts/Regulators.ttf
/home/jack/fonts/Quatl.ttf
/home/jack/fonts/DancingScript-VariableFont_wght.ttf
/home/jack/fonts/Tafelschrift.ttf     (nice script)
/home/jack/fonts/VeraSe.ttf

IMG=Image.open("sample-out.png")
IMG



from PIL import ImageFilter, ImageDraw, ImageFont
import time
import shutil
import os
import random
from PIL import Image
from random import randint
path = '/mnt/40ec525c-34bc-44ef-99c8-53f5524ad88b/Images/All-images/'
img = random.choice(os.listdir(path))
path0 = '/mnt/40ec525c-34bc-44ef-99c8-53f5524ad88b/Images/All-images/'
img0 = random.choice(os.listdir(path0))
file_path =path+img
file_path0 =path0+img0
IMG = Image.open(file_path)
IMG0 = Image.open(file_path0)
IMG0 =IMG0.resize((640,640), Image.NEAREST)
w,h = IMG0.size
IMG1 = IMG0.convert('RGBA')
im =IMG.resize((1280,720), Image.NEAREST)
foreground = Image.new('RGBA', (w+5,h+5), (0, 0, 0, 150))
im.paste(foreground, (580, 60), foreground)
im1 = im.filter(ImageFilter.MinFilter(7))
background = im1.filter(ImageFilter.BLUR)
foreground1 = Image.new('RGBA', (1280,720), (255, 255, 255, 100))
background.paste(foreground1, (0, 0), foreground1)
background.paste(IMG1, (600, 50), IMG1)
background
text0 = "CREATED by"
text1 = "LBRY-Toolbox"
text2 = "ImageBot"
x= randint(1,4)
r=randint(125,200)
g=randint(125,200)
b=randint(125,200)
colour = (r, g, b)
colours = (0,0,0)

if x==1:font_file = '/usr/share/fonts/truetype/freefont/FreeSansBold.ttf'
if x==2:font_file ="/home/jack/fonts/Biryani-Black.ttf"
if x==3:font_file ="/home/jack/fonts/ChangaOne-Regular.ttf"
if x==4:font_file ="/home/jack/fonts/Exo-Black.ttf"
font_size = 70
font = ImageFont.truetype(font_file, font_size)
w, h = font.getsize(text)
draw = ImageDraw.Draw(background)
H=x*8
draw.text((30+H, 170+H),text0, colours, font=font)
draw.text((30+H, 270+H),text1, colours, font=font)
draw.text((30+H, 370+H),text2, colours, font=font)
draw.text((30+H-5, 170+H+5),text0, colour, font=font)
draw.text((30+H-5, 270+H+5),text1, colour, font=font)
draw.text((30+H-5, 370+H+5),text2, colour, font=font)
DT = time.strftime("images/%Y-%m-%d-%H-%M.png")
background.save(DT)

from PIL import Image
file_path = DT
IMG = Image.open(file_path)
IMG

from PIL import ImageFilter, ImageDraw, ImageFont
import time
import shutil
import os
import random
from PIL import Image
from random import randint
def pick():    
        font_path = '/home/jack/fonts/'
        font=random.choice([x for x in os.listdir(font_path) if os.path.isfile(os.path.join(font_path, x))])
        return font_path+font
def mkimage():
    path = '/mnt/40ec525c-34bc-44ef-99c8-53f5524ad88b/Images/All-images/'
    img = random.choice(os.listdir(path))
    file_path =path+img 
    path0 = '/mnt/40ec525c-34bc-44ef-99c8-53f5524ad88b/Images/All-images/'
    img0 = random.choice(os.listdir(path0))
    file_path0 =path0+img0
    IMG = Image.open(file_path)
    IMG0 = Image.open(file_path0)
    IMG0 =IMG0.resize((640,640), Image.NEAREST)
    w,h = IMG0.size
    IMG1 = IMG0.convert('RGBA')
    im =IMG.resize((1280,720), Image.NEAREST)
    foreground = Image.new('RGBA', (w+5,h+5), (0, 0, 0, 150))
    im.paste(foreground, (580, 60), foreground)
    im1 = im.filter(ImageFilter.MinFilter(7))
    background = im1.filter(ImageFilter.BLUR)
    foreground1 = Image.new('RGBA', (1280,720), (255, 255, 255, 100))
    background.paste(foreground1, (0, 0), foreground1)
    background.paste(IMG1, (600, 50), IMG1)
    background
    text0 = "CREATED by"
    text1 = "LBRY-Toolbox"
    text2 = "ImageBot"
    x= randint(1,4)
    r=randint(125,200)
    g=randint(125,200)
    b=randint(125,200)
    colour = (r, g, b)
    colours = (0,0,0)
    font_file = pick()
    #font_file = random.choice([x for x in os.listdir(font_path) if os.path.isfile(os.path.join(font_path, x))])
    #if x==1:font_file = '/usr/share/fonts/truetype/freefont/FreeSansBold.ttf'
    #if x==2:font_file ="/home/jack/fonts/Biryani-Black.ttf"
    #if x==3:font_file ="/home/jack/fonts/ChangaOne-Regular.ttf"
    #if x==4:font_file ="/home/jack/fonts/Exo-Black.ttf"
    font_size = 70
    font = ImageFont.truetype(font_file, font_size)
    w, h = font.getsize(text)
    draw = ImageDraw.Draw(background)
    H=x*8
    draw.text((30+H, 170+H),text0, colours, font=font)
    draw.text((30+H, 270+H),text1, colours, font=font)
    draw.text((30+H, 370+H),text2, colours, font=font)
    draw.text((30+H-5, 170+H+5),text0, colour, font=font)
    draw.text((30+H-5, 270+H+5),text1, colour, font=font)
    draw.text((30+H-5, 370+H+5),text2, colour, font=font)
    DT = time.strftime("manybot/%Y-%m-%d-%H-%M-%S.png")
    background.save(DT)

for i in range(1,500):
    time.sleep(3)
    print ".",
    mkimage()

from PIL import ImageFilter, ImageDraw, ImageFont
import time
import shutil
import os
import random
from PIL import Image
from random import randint
path = '/mnt/40ec525c-34bc-44ef-99c8-53f5524ad88b/Images/GOOD-Blends/'
img = random.choice(os.listdir(path))
path0 = '/mnt/40ec525c-34bc-44ef-99c8-53f5524ad88b/Images/GOOD-Blends/'
img0 = random.choice(os.listdir(path0))
file_path =path+img
file_path0 =path0+img0
IMG = Image.open(file_path)
IMG0 = Image.open(file_path0)
IMG0 =IMG0.resize((640,640), Image.NEAREST)
w,h = IMG0.size
IMG1 = IMG0.convert('RGBA')
im =IMG.resize((1280,720), Image.NEAREST)
foreground = Image.new('RGBA', (w+5,h+5), (0, 0, 0, 150))
im.paste(foreground, (580, 60), foreground)
im1 = im.filter(ImageFilter.MinFilter(7))
background = im1.filter(ImageFilter.BLUR)
foreground1 = Image.new('RGBA', (1280,720), (255, 255, 255, 100))
background.paste(foreground1, (0, 0), foreground1)
background.paste(IMG1, (600, 50), IMG1)
background
text0 = "CREATED by"
text1 = "LBRY-Toolbox"
text2 = "ImageBot"
x= randint(1,4)
r=randint(125,200)
g=randint(125,200)
b=randint(125,200)
colour = (r, g, b)
colours = (0,0,0)

if x==1:font_file = '/usr/share/fonts/truetype/freefont/FreeSansBold.ttf'
if x==2:font_file ="/home/jack/fonts/Biryani-Black.ttf"
if x==3:font_file ="/home/jack/fonts/ChangaOne-Regular.ttf"
if x==4:font_file ="/home/jack/fonts/Exo-Black.ttf"
font_size = 70
font = ImageFont.truetype(font_file, font_size)
w, h = font.getsize(text)
draw = ImageDraw.Draw(background)
H=x*8
draw.text((30+H, 170+H),text0, colours, font=font)
draw.text((30+H, 270+H),text1, colours, font=font)
draw.text((30+H, 370+H),text2, colours, font=font)
draw.text((30+H-5, 170+H+5),text0, colour, font=font)
draw.text((30+H-5, 270+H+5),text1, colour, font=font)
draw.text((30+H-5, 370+H+5),text2, colour, font=font)
DT = time.strftime("images/%Y-%m-%d-%H-%M.png")
background.save(DT)

from PIL import Image
file_path = DT
IMG = Image.open(file_path)
IMG

for x in range(1,40):
    y= randint(1,4)
    print y,

from PIL import ImageFilter, ImageDraw, ImageFont
import time
import shutil
import os
import random
from PIL import Image
from random import randint
path = '/mnt/40ec525c-34bc-44ef-99c8-53f5524ad88b/Images/forvids/images/'
img = random.choice(os.listdir(path))
file_path =path+img
file_path0 =path+img
IMG = Image.open(file_path)
IMG0 = Image.open(file_path0)
IMG0 =IMG0.resize((640,640), Image.NEAREST)
w,h = IMG0.size
IMG1 = IMG0.convert('RGBA')
im =IMG.resize((1280,720), Image.NEAREST)
foreground = Image.new('RGBA', (w+5,h+5), (0, 0, 0, 150))
im.paste(foreground, (580, 60), foreground)
im1 = im.filter(ImageFilter.MinFilter(7))
background = im1.filter(ImageFilter.BLUR)
foreground1 = Image.new('RGBA', (1280,720), (255, 255, 255, 100))
background.paste(foreground1, (0, 0), foreground1)
background.paste(IMG1, (600, 50), IMG1)
background
text0 = "CREATED by"
text1 = "LBRY-Toolbox"
text2 = "ImageBot"
x= randint(1,4)
r=randint(125,200)
g=randint(125,200)
b=randint(125,200)
colour = (r, g, b)
colours = (0,0,0)

if x==1:font_file = '/usr/share/fonts/truetype/freefont/FreeSansBold.ttf'
if x==2:font_file ="/home/jack/fonts/Biryani-Black.ttf"
if x==3:font_file ="/home/jack/fonts/ChangaOne-Regular.ttf"
if x==4:font_file ="/home/jack/fonts/Exo-Black.ttf"
font_size = 70
font = ImageFont.truetype(font_file, font_size)
w, h = font.getsize(text)
draw = ImageDraw.Draw(background)
H=x*8
draw.text((30+H, 170+H),text0, colours, font=font)
draw.text((30+H, 270+H),text1, colours, font=font)
draw.text((30+H, 370+H),text2, colours, font=font)
draw.text((30+H-5, 170+H+5),text0, colour, font=font)
draw.text((30+H-5, 270+H+5),text1, colour, font=font)
draw.text((30+H-5, 370+H+5),text2, colour, font=font)
DT = time.strftime("images/%Y-%m-%d-%H-%M.png")
background.save(DT)

from PIL import Image
file_path = DT
IMG = Image.open(file_path)
IMG


#image = Image.open(path+img)
print path+img
#shutil.copy(image,"images/image1.jpg")
#shutil.copy(image,"images/image2.jpg")

import shutil
import os
import random
from PIL import Image
path = '/mnt/40ec525c-34bc-44ef-99c8-53f5524ad88b/Images/forvids/images/'
img = random.choice(os.listdir(path))
img = Image.open(path+img)
def getAverageRGB(img):
  """
  Given PIL Image, return average value of color as (r, g, b)
  """
  # no. of pixels in image
  npixels = image.size[0]*image.size[1]
  # get colors as [(cnt1, (r1, g1, b1)), ...]
  cols = image.getcolors(npixels)
  # get [(c1*r1, c1*g1, c1*g2),...]
  sumRGB = [(x[0]*x[1][0], x[0]*x[1][1], x[0]*x[1][2]) for x in cols] 
  # calculate (sum(ci*ri)/np, sum(ci*gi)/np, sum(ci*bi)/np)
  # the zip gives us [(c1*r1, c2*r2, ..), (c1*g1, c1*g2,...)...]
  avg = tuple([sum(x)/npixels for x in zip(*sumRGB)])
  return avg
print getAverageRGB(img)

!mv  Retrieve-Twitter-Tweets-Images.html /var/www/lbry-toolbox.com/public/notebooks

!ls *.jpg

!wget https://jacknorthrup.com/jupyter-notebooks/retrieve-firefox-passwords-enter-sqlite-database.html

!wget https://jacknorthrup.com/image2/v2.jpg

from PIL import Image
file_path = DT
IMG = Image.open(file_path)
IMG

path = '/home/jack/Desktop/JupyterNotebooks-languages/manybot/'
img = random.choice(os.listdir(path))
file_Path =path+img

IM=Imageopen(file_Path)
IM

from PIL import ImageFont, ImageDraw, Image
import time
import os
import random
from random import randint
def pick(font_path):    
        
        font=random.choice([x for x in os.listdir(font_path) if os.path.isfile(os.path.join(font_path, x))])
        return font_path+font
def mkimage(path1):
    
    img = random.choice(os.listdir(path1))
    file_path =path1+img 
    return file_path

def mkbatch(mkimage,pick):
    image = Image.open(mkimage)
    image = image.resize((1280,720), Image.NEAREST)
    W,H = image.size
    draw = ImageDraw.Draw(image)
    txt = "Python Generated /Processed Images"
    fontsize = 6 # starting font size

    W, H = image.size

    # portion of image width you want text width to be
    blank = Image.new('RGB',(W, H))

    FONT = pick
    font = ImageFont.truetype(FONT, fontsize)
    #print image.size

    W,H = blank.size
    blank = blank.resize((W-100, H-30,), Image.NEAREST)
    #print blank.size
    while (font.getsize(txt)[0] < blank.size[0]) and (font.getsize(txt)[1] < blank.size[1]):
        # iterate until the text size is just larger than the criteria
        fontsize += 1
        font = ImageFont.truetype(FONT, fontsize)

    # optionally de-increment to be sure it is less than criteria
    fontsize -= 1
    font = ImageFont.truetype(FONT, fontsize)

    w, h = draw.textsize(txt, font=font)

    #print 'final font size',fontsize, FONT
    draw.text((15,625), txt, font=font, fill="black") # put the text on the image
    draw.text((20,620), txt, font=font, fill="white") # put the text on the image
    DT = time.strftime("base/%Y-%m-%d-%H-%M-%S.png")
    image.save(DT) # save it
    #image
for i in range(1,500):
    path1 = '/mnt/40ec525c-34bc-44ef-99c8-53f5524ad88b/Images/All-images/'
    font_path = '/home/jack/fonts/'
    mkbatch(mkimage(path1),pick(font_path))
    time.sleep(3)
    print ".",

!pwd

scp /home/jack/Desktop/JupyterNotebooks-languages/images/BGI-056.jpg jack@192.243.108.78:/var/www/lbry-toolbox.com/public/images

!ls /home/jack/Desktop/JupyterNotebooks-languages/images/BGI-056.jpg

/mnt/40ec525c-34bc-44ef-99c8-53f5524ad88b/Images/data/ancient art

https://lbry-toolbox.com/images/BGI-056.jpg

#!/usr/bin/python2
import os
from random import randint
from time import sleep
import time
import urllib
import simplejson as json
import requests
import sys
import subprocess
from Completedpy2 import track_download
import sqlite3
import watchVID
DT = time.strftime("%Y-%m-%d-%H:%M")
name = "Plot-Created-by-LBRYCron-Bot" #no Spaces or Special Characters
title = "LBRY LBC Wallet Balance Plot Generated by a Linux Cron Job"
file_path ="/home/jack/Desktop/JupyterNotebooks-languages/test1280.png"
data = requests.post("http://localhost:5279", json={"method": "publish", "params": {"name": name, "bid": "0.01", "title": title, "file_path": file_path, "tags": "python plot","description":"Wallet balance plot generated by a Linux cron job" , "channel_name": "@MyLinuxToyBox" }}).json()
LINES = (json.dumps(data, indent=2 * ' '))
Lin =str(LINES)
L = Lin.split("\n")
for lines in L:
        print lines


from PIL import Image
file_path ="/home/jack/Desktop/JupyterNotebooks-languages/test-full.png"
IMG = Image.open(file_path)
IM =IMG.resize((1280,720), Image.NEAREST)
im = IM.size
IM.save("/home/jack/Desktop/JupyterNotebooks-languages/test1280.png")
IM

!lbrynet address list --address=bDyZqrP3KoUVjotbdiRsPgkXpqHvASLPrT --page_size=50 --page=1

!lbrynet address list 


!ls test.jpg



publish

Create or replace a stream claim at a given name (use 'stream create/update' for more control).
Arguments

name    str    name of the content (can only consist of a-z A-Z 0-9 and -(dash))
bid    optionaldecimal    amount to back the claim
file_path    optionalstr    path to file to be associated with name.
fee_currency    optionalstring    specify fee currency
fee_amount    optionaldecimal    content download fee
fee_address   optionalstr    address where to send fee payments, gefaut value from --claim_address if not provided
title    optionalstr    title of the publication
description    optionalstr    description of the publication
author    optionalstr    author of the publication. The usage for this field is not the same as for channels.
The author field is used to credit an author who is not the publisher and is not represented by the
channel. For example, a pdf file of 'The Odyssey' has an author of 'Homer' but may by published to a
channel such as '@classics', or to no channel at all
tags    optionallist    add content tags
languages    optionallist    languages used by the channel, using RFC 5646 format, eg: for English 
    `--languages=en` for Spanish (Spain) `--languages=es-ES` for Spanish (Mexican) `--languages=es-MX`
    for Chinese (Simplified) `--languages=zh-Hans` for Chinese (Traditional) `--languages=zh-Hant`
locations    optionallist    locations relevant to the stream, consisting of 2 letter `country` 
code and a `state`, `city` and a postal `code` along with a `latitude` and `longitude`. for JSON RPC:
    pass a dictionary with aforementioned attributes as keys,
eg: ... "locations": [{'country': 'US', 'state': 'NH'}] ... for command line: pass a colon delimited 
list with values in the following order: "COUNTRY:STATE:CITY:CODE:LATITUDE:LONGITUDE" making
sure to include colon for blank values, for example to provide only the 
city: ... --locations="::Manchester" with all values set: ...
--locations="US:NH:Manchester:03101:42.990605:-71.460989" optionally, you can just pass 
the "LATITUDE:LONGITUDE": ... --locations="42.990605:-71.460989" finally, you can also pass 
JSON string of dictionary on the command line as you would via JSON RPC ...
 --locations="{'country': 'US', 'state': 'NH'}"
    license
    optionalstr
    publication license
    license_url
    optionalstr
    publication license url
    thumbnail_url
    optionalstr
    thumbnail url
    release_time
    optionalint
    original public release of content, seconds since UNIX epoch
    width
    optionalint
    image/video width, automatically calculated from media file
    height
    optionalint
    image/video height, automatically calculated from media file
    duration
    optionalint
    audio/video duration in seconds, automatically calculated
    channel_id
    optionalstr
    claim id of the publisher channel
    channel_name
    optionalstr
    name of publisher channel
    channel_account_id
    optionalstr
    one or more account ids for accounts to look in for channel certificates, defaults to all accounts.
    account_id
    optionalstr
    account to use for holding the transaction
    wallet_id
    optionalstr
    restrict operation to specific wallet
    funding_account_ids
    optionallist
    ids of accounts to fund this transaction
    claim_address
    optionalstr
    address where the claim is sent to, if not specified it will be determined automatically from the account
    preview
    optionalbool
    do not broadcast the transaction
    blocking
    optionalbool
    wait until transaction is in mempool


def pick():    
        font_path = '/home/jack/fonts/'
        font=random.choice([x for x in os.listdir(font_path) if os.path.isfile(os.path.join(font_path, x))])
        return font_path+font
for i in range(1,100):
    print pick()    



def getAverageRGB(img):
  """
  Given PIL Image, return average value of color as (r, g, b)
  """
  # no. of pixels in image
  npixels = image.size[0]*image.size[1]
  # get colors as [(cnt1, (r1, g1, b1)), ...]
  cols = image.getcolors(npixels)
  # get [(c1*r1, c1*g1, c1*g2),...]
  sumRGB = [(x[0]*x[1][0], x[0]*x[1][1], x[0]*x[1][2]) for x in cols] 
  # calculate (sum(ci*ri)/np, sum(ci*gi)/np, sum(ci*bi)/np)
  # the zip gives us [(c1*r1, c2*r2, ..), (c1*g1, c1*g2,...)...]
  avg = tuple([sum(x)/npixels for x in zip(*sumRGB)])
  return avg
print getAverageRGB(img)

#https://stackoverflow.com/questions/24021579/how-to-set-appropriate-line-width-for-drawing-text-in-python-pil
from PIL import Image
from PIL import ImageFont
from PIL import ImageDraw 
import textwrap
def pick():    
        font_path = '/home/jack/fonts/'
        font=random.choice([x for x in os.listdir(font_path) if os.path.isfile(os.path.join(font_path, x))])
        return font_path+font
    
size_x = 600 #This value can arbitrarily change
size_y = 700 #This value can arbitrarily change
font_size = 18 #This value can be adjusted to fit parameters of image if necessary

my_text = ['Lorem ipsum dolor sit amet, consectetur adipiscing elit. Etiam scelerisque sapien convallis nisl facilisis, sed facilisis odio accumsan. Maecenas vel leo eu turpis porta dictum at vel neque. Donec sagittis felis non tellus lacinia facilisis. Vivamus vel nisi ullamcorper, feugiat lorem sagittis, pellentesque dolor. Curabitur est magna, feugiat ut nibh quis, blandit vestibulum nisl. Sed pulvinar condimentum purus et rutrum. Proin magna arcu, scelerisque at gravida ut, convallis quis orci. Mauris ipsum tortor, laoreet et leo ac, lacinia euismod tellus. Curabitur volutpat nisi a metus faucibus, vel iaculis nisl fermentum. Curabitur et orci id sapien porttitor dignissim at ac dolor. Donec nec mattis nisi. ']

tx = Image.new('RGB', (size_x, size_y),color=(255,255,255))
draw = ImageDraw.Draw(tx)
randomfont=pick()
my_font = ImageFont.truetype(randomfont,size=font_size)
lines = textwrap.wrap(my_text[0], width = 130) #This width value needs to be set automatically
y_text = 0
for line in lines:
    width, height = my_font.getsize(line)
    draw.text((0, y_text), line, font = my_font, fill = (0,0,0))
    y_text += height

tx.show()

!ls /home/jack/Desktop/post

from PIL import Image
image = Image.open("/home/jack/Desktop/post/pil_text.png")
image

!ls -rant /home/jack/Desktop/VPS_resources

from PIL import Image
image = Image.open("/home/jack/Desktop/VPS_resources/202002201016-final.png")
image

from PIL import Image
image = Image.open("/home/jack/Desktop/post/202002200046-POST.png")
image

!cp base/2020-02-21-04-59-24.png /var/www/lbry-toolbox.com/public/images

https://lbry-toolbox.com/images/2020-02-21-04-59-24.png

from IPython.core.display import HTML
HTML("""
<style>
#notebook-container {
    padding: 15px;
    background-color: #E3F6FF;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.3);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.3);
}
.notebook_app {
    background-color: lightblue;
}
#header{
background-color: #ffebcd;
}
#notebook_name.filename{
color:DarkRed;
font-size:200%;
}
body #header{
background-color:#F9E1DF;
}
</style>
""")




import vsketch

#JES4-3 #KyraMoran #created 9/20/19

#this program makes shapes based on the x and y coordinate range in the picture

from random import *

#makeBackground
lightBlue = makeColor (100,150,200)
pic = makeEmptyPicture(600,600,lightBlue)


pink1 = makeColor (230, 160, 160) #just wanted to practice making a color
  
for i in range (200):
  xCord = randint(0,600) #starting x coordinate
  yCord = randint(0,600) #starting y coordinate
  circle = randint(10,60) #height and width of circles
  square = randint(10,100) #height and width of squares
  ovalWidth = randint (10,50) #width of ovals
  ovalHeight = randint (10,80) #height of ovals
  
  if xCord < 200: #left third
    addOval(pic,xCord,yCord, circle, circle, green)
    
  elif 200 < xCord < 400: #middle third
    if yCord < 200:
      addRect(pic, xCord, yCord, square, square, pink1) #top third
    elif 200 <= yCord <= 400:
      addRect(pic, xCord, yCord, square, square, blue) #middle third   
    else:
      addRect(pic, xCord, yCord, square, square, yellow) #bottom third
    
  else: #right third
    addOval(pic, xCord, yCord, ovalWidth, ovalHeight, lightGray)

show(pic)

https://spin.atomicobject.com/2022/04/26/generative-art-recursion/

function getCircleX(radians, radius) {
  return Math.cos(radians) * radius;
}

console.log(getCircleX(1, 10));
// expected output: 5.403023058681398

console.log(getCircleX(2, 10));
// expected output: -4.161468365471424

console.log(getCircleX(Math.PI, 10));
// expected output: -10


//helper
/**
 * converts degree to radians
 * @param degree
 * @returns {number}
 */
var toRadians = function (degree) {
    return degree * (Math.PI / 180);
};

/**
 * Converts radian to degree
 * @param radians
 * @returns {number}
 */
var toDegree = function (radians) {
    return radians * (180 / Math.PI);
}

/**
 * Rounds a number mathematical correct to the number of decimals
 * @param number
 * @param decimals (optional, default: 5)
 * @returns {number}
 */
var roundNumber = function(number, decimals) {
    decimals = decimals || 5;
    return Math.round(number * Math.pow(10, decimals)) / Math.pow(10, decimals);
}
//the object
var MathD = {
    sin: function(number){
        return roundNumber(Math.sin(toRadians(number)));
    },
    cos: function(number){
        return roundNumber(Math.cos(toRadians(number)));
    },
    tan: function(number){
        return roundNumber(Math.tan(toRadians(number)));
    },
    asin: function(number){
        return roundNumber(toDegree(Math.asin(number)));
    },
    acos: function(number){
       return roundNumber(toDegree(Math.acos(number)));
   },
   atan: function(number){
       return roundNumber(toDegree(Math.atan(number)));
   }
};


Math.sin(35)

MathD{cos(3)}

toRadians(45)

var data = [
    { 
        "name": "ananta",
        "age": "15",
        "country": "Atlanta"
    }
];

data.push({"name": "Tony Montana", "age": "99"});

data.push({"country": "IN"});

data

var c = document.getElementById("myCanvas");
var ctx = c.getContext("2d");
x1 = 30;
y1 = 40;
r =  50;
theta = 0.5;
ctx.moveTo(x1, y1);
ctx.lineTo(x1 + r * Math.cos(theta), y1 + r * Math.sin(theta));
ctx.stroke();

//where you must make sure that theta is in radians and that ctx is defined to be whatever canvas context you //want it to be (in the above code, this means you want something like

<canvas id="myCanvas" width="200" height="100"
style="border:1px solid #000000;">
</canvas>

function drawTree(x, y, angle, length) {
  const [x1, y1] = [x, y];
  const x2 = x1 + Math.cos(angle) * length;
  const y2 = y1 - Math.sin(angle) * length;
  
  var line = (x1, y1, x2, y2);
  var minLength = 5
  var angleChange = 6
  var lengthRatio = .6
  if (length >= minLength) {
    drawTree(x2, y2, angle + angleChange, length * lengthRatio);
    drawTree(x2, y2, angle - angleChange, length * lengthRatio);
  } else {
    drawLeaves(x2, y2);
  }
}

function drawLeaves(x, y) {
  drawTree.push(x,y);
  
  fill(leafColor);
  noStroke();
  
  for (let i = 0; i < leafDensity; i++) {
    circle(
      randomGaussian(x, 10),
      randomGaussian(y, 10),
      random(2, 5)
    );
  }
  
  pop();
}

drawTree(3, 4, 37, 30)

function drawTree(x, y, angle, length) {
  const [x1, y1] = [x, y];
  const x2 = x1 + cos(angle) * length;
  const y2 = y1 - sin(angle) * length;
  
  line(x1, y1, x2, y2);

  if (length >= minLength) {
    drawTree(x2, y2, angle + angleChange, length * lengthRatio);
    drawTree(x2, y2, angle - angleChange, length * lengthRatio);
  } else {
    drawLeaves(x2, y2);
  }
}

function drawLeaves(x, y) {
  push();
  
  fill(leafColor);
  noStroke();
  
  for (let i = 0; i < leafDensity; i++) {
    circle(
      randomGaussian(x, 10),
      randomGaussian(y, 10),
      random(2, 5)
    );
  }
  
  pop();
}

drawTree(3, 4, 37, 30)

!npm install math

%%javascript
// We make sure the `counter` module is defined
// only once.
require.undef('counter');

// We define the `counter` module depending on the
// Jupyter widgets framework.
define('counter', ["@jupyter-widgets/base"],
       function(widgets) {

    // We create the CounterView frontend class,
    // deriving from DOMWidgetView.
    var CounterView = widgets.DOMWidgetView.extend({

        // This method creates the HTML widget.
        render: function() {
            // The value_changed() method should be
            // called when the model's value changes
            // on the kernel side.
            this.value_changed();
            this.model.on('change:value',
                          this.value_changed, this);

            var model = this.model;
            var that = this;

            // We create the plus and minus buttons.
            this.bm = $('<button/>')
            .text('-')
            .click(function() {
                // When the button is clicked,
                // the model's value is updated.
                var x = model.get('value');
                model.set('value', x - 1);
                that.touch();
            });

            this.bp = $('<button/>')
            .text('+')
            .click(function() {
                var x = model.get('value');
                model.set('value', x + 1);
                that.touch();
            });

            // This element displays the current
            // value of the counter.
            this.span = $('<span />')
            .text('0')
            .css({marginLeft: '10px',
                  marginRight: '10px'});

            // this.el represents the widget's DOM
            // element. We add the minus button,
            // the span element, and the plus button.
            $(this.el)
            .append(this.bm)
            .append(this.span)
            .append(this.bp);
        },

        value_changed: function() {
            // Update the displayed number when the
            // counter's value changes.
            var x = this.model.get('value');
            $($(this.el).children()[1]).text(x);
        },
    });

    return {
        CounterView : CounterView
    };
});


CounterView()



import vsketch

#JES4-3 #KyraMoran #created 9/20/19

#this program makes shapes based on the x and y coordinate range in the picture

from random import *

#makeBackground
lightBlue = makeColor (100,150,200)
pic = makeEmptyPicture(600,600,lightBlue)


pink1 = makeColor (230, 160, 160) #just wanted to practice making a color
  
for i in range (200):
  xCord = randint(0,600) #starting x coordinate
  yCord = randint(0,600) #starting y coordinate
  circle = randint(10,60) #height and width of circles
  square = randint(10,100) #height and width of squares
  ovalWidth = randint (10,50) #width of ovals
  ovalHeight = randint (10,80) #height of ovals
  
  if xCord < 200: #left third
    addOval(pic,xCord,yCord, circle, circle, green)
    
  elif 200 < xCord < 400: #middle third
    if yCord < 200:
      addRect(pic, xCord, yCord, square, square, pink1) #top third
    elif 200 <= yCord <= 400:
      addRect(pic, xCord, yCord, square, square, blue) #middle third   
    else:
      addRect(pic, xCord, yCord, square, square, yellow) #bottom third
    
  else: #right third
    addOval(pic, xCord, yCord, ovalWidth, ovalHeight, lightGray)

show(pic)

https://spin.atomicobject.com/2022/04/26/generative-art-recursion/

function getCircleX(radians, radius) {
  return Math.cos(radians) * radius;
}

console.log(getCircleX(1, 10));
// expected output: 5.403023058681398

console.log(getCircleX(2, 10));
// expected output: -4.161468365471424

console.log(getCircleX(Math.PI, 10));
// expected output: -10


//helper
/**
 * converts degree to radians
 * @param degree
 * @returns {number}
 */
var toRadians = function (degree) {
    return degree * (Math.PI / 180);
};

/**
 * Converts radian to degree
 * @param radians
 * @returns {number}
 */
var toDegree = function (radians) {
    return radians * (180 / Math.PI);
}

/**
 * Rounds a number mathematical correct to the number of decimals
 * @param number
 * @param decimals (optional, default: 5)
 * @returns {number}
 */
var roundNumber = function(number, decimals) {
    decimals = decimals || 5;
    return Math.round(number * Math.pow(10, decimals)) / Math.pow(10, decimals);
}
//the object
var MathD = {
    sin: function(number){
        return roundNumber(Math.sin(toRadians(number)));
    },
    cos: function(number){
        return roundNumber(Math.cos(toRadians(number)));
    },
    tan: function(number){
        return roundNumber(Math.tan(toRadians(number)));
    },
    asin: function(number){
        return roundNumber(toDegree(Math.asin(number)));
    },
    acos: function(number){
       return roundNumber(toDegree(Math.acos(number)));
   },
   atan: function(number){
       return roundNumber(toDegree(Math.atan(number)));
   }
};


Math.sin(35)

MathD{cos(3)}

toRadians(45)

var data = [
    { 
        "name": "ananta",
        "age": "15",
        "country": "Atlanta"
    }
];

data.push({"name": "Tony Montana", "age": "99"});

data.push({"country": "IN"});

data

var c = document.getElementById("myCanvas");
var ctx = c.getContext("2d");
x1 = 30;
y1 = 40;
r =  50;
theta = 0.5;
ctx.moveTo(x1, y1);
ctx.lineTo(x1 + r * Math.cos(theta), y1 + r * Math.sin(theta));
ctx.stroke();

//where you must make sure that theta is in radians and that ctx is defined to be whatever canvas context you //want it to be (in the above code, this means you want something like

<canvas id="myCanvas" width="200" height="100"
style="border:1px solid #000000;">
</canvas>

function drawTree(x, y, angle, length) {
  const [x1, y1] = [x, y];
  const x2 = x1 + Math.cos(angle) * length;
  const y2 = y1 - Math.sin(angle) * length;
  
  var line = (x1, y1, x2, y2);
  var minLength = 5
  var angleChange = 6
  var lengthRatio = .6
  if (length >= minLength) {
    drawTree(x2, y2, angle + angleChange, length * lengthRatio);
    drawTree(x2, y2, angle - angleChange, length * lengthRatio);
  } else {
    drawLeaves(x2, y2);
  }
}

function drawLeaves(x, y) {
  drawTree.push(x,y);
  
  fill(leafColor);
  noStroke();
  
  for (let i = 0; i < leafDensity; i++) {
    circle(
      randomGaussian(x, 10),
      randomGaussian(y, 10),
      random(2, 5)
    );
  }
  
  pop();
}

drawTree(3, 4, 37, 30)

function drawTree(x, y, angle, length) {
  const [x1, y1] = [x, y];
  const x2 = x1 + cos(angle) * length;
  const y2 = y1 - sin(angle) * length;
  
  line(x1, y1, x2, y2);

  if (length >= minLength) {
    drawTree(x2, y2, angle + angleChange, length * lengthRatio);
    drawTree(x2, y2, angle - angleChange, length * lengthRatio);
  } else {
    drawLeaves(x2, y2);
  }
}

function drawLeaves(x, y) {
  push();
  
  fill(leafColor);
  noStroke();
  
  for (let i = 0; i < leafDensity; i++) {
    circle(
      randomGaussian(x, 10),
      randomGaussian(y, 10),
      random(2, 5)
    );
  }
  
  pop();
}

drawTree(3, 4, 37, 30)

!npm install math

%%javascript
// We make sure the `counter` module is defined
// only once.
require.undef('counter');

// We define the `counter` module depending on the
// Jupyter widgets framework.
define('counter', ["@jupyter-widgets/base"],
       function(widgets) {

    // We create the CounterView frontend class,
    // deriving from DOMWidgetView.
    var CounterView = widgets.DOMWidgetView.extend({

        // This method creates the HTML widget.
        render: function() {
            // The value_changed() method should be
            // called when the model's value changes
            // on the kernel side.
            this.value_changed();
            this.model.on('change:value',
                          this.value_changed, this);

            var model = this.model;
            var that = this;

            // We create the plus and minus buttons.
            this.bm = $('<button/>')
            .text('-')
            .click(function() {
                // When the button is clicked,
                // the model's value is updated.
                var x = model.get('value');
                model.set('value', x - 1);
                that.touch();
            });

            this.bp = $('<button/>')
            .text('+')
            .click(function() {
                var x = model.get('value');
                model.set('value', x + 1);
                that.touch();
            });

            // This element displays the current
            // value of the counter.
            this.span = $('<span />')
            .text('0')
            .css({marginLeft: '10px',
                  marginRight: '10px'});

            // this.el represents the widget's DOM
            // element. We add the minus button,
            // the span element, and the plus button.
            $(this.el)
            .append(this.bm)
            .append(this.span)
            .append(this.bp);
        },

        value_changed: function() {
            // Update the displayed number when the
            // counter's value changes.
            var x = this.model.get('value');
            $($(this.el).children()[1]).text(x);
        },
    });

    return {
        CounterView : CounterView
    };
});


CounterView()



type Data struct {
    value string
}

func (d Data) Value() string {
    return d.value
}

type WithValue interface {
    Value() string
}

d := Data{"hello"}

// Got a link error because of https://github.com/golang/go/issues/22998
d.Value()

// This works without any problem.
WithValue(d).Value()

import (
    "fmt"
    "time"
)

go func() {
    panic("die!")
}()

time.Sleep(10 * time.Millisecond)
fmt.Println("main done")

import (
    "fmt"
)

type Hello interface {
    SayHello()
}

type person struct {
    name string
}

func (p *person) SayHello() {
    fmt.Printf("Hello, I'm %s.\n", p.name)
}

p := person{"yunabe"}
fmt.Println("---- 1 ----")
p.SayHello()

var h Hello = &p
fmt.Println("---- 2 ----")
h.SayHello()

import (
    "fmt"
    "log"
    "runtime"
    "runtime/debug"
)

type MyData struct {
    b []byte
}

func (m *MyData) Size() int {
    return len(m.b)
}

func NewMyData() *MyData {
    return &MyData{
        b: make([]byte, 10 * (1 << 20)),
    }
}

var l []*MyData
for i := 0; i < 100; i++ {
    d := NewMyData()
    l = append(l, d)
}
l = nil
debug.FreeOSMemory()
runtime.GC()

import (
    "fmt"
)

for i := 0; i < 3; i++ {
    go func(id int) {
        fmt.Println("goroutine:", id)
    }(i)
}



import plotly.graph_objects as go
import time
from PIL import Image

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"


STAT =LASTFILE[57:-4]
DataIn = open(LASTFILE).readlines()

#SEARCH = input("SEARCH: ")
#SEARCH = "Brazil"
#SEARCH = "Spain"
#SEARCH = "Philippine"
SEARCH = "Ecuador"
#SEARCH = "Germany"
#SEARCH = "Japan"
#SEARCH = "US"
cnt = 0
CNTS=0
counts=[]
for line in DataIn:
    if cnt==0:print(line)
    cnt=cnt+1
    line=line.lstrip(",")
    #if SEARCH in line:print(line)
    if SEARCH in line:
        print(line)
        print(line[31:-1])
        entry = line[31:-1]
        entry=entry.split(",")
        for num in entry:
            counts.append(int(num))
            
filename0 = time.strftime("images/"+SEARCH+"_"+STAT+"Deaths_%Y%m%d%H%M%S.png")            
fig = go.Figure()
fig.add_trace(go.Scatter(y=counts))
fig.add_trace(go.Bar(y=counts))
fig.update_layout(title = SEARCH+' CONDID-19 Deaths')
fig.show() 



IncreasePerDay=[]
All = (len(counts))
for x in range(0,All):
    try:
        Sum = (counts[x+1]-counts[x])
        print(Sum, end = " ")
        IncreasePerDay.append(Sum)
    except:
        pass
    
filename1 = time.strftime("images/"+SEARCH+"_"+STAT+"IncreasePerDay"+"_%Y%m%d%H%M%S.png")
fig = go.Figure()
fig.add_trace(go.Scatter(y=IncreasePerDay))
fig.add_trace(go.Bar(y=IncreasePerDay))
fig.update_layout(title = SEARCH+' Increase Each day CONDID-19 Cases')
fig.show() 





!pip install path

import os
import inspect
print(inspect.getfile(Basemap))



import requests as req

URL ="https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"
print (URL[-25:])
STAT =URL[57:-4]
resp = req.get(URL)

#LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"
#STAT =LASTFILE[57:-4]
#DataIn = open(LASTFILE).readlines()

content = resp.text

TEMP = open(URL[-25:],"w")
TEMP.write(content)
TEMP.close()


import plotly.graph_objects as go
import time
from PIL import Image

LASTFILE="covid19_deaths_global.csv"
STAT =LASTFILE[57:-4]
DataIn = open(LASTFILE).readlines()

#SEARCH = input("SEARCH: ")
#SEARCH = "Brazil"
#SEARCH = "Spain"
SEARCH = "Philippine"
#SEARCH = "Ecuador"
#SEARCH = "Germany"
#SEARCH = "Japan"
#SEARCH = "US"
SEARCH="Mexico"
cnt = 0
CNTS=0
counts=[]
for line in DataIn:
    if cnt==0:print(line)
    cnt=cnt+1
    line=line.lstrip(",")
    #if SEARCH in line:print(line)
    if SEARCH in line:
        line=line.split(",0,0",1)[-1]
        line = "0,0"+line
        print(line)
        entry = line
        entry=entry.split(",")
        for num in entry:
            counts.append(int(num))
            
filename0 = time.strftime("images/"+SEARCH+"_"+STAT+"Deaths_%Y%m%d%H%M%S.png")            
fig = go.Figure()
fig.add_trace(go.Scatter(y=counts))
fig.add_trace(go.Bar(y=counts))
fig.update_layout(title = SEARCH+' CONDID-19 Deaths')
fig.show() 



IncreasePerDay=[]
All = (len(counts))
for x in range(0,All):
    try:
        Sum = (counts[x+1]-counts[x])
        print(Sum, end = " ")
        IncreasePerDay.append(Sum)
    except:
        pass
    
filename1 = time.strftime("images/"+SEARCH+"_"+STAT+"IncreasePerDay"+"_%Y%m%d%H%M%S.png")
fig = go.Figure()
fig.add_trace(go.Scatter(y=IncreasePerDay))
fig.add_trace(go.Bar(y=IncreasePerDay))
fig.update_layout(title = SEARCH+' Increase Each day CONDID-19 Cases')
fig.show() 

import plotly.graph_objects as go
import time
from PIL import Image

LASTFILE="COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"


STAT =LASTFILE[57:-4]
DataIn = open(LASTFILE).readlines()

#SEARCH = input("SEARCH: ")
#SEARCH = "Brazil"
#SEARCH = "Spain"
#SEARCH = "Philippine"
#SEARCH = "Ecuador"
SEARCH = "Germany"
#SEARCH = "Japan"
#SEARCH = "US"
cnt = 0
CNTS=0
counts=[]
for line in DataIn:
    if cnt==0:print(line)
    cnt=cnt+1
    line=line.lstrip(",")
    #if SEARCH in line:print(line)
    if SEARCH in line:
        line=line.split(",0,0",1)[-1]
        line = "0,0"+line
        print(line)
        entry = line
        entry=entry.split(",")
        for num in entry:
            counts.append(int(num))
            
filename0 = time.strftime("images/"+SEARCH+"_"+STAT+"Deaths_%Y%m%d%H%M%S.png")            
fig = go.Figure()
fig.add_trace(go.Scatter(y=counts))
fig.add_trace(go.Bar(y=counts))
fig.update_layout(title = SEARCH+' CONDID-19 Deaths')
fig.show() 



IncreasePerDay=[]
All = (len(counts))
for x in range(0,All):
    try:
        Sum = (counts[x+1]-counts[x])
        print(Sum, end = " ")
        IncreasePerDay.append(Sum)
    except:
        pass
    
filename1 = time.strftime("images/"+SEARCH+"_"+STAT+"IncreasePerDay"+"_%Y%m%d%H%M%S.png")
fig = go.Figure()
fig.add_trace(go.Scatter(y=IncreasePerDay))
fig.add_trace(go.Bar(y=IncreasePerDay))
fig.update_layout(title = SEARCH+' Increase Each day CONDID-19 Cases')
fig.show() 

data="Ecuador,-1.8312,-78.1834,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,2,2,2,3,5,7,14,18,27,28,34,36,48,58,60,75,93,120,145,172,180,191,191,242,272,297,315,333,355,369,388,403,421,456,474,507,520,537,560,576,576"

data=data.split(",0,0",1)[-1]
print ("0,0"+data)



from IPython import get_ipython

ip = get_ipython()
assert ip.history_manager.hist_file == ':memory:'

from IPython import get_ipython

ip = get_ipython()
assert ip.history_manager.hist_file == ':memory:'

import onnx
import os


# Preprocessing: load the ONNX model
model_path = os.path.join('resources', 'single_relu.onnx')
onnx_model = onnx.load(model_path)

print('The model is:\n{}'.format(onnx_model))

# Check the model
try:
    onnx.checker.check_model(onnx_model)
except onnx.checker.ValidationError as e:
    print('The model is invalid: %s' % e)
else:
    print('The model is valid!')

class MyClass:
  x = 5

print(MyClass)

class MyClass:
  x = 5

p1 = MyClass()
print(p1.x)

class Person:
  def __init__(self, name, age):
    self.name = name
    self.age = age

p1 = Person("John", 36)

print(p1.name)
print(p1.age) 

!ls /home/jack/miniconda3/envs/cloned_base/lib/python3.9/site-packages/PIL





!ls /home/jack/Desktop/*.txt

tx=open("/home/jack/Desktop/pas.txt").readlines()
for line in tx:
    line = line.replace("\n","")
    line = line.replace("\\n')","")
    print (line)

ex ="(2, u'https://app.arukas.io jahral@yahoo.com tr4356hyFrt##"
ex2 =ex.lstrip("(")
print (ex)
print (ex2)

help.strip()

!pip list>>freeze.txt

ftx=open("freeze.txt").readlines()
for line in ftx:
    line = line.replace("\n","")
    line = line.replace("\\n')","")
    print (line)

!ls /lib/python3.8/re.py

ftx=open("/lib/python3.8/re.py").readlines()
for line in ftx:
    line = line.replace("\n","")
    line = line.replace("\\n')","")
    print (line)

import re
help(re)

import re
ex ="(2, u'https://app.arukas.io jahral@yahoo.com tr4356hyFrt##"
ex2 =ex.split("u'")
print (ex)
print (ex2[1])

ftx=open("pas.txt").readlines()
LS = []
for line in ftx:
    line = line.replace("\n","")
    linez = line.replace("\\n')","")
    linex =linez.split("u'")
    print (linex)
    LS.append(linex)

len(LS)

import time
for line in LS:
    time.sleep (.5)
    print(line[1])

import sys
import sqlite3
conn = sqlite3.connect("pas.db")
conn.text_factory = str
c = conn.cursor()

def create():
    import sqlite3
    conn = sqlite3.connect("./pas.db")
    conn.text_factory = str
    c = conn.cursor()
    c.execute("CREATE VIRTUAL TABLE PROJECT using FTS4 (input)")
    conn.commit()
    text = "Database Created"
    return text

def insert(data,conn=conn, c=c):
    c.execute("INSERT into PROJECT values (?)", (data,))
    for row in c.execute("SELECT ROWID,* FROM PROJECT ORDER BY ROWID DESC LIMIT 1"):
        print ("\nPOST VERIFIED:\n",row[0],row[1])
    #conn.commit()
    #conn.close()
    return data

create()

import time
for data in LS:
    insert(data[1])
    
conn.commit()
conn.close()   

def main():
    conn = sqlite3.connect("./pas.db")
    conn.text_factory = str
    c = conn.cursor()
    for row in c.execute("SELECT rowid, * FROM PROJECT"):
        print (row[0],": ",row[1])
main()

!ls *.db

conn.commit()
conn.close()

!rm pas.db



from __future__ import print_function
from IPython.display import clear_output

for i in range(10):
    clear_output()
    print(i)

print("Hello world")
clear_output()

print("Hello world", end='')
clear_output(wait=True)  # no output after this

print("Hello", end='')
clear_output(wait=True)  # here we have new output after wait=True
print("world", end='')

handle0 = display("Hello world", display_id="id0")

handle1 = display("Hello", display_id="id1")

handle1.update('world')

handle2 = display("Hello world", display_id="id2")
clear_output()  # clears all output, also with display_ids

handle3 = display("Hello world", display_id="id3")
clear_output(wait=True)

handle4 = display("Hello", display_id="id4")
clear_output(wait=True)
print('world', end='')

handle4.update('Hello world')  # it is cleared, so it should not show up in the above cell

from __future__ import print_function
from IPython.display import clear_output

for i in range(10):
    clear_output()
    print(i)

print("Hello world")
clear_output()

print("Hello world", end='')
clear_output(wait=True)  # no output after this

print("Hello", end='')
clear_output(wait=True)  # here we have new output after wait=True
print("world", end='')

handle0 = display("Hello world", display_id="id0")

handle1 = display("Hello", display_id="id1")

handle1.update('world')

handle2 = display("Hello world", display_id="id2")
clear_output()  # clears all output, also with display_ids

handle3 = display("Hello world", display_id="id3")
clear_output(wait=True)

handle4 = display("Hello", display_id="id4")
clear_output(wait=True)
print('world', end='')

handle4.update('Hello world')  # it is cleared, so it should not show up in the above cell

import os
os.chdir("/home/jack/Desktop/dockercommands")

!ls images

from PIL import Image, ImageTk
import PIL
from sys import argv
import sys
from tkinter import *
import cv2
import numpy as np 

window = Tk(className="Clickable")
data = []
#image = PIL.Image.open("mouse-sizing-n-cropping-files/jungle700.jpg")
image = PIL.Image.open("/home/jack/Desktop/dockercommands/archived-images/20221109-201146_.png")
canvas = Canvas(window, width=image.size[0], height=image.size[1])
canvas.pack()
image_tk = ImageTk.PhotoImage(image)
canvas.create_image(image.size[0]//2, image.size[1]//2, image=image_tk)

def callback(event):
    #print "[",event.x,"],["+event.y,"]"
    #Data= ("[",event.x,",",event.y,"],",)
    Data= [event.x,event.y]
    data.append(Data)
    print ("[",event.x,",",event.y,"],",)

canvas.bind("<Button-1>", callback)
mainloop()

poly = np.array(data, np.int32)

# Read images
#dst = cv2.imread("mouse-sizing-n-cropping-files/soil600.jpg")
src = cv2.imread("/home/jack/Desktop/dockercommands/archived-images/20221109-201146_.png")
dst = cv2.imread("/home/jack/Desktop/dockercommands/archived-images/20221109-201157_.png")
#src = cv2.imread("mouse-sizing-n-cropping-files/jungle700.jpg")
src_mask = np.zeros(src.shape, src.dtype)
#poly = np.array([ [1,100], [1,50], [151,63], [254,37], [298,90], [272,134], [43,122] ], np.int32)
cv2.fillPoly(src_mask, [poly], (255, 255, 255))
# This is where the CENTER where thr 'poly' will be placed
center = (250,275)
# Clone seamlessly.
output = cv2.seamlessClone(src, dst, src_mask, center, cv2.NORMAL_CLONE)
# Write result
cv2.imwrite("01-cloning-0000x.jpg", output);
im = PIL.Image.open("01-cloning-0000x.jpg")
im

import tkinter as tk
Name="fds"
window = tk.Tk(className = Name)
def change_className():
    global Name
    Name = "dsfsd"
    window.title(Name)

#bool=True
button=tk.Button(window,command=change_className)
button.pack()
window.mainloop()

import tkinter as tk

class App(tk.Frame):
    def __init__(self, master=None):
        super().__init__(master)
        self.pack()

# create the application
myapp = App()

#
# here are method calls to the window manager class
#
myapp.master.title("My Do-Nothing Application")
myapp.master.minsize(600, 400)
myapp.master.maxsize(1000, 800)

# start the program
myapp.mainloop()



from PIL import Image, ImageTk
from sys import argv
from tkinter import *
import tkinter
from PIL import Image
window = tkinter.Tk(className="bla")

image = Image.open("mouse-sizing-n-cropping-files/jungle700.jpg")
canvas = tkinter.Canvas(window, width=image.size[0], height=image.size[1])
canvas.pack()
image_tk = ImageTk.PhotoImage(image)

data = (image.size[0]//2, image.size[1]//2, image==image_tk)
print (data)
#canvas.create_image(image.size[0]//2, image.size[1]//2, image==image_tk)

from PIL import Image, ImageTk
from sys import argv
from tkinter import *
import tkinter
from PIL import Image
window = tkinter.Tk(className="bla")

image = Image.open("mouse-sizing-n-cropping-files/jungle700.jpg")
canvas = tkinter.Canvas(window, width=image.size[0], height=image.size[1])
canvas.pack()
image_tk = ImageTk.PhotoImage(image)
canvas.create_image(image.size[0]//2, image.size[1]//2, image=image_tk)

def callback(event):
    #print "[",event.x,"],["+event.y,"]"
    print ("[",event.x,",",event.y,"],",)

canvas.bind("<Button-1>", callback)
tkinter.mainloop()



# @title Imports and utility functions
import os

import IPython
from IPython.display import display
import numpy as np
import PIL.Image
import pandas as pd
import six
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()

import tensorflow_hub as hub

def imgrid(imarray, cols=8, pad=1):
  pad = int(pad)
  assert pad >= 0
  cols = int(cols)
  assert cols >= 1
  N, H, W, C = imarray.shape
  rows = int(np.ceil(N / float(cols)))
  batch_pad = rows * cols - N
  assert batch_pad >= 0
  post_pad = [batch_pad, pad, pad, 0]
  pad_arg = [[0, p] for p in post_pad]
  imarray = np.pad(imarray, pad_arg, 'constant')
  H += pad
  W += pad
  grid = (imarray
          .reshape(rows, cols, H, W, C)
          .transpose(0, 2, 1, 3, 4)
          .reshape(rows*H, cols*W, C))
  return grid[:-pad, :-pad]


def imshow(a, format='png', jpeg_fallback=True):
  a = np.asarray(a, dtype=np.uint8)
  if six.PY3:
    str_file = six.BytesIO()
  else:
    str_file = six.StringIO()
  PIL.Image.fromarray(a).save(str_file, format)
  png_data = str_file.getvalue()
  try:
    disp = display(IPython.display.Image(png_data))
  except IOError:
    if jpeg_fallback and format != 'jpeg':
      print ('Warning: image was too large to display in format "{}"; '
             'trying jpeg instead.').format(format)
      return imshow(a, format='jpeg')
    else:
      raise
  return disp


class Generator(object):

  def __init__(self, module_spec):
    self._module_spec = module_spec
    self._sess = None
    self._graph = tf.Graph()
    self._load_model()

  @property
  def z_dim(self):
    return self._z.shape[-1].value

  @property
  def conditional(self):
    return self._labels is not None

  def _load_model(self):
    with self._graph.as_default():
      self._generator = hub.Module(self._module_spec, name="gen_module",
                                   tags={"gen", "bsNone"})
      input_info = self._generator.get_input_info_dict()
      inputs = {k: tf.placeholder(v.dtype, v.get_shape().as_list(), k)
                for k, v in self._generator.get_input_info_dict().items()}
      self._samples = self._generator(inputs=inputs, as_dict=True)["generated"]
      print("Inputs:", inputs)
      print("Outputs:", self._samples)
      self._z = inputs["z"]
      self._labels = inputs.get("labels", None)

  def _init_session(self):
    if self._sess is None:
      self._sess = tf.Session(graph=self._graph)
      self._sess.run(tf.global_variables_initializer())

  def get_noise(self, num_samples, seed=None):
    if np.isscalar(seed):
      np.random.seed(seed)
      return np.random.normal(size=[num_samples, self.z_dim])
    z = np.empty(shape=(len(seed), self.z_dim), dtype=np.float32)
    for i, s in enumerate(seed):
      np.random.seed(s)
      z[i] = np.random.normal(size=[self.z_dim])
    return z

  def get_samples(self, z, labels=None):
    with self._graph.as_default():
      self._init_session()
      feed_dict = {self._z: z}
      if self.conditional:
        assert labels is not None
        assert labels.shape[0] == z.shape[0]
        feed_dict[self._labels] = labels
      samples = self._sess.run(self._samples, feed_dict=feed_dict)
      return np.uint8(np.clip(256 * samples, 0, 255))


class Discriminator(object):

  def __init__(self, module_spec):
    self._module_spec = module_spec
    self._sess = None
    self._graph = tf.Graph()
    self._load_model()

  @property
  def conditional(self):
    return "labels" in self._inputs

  @property
  def image_shape(self):
    return self._inputs["images"].shape.as_list()[1:]

  def _load_model(self):
    with self._graph.as_default():
      self._discriminator = hub.Module(self._module_spec, name="disc_module",
                                       tags={"disc", "bsNone"})
      input_info = self._discriminator.get_input_info_dict()
      self._inputs = {k: tf.placeholder(v.dtype, v.get_shape().as_list(), k)
                      for k, v in input_info.items()}
      self._outputs = self._discriminator(inputs=self._inputs, as_dict=True)
      print("Inputs:", self._inputs)
      print("Outputs:", self._outputs)

  def _init_session(self):
    if self._sess is None:
      self._sess = tf.Session(graph=self._graph)
      self._sess.run(tf.global_variables_initializer())

  def predict(self, images, labels=None):
    with self._graph.as_default():
      self._init_session()
      feed_dict = {self._inputs["images"]: images}
      if "labels" in self._inputs:
        assert labels is not None
        assert labels.shape[0] == images.shape[0]
        feed_dict[self._inputs["labels"]] = labels
      return self._sess.run(self._outputs, feed_dict=feed_dict)


# @title Select a model { run: "auto" }

model_name = "S3GAN 128x128 20% labels (FID 6.9, IS 98.1)"  # @param ["S3GAN 256x256 10% labels (FID 8.8, IS 130.7)", "S3GAN 128x128 2.5% labels (FID 12.6, IS 48.7)", "S3GAN 128x128 5% labels (FID 8.4, IS 74.0)", "S3GAN 128x128 10% labels (FID 7.6, IS 90.3)", "S3GAN 128x128 20% labels (FID 6.9, IS 98.1)"]
models = {
    "S3GAN 256x256 10% labels": "https://tfhub.dev/google/compare_gan/s3gan_10_256x256/1",
    "S3GAN 128x128 2.5% labels": "https://tfhub.dev/google/compare_gan/s3gan_2_5_128x128/1",
    "S3GAN 128x128 5% labels": "https://tfhub.dev/google/compare_gan/s3gan_5_128x128/1",
    "S3GAN 128x128 10% labels": "https://tfhub.dev/google/compare_gan/s3gan_10_128x128/1",
    "S3GAN 128x128 20% labels": "https://tfhub.dev/google/compare_gan/s3gan_20_128x128/1",
}

module_spec = models[model_name.split(" (")[0]]
print("Module spec:", module_spec)
from tensorflow.python.framework import ops
ops.reset_default_graph()
#tf.reset_default_graph()
print("Loading model...")
sampler = Generator(module_spec)
print("Model loaded.")


from tensorflow.python.framework import ops
ops.reset_default_graph()





import tensorflow_hub as hub
import random
from PIL import Image
import os
import sys
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import time

def load_img(img_path):
    img = tf.io.read_file(img_path)
    img = tf.image.decode_image(img, channels=3)
    img = tf.image.convert_image_dtype(img, tf.float32)
    img = img[tf.newaxis, :]
    return img
def prep_content(content):
    PI = Image.open(content)
    PI = PI.resize((720,480), Image.NEAREST)
    CFilename = os.path.basename(content)
    PI.save("preped_images/Content_"+CFilename)
    Content_data="preped_images/Content_"+CFilename
    return Content_data
    
def prep_style(style):
    PI = Image.open(style)
    PI = PI.resize((720,480), Image.NEAREST)
    SFilename = os.path.basename(style)
    PI.save("preped_images/Style_"+SFilename)
    Style_data="preped_images/Style_"+SFilename
    return Style_data    


path = r"/home/jack/Desktop/Imagedata/0-original-images/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
content=(path+base_image)
print("content: "+path+base_image)

#content = "/home/jack/Pictures/1022362.jpg"
path = r"/home/jack/Desktop/Imagedata/4-publish-images/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
style=(path+base_image)
print("style: "+path+base_image)
#style = "/home/jack/Pictures/1022362.jpg

content_image = load_img(prep_content(content))
style_image = load_img(prep_style(style))
content_image.shape
def tensor_to_image(tensor):
    tensor = tensor*255
    tensor = np.array(tensor, dtype=np.uint8)
    if np.ndim(tensor)>3:
        assert tensor.shape[0] == 1
        tensor = tensor[0]
        return Image.fromarray(tensor)
tensor = style_image
im = tensor_to_image(tensor)
timestr = time.strftime("%Y%m%d-%H%M%S")
savefile = "images/"+timestr+".jpg"
print(savefile)
im.save(savefile)
#TensorShape([1, 200, 200, 3])


im = Image.open(savefile)
print(im.size)
im


!mkdir /home/jack/Desktop/Imagedata/newstuff

%matplotlib inline
from matplotlib import pyplot as plt
path = r"/home/jack/Desktop/Imagedata/0-original-images/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
content=(path+base_image)
print("content: "+path+base_image)

#content = "/home/jack/Pictures/1022362.jpg"
path = r"/home/jack/Desktop/Imagedata/4-publish-images/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
style=(path+base_image)
print("style: "+path+base_image)

im1 = Image.open(content)
im2 = Image.open(style)

plt.figure(figsize = (10,10))
plt.imshow(im1)
plt.imshow(im2, alpha=0.5)


from PIL import Image
import time
import random
import os

def mknewimage(path1,path2):
    base_image = random.choice([
        x for x in os.listdir(path1)
        if os.path.isfile(os.path.join(path1, x))
    ])
    content=(path1+base_image)
    print("content: "+path1+base_image)

    #content = "/home/jack/Pictures/1022362.jpg"
    #path2 = r"/home/jack/Desktop/Imagedata/4-publish-images/"
    base_image = random.choice([
        x for x in os.listdir(path2)
        if os.path.isfile(os.path.join(path2, x))
    ])
    style=(path2+base_image)
    print("style: "+path2+base_image)

    im1 = Image.open(content)
    background = im1.resize((720,480), Image.BICUBIC)
    im2 = Image.open(style)
    overlay = im2.resize((720,480), Image.BICUBIC)
    #background = Image.open(content)
    #overlay = Image.open(style)

    background = background.convert("RGBA")
    overlay = overlay.convert("RGBA")

    new_img = Image.blend(background, overlay, 0.6)

    timestr = time.strftime("%Y%m%d-%H%M%S")
    savefile = "/home/jack/Desktop/Imagedata/newstuff/"+timestr+".png"
    print(savefile)

    new_img.save(savefile,"PNG")
    return new_img

for x in range(0,300):
    time.sleep(5)
    path1 = r"/home/jack/Desktop/Imagedata/0-original-images/"
    path2 = r"/home/jack/Desktop/Imagedata/4-publish-images/"
    nim = mknewimage(path1,path2)
    print(x,nim)


for x in range(300,900):
    time.sleep(5)
    path1 = r"/home/jack/Desktop/Imagedata/0-original-images/"
    path2 = r"/home/jack/Desktop/Imagedata/4-publish-images/"
    nim = mknewimage(path1,path2)
    print(x,nim)


def mknewimage(path1):
    base_image = random.choice([
        x for x in os.listdir(path1)
        if os.path.isfile(os.path.join(path1, x))
    ])
    content=(path1+base_image)
    print("content: "+path1+base_image)
path1 = r"/home/jack/Desktop/Imagedata/0-original-images/"
mknewimage(path1)

from PIL import Image
import time


def mknewimage(path1,path2):
    base_image = random.choice([
        x for x in os.listdir(path1)
        if os.path.isfile(os.path.join(path1, x))
    ])
    content=(path1+base_image)
    print("content: "+path1+base_image)

    #content = "/home/jack/Pictures/1022362.jpg"
    #path2 = r"/home/jack/Desktop/Imagedata/4-publish-images/"
    base_image = random.choice([
        x for x in os.listdir(path2)
        if os.path.isfile(os.path.join(path2, x))
    ])
    style=(path2+base_image)
    print("style: "+path2+base_image)

    im1 = Image.open(content)
    background = im1.resize((720,480), Image.BICUBIC)
    im2 = Image.open(style)
    overlay = im2.resize((720,480), Image.BICUBIC)
 

    background = background.convert("RGBA")
    overlay = overlay.convert("RGBA")

    new_img = Image.blend(background, overlay, 0.6)

    timestr = time.strftime("%Y%m%d-%H%M%S")
    savefile = "/home/jack/Desktop/Imagedata/newstuff/"+timestr+".png"
    print(savefile)

    new_img.save(savefile,"PNG")
    return new_img


path1 = r"/home/jack/Desktop/Imagedata/0-original-images/"
path2 = r"/home/jack/Desktop/Imagedata/4-publish-images/"
nim = mknewimage(path1,path2)
nim

img = im
PI = Image.open("/home/jack/Desktop/Imagedata/4-publish-images/00257polarized.jpg")
PI = PI.resize((720,480), Image.NEAREST)

import numpy as np
mask = img
#mask[3:-3, 3:-3] = 1 # white square in black background
im = mask + PI#np.random.randn(10,10) * 0.01 # random image
masked = np.ma.masked_where(mask == 0, mask)

import matplotlib.pyplot as plt
plt.figure()
plt.subplot(1,2,1)
plt.imshow(im, 'gray', interpolation='none')
plt.subplot(1,2,2)
plt.imshow(im, 'gray', interpolation='none')
plt.imshow(masked, 'jet', interpolation='none', alpha=0.7)
plt.show()


import numpy as np
mask = np.zeros((10,10))
mask[3:-3, 3:-3] = 1 # white square in black background
im = mask + np.random.randn(10,10) * 0.01 # random image
masked = np.ma.masked_where(mask == 0, mask)

import matplotlib.pyplot as plt
plt.figure()
plt.subplot(1,2,1)
plt.imshow(im, 'gray', interpolation='none')
plt.subplot(1,2,2)
plt.imshow(im, 'gray', interpolation='none')
plt.imshow(masked, 'jet', interpolation='none', alpha=0.7)
plt.show()


#!/home/jack/miniconda3/envs/cloned_base/bin/python
from PIL import Image, ImageDraw, ImageFont, ImageChops, ImageFilter, ImageEnhance
from tensorflow.python.ops.numpy_ops import np_config
np_config.enable_numpy_behavior()
import random
import os
import numpy as np
from random import randint
import sys
import markovify
import twython
from twython import Twython
import time
import shutil
from randtext import randTXT
import tensorflow as tf
import tensorflow_hub as hub
def prep_content(content):
    PI = Image.open(content)
    PI = PI.resize((720,480), Image.NEAREST)
    CFilename = os.path.basename(content)
    PI.save("preped_images/Content_"+CFilename)
    Content_data="preped_images/Content_"+CFilename
    return Content_data
    
def prep_style(style):
    PI = Image.open(style)
    PI = PI.resize((720,480), Image.NEAREST)
    SFilename = os.path.basename(style)
    PI.save("preped_images/Style_"+SFilename)
    Style_data="preped_images/Style_"+SFilename
    return Style_data    


path = r"/home/jack/Desktop/Imagedata/0-original-images/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
content=(path+base_image)
print("content"+path+base_image)

#content = "/home/jack/Pictures/1022362.jpg"


path = r"/home/jack/Desktop/Imagedata/4-publish-images/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
style=(path+base_image)
print("style"+path+base_image)
#style = "/home/jack/Pictures/1022362.jpg

content_image = load_img(prep_content(content))
style_image = load_img(prep_style(style))
# A node server http-server was started in Directory before the "Models" directory
hub_model = hub.load('http://localhost:8080/Models/magenta_arbitrary-image-stylization-v1-256_2.tar.gz')
#hub_model = hub.load('http://localhost:8080/Models/magenta_arbitrary-image-stylization-v1-256_fp16_transfer_1.tflite')
stylized_image = hub_model(tf.constant(content_image), tf.constant(style_image))[0]
im = tensor_to_image(stylized_image)
timestr = time.strftime("%Y%m%d-%H%M%S")
savefile = "images/"+timestr+".jpg"
im.save(savefile)
#print(im.size)
#im
iml = im.resize((720,480), Image.NEAREST)
iml.save("720x480/temp.jpg")
#iml

im = Image.open("720x480/temp.jpg")
enhancer = ImageEnhance.Sharpness(im)
factor = 1.5
im_s_1 = enhancer.enhance(factor)
im_s_1.save('720x480/Sharpened-temp.jpg');


STR = randTXT()
Hash = ["#AIart #Tensorflow #twitme #Python #100DaysOfCode\n","#tensorflow #styletransfer #PythonGraphics #PIL #PythonImageLibrary\n","#NFTartist #NFTProject #NEARnft #nearNFTs \n","#NFT #NFTs #NFTCommunity #NFTdrop #nftart\n","#CreativeCoding  #AI #genart #p5js #Generative\n","#twitme #Python #100DaysOfCode\n","#Python #100DaysOfCode #PythonBots #codefor30days\n" ]
hashnum = randint(0,len(Hash)-1)
hashs =Hash[0]
# add the hash to STR generated with randTXT()
STR = hashs
STR= STR[:180]
print(STR)
# Open background image and work out centre
x = 720//2
y = 480//2

# The text we want to add
#text = "NFT TwitterBot Project"
text = STR
# Create font
font = ImageFont.truetype('/snap/gnome-3-38-2004/99/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', 15)

#nap=randint(10,400)
#time.sleep(nap)
'''
path = r"/home/jack/Desktop/Imagedata/4-publish-images/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])'''
#filename1='images/result.png'
filename1='720x480/Sharpened-temp.jpg'

bg = Image.open(filename1).convert('RGB')
x = bg.width//2
y = bg.height//2
src_path = filename1
#dst_path = "/home/jack/Desktop/Imagedata/3-resource_images/"
#shutil.move(src_path, dst_path)

# The text we want to add
text=STR[:249]
print("len(text): ",len(text))
# Create font
font = ImageFont.truetype('/snap/gnome-3-38-2004/99/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', 15)

# Create piece of canvas to draw text on and blur
blurred = Image.new('RGBA', bg.size)
draw = ImageDraw.Draw(blurred)
CH = randint(0,1)
if CH == 0:COLor = ["white","black"]
elif CH == 1:COLor = ["black","white"]  
draw.text(xy=(x-10,y+220), text=text, fill=COLor[0], font=font, anchor='mm')
draw.text(xy=(x-11,y+221), text=text, fill=COLor[0], font=font, anchor='mm')
draw.text(xy=(x-12,y+219), text=text, fill=COLor[0], font=font, anchor='mm')
draw.text(xy=(x-10,y+218), text=text, fill=COLor[0], font=font, anchor='mm')
blurred = blurred.filter(ImageFilter.BoxBlur(2))

# Paste soft text onto background
bg.paste(blurred,blurred)

# Draw on sharp text
draw = ImageDraw.Draw(bg)
draw.text(xy=(x-10,y+220), text=text, fill=COLor[1], font=font, anchor='mm')
postage = ["perferations.png","perferations+.png","frames.png","usa-perferations.png","usar-perferations.png","usal-perferations.png"]
Num = randint( 0, len(postage)-1)
BOARDER ="overlays/frame-lite.png"
#BOARDER ="overlays/nouveau-black-frame1.png"
#BOARDER = "overlays/"+postage[Num]
mask=Image.open(BOARDER).convert('RGBA') 
bg.paste(mask, (0,0), mask=mask)
bg.save('images/useresult.png')
#removed keys for privacy reasons
CONSUMER_KEY = 'APIkey()[0]'
CONSUMER_SECRET = 'APIkey()[1]'
ACCESS_KEY = 'APIkey()[2]'
ACCESS_SECRET = 'APIkey()[3]'

twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)
PATH = "images/useresult.png"
timestr = time.strftime("%Y%m%d-%H%M%S")
#print (timestr+".png")

#python program to check if a directory exists
import os
path = "posted"
# Check whether the specified path exists or not
isExist = os.path.exists(path)
if not isExist:
    # Create a new directory because it does not exist
    os.makedirs(path)
    print("The new directory is created!")
shutil.copy(PATH, "posted/"+timestr+".png")
# 1 , 2, 3, 12, 5, 15, 8, 6
#photo = open('/home/jack/Desktop/deep-dream-generator/notebooks/images/'+file_list[rnd]+'.jpg','rb')

photo = open(PATH,'rb')
#photo = open("images/waves1.gif","rb")
#response = twitter.upload_media(media=photo)
#twitter.update_status(status=STR, media_ids=[response['media_id']])
im = Image.open(PATH)

im

def load_img(img_path):
    img = tf.io.read_file(img_path)
    img = tf.image.decode_image(img, channels=3)
    img = tf.image.convert_image_dtype(img, tf.float32)
    img = img[tf.newaxis, :]
    return img


from PIL import Image
im = Image.open(savefile)
print(im.size)
im

style_image

import time

def tensor_to_image(tensor):
    tensor = tensor*255
    tensor = np.array(tensor, dtype=np.uint8)
    if np.ndim(tensor)>3:
        assert tensor.shape[0] == 1
        tensor = tensor[0]
        return Image.fromarray(tensor)
tensor = style_image
im = tensor_to_image(tensor)
timestr = time.strftime("%Y%m%d-%H%M%S")
savefile = "images/"+timestr+".jpg"
print(savefile)
im.save(savefile)

# A node server http-server was started in Directory before the "Models" directory
hub_model = hub.load('http://localhost:8080/Models/magenta_arbitrary-image-stylization-v1-256_2.tar.gz')
#hub_model = hub.load('http://localhost:8080/Models/magenta_arbitrary-image-stylization-v1-256_fp16_transfer_1.tflite')


content_image = load_image('profile.jfif')
style_image = load_image('monet.jpeg')

2. Visualize Output

content_image.shape

TensorShape([1, 200, 200, 3])

plt.imshow(np.squeeze(style_image))
plt.show()



def random_image(path0):
        random_file = random.choice(os.listdir(path0))
        random_file_path = os.path.join(path0, random_file)
        return random_file_path
    
def random_image2(path1):
        random_file = random.choice(os.listdir(path1))
        random_file_path = os.path.join(path1, random_file)
        return random_file_path
    
path0 = "/home/jack/Desktop/Imagedata/0-original-images/"
content=random_image(path0)
print("content"+content)
#content = "/home/jack/Pictures/1022362.jpg"

path1 = "/home/jack/Desktop/Imagedata/4-publish-images/"
style=random_image2(path1)
print("style"+style)
    


#!/home/jack/miniconda3/envs/cloned_base/bin/python
from PIL import Image, ImageDraw, ImageFont, ImageChops, ImageFilter, ImageEnhance
import PIL
from tensorflow.python.ops.numpy_ops import np_config
np_config.enable_numpy_behavior()
import random
import os
import numpy as np
from random import randint
import sys
import markovify
import twython
from twython import Twython
import time
import shutil
from randtext import randTXT
import tensorflow as tf
import tensorflow_hub as hub
import matplotlib.pyplot as plt
def main():
    def tensor_to_image(tensor):
        tensor = tensor*255
        tensor = np.array(tensor, dtype=np.uint8)
        if np.ndim(tensor)>3:
            assert tensor.shape[0] == 1
            tensor = tensor[0]
        return PIL.Image.fromarray(tensor)
    def load_img(path_to_img):
        max_dim = 512
        img = tf.io.read_file(path_to_img)
        img = tf.image.decode_image(img, channels=3)
        img = tf.image.convert_image_dtype(img, tf.float32)

        shape = tf.cast(tf.shape(img)[:-1], tf.float32)
        long_dim = max(shape)
        scale = max_dim / long_dim

        new_shape = tf.cast(shape * scale, tf.int32)

        img = tf.image.resize(img, new_shape)
        img = img[tf.newaxis, :]
        return img
    def imshow(image, title=None):
        if len(image.shape) > 3:
            image = tf.squeeze(image, axis=0)

            plt.imshow(image)
            if title:
                plt.title(title)
    def prep_content(content):
        PI = Image.open(content)
        PI = PI.resize((720,480), Image.NEAREST)
        CFilename = os.path.basename(content)
        PI.save("preped_images/Content_"+CFilename)
        Content_data="preped_images/Content_"+CFilename
        return Content_data
    
    def prep_style(style):
        PI = Image.open(style)
        PI = PI.resize((720,480), Image.NEAREST)
        SFilename = os.path.basename(style)
        PI.save("preped_images/Style_"+SFilename)
        Style_data="preped_images/Style_"+SFilename
        return Style_data    

    
    #find a random image in the folder and return the path
    def random_image(path0):
        random_file = random.choice(os.listdir(path0))
        random_file_path = os.path.join(path0, random_file)
        return random_file_path
    path0 = "/home/jack/Desktop/Imagedata/0-original-images/"
    content=random.choice([x for x in os.listdir(path0) if os.path.isfile(os.path.join(path0, x))])
    #content=random_image(path0)
    print("content"+content)
    #content = "/home/jack/Pictures/1022362.jpg"
    
    def random_image2(path1):
        random_file = random.choice(os.listdir(path1))
        random_file_path = os.path.join(path1, random_file)
        return random_file_path
    path1 = "/home/jack/Desktop/Imagedata/4-publish-images/"
    style=random.choice([x for x in os.listdir(path1) if os.path.isfile(os.path.join(path1, x))])
    #style=random_image2(path1)
    print("style"+style)
    
    #style = "/home/jack/Pictures/1022362.jpg

    content_image = load_img(prep_content(content))
    style_image = load_img(prep_style(style))
    # A node server http-server was started in Directory before the "Models" directory
    hub_model = hub.load('http://localhost:8080/Models/magenta_arbitrary-image-stylization-v1-256_2.tar.gz')
    #hub_model = hub.load('http://localhost:8080/Models/magenta_arbitrary-image-stylization-v1-256_fp16_transfer_1.tflite')
    stylized_image = hub_model(tf.constant(content_image), tf.constant(style_image))[0]
    im = tensor_to_image(stylized_image)
    timestr = time.strftime("%Y%m%d-%H%M%S")
    savefile = "images/"+timestr+".jpg"
    im.save(savefile)
    #print(im.size)
    #im
    iml = im.resize((720,480), Image.NEAREST)
    iml.save("720x480/temp.jpg")
    #iml

    im = Image.open("720x480/temp.jpg")
    enhancer = ImageEnhance.Sharpness(im)
    factor = 1.5
    im_s_1 = enhancer.enhance(factor)
    im_s_1.save('720x480/Sharpened-temp.jpg');


    STR = randTXT()
    Hash = ["#AIart #Tensorflow #twitme #Python #100DaysOfCode\n","#tensorflow #styletransfer #PythonGraphics #PIL #PythonImageLibrary\n","#NFTartist #NFTProject #NEARnft #nearNFTs \n","#NFT #NFTs #NFTCommunity #NFTdrop #nftart\n","#CreativeCoding  #AI #genart #p5js #Generative\n","#twitme #Python #100DaysOfCode\n","#Python #100DaysOfCode #PythonBots #codefor30days\n" ]
    hashnum = randint(0,len(Hash)-1)
    hashs =Hash[0]
    # add the hash to STR generated with randTXT()
    STR = hashs
    STR= STR[:180]
    print(STR)
    # Open background image and work out centre
    x = 720//2
    y = 480//2

    # The text we want to add
    #text = "NFT TwitterBot Project"
    text = STR
    # Create font
    font = ImageFont.truetype('/snap/gnome-3-38-2004/99/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', 15)

    #nap=randint(10,400)
    #time.sleep(nap)
    '''
    path = r"/home/jack/Desktop/Imagedata/4-publish-images/"
    base_image = random.choice([
        x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
        ])'''
    #filename1='images/result.png'
    filename1='720x480/Sharpened-temp.jpg'

    bg = Image.open(filename1).convert('RGB')
    x = bg.width//2
    y = bg.height//2
    src_path = filename1
    #dst_path = "/home/jack/Desktop/Imagedata/3-resource_images/"
    #shutil.move(src_path, dst_path)

    # The text we want to add
    text=STR[:249]
    print("len(text): ",len(text))
    # Create font
    font = ImageFont.truetype('/snap/gnome-3-38-2004/99/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', 15)

    # Create piece of canvas to draw text on and blur
    blurred = Image.new('RGBA', bg.size)
    draw = ImageDraw.Draw(blurred)
    CH = randint(0,1)
    if CH == 0:COLor = ["white","black"]
    elif CH == 1:COLor = ["black","white"]  
    draw.text(xy=(x-10,y+220), text=text, fill=COLor[0], font=font, anchor='mm')
    draw.text(xy=(x-11,y+221), text=text, fill=COLor[0], font=font, anchor='mm')
    draw.text(xy=(x-12,y+219), text=text, fill=COLor[0], font=font, anchor='mm')
    draw.text(xy=(x-10,y+218), text=text, fill=COLor[0], font=font, anchor='mm')
    blurred = blurred.filter(ImageFilter.BoxBlur(2))

    # Paste soft text onto background
    bg.paste(blurred,blurred)

    # Draw on sharp text
    draw = ImageDraw.Draw(bg)
    draw.text(xy=(x-10,y+220), text=text, fill=COLor[1], font=font, anchor='mm')
    postage = ["perferations.png","perferations+.png","frames.png","usa-perferations.png","usar-perferations.png","usal-perferations.png"]
    Num = randint( 0, len(postage)-1)
    BOARDER ="overlays/frame-lite.png"
    #BOARDER ="overlays/nouveau-black-frame1.png"
    #BOARDER = "overlays/"+postage[Num]
    mask=Image.open(BOARDER).convert('RGBA') 
    bg.paste(mask, (0,0), mask=mask)
    bg.save('images/useresult.png')
    #removed keys for privacy reasons
    CONSUMER_KEY = 'APIkey()[0]'
    CONSUMER_SECRET = 'APIkey()[1]'
    ACCESS_KEY = 'APIkey()[2]'
    ACCESS_SECRET = 'APIkey()[3]'

    twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)
    PATH = "images/useresult.png"
    timestr = time.strftime("%Y%m%d-%H%M%S")
    #print (timestr+".png")

    #python program to check if a directory exists
    import os
    path = "posted"
    # Check whether the specified path exists or not
    isExist = os.path.exists(path)
    if not isExist:
        # Create a new directory because it does not exist
        os.makedirs(path)
        print("The new directory is created!")
    shutil.copy(PATH, "posted/"+timestr+".png")
    # 1 , 2, 3, 12, 5, 15, 8, 6
    #photo = open('/home/jack/Desktop/deep-dream-generator/notebooks/images/'+file_list[rnd]+'.jpg','rb')

    photo = open(PATH,'rb')
    #photo = open("images/waves1.gif","rb")
    #response = twitter.upload_media(media=photo)
    #twitter.update_status(status=STR, media_ids=[response['media_id']])
    im = Image.open(PATH)
    im

    #response = twitter.upload_media(media=photo)
    #twitter.update_status(status=STR, media_ids=[response['media_id']])

main()

import os
import random
import dircache

dir = 'posted/'
filename = random.choice(dircache.listdir(dir))
path = os.path.join(dir, filename)
print(path)



%reset -f

!sudo locate colorific/__init__.py

!sudo locate colormath/__init__.py

!pip install colorific

import colorific
help(colorific)

import colormath
help(colormath.color_objects)

!rm ascii_arty.py

%%writefile ascii_arty.py
#!/home/jack/anaconda2/bin
#! /usr/bin/env python2
# Requires: PIL, colormath
#
# Improved algorithm now automatically crops the image and uses much 
# better color matching
 
from PIL import Image, ImageChops
from colormath.color_conversions import convert_color
from colormath.color_objects import LabColor
from colormath.color_objects import sRGBColor as RGBColor
from colormath.color_diff import delta_e_cmc as cmc
import argparse
import sys
import math



ANSI_CODES = (
    '\033[00;30m',     # black
    '\033[00;31m',     # red
    '\033[00;32m',     # green
    '\033[00;33m',     # yellow
    '\033[00;34m',     # blue
    '\033[00;35m',     # magenta
    '\033[00;36m',     # cyan
    '\033[00;37m',     # gray
    '\033[01;30m',   # dark gray
    '\033[01;31m',   # bright red
    '\033[01;32m',   # bright green
    '\033[01;33m',   # bright yellow
    '\033[01;34m',   # bright blue
    '\033[01;35m',   # bright magenta
    '\033[01;36m',   # bright cyan
    '\033[01;37m',   # white
)
ANSI_COLORS = (
    RGBColor(0, 0, 0),          # black
    RGBColor(205, 0, 0),        # red
    RGBColor(0, 205, 0),        # green
    RGBColor(205, 205, 0),      # yellow
    RGBColor(0, 0, 238),        # blue
    RGBColor(205, 0, 205),      # magenta
    RGBColor(0, 205, 205),      # cyan
    RGBColor(229, 229, 229),    # gray
    RGBColor(127, 127, 127),    # dark gray
    RGBColor(255, 0, 0),        # bright red
    RGBColor(0, 255, 0),        # bright green
    RGBColor(255, 255, 0),      # bright yellow
    RGBColor(92, 92, 255),      # bright blue
    RGBColor(255, 0, 255),      # bright magenta
    RGBColor(0, 255, 255),      # bright cyan
    RGBColor(255, 255, 255),    # white
)
ANSI_RESET = '\033[0m'
INFINITY = float('inf')


def closest_ansi_color(color):
    # Look up the closest ANSI color
    color = RGBColor(*color[:3])
    closest_dist = INFINITY
    closest_color_index = 0
    for i, c in enumerate(ANSI_COLORS):
        d = color_distance(c, color)
        if d < closest_dist:
            closest_dist = d
            closest_color_index = i
    return ANSI_CODES[closest_color_index]


def color_distance(c1, c2):
    # return a value representing a relative distance between two RGB
    # color values, weighted for human eye sensitivity
    return c1.delta_e(c2, mode='cmc', pl=1, pc=1)
    # return (math.pow((c2[0] - c1[0]) * 0.30, 2) +
    #         math.pow((c2[1] - c1[1]) * 0.49, 2) +
    #         math.pow((c2[2] - c1[2]) * 0.21, 2))


def convert_image(filename, output_file, fill_char='##'):
    # render an image as ASCII by converting it to RGBA then using the
    # color lookup table to find the closest colors, then filling with 
    # fill_char
    # TODO: use a set of fill characters and choose among them based on
    # color value
    im = Image.open(filename)
    if im.mode != 'RGBA':
        im = im.convert('RGBA')
    # crop the image
    bg = Image.new(im.mode, im.size, im.getpixel((0,0)))
    diff = ImageChops.difference(im, bg)
    diff = ImageChops.add(diff, diff, 2.0, -100)
    bbox = diff.getbbox()
    if bbox:
        im = im.crop(bbox)
    w = im.size[0]
    o = ''
    last_color = None
    for i, p in enumerate(im.getdata()):
        if i % w == 0:
            o += '\n'
        if im.mode == 'RGBA' and p[3] == 0:
            o += ' ' * len(fill_char)
        else:
            c = closest_ansi_color(p)
            if last_color != c:
                o += c
                last_color = c
            o += fill_char
    o += ANSI_RESET + '\n\n'
    if output_file is not sys.stdout:
        output_file = open(output_file, 'w')
    output_file.write(o)
    output_file.close()


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('filename', help='File to convert to ASCII art')
    parser.add_argument('-o', '--output_file', nargs='?', default=sys.stdout,
                        help='Path to the output file, defaults to stdout')
    parser.add_argument('-f', '--fill_char', nargs='?', default='##',
                        help='Character to use for solid pixels in the image')
    args = parser.parse_args()
    convert_image(args.filename, args.output_file, fill_char=args.fill_char)


!ls 

fill_char='##'

convert_image('junk/20170820120735.jpg','junk/output_file.jpg', fill_char)

filename='junk/01.jpg'
    output_file='junk/output_file.jpg'
    fill_char='##'
    convert_image(filename, output_file, fill_char=args.fill_char)
    

convert_image('out_cartoon0022.jpg','output_file.jpg', fill_char='##')    

import colour_science

#!/usr/bin/env python
# -*- coding: utf-8 -*-
colour-science
"""
:math:`\Delta E_{ab}` - Delta E Colour Difference
=================================================

Defines :math:`\Delta E_{ab}` colour difference computation objects:

The following methods are available:

-   :func:`delta_E_CIE1976`
-   :func:`delta_E_CIE1994`
-   :func:`delta_E_CIE2000`
-   :func:`delta_E_CMC`

See Also
--------
`Delta E - Colour Difference IPython Notebook
<http://nbviewer.ipython.org/github/colour-science/colour-ipython/blob/master/notebooks/difference/delta_e.ipynb>`_  # noqa

References
----------
.. [1]  Wikipedia. (n.d.). Color difference. Retrieved August 29, 2014, from
        http://en.wikipedia.org/wiki/Color_difference
"""

from __future__ import division, unicode_literals

import numpy as np

from colour.utilities import CaseInsensitiveMapping

__author__ = 'Colour Developers'
__copyright__ = 'Copyright (C) 2013 - 2014 - Colour Developers'
__license__ = 'New BSD License - http://opensource.org/licenses/BSD-3-Clause'
__maintainer__ = 'Colour Developers'
__email__ = 'colour-science@googlegroups.com'
__status__ = 'Production'

__all__ = ['delta_E_CIE1976',
           'delta_E_CIE1994',
           'delta_E_CIE2000',
           'delta_E_CMC',
           'DELTA_E_METHODS',
           'delta_E']


[docs]
def delta_E_CIE1976(Lab1, Lab2, **kwargs):
    """
    Returns the difference :math:`\Delta E_{ab}` between two given
    *CIE Lab* *array_like* colours using CIE 1976 recommendation.

    Parameters
    ----------
    Lab1 : array_like, (3,)
        *CIE Lab* *array_like* colour 1.
    Lab2 : array_like, (3,)
        *CIE Lab* *array_like* colour 2.
    \*\*kwargs : \*\*, optional
        Unused parameter provided for signature compatibility with other
        :math:`\Delta E_{ab}` computation objects.

    Returns
    -------
    numeric
        Colour difference :math:`\Delta E_{ab}`.

    References
    ----------
    .. [2]  Lindbloom, B. (2003). Delta E (CIE 1976). Retrieved February 24,
            2014, from http://brucelindbloom.com/Eqn_DeltaE_CIE76.html

    Examples
    --------
    >>> Lab1 = np.array([100, 21.57210357, 272.2281935])
    >>> Lab2 = np.array([100, 426.67945353, 72.39590835])
    >>> delta_E_CIE1976(Lab1, Lab2)  # doctest: +ELLIPSIS
    451.7133019...
    """
    return np.linalg.norm(np.array(Lab1) - np.array(Lab2))


[docs]
def delta_E_CIE1994(Lab1, Lab2, textiles=True, **kwargs):
    """
    Returns the difference :math:`\Delta E_{ab}` between two given *CIE Lab*
    *array_like* colours using CIE 1994 recommendation.

    Parameters
    ----------
    Lab1 : array_like, (3,)
        *CIE Lab* *array_like* colour 1.
    Lab2 : array_like, (3,)
        *CIE Lab* *array_like* colour 2.
    textiles : bool, optional
        Application specific weights.
    \*\*kwargs : \*\*, optional
        Unused parameter provided for signature compatibility with other
        :math:`\Delta E_{ab}` computation objects.

    Returns
    -------
    numeric
        Colour difference :math:`\Delta E_{ab}`.

    References
    ----------
    .. [3]  Lindbloom, B. (2011). Delta E (CIE 1994). Retrieved February 24,
            2014, from http://brucelindbloom.com/Eqn_DeltaE_CIE94.html

    Examples
    --------
    >>> Lab1 = np.array([100, 21.57210357, 272.2281935])
    >>> Lab2 = np.array([100, 426.67945353, 72.39590835])
    >>> delta_E_CIE1994(Lab1, Lab2)  # doctest: +ELLIPSIS
    88.3355530...
    >>> delta_E_CIE1994(Lab1, Lab2, textiles=False)  # doctest: +ELLIPSIS
    83.7792255...
    """

    k1 = 0.048 if textiles else 0.045
    k2 = 0.014 if textiles else 0.015
    kL = 2 if textiles else 1
    kC = 1
    kH = 1

    L1, a1, b1 = np.ravel(Lab1)
    L2, a2, b2 = np.ravel(Lab2)

    C1 = np.sqrt(a1 ** 2 + b1 ** 2)
    C2 = np.sqrt(a2 ** 2 + b2 ** 2)

    sL = 1
    sC = 1 + k1 * C1
    sH = 1 + k2 * C1

    delta_L = L1 - L2
    delta_C = C1 - C2
    delta_A = a1 - a2
    delta_B = b1 - b2

    try:
        delta_H = np.sqrt(delta_A ** 2 + delta_B ** 2 - delta_C ** 2)
    except ValueError:
        delta_H = 0.0

    L = (delta_L / (kL * sL)) ** 2
    C = (delta_C / (kC * sC)) ** 2
    H = (delta_H / (kH * sH)) ** 2

    return np.sqrt(L + C + H)


[docs]
def delta_E_CIE2000(Lab1, Lab2, **kwargs):
    """
    Returns the difference :math:`\Delta E_{ab}` between two given *CIE Lab*
    *array_like* colours using CIE 2000 recommendation.

    Parameters
    ----------
    Lab1 : array_like, (3,)
        *CIE Lab* *array_like* colour 1.
    Lab2 : array_like, (3,)
        *CIE Lab* *array_like* colour 2.
    \*\*kwargs : \*\*, optional
        Unused parameter provided for signature compatibility with other
        :math:`\Delta E_{ab}` computation objects.

    Returns
    -------
    numeric
        Colour difference :math:`\Delta E_{ab}`.

    References
    ----------

    .. [4]  Lindbloom, B. (2009). Delta E (CIE 2000). Retrieved February 24,
            2014, from http://brucelindbloom.com/Eqn_DeltaE_CIE2000.html

    Examples
    --------
    >>> Lab1 = np.array([100, 21.57210357, 272.2281935])
    >>> Lab2 = np.array([100, 426.67945353, 72.39590835])
    >>> delta_E_CIE2000(Lab1, Lab2)  # doctest: +ELLIPSIS
    94.0356490...
    """

    L1, a1, b1 = np.ravel(Lab1)
    L2, a2, b2 = np.ravel(Lab2)

    kL = 1
    kC = 1
    kH = 1

    l_bar_prime = 0.5 * (L1 + L2)

    c1 = np.sqrt(a1 * a1 + b1 * b1)
    c2 = np.sqrt(a2 * a2 + b2 * b2)

    c_bar = 0.5 * (c1 + c2)
    c_bar7 = np.power(c_bar, 7)

    g = 0.5 * (1 - np.sqrt(c_bar7 / (c_bar7 + 25 ** 7)))

    a1_prime = a1 * (1 + g)
    a2_prime = a2 * (1 + g)
    c1_prime = np.sqrt(a1_prime * a1_prime + b1 * b1)
    c2_prime = np.sqrt(a2_prime * a2_prime + b2 * b2)
    c_bar_prime = 0.5 * (c1_prime + c2_prime)

    h1_prime = (np.arctan2(b1, a1_prime) * 180) / np.pi
    if h1_prime < 0:
        h1_prime += 360

    h2_prime = (np.arctan2(b2, a2_prime) * 180) / np.pi
    if h2_prime < 0.0:
        h2_prime += 360

    h_bar_prime = (0.5 * (h1_prime + h2_prime + 360)
                   if np.fabs(h1_prime - h2_prime) > 180 else
                   0.5 * (h1_prime + h2_prime))

    t = (1 - 0.17 * np.cos(np.pi * (h_bar_prime - 30) / 180) +
         0.24 * np.cos(np.pi * (2 * h_bar_prime) / 180) +
         0.32 * np.cos(np.pi * (3 * h_bar_prime + 6) / 180) -
         0.20 * np.cos(np.pi * (4 * h_bar_prime - 63) / 180))

    if np.fabs(h2_prime - h1_prime) <= 180:
        delta_h_prime = h2_prime - h1_prime
    else:
        delta_h_prime = (h2_prime - h1_prime + 360
                         if h2_prime <= h1_prime else
                         h2_prime - h1_prime - 360)

    delta_L_prime = L2 - L1
    delta_C_prime = c2_prime - c1_prime
    delta_H_prime = (2 * np.sqrt(c1_prime * c2_prime) *
                     np.sin(np.pi * (0.5 * delta_h_prime) / 180))

    sL = 1 + ((0.015 * (l_bar_prime - 50) * (l_bar_prime - 50)) /
              np.sqrt(20 + (l_bar_prime - 50) * (l_bar_prime - 50)))
    sC = 1 + 0.045 * c_bar_prime
    sH = 1 + 0.015 * c_bar_prime * t

    delta_theta = (30 * np.exp(-((h_bar_prime - 275) / 25) *
                               ((h_bar_prime - 275) / 25)))

    c_bar_prime7 = c_bar_prime ** 7

    rC = np.sqrt(c_bar_prime7 / (c_bar_prime7 + 25 ** 7))
    rT = -2 * rC * np.sin(np.pi * (2 * delta_theta) / 180)

    return np.sqrt(
        (delta_L_prime / (kL * sL)) * (delta_L_prime / (kL * sL)) +
        (delta_C_prime / (kC * sC)) * (delta_C_prime / (kC * sC)) +
        (delta_H_prime / (kH * sH)) * (delta_H_prime / (kH * sH)) +
        (delta_C_prime / (kC * sC)) * (delta_H_prime / (kH * sH)) * rT)


[docs]
def delta_E_CMC(Lab1, Lab2, l=2, c=1):
    """
    Returns the difference :math:`\Delta E_{ab}` between two given *CIE Lab*
    *array_like* colours using *Colour Measurement Committee* recommendation.

    The quasimetric has two parameters: *Lightness* (l) and *chroma* (c),
    allowing the users to weight the difference based on the ratio of l:c.
    Commonly used values are 2:1 for acceptability and 1:1 for the threshold of
    imperceptibility.

    Parameters
    ----------
    Lab1 : array_like, (3,)
        *CIE Lab* *array_like* colour 1.
    Lab2 : array_like, (3,)
        *CIE Lab* *array_like* colour 2.
    l : numeric, optional
        Lightness weighting factor.
    c : numeric, optional
        Chroma weighting factor.

    Returns
    -------
    numeric
        Colour difference :math:`\Delta E_{ab}`.

    References
    ----------
    .. [5]  Lindbloom, B. (2009). Delta E (CMC). Retrieved February 24, 2014,
            from http://brucelindbloom.com/Eqn_DeltaE_CMC.html

    Examples
    --------
    >>> Lab1 = np.array([100, 21.57210357, 272.2281935])
    >>> Lab2 = np.array([100, 426.67945353, 72.39590835])
    >>> delta_E_CMC(Lab1, Lab2)  # doctest: +ELLIPSIS
    172.7047712...
    """

    L1, a1, b1 = np.ravel(Lab1)
    L2, a2, b2 = np.ravel(Lab2)

    c1 = np.sqrt(a1 * a1 + b1 * b1)
    c2 = np.sqrt(a2 * a2 + b2 * b2)
    sl = 0.511 if L1 < 16 else (0.040975 * L1) / (1 + 0.01765 * L1)
    sc = 0.0638 * c1 / (1 + 0.0131 * c1) + 0.638
    h1 = 0 if c1 < 0.000001 else (np.arctan2(b1, a1) * 180) / np.pi

    while h1 < 0:
        h1 += 360

    while h1 >= 360:
        h1 -= 360

    t = (0.56 + np.fabs(0.2 * np.cos((np.pi * (h1 + 168)) / 180))
         if 164 <= h1 <= 345 else
         0.36 + np.fabs(0.4 * np.cos((np.pi * (h1 + 35)) / 180)))
    c4 = c1 * c1 * c1 * c1
    f = np.sqrt(c4 / (c4 + 1900))
    sh = sc * (f * t + 1 - f)

    delta_L = L1 - L2
    delta_C = c1 - c2
    delta_A = a1 - a2
    delta_B = b1 - b2
    delta_H2 = delta_A * delta_A + delta_B * delta_B - delta_C * delta_C

    v1 = delta_L / (l * sl)
    v2 = delta_C / (c * sc)
    v3 = sh

    return np.sqrt(v1 * v1 + v2 * v2 + (delta_H2 / (v3 * v3)))


DELTA_E_METHODS = CaseInsensitiveMapping(
    {'CIE 1976': delta_E_CIE1976,
     'CIE 1994': delta_E_CIE1994,
     'CIE 2000': delta_E_CIE2000,
     'CMC': delta_E_CMC})
"""
Supported *Delta E* computations methods.

DELTA_E_METHODS : CaseInsensitiveMapping
    {'CIE 1976', 'CIE 1994', 'CIE 2000', 'CMC'}

Aliases:

-   'cie1976': 'CIE 1976'
-   'cie1994': 'CIE 1994'
-   'cie2000': 'CIE 2000'
"""
DELTA_E_METHODS['cie1976'] = DELTA_E_METHODS['CIE 1976']
DELTA_E_METHODS['cie1994'] = DELTA_E_METHODS['CIE 1994']
DELTA_E_METHODS['cie2000'] = DELTA_E_METHODS['CIE 2000']


[docs]
def delta_E(Lab1, Lab2, method='CMC', **kwargs):
    """
    Returns the *Lightness* :math:`L^*` using given method.

    Parameters
    ----------
    Lab1 : array_like, (3,)
        *CIE Lab* *array_like* colour 1.
    Lab2 : array_like, (3,)
        *CIE Lab* *array_like* colour 2.
    method : unicode, optional
        {'CMC', 'CIE 1976', 'CIE 1994', 'CIE 2000'}
        Computation method.
    \*\*kwargs : \*\*
        Keywords arguments.

    Returns
    -------
    numeric
        Colour difference :math:`\Delta E_{ab}`.

    Examples
    --------
    >>> Lab1 = np.array([100, 21.57210357, 272.2281935])
    >>> Lab2 = np.array([100, 426.67945353, 72.39590835])
    >>> delta_E(Lab1, Lab2)  # doctest: +ELLIPSIS
    172.7047712...
    >>> delta_E(Lab1, Lab2, method='CIE 1976')  # doctest: +ELLIPSIS
    451.7133019...
    >>> delta_E(Lab1, Lab2, method='CIE 1994')  # doctest: +ELLIPSIS
    88.3355530...
    >>> delta_E(Lab1, Lab2, method='CIE 1994', textiles=False)  # noqa  # doctest: +ELLIPSIS
    83.7792255...
    >>> delta_E(Lab1, Lab2, method='CIE 2000')  # doctest: +ELLIPSIS
    94.0356490...
    """

    return DELTA_E_METHODS.get(method)(Lab1, Lab2, **kwargs)





!ls *.jpg

ascii_arty(doc)



%reset -f

!sudo locate colorific/__init__.py

!sudo locate colormath/__init__.py

import colorific
help(colorific)

!pip install colorific

import colormath
help(colormath.color_objects)

!rm ascii_arty.py

#%%writefile ascii_arty.py
#!/home/jack/anaconda2/bin
#! /usr/bin/env python2
# Requires: PIL, colormath
#
# Improved algorithm now automatically crops the image and uses much 
# better color matching
 
from PIL import Image, ImageChops
from colormath.color_conversions import convert_color
from colormath.color_objects import LabColor
from colormath.color_objects import sRGBColor as RGBColor
from colormath.color_diff import delta_e_cmc as cmc
import argparse
import sys
import math



ANSI_CODES = (
    '\033[00;30m',     # black
    '\033[00;31m',     # red
    '\033[00;32m',     # green
    '\033[00;33m',     # yellow
    '\033[00;34m',     # blue
    '\033[00;35m',     # magenta
    '\033[00;36m',     # cyan
    '\033[00;37m',     # gray
    '\033[01;30m',   # dark gray
    '\033[01;31m',   # bright red
    '\033[01;32m',   # bright green
    '\033[01;33m',   # bright yellow
    '\033[01;34m',   # bright blue
    '\033[01;35m',   # bright magenta
    '\033[01;36m',   # bright cyan
    '\033[01;37m',   # white
)
ANSI_COLORS = (
    RGBColor(0, 0, 0),          # black
    RGBColor(205, 0, 0),        # red
    RGBColor(0, 205, 0),        # green
    RGBColor(205, 205, 0),      # yellow
    RGBColor(0, 0, 238),        # blue
    RGBColor(205, 0, 205),      # magenta
    RGBColor(0, 205, 205),      # cyan
    RGBColor(229, 229, 229),    # gray
    RGBColor(127, 127, 127),    # dark gray
    RGBColor(255, 0, 0),        # bright red
    RGBColor(0, 255, 0),        # bright green
    RGBColor(255, 255, 0),      # bright yellow
    RGBColor(92, 92, 255),      # bright blue
    RGBColor(255, 0, 255),      # bright magenta
    RGBColor(0, 255, 255),      # bright cyan
    RGBColor(255, 255, 255),    # white
)
ANSI_RESET = '\033[0m'
INFINITY = float('inf')


def closest_ansi_color(color):
    # Look up the closest ANSI color
    color = RGBColor(*color[:3])
    closest_dist = INFINITY
    closest_color_index = 0
    for i, c in enumerate(ANSI_COLORS):
        d = color_distance(c, color)
        if d < closest_dist:
            closest_dist = d
            closest_color_index = i
    return ANSI_CODES[closest_color_index]


def color_distance(c1, c2):
    # return a value representing a relative distance between two RGB
    # color values, weighted for human eye sensitivity
    return c1.delta_e(c2, mode='cmc', pl=1, pc=1)
    # return (math.pow((c2[0] - c1[0]) * 0.30, 2) +
    #         math.pow((c2[1] - c1[1]) * 0.49, 2) +
    #         math.pow((c2[2] - c1[2]) * 0.21, 2))


def convert_image(filename, output_file, fill_char='##'):
    # render an image as ASCII by converting it to RGBA then using the
    # color lookup table to find the closest colors, then filling with 
    # fill_char
    # TODO: use a set of fill characters and choose among them based on
    # color value
    im = Image.open(filename)
    if im.mode != 'RGBA':
        im = im.convert('RGBA')
    # crop the image
    bg = Image.new(im.mode, im.size, im.getpixel((0,0)))
    diff = ImageChops.difference(im, bg)
    diff = ImageChops.add(diff, diff, 2.0, -100)
    bbox = diff.getbbox()
    if bbox:
        im = im.crop(bbox)
    w = im.size[0]
    o = ''
    last_color = None
    for i, p in enumerate(im.getdata()):
        if i % w == 0:
            o += '\n'
        if im.mode == 'RGBA' and p[3] == 0:
            o += ' ' * len(fill_char)
        else:
            c = closest_ansi_color(p)
            if last_color != c:
                o += c
                last_color = c
            o += fill_char
    o += ANSI_RESET + '\n\n'
    if output_file is not sys.stdout:
        output_file = open(output_file, 'w')
    output_file.write(o)
    output_file.close()


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('filename', help='File to convert to ASCII art')
    parser.add_argument('-o', '--output_file', nargs='?', default=sys.stdout,
                        help='Path to the output file, defaults to stdout')
    parser.add_argument('-f', '--fill_char', nargs='?', default='##',
                        help='Character to use for solid pixels in the image')
    args = parser.parse_args()
    convert_image(args.filename, args.output_file, fill_char=args.fill_char)


!ls 

!python ascii_arty.py 'junk/20170820120735.jpg', -o 'junk/output_file.jpg' -f '##'

filename='junk/01.jpg'
    output_file='junk/output_file.jpg'
    fill_char='##'
    convert_image(filename, output_file, fill_char=args.fill_char)
    

import ascii_arty
ascii_arty.convert_image('junk/01.jpg', -o 'junk/output_file.jpg', fill_char='##')    

!ls junk/output_file.jpg



%reset -f

!sudo locate colorific/__init__.py

!sudo locate colormath/__init__.py

import colorific
help(colorific)

import colormath
help(colormath.color_objects)

!rm ascii_arty.py

#%%writefile ascii_arty.py
#!/home/jack/anaconda2/bin
#! /usr/bin/env python2
# Requires: PIL, colormath
#
# Improved algorithm now automatically crops the image and uses much 
# better color matching
 
from PIL import Image, ImageChops
from colormath.color_conversions import convert_color
from colormath.color_objects import LabColor
from colormath.color_objects import sRGBColor as RGBColor
from colormath.color_diff import delta_e_cmc as cmc
import argparse
import sys
import math



ANSI_CODES = (
    '\033[00;30m',     # black
    '\033[00;31m',     # red
    '\033[00;32m',     # green
    '\033[00;33m',     # yellow
    '\033[00;34m',     # blue
    '\033[00;35m',     # magenta
    '\033[00;36m',     # cyan
    '\033[00;37m',     # gray
    '\033[01;30m',   # dark gray
    '\033[01;31m',   # bright red
    '\033[01;32m',   # bright green
    '\033[01;33m',   # bright yellow
    '\033[01;34m',   # bright blue
    '\033[01;35m',   # bright magenta
    '\033[01;36m',   # bright cyan
    '\033[01;37m',   # white
)
ANSI_COLORS = (
    RGBColor(0, 0, 0),          # black
    RGBColor(205, 0, 0),        # red
    RGBColor(0, 205, 0),        # green
    RGBColor(205, 205, 0),      # yellow
    RGBColor(0, 0, 238),        # blue
    RGBColor(205, 0, 205),      # magenta
    RGBColor(0, 205, 205),      # cyan
    RGBColor(229, 229, 229),    # gray
    RGBColor(127, 127, 127),    # dark gray
    RGBColor(255, 0, 0),        # bright red
    RGBColor(0, 255, 0),        # bright green
    RGBColor(255, 255, 0),      # bright yellow
    RGBColor(92, 92, 255),      # bright blue
    RGBColor(255, 0, 255),      # bright magenta
    RGBColor(0, 255, 255),      # bright cyan
    RGBColor(255, 255, 255),    # white
)
ANSI_RESET = '\033[0m'
INFINITY = float('inf')


def closest_ansi_color(color):
    # Look up the closest ANSI color
    color = RGBColor(*color[:3])
    closest_dist = INFINITY
    closest_color_index = 0
    for i, c in enumerate(ANSI_COLORS):
        d = color_distance(c, color)
        if d < closest_dist:
            closest_dist = d
            closest_color_index = i
    return ANSI_CODES[closest_color_index]


def color_distance(c1, c2):
    # return a value representing a relative distance between two RGB
    # color values, weighted for human eye sensitivity
    return c1.delta_e(c2, mode='cmc', pl=1, pc=1)
    # return (math.pow((c2[0] - c1[0]) * 0.30, 2) +
    #         math.pow((c2[1] - c1[1]) * 0.49, 2) +
    #         math.pow((c2[2] - c1[2]) * 0.21, 2))


def convert_image(filename, output_file, fill_char='##'):
    # render an image as ASCII by converting it to RGBA then using the
    # color lookup table to find the closest colors, then filling with 
    # fill_char
    # TODO: use a set of fill characters and choose among them based on
    # color value
    im = Image.open(filename)
    if im.mode != 'RGBA':
        im = im.convert('RGBA')
    # crop the image
    bg = Image.new(im.mode, im.size, im.getpixel((0,0)))
    diff = ImageChops.difference(im, bg)
    diff = ImageChops.add(diff, diff, 2.0, -100)
    bbox = diff.getbbox()
    if bbox:
        im = im.crop(bbox)
    w = im.size[0]
    o = ''
    last_color = None
    for i, p in enumerate(im.getdata()):
        if i % w == 0:
            o += '\n'
        if im.mode == 'RGBA' and p[3] == 0:
            o += ' ' * len(fill_char)
        else:
            c = closest_ansi_color(p)
            if last_color != c:
                o += c
                last_color = c
            o += fill_char
    o += ANSI_RESET + '\n\n'
    if output_file is not sys.stdout:
        output_file = open(output_file, 'w')
    output_file.write(o)
    output_file.close()


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('filename', help='File to convert to ASCII art')
    parser.add_argument('-o', '--output_file', nargs='?', default=sys.stdout,
                        help='Path to the output file, defaults to stdout')
    parser.add_argument('-f', '--fill_char', nargs='?', default='##',
                        help='Character to use for solid pixels in the image')
    args = parser.parse_args()
    convert_image(args.filename, args.output_file, fill_char=args.fill_char)


!ls 

!python ascii_arty.py 'junk/20170820120735.jpg', -o 'junk/output_file.jpg' -f '##'

filename='junk/01.jpg'
    output_file='junk/output_file.jpg'
    fill_char='##'
    convert_image(filename, output_file, fill_char=args.fill_char)
    

import ascii_arty
ascii_arty.convert_image('junk/01.jpg', -o 'junk/output_file.jpg', fill_char='##')    

!ls junk/output_file.jpg



import tensorflow as tf

import traceback
import contextlib

# Some helper code to demonstrate the kinds of errors you might encounter.
@contextlib.contextmanager
def assert_raises(error_class):
  try:
    yield
  except error_class as e:
    print('Caught expected exception \n  {}:'.format(error_class))
    traceback.print_exc(limit=2)
  except Exception as e:
    raise e
  else:
    raise Exception('Expected {} to be raised but no error was raised!'.format(
        error_class))

def test_tf_cond(f, *args):
  g = f.get_concrete_function(*args).graph
  if any(node.name == 'cond' for node in g.as_graph_def().node):
    print("{}({}) uses tf.cond.".format(
        f.__name__, ', '.join(map(str, args))))
  else:
    print("{}({}) executes normally.".format(
        f.__name__, ', '.join(map(str, args))))

  print("  result: ",f(*args).numpy())

@tf.function
def dropout(x, training=True):
  if training:
    x = tf.nn.dropout(x, rate=0.5)
  return x

test_tf_cond(dropout, tf.ones([10], dtype=tf.float32), True)

test_tf_cond(dropout, tf.ones([10], dtype=tf.float32), tf.constant(True))

@tf.function
def f(x):
  if x > 0:
    x = x + 1.
    print("Tracing `then` branch")
  else:
    x = x - 1.
    print("Tracing `else` branch")
  return x

f(-1.0).numpy()

f(1.0).numpy()

f(tf.constant(1.0)).numpy()

@tf.function
def f():
  if tf.constant(True):
    x = tf.ones([3, 3])
  return x

# Throws an error because both branches need to define `x`.
with assert_raises(ValueError):
  f()

@tf.function
def f(x, y):
  if bool(x):
    y = y + 1.
    print("Tracing `then` branch")
  else:
    y = y - 1.
    print("Tracing `else` branch")
  return y

f(True, 0).numpy()

f(False, 0).numpy()

with assert_raises(TypeError):
  f(tf.constant(True), 0.0)

def test_dynamically_unrolled(f, *args):
  g = f.get_concrete_function(*args).graph
  if any(node.name == 'while' for node in g.as_graph_def().node):
    print("{}({}) uses tf.while_loop.".format(
        f.__name__, ', '.join(map(str, args))))
  elif any(node.name == 'ReduceDataset' for node in g.as_graph_def().node):
    print("{}({}) uses tf.data.Dataset.reduce.".format(
        f.__name__, ', '.join(map(str, args))))
  else:
    print("{}({}) gets unrolled.".format(
        f.__name__, ', '.join(map(str, args))))


@tf.function
def for_in_range():
  x = 0
  for i in range(5):
    x += i
  return x

test_dynamically_unrolled(for_in_range)

@tf.function
def for_in_tfrange():
  x = tf.constant(0, dtype=tf.int32)
  for i in tf.range(5):
    x += i
  return x

test_dynamically_unrolled(for_in_tfrange)

@tf.function
def for_in_tfdataset():
  x = tf.constant(0, dtype=tf.int64)
  for i in tf.data.Dataset.range(5):
    x += i
  return x

test_dynamically_unrolled(for_in_tfdataset)

@tf.function
def while_py_cond():
  x = 5
  while x > 0:
    x -= 1
  return x

test_dynamically_unrolled(while_py_cond)

@tf.function
def while_tf_cond():
  x = tf.constant(5)
  while x > 0:
    x -= 1
  return x

test_dynamically_unrolled(while_tf_cond)

@tf.function
def while_py_true_py_break(x):
  while True:  # py true
    if x == 0: # py break
      break
    x -= 1
  return x

test_dynamically_unrolled(while_py_true_py_break, 5)

@tf.function
def buggy_while_py_true_tf_break(x):
  while True:   # py true
    if tf.equal(x, 0): # tf break
      break
    x -= 1
  return x

with assert_raises(TypeError):
  test_dynamically_unrolled(buggy_while_py_true_tf_break, 5)

@tf.function
def while_tf_true_tf_break(x):
  while tf.constant(True): # tf true
    if x == 0:  # py break
      break
    x -= 1
  return x

test_dynamically_unrolled(while_tf_true_tf_break, 5)

@tf.function
def buggy_py_for_tf_break():
  x = 0
  for i in range(5):  # py for
    if tf.equal(i, 3): # tf break
      break
    x += i
  return x

with assert_raises(TypeError):
  test_dynamically_unrolled(buggy_py_for_tf_break)

@tf.function
def tf_for_py_break():
  x = 0
  for i in tf.range(5): # tf for
    if i == 3:  # py break
      break
    x += i
  return x

test_dynamically_unrolled(tf_for_py_break)

batch_size = 2
seq_len = 3
feature_size = 4

def rnn_step(inp, state):
  return inp + state

@tf.function
def dynamic_rnn(rnn_step, input_data, initial_state):
  # [batch, time, features] -> [time, batch, features]
  input_data = tf.transpose(input_data, [1, 0, 2])
  max_seq_len = input_data.shape[0]

  states = tf.TensorArray(tf.float32, size=max_seq_len)
  state = initial_state
  for i in tf.range(max_seq_len):
    state = rnn_step(input_data[i], state)
    states = states.write(i, state)
  return tf.transpose(states.stack(), [1, 0, 2])
  
dynamic_rnn(rnn_step,
            tf.random.uniform([batch_size, seq_len, feature_size]),
            tf.zeros([batch_size, feature_size]))

@tf.function
def buggy_loop_var_uninitialized():
  for i in tf.range(3):
    x = i
  return x

with assert_raises(ValueError):
  buggy_loop_var_uninitialized()

@tf.function
def f():
  x = tf.constant(0)
  for i in tf.range(3):
    x = i
  return x

f()

@tf.function
def buggy_loop_type_changes():
  x = tf.constant(0, dtype=tf.float32)
  for i in tf.range(3): # Yields tensors of type tf.int32...
    x = i
  return x

with assert_raises(TypeError):
  buggy_loop_type_changes()

@tf.function
def buggy_concat():
  x = tf.ones([0, 10])
  for i in tf.range(5):
    x = tf.concat([x, tf.ones([1, 10])], axis=0)
  return x

with assert_raises(ValueError):
  buggy_concat()

@tf.function
def concat_with_padding():
  x = tf.zeros([5, 10])
  for i in tf.range(5):
    x = tf.concat([x[:i], tf.ones([1, 10]), tf.zeros([4-i, 10])], axis=0)
    x.set_shape([5, 10])
  return x

concat_with_padding()


!pip install -q deeppavlov

# %load https://raw.githubusercontent.com/deepmipt/DeepPavlov/master/deeppavlov/configs/faq/tfidf_logreg_en_faq.json
{
  "dataset_reader": {
    "class_name": "faq_reader",
    "x_col_name": "Question",
    "y_col_name": "Answer",
    "data_url": "http://files.deeppavlov.ai/faq/school/faq_school_en.csv"
  },
  "dataset_iterator": {
    "class_name": "data_learning_iterator"
  },
  "chainer": {
    "in": "q",
    "in_y": "y",
    "pipe": [
      {
        "class_name": "stream_spacy_tokenizer",
        "in": "q",
        "id": "my_tokenizer",
        "lemmas": true,
        "out": "q_token_lemmas"
      },
      {
        "ref": "my_tokenizer",
        "in": "q_token_lemmas",
        "out": "q_lem"
      },
      {
        "in": [
          "q_lem"
        ],
        "out": [
          "q_vect"
        ],
        "fit_on": [
          "q_lem"
        ],
        "id": "tfidf_vec",
        "class_name": "sklearn_component",
        "save_path": "{MODELS_PATH}/faq/mipt/en_mipt_faq_v4/tfidf.pkl",
        "load_path": "{MODELS_PATH}/faq/mipt/en_mipt_faq_v4/tfidf.pkl",
        "model_class": "sklearn.feature_extraction.text:TfidfVectorizer",
        "infer_method": "transform"
      },
      {
        "id": "answers_vocab",
        "class_name": "simple_vocab",
        "fit_on": [
          "y"
        ],
        "save_path": "{MODELS_PATH}/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict",
        "load_path": "{MODELS_PATH}/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict",
        "in": "y",
        "out": "y_ids"
      },
      {
        "in": "q_vect",
        "fit_on": [
          "q_vect",
          "y_ids"
        ],
        "out": [
          "y_pred_proba"
        ],
        "class_name": "sklearn_component",
        "main": true,
        "save_path": "{MODELS_PATH}/faq/mipt/en_mipt_faq_v4/logreg.pkl",
        "load_path": "{MODELS_PATH}/faq/mipt/en_mipt_faq_v4/logreg.pkl",
        "model_class": "sklearn.linear_model:LogisticRegression",
        "infer_method": "predict_proba",
        "C": 1000,
        "penalty": "l2"
      },
      {
        "in": "y_pred_proba",
        "out": "y_pred_ids",
        "class_name": "proba2labels",
        "max_proba": true
      },
      {
        "in": "y_pred_ids",
        "out": "y_pred_answers",
        "ref": "answers_vocab"
      }
    ],
    "out": [
      "y_pred_answers",
      "y_pred_proba"
    ]
  },
  "train": {
    "evaluation_targets": [],
    "class_name": "fit_trainer"
  },
  "metadata": {
    "variables": {
      "ROOT_PATH": "~/.deeppavlov",
      "DOWNLOADS_PATH": "{ROOT_PATH}/downloads",
      "MODELS_PATH": "{ROOT_PATH}/models"
    },
    "download": [
      {
        "url": "http://files.deeppavlov.ai/faq/mipt/en_mipt_faq_v4.tar.gz",
        "subdir": "{MODELS_PATH}/faq/mipt"
      }
    ]
  }
}


!python -m deeppavlov install tfidf_logreg_en_faq

!python -m deeppavlov interact tfidf_logreg_en_faq -d

from deeppavlov import configs
from deeppavlov.core.common.file import read_json
from deeppavlov.core.commands.infer import build_model

faq = build_model(configs.faq.tfidf_logreg_en_faq, download = True)
a = faq(["I need help"])
a

!python -m deeppavlov train tfidf_logreg_en_faq

%%bash
wget -q http://files.deeppavlov.ai/faq/school/faq_school_en.csv -O faq.csv
echo "What's DeepPavlov?, DeepPavlov is an open-source conversational AI library" >> faq.csv

from deeppavlov import configs, train_model

model_config = read_json(configs.faq.tfidf_logreg_en_faq)
model_config["dataset_reader"]["data_path"] = "/content/faq.csv"
model_config["dataset_reader"]["data_url"] = None
faq = train_model(model_config)
a = faq(["tell me about DeepPavlov"])
a

!pip install -q deeppavlov

# %load https://raw.githubusercontent.com/deepmipt/DeepPavlov/master/deeppavlov/configs/faq/tfidf_logreg_en_faq.json
{
  "dataset_reader": {
    "class_name": "faq_reader",
    "x_col_name": "Question",
    "y_col_name": "Answer",
    "data_url": "http://files.deeppavlov.ai/faq/school/faq_school_en.csv"
  },
  "dataset_iterator": {
    "class_name": "data_learning_iterator"
  },
  "chainer": {
    "in": "q",
    "in_y": "y",
    "pipe": [
      {
        "class_name": "stream_spacy_tokenizer",
        "in": "q",
        "id": "my_tokenizer",
        "lemmas": true,
        "out": "q_token_lemmas"
      },
      {
        "ref": "my_tokenizer",
        "in": "q_token_lemmas",
        "out": "q_lem"
      },
      {
        "in": [
          "q_lem"
        ],
        "out": [
          "q_vect"
        ],
        "fit_on": [
          "q_lem"
        ],
        "id": "tfidf_vec",
        "class_name": "sklearn_component",
        "save_path": "{MODELS_PATH}/faq/mipt/en_mipt_faq_v4/tfidf.pkl",
        "load_path": "{MODELS_PATH}/faq/mipt/en_mipt_faq_v4/tfidf.pkl",
        "model_class": "sklearn.feature_extraction.text:TfidfVectorizer",
        "infer_method": "transform"
      },
      {
        "id": "answers_vocab",
        "class_name": "simple_vocab",
        "fit_on": [
          "y"
        ],
        "save_path": "{MODELS_PATH}/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict",
        "load_path": "{MODELS_PATH}/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict",
        "in": "y",
        "out": "y_ids"
      },
      {
        "in": "q_vect",
        "fit_on": [
          "q_vect",
          "y_ids"
        ],
        "out": [
          "y_pred_proba"
        ],
        "class_name": "sklearn_component",
        "main": true,
        "save_path": "{MODELS_PATH}/faq/mipt/en_mipt_faq_v4/logreg.pkl",
        "load_path": "{MODELS_PATH}/faq/mipt/en_mipt_faq_v4/logreg.pkl",
        "model_class": "sklearn.linear_model:LogisticRegression",
        "infer_method": "predict_proba",
        "C": 1000,
        "penalty": "l2"
      },
      {
        "in": "y_pred_proba",
        "out": "y_pred_ids",
        "class_name": "proba2labels",
        "max_proba": true
      },
      {
        "in": "y_pred_ids",
        "out": "y_pred_answers",
        "ref": "answers_vocab"
      }
    ],
    "out": [
      "y_pred_answers",
      "y_pred_proba"
    ]
  },
  "train": {
    "evaluation_targets": [],
    "class_name": "fit_trainer"
  },
  "metadata": {
    "variables": {
      "ROOT_PATH": "~/.deeppavlov",
      "DOWNLOADS_PATH": "{ROOT_PATH}/downloads",
      "MODELS_PATH": "{ROOT_PATH}/models"
    },
    "download": [
      {
        "url": "http://files.deeppavlov.ai/faq/mipt/en_mipt_faq_v4.tar.gz",
        "subdir": "{MODELS_PATH}/faq/mipt"
      }
    ]
  }
}


!python -m deeppavlov install tfidf_logreg_en_faq

!python -m deeppavlov interact tfidf_logreg_en_faq -d

from deeppavlov import configs
from deeppavlov.core.common.file import read_json
from deeppavlov.core.commands.infer import build_model

faq = build_model(configs.faq.tfidf_logreg_en_faq, download = True)
a = faq(["I need help"])
a

!python -m deeppavlov train tfidf_logreg_en_faq

!ls

%%bash
wget -q http://files.deeppavlov.ai/faq/school/faq_school_en.csv -O faq.csv
echo "What's DeepPavlov?, DeepPavlov is an open-source conversational AI library" >> faq.csv

from deeppavlov import configs, train_model

model_config = read_json(configs.faq.tfidf_logreg_en_faq)
model_config["dataset_reader"]["data_path"] = "faq.csv"
model_config["dataset_reader"]["data_url"] = None
faq = train_model(model_config)
a = faq(["tell me about DeepPavlov"])
a

a = faq(["What if I fail an exam?"])
a

!ls

# %load faq.csv
Question,Answer
What is the preparatory course?,"The preparatory course is a special educational program lasting one academic year  that is, between seven and 10 months. Students taking this course study Russian, mathematics, and physics. The course ends with an exam, and the passing students receive a certificate of completion."
I am interested in the preparatory course.,"The preparatory course is a special educational program lasting one academic year  that is, between seven and 10 months. Students taking this course study Russian, mathematics, and physics. The course ends with an exam, and the passing students receive a certificate of completion."
Do you have a preparatory course?,"The preparatory course is a special educational program lasting one academic year  that is, between seven and 10 months. Students taking this course study Russian, mathematics, and physics. The course ends with an exam, and the passing students receive a certificate of completion."
What is an invitation letter?,An invitation is an official document prepared by the Ministry of Internal Affairs of the Russian Federation. It confirms that the student to whom the invitation is addressed has been admitted to the university. The invitation contains the students passport data and specifies the full designation of the university. This document needs to be submitted to the Russian Embassy in order to receive a visa. The internal affairs ministry usually issues the invitation letter within 45 days.
How can I get a visa from the Russian Embassy?,An invitation is an official document prepared by the Ministry of Internal Affairs of the Russian Federation. It confirms that the student to whom the invitation is addressed has been admitted to the university. The invitation contains the students passport data and specifies the full designation of the university. This document needs to be submitted to the Russian Embassy in order to receive a visa. The internal affairs ministry usually issues the invitation letter within 45 days.
How long does it take to issue an invitation letter?,An invitation is an official document prepared by the Ministry of Internal Affairs of the Russian Federation. It confirms that the student to whom the invitation is addressed has been admitted to the university. The invitation contains the students passport data and specifies the full designation of the university. This document needs to be submitted to the Russian Embassy in order to receive a visa. The internal affairs ministry usually issues the invitation letter within 45 days.
Where should I submit the invitation letter?,An invitation is an official document prepared by the Ministry of Internal Affairs of the Russian Federation. It confirms that the student to whom the invitation is addressed has been admitted to the university. The invitation contains the students passport data and specifies the full designation of the university. This document needs to be submitted to the Russian Embassy in order to receive a visa. The internal affairs ministry usually issues the invitation letter within 45 days.
What does registration mean?,"Registration grants a foreign citizen the legal right to stay on the territory of Russia. It is usually provided for a period of one year and needs to be renewed annually. To prolong your registration, submit an application about three weeks before it expires. Upon arrival at the university, a student needs to register at the International Department of MIPT within three days, including the day of arrival. The registration stamp is put on the migration card. It is recommended that the passport be renewed before a trip to Russia for the full period of study."
Where can I get registration?,"Registration grants a foreign citizen the legal right to stay on the territory of Russia. It is usually provided for a period of one year and needs to be renewed annually. To prolong your registration, submit an application about three weeks before it expires. Upon arrival at the university, a student needs to register at the International Department of MIPT within three days, including the day of arrival. The registration stamp is put on the migration card. It is recommended that the passport be renewed before a trip to Russia for the full period of study."
For how long can I get registration?,"Registration grants a foreign citizen the legal right to stay on the territory of Russia. It is usually provided for a period of one year and needs to be renewed annually. To prolong your registration, submit an application about three weeks before it expires. Upon arrival at the university, a student needs to register at the International Department of MIPT within three days, including the day of arrival. The registration stamp is put on the migration card. It is recommended that the passport be renewed before a trip to Russia for the full period of study."
How to prolong registration?,"Registration grants a foreign citizen the legal right to stay on the territory of Russia. It is usually provided for a period of one year and needs to be renewed annually. To prolong your registration, submit an application about three weeks before it expires. Upon arrival at the university, a student needs to register at the International Department of MIPT within three days, including the day of arrival. The registration stamp is put on the migration card. It is recommended that the passport be renewed before a trip to Russia for the full period of study."
Is it possible to study and work at the same time?,"Students at Russian universities are required to attend all lectures as only the knowledge gained during classroom instruction enables one to become a skilled and knowledgeable professional. This means that side job opportunities are limited to working after classes, on weekends, or during vacations. However, even that should probably be reserved for when you have gotten to know the country and the language better. Usually, it is during the junior year that getting a job really becomes an option, but only if you study well and attend all mandatory classes."
Do you permit work during studies?,"Students at Russian universities are required to attend all lectures as only the knowledge gained during classroom instruction enables one to become a skilled and knowledgeable professional. This means that side job opportunities are limited to working after classes, on weekends, or during vacations. However, even that should probably be reserved for when you have gotten to know the country and the language better. Usually, it is during the junior year that getting a job really becomes an option, but only if you study well and attend all mandatory classes."
Can I combine study and work?,"Students at Russian universities are required to attend all lectures as only the knowledge gained during classroom instruction enables one to become a skilled and knowledgeable professional. This means that side job opportunities are limited to working after classes, on weekends, or during vacations. However, even that should probably be reserved for when you have gotten to know the country and the language better. Usually, it is during the junior year that getting a job really becomes an option, but only if you study well and attend all mandatory classes."
Do I have to attend all lectures?,"Students at Russian universities are required to attend all lectures as only the knowledge gained during classroom instruction enables one to become a skilled and knowledgeable professional. This means that side job opportunities are limited to working after classes, on weekends, or during vacations. However, even that should probably be reserved for when you have gotten to know the country and the language better. Usually, it is during the junior year that getting a job really becomes an option, but only if you study well and attend all mandatory classes."
How long does the academic year last?,"The academic year lasts 10 months  from Sept. 1 to June 30  and consists of two semesters. The first semester begins Sept. 1 and ends Jan. 25, and the second is between Feb. 9 and June 30. Between the semesters, the students are on vacations. The brief winter break lasts two weeks, from Jan. 25 to Feb. 9, and the summer vacations are two months long, from July 1 to Aug. 30. During that time, some students stay in Russia, while others go back home to spend time with their families."
Where can I find the academic calendar?,"The academic year lasts 10 months  from Sept. 1 to June 30  and consists of two semesters. The first semester begins Sept. 1 and ends Jan. 25, and the second is between Feb. 9 and June 30. Between the semesters, the students are on vacations. The brief winter break lasts two weeks, from Jan. 25 to Feb. 9, and the summer vacations are two months long, from July 1 to Aug. 30. During that time, some students stay in Russia, while others go back home to spend time with their families."
Do you have a vacation between semesters?,"The academic year lasts 10 months  from Sept. 1 to June 30  and consists of two semesters. The first semester begins Sept. 1 and ends Jan. 25, and the second is between Feb. 9 and June 30. Between the semesters, the students are on vacations. The brief winter break lasts two weeks, from Jan. 25 to Feb. 9, and the summer vacations are two months long, from July 1 to Aug. 30. During that time, some students stay in Russia, while others go back home to spend time with their families."
How many semesters are there?,"The academic year lasts 10 months  from Sept. 1 to June 30  and consists of two semesters. The first semester begins Sept. 1 and ends Jan. 25, and the second is between Feb. 9 and June 30. Between the semesters, the students are on vacations. The brief winter break lasts two weeks, from Jan. 25 to Feb. 9, and the summer vacations are two months long, from July 1 to Aug. 30. During that time, some students stay in Russia, while others go back home to spend time with their families."
How long does the summer vacation last?,"The academic year lasts 10 months  from Sept. 1 to June 30  and consists of two semesters. The first semester begins Sept. 1 and ends Jan. 25, and the second is between Feb. 9 and June 30. Between the semesters, the students are on vacations. The brief winter break lasts two weeks, from Jan. 25 to Feb. 9, and the summer vacations are two months long, from July 1 to Aug. 30. During that time, some students stay in Russia, while others go back home to spend time with their families."
What documents are required for admission?,"The papers you need are: passport, documents certifying prior education (with transcripts), medical certificate confirming your good health. The submitted documents have to be translated into Russian."
Should I translate the submitted documents into Russian?,"The papers you need are: passport, documents certifying prior education (with transcripts), medical certificate confirming your good health. The submitted documents have to be translated into Russian."
Do I need to attach a transcript of prior education to the submitted documents?,"The papers you need are: passport, documents certifying prior education (with transcripts), medical certificate confirming your good health. The submitted documents have to be translated into Russian."
What are the tuition fees?,"A program taught in Russian will cost you 250,000 rubles per year. The fees on English-taught programs are higher, at 400,000 rubles per year."
How much should I pay for English-taught programs?,"A program taught in Russian will cost you 250,000 rubles per year. The fees on English-taught programs are higher, at 400,000 rubles per year."
How expensive is it to study in Russian?,"A program taught in Russian will cost you 250,000 rubles per year. The fees on English-taught programs are higher, at 400,000 rubles per year."
Should I insure my life?,"Life and health insurance are obligatory for any foreign citizen arriving in Russia to study. The cost of life and health insurance is 8,200 rubles per year. A student needs to carry the insurance policy specifying the phone number of the insurance company and the emergency health service at all times. All Russian universities have medical offices for first aid and general medical care."
What if I need first aid or general medical care?,"All Russian universities have medical offices for first aid and general medical care."
Whats the cost of life insurance?,"Life and health insurance are obligatory for any foreign citizen arriving in Russia to study. The cost of life and health insurance is 8,200 rubles per year. A student needs to carry the insurance policy specifying the phone number of the insurance company and the emergency health service at all times. All Russian universities have medical offices for first aid and general medical care."
Do you have a medical office in the university?,"All Russian universities have medical offices for first aid and general medical care."
Is life insurance obligatory?,"Life and health insurance are obligatory for any foreign citizen arriving in Russia to study. The cost of life and health insurance is 8,200 rubles per year. A student needs to carry the insurance policy specifying the phone number of the insurance company and the emergency health service at all times. All Russian universities have medical offices for first aid and general medical care."
In which cases can a student be expelled from the university?,"You can be expelled from the university: of your own free will, for health reasons, for poor academic progress. In the latter case, the grounds for expelling a student are: not passing the exams in multiple subjects in the allotted time at the end of a semester, repeatedly failing an exam or not turning up for it in the designated time, failing an exam in front of the board of examiners, which usually convenes after three failed attempts, violating rules of conduct or other regulations."
How many failing attempts are permitted on exams?,"You can be expelled from the university: of your own free will, for health reasons, for poor academic progress. In the latter case, the grounds for expelling a student are: not passing the exams in multiple subjects in the allotted time at the end of a semester, repeatedly failing an exam or not turning up for it in the designated time, failing an exam in front of the board of examiners, which usually convenes after three failed attempts, violating rules of conduct or other regulations."
How to get a bank card?,Visit the social service on the second floor of the building housing the dining hall. The social service is next to local internal affairs office.
Where can I get a bank card?,Visit the social service on the second floor of the building housing the dining hall. The social service is next to local internal affairs office.
How to get a social card?,"To issue a social card, you need to visit a multifunctional center in Moscow. Fill in the application provided at the multifunctional center. You need to have a notarized copy of your passport and your student ID with you. The latter refers to the credential you use daily to gain access to university buildings."
Where can I get a social card?,"To issue a social card, you need to visit a multifunctional center in Moscow. Fill in the application provided at the multifunctional center. You need to have a notarized copy of your passport and your student ID with you. The latter refers to the credential you use daily to gain access to university buildings."
Do I need a social card?,"To issue a social card, you need to visit a multifunctional center in Moscow. Fill in the application provided at the multifunctional center. You need to have a notarized copy of your passport and your student ID with you. The latter refers to the credential you use daily to gain access to university buildings."
What if I have a problem or other questions?,"If you have any further inquiries, you can address them to the International Students Office, which is located in the Auditorium Building, Room 315. The phone number is (7-495) 408-7043."
I need assistance.,"If you have any further inquiries, you can address them to the International Students Office, which is located in the Auditorium Building, Room 315. The phone number is (7-495) 408-7043."
I need help.,"If you have any further inquiries, you can address them to the International Students Office, which is located in the Auditorium Building, Room 315. The phone number is (7-495) 408-7043."
Can you help me?,"If you have any further inquiries, you can address them to the International Students Office, which is located in the Auditorium Building, Room 315. The phone number is (7-495) 408-7043."
What's DeepPavlov?, DeepPavlov is an open-source conversational AI library


!ls chatterbot-corpus/chatterbot_corpus/data/english

# Title_Maker 
# -*- coding: utf-8 -*-
from chatterbot import ChatBot
import logging

# Comment out the following line to disable verbose logging
logging.basicConfig(level=logging.INFO)

def coptitle(coptit):
    copt = open(coptit+".corpus.json","w")
    copbrac ="{"
    copsp = "\n    \""
    copclo = "\": ["
    copt.write(copbrac+copsp+coptit+copclo)
    copt.close()
coptit = raw_input('title')
coptitle(coptit)
       

# Copra_Maker
# -*- coding: utf-8 -*-
from chatterbot import ChatBot

import logging

# Comment out the following line to disable verbose logging
logging.basicConfig(level=logging.INFO)

speak = raw_input('speak')
respond = raw_input('respond')
space = "            \""
txtstart = "        ["
txtspace = "            "
txtend = "        ],"

def copraIn():

    cop = open("tagalog.corpus.json","a")
    #cop.write("\n"+ txspace + "\""+txtstart + speak + "\"\n" + txspace + "\""+respond+"\"" + "\n" + txtend)
    cop.write("\n"+txtstart+"\n"+space+speak+"\""+txtspace+"\n"+space+respond+"\"\n"+txtend)
    cop.close()

    

copraIn()

%%writefile tagalog.corpus.json
{
    "tagalog": [
        [
            "Good evening!",            
            "Magandang Gabi!"
        ],
        [
            "How are you?",            
            "Mabuti naman,Salamat!"
        ],
        [
            "Mabuti naman,Salamat!",            
            "At ikaw? "
        ],
        [
            "How are you",            
            "I'm fine, thanks! And you?"
        ],
        [
            "How are you?",            
            "Kumusta?"
        ],
        [
            "How are you?",            
            "Mabuti naman,Salamat!"
        ],
        [
            "Mabuti naman,Salamat!",            
            "At ikaw? "
        ],
        [
            "Hey! Friend!",            
            "Kaibigan! In Tagalog"
        ],
        [
            "Anong bago?",            
            "What's new? Wala naman."
        ],
        [
            "See you later!",            
            "See you later! is Sa muling pagkikita!"
        ],
        [
            "Akoy nawawala",            
            "You are lost - Akoy nawawala"
        ],
        [
            "How much is this?",            
            "Magkano ito? means How much is this?"
        ],
        [
            "Excuse me!",            
            "Makikiraan po!"
        ],
        [
            "Makikiraan po!",            
            "Excuse me! ( to pass by) Makikiraan po!"
        ],
        [
            "Come with me!",            
            "Sumama ka sa akin!"
        ],
        [
            "One moment please!",            
            "Isang Saglit lang po."
        ],
        [
            "Go straight! then turn left/ right!",            
            "Diretso lang, tapos kaliwa/kanan!"
        ],
        [
            "Where is the bathroom",            
            "Nasaan ang palikuran - Where is the bathroom"
        ],
        [
            "Can I help you? ",            
            "Pwede ba kitang tulungan?"
        ],
        [
            "See you later!",            
            "Sa muling pagkikita! - See you later!"
        ],
        [
            "how do I say just a little in Tagalog.",            
            "Kaunti lang. Means just a little"
        ],
        [
            "Happy birthday!",            
            "Maligayang Kaarawan! Happy Birthday in Tagalog"
        ],
        [
            "Good night and sweet dreams!",            
            "Gandang Gabi!"
        ],
        [
            "No Problem!",            
            "Walang Problema.."
        ],
        [
            "Pwedeng pakihinaan ang iyong pagsasalita?",            
            "Can You Speak Slowly?"
        ],
        [
            "I do not understand.",            
            "Pwedeng pakihinaan ang iyong pagsasalita?"
        ],
        [
            "How do I say, I Have No Idea.",            
            "Wala akong ideya."
        ],
        [
            "how do I say I Don't Know!",            
            "Hindi ko alam."
        ],
        [
            "How are you ?",            
            "Mabuti!"
        ],
        [
            "Gusto mo ba dito?",            
            "Ang Pilipinas ay magandang bansa."
        ],
        [
            "Gusto ko ang Tagalog.",            
            "I like Tagalog also."
        ],
        [
            "How old are you?",            
            "I am not very old ilang taon ka na?"
        ]
    ]
}

# Train based on the english corpus
chatbot.train("chatterbot.corpus.english")

# Train based on english greetings corpus
chatbot.train("chatterbot.corpus.english.tagalog")

# Train based on the english conversations corpus
chatbot.train("chatterbot.corpus.english.conversations")


from chatterbot import ChatBot

chatbot = ChatBot(
    'MonkMonk',
    trainer='chatterbot.trainers.ChatterBotCorpusTrainer'
)

# Train based on the english corpus
#chatbot.train("chatterbot.corpus.english")
#chatbot.train("chatterbot.corpus.english.greetings",
chatbot.train("chatterbot.new-stuff")    
# Get a response to an input statement
chatbot.get_response("Well, Mr. Dudah, How are you ?")



from chatterbot import ChatBot

chatbot = ChatBot(
    'MonkMonk',
    trainer='chatterbot.trainers.ChatterBotCorpusTrainer')

    # Train based on the english corpus
    #chatbot.train("chatterbot.corpus.english")
chatbot.train("chatterbot.corpus.english.greetings")
    # Get a response to an input statement
while True:
    try:
        bot_input = chatbot.get_response(None)

    # Press ctrl-c or ctrl-d on the keyboard to exit
    except (KeyboardInterrupt, EOFError, SystemExit):
        break


# %load chatterbot-corpus/chatterbot_corpus/corpus.py
import os


class Corpus(object):

    def __init__(self):
        current_directory = os.path.dirname(os.path.abspath(__file__))
        self.data_directory = os.path.join(current_directory, 'data')

    def get_file_path(self, dotted_path, extension='json'):
        """
        Reads a dotted file path and returns the file path.
        """

        # If the operating system's file path seperator character is in the string
        if os.sep in dotted_path or '/' in dotted_path:
            # Assume the path is a valid file path
            return dotted_path

        parts = dotted_path.split('.')
        if parts[0] == 'chatterbot':
            parts.pop(0)
            parts[0] = self.data_directory

        corpus_path = os.path.join(*parts)

        if os.path.exists(corpus_path + '.{}'.format(extension)):
            corpus_path += '.{}'.format(extension)

        return corpus_path

    def read_corpus(self, file_name):
        """
        Read and return the data from a corpus json file.
        """
        import json
        import io

        with io.open(file_name, encoding='utf-8') as data_file:
            data = json.load(data_file)
        return data

    def list_corpus_files(self, dotted_path):
        """
        Return a list of file paths to each data file in
        the specified corpus.
        """
        corpus_path = self.get_file_path(dotted_path, extension='corpus.json')
        paths = []

        if os.path.isdir(corpus_path):
            for dirname, dirnames, filenames in os.walk(corpus_path):
                for datafile in filenames:
                    if datafile.endswith('corpus.json'):
                        paths.append(os.path.join(dirname, datafile))
        else:
            paths.append(corpus_path)

        paths.sort()
        return paths

    def load_corpus(self, dotted_path):
        """
        Return the data contained within a specified corpus.
        """
        data_file_paths = self.list_corpus_files(dotted_path)

        corpora = []

        for file_path in data_file_paths:
            corpus = self.read_corpus(file_path)

            for key in list(corpus.keys()):
                corpora.append(corpus[key])

        return corpora


!ls chatterbot-corpus/chatterbot_corpus/data/english

# Title_Maker 
def coptitle(coptit):
    copt = open("chatterbot-corpus/chatterbot_corpus/data/english/"+ coptit + ".corpus.json","w")
    copbrac ="{"
    copsp = "\n    \""
    copclo = "\": ["
    copt.write(copbrac+copsp+coptit+copclo)
    copt.close()
coptit = raw_input('title')
coptitle(coptit)
       

!rm chatterbot-corpus/chatterbot_corpus/data/english/  chitcht.corpus.json	

!ls chatterbot-corpus/chatterbot_corpus/data/english/

!ls chatterbot-corpus/chatterbot_corpus/data/english/coptit+.corpus.json

# %load chatterbot-corpus/chatterbot_corpus/data/english/chitchat.corpus.json
{
    "chitchat": [
        [
            "Hey, Dude, What you want ?"            
            "I want to know why you call me Dude ?"
        ],

# Copra_Maker
# Fillin the name of the file you just created
speak = raw_input('speak')
respond = raw_input('respond')
space = "            \""
txtstart = "        ["
txtspace = "            "
txtend = "        ],"

def copraIn():

   cop = open("chatterbot-corpus/chatterbot_corpus/data/english/chitchat.corpus.json","a")
   #cop.write("\n"+ txspace + "\""+txtstart + speak + "\"\n" + txspace + "\""+respond+"\"" + "\n" + txtend)
   cop.write("\n"+txtstart+"\n"+space+speak+"\""+txtspace+"\n"+space+respond+"\"\n"+txtend)
   cop.close()


copraIn()

# Train based on the english corpus
chatbot.train("chatterbot.corpus.english")

# Train based on english greetings corpus
chatbot.train("chatterbot.corpus.english.greetings")

# Train based on the english conversations corpus
chatbot.train("chatterbot.corpus.english.conversations")


from chatterbot import ChatBot

chatbot = ChatBot(
    'MonkMonk',
    trainer='chatterbot.trainers.ChatterBotCorpusTrainer'
)

# Train based on the english corpus
#chatbot.train("chatterbot.corpus.english")
chatbot.train("chatterbot.corpus.english")
# Get a response to an input statement
while True:
    try:
        bot_input = bot.get_response(None)

    # Press ctrl-c or ctrl-d on the keyboard to exit
    except (KeyboardInterrupt, EOFError, SystemExit):
        break


# %load chatterbot-corpus/chatterbot_corpus/corpus.py
import os


class Corpus(object):

    def __init__(self):
        current_directory = os.path.dirname(os.path.abspath(__file__))
        self.data_directory = os.path.join(current_directory, 'data')

    def get_file_path(self, dotted_path, extension='json'):
        """
        Reads a dotted file path and returns the file path.
        """

        # If the operating system's file path seperator character is in the string
        if os.sep in dotted_path or '/' in dotted_path:
            # Assume the path is a valid file path
            return dotted_path

        parts = dotted_path.split('.')
        if parts[0] == 'chatterbot':
            parts.pop(0)
            parts[0] = self.data_directory

        corpus_path = os.path.join(*parts)

        if os.path.exists(corpus_path + '.{}'.format(extension)):
            corpus_path += '.{}'.format(extension)

        return corpus_path

    def read_corpus(self, file_name):
        """
        Read and return the data from a corpus json file.
        """
        import json
        import io

        with io.open(file_name, encoding='utf-8') as data_file:
            data = json.load(data_file)
        return data

    def list_corpus_files(self, dotted_path):
        """
        Return a list of file paths to each data file in
        the specified corpus.
        """
        corpus_path = self.get_file_path(dotted_path, extension='corpus.json')
        paths = []

        if os.path.isdir(corpus_path):
            for dirname, dirnames, filenames in os.walk(corpus_path):
                for datafile in filenames:
                    if datafile.endswith('corpus.json'):
                        paths.append(os.path.join(dirname, datafile))
        else:
            paths.append(corpus_path)

        paths.sort()
        return paths

    def load_corpus(self, dotted_path):
        """
        Return the data contained within a specified corpus.
        """
        data_file_paths = self.list_corpus_files(dotted_path)

        corpora = []

        for file_path in data_file_paths:
            corpus = self.read_corpus(file_path)

            for key in list(corpus.keys()):
                corpora.append(corpus[key])

        return corpora


import json
L = input("Which file: ")
print(L)
#def savjson(data):
datain = open("aa"+L+"json.json","w")
    
datain.write("{\n \"conversations\": \n[\n")
def convert() :
    count = 0
    #ALL = []
    f = open("/home/jack/Desktop/PAV/opensubtitles/raw/lines/lines-aa"+L+"", "r").readlines()
    for line in f:
        line = line.replace("\n","")
        line =line.replace("\"","'")
        count=count+1
        newline =[]
        txt = "[\""
        if(count % 2 != 0):
            newline.append(""+line +"")
            txt2 = txt+line
        if(count % 2 == 0):
            newline.append(""+line +"")
            txt3 = txt2 +"\",\n\""+ line +"\"],\n"
            if count<5000:datain.write(txt3)
    return #print("--\n",ALL)

convert() 
datain.write("]}")
datain.close() 
file = "aa"+L+"json.json"
print(file)


#You could parse it as YAML (whose in-line syntax is a more permissive superset of JSON):

import yaml
data = yaml.load(open("aaxjson.json"))

#then to get valid JSON back you can dump the object back out:

import json
#json.dumps(data)
with open('new_data.json', 'w') as outfile:
    outfile.write(str(data))


!cp AWK /usr/local/bin

import shlex, subprocess
command_line = input()
args = shlex.split(command_line)
# awk 'NR>2{print a;} {a=b; b=$0} END{sub(/,$/, "", a); print a;print b;}'  aaujson.json > aauCjson.json
# awk 'NR>2{print a;} {a=b; b=$0} END{sub(/,$/, "", a); print a;print b;}'  aaujson.json>aauCjson.json
print(args)
#
p = subprocess.Popen(args) # Success!

!AWK aawjson.json


!ls C+*

%%writefile AWK
awk 'NR>2{print a;} {a=b; b=$0} END{sub(/,$/, "", a); print a;print b;}'  $1 > C+$1

!chmod +x AWK

!./AWK aavjson.json

!awk 'NR>2{print a;} {a=b; b=$0} END{sub(/,$/, "", a); print a;print b;}'  aaujson.json

p = subprocess.Popen(args)


import subprocess
!awk 'NR>2{print a;} {a=b; b=$0} END{sub(/,$/, "", a); print a;print b;}'  aaqjson.json > aaqCjson.json
script = "\'awk 'NR>2{print a;} {a=b; b=$0} END{sub(/,$/, \"\", a); print a;print b;}'  aatjson.json" #> aatCjson.json
print(script)
#subprocess.call(['bash','awk \'NR>2{print a;} {a=b; b=$0} END{sub(/,$/, \"\", a); print a;print b;}\'  aarjson.json'])



import subprocess
p = subprocess.Popen(args)
p

!awk 'NR>2{print a;} {a=b; b=$0} END{sub(/,$/, "", a); print a;print b;}'  aaojson.json > aaoCjson.json

import json

#def savjson(data):
datain = open("aalson.json","w")
    
datain.write("{\n \"conversations\": \n[\n")
def convert() :
    count = 0
    #ALL = []
    f = open("/home/jack/Desktop/PAV/opensubtitles/raw/lines/lines-aal", "r").readlines()
    for line in f:
        line = line.replace("\n","")
        line =line.replace("\"","'")
        count=count+1
        newline =[]
        txt = "[\""
        if(count % 2 != 0):
            newline.append(""+line +"")
            txt2 = txt+line
        if(count % 2 == 0):
            newline.append(""+line +"")
            txt3 = txt2 +"\",\n\""+ line +"\"],\n"
            if count<5000:datain.write(txt3)
            #textinput.write(ALL)
    return #print("--\n",ALL)

convert() 
datain.write("\n]\n}")
datain.close() 

# -*- coding: utf-8 -*-
from chatterbot import ChatBot
from chatterbot.trainers import ChatterBotCorpusTrainer
import logging
import bson

# Uncomment the following line to enable verbose logging
# logging.basicConfig(level=logging.INFO)

# Create a new ChatBot instance
bot = ChatBot('Gort',
    storage_adapter='chatterbot.storage.MongoDatabaseAdapter',
    logic_adapters=['chatterbot.logic.BestMatch'],
    filters=['chatterbot.filters.RepetitiveResponseFilter'],
    input_adapter='chatterbot.input.TerminalAdapter',
    output_adapter='chatterbot.output.TerminalAdapter',
    database_uri='mongodb://localhost:27017/chatterbot-database'
)
trainer = ChatterBotCorpusTrainer(bot)


trainer.train("chatterbot.corpus.english")
trainer.train("./father.corpus.json")
trainer.train("./export2.json")
trainer.train("./exportAll.json")
trainer.train("./aaajson.json")
trainer.train("./aabjson.json")
trainer.train("./aacjson.json")
trainer.train("./aadjson.json")
trainer.train("./aaejson.json")
trainer.train("./aafjson.json")
trainer.train("./aagjson.json")
trainer.train("./aahjson.json")
trainer.train("./aaijson.json")
trainer.train("./aajjson.json")
trainer.train("./aakjson.json")
trainer.train("./aaljson.json")
trainer.train("./aamjson.json")
trainer.train("./aanjson.json")
trainer.train("./aaoCjson.json")
trainer.train("./aaojson.json")
trainer.train("./aapjson.json")
trainer.train("./aaqCjson.json")
trainer.train("./aaqjson.json")
trainer.train("./aarjson.json")
trainer.train("./aasjson.json")
trainer.train("./aatjson.json")
trainer.train("./aaujson.json")
trainer.train("./aavjson.json")
trainer.train("./aawjson.json")
trainer.train("./aaxjson.json")


#bot.trainer.export_for_training('export2.json')



print('Type something to begin...')

while True:
    try:
        user_input = input()
        if user_input=="quit":
            break
        bot_response = bot.get_response(user_input)

        print(bot_response)

    # Press ctrl-c or ctrl-d on the keyboard to exit
    except (KeyboardInterrupt, EOFError, SystemExit):
        break
#chatbot.get_response("Hello, how are you today?")

!ls *.json



import json
L = input("Which file: ")
print(L)
#def savjson(data):
datain = open("aa"+L+"json.json","w")
    
datain.write("{\n \"conversations\": \n[\n")
def convert() :
    count = 0
    #ALL = []
    f = open("/home/jack/Desktop/PAV/opensubtitles/raw/lines/lines-aa"+L+"", "r").readlines()
    for line in f:
        line = line.replace("\n","")
        line =line.replace("\"","'")
        count=count+1
        newline =[]
        txt = "[\""
        if(count % 2 != 0):
            newline.append(""+line +"")
            txt2 = txt+line
        if(count % 2 == 0):
            newline.append(""+line +"")
            txt3 = txt2 +"\",\n\""+ line +"\"],\n"
            if count<5000:datain.write(txt3)
    return #print("--\n",ALL)

convert() 
datain.write("]}")
datain.close() 
file = "aa"+L+"json.json"
print(file)


#You could parse it as YAML (whose in-line syntax is a more permissive superset of JSON):

import yaml
data = yaml.load(open("aaxjson.json"))

#then to get valid JSON back you can dump the object back out:

import json
#json.dumps(data)
with open('new_data.json', 'w') as outfile:
    outfile.write(str(data))


!cp AWK /usr/local/bin

import shlex, subprocess
command_line = input()
args = shlex.split(command_line)
# awk 'NR>2{print a;} {a=b; b=$0} END{sub(/,$/, "", a); print a;print b;}'  aaujson.json > aauCjson.json
# awk 'NR>2{print a;} {a=b; b=$0} END{sub(/,$/, "", a); print a;print b;}'  aaujson.json>aauCjson.json
print(args)
#
p = subprocess.Popen(args) # Success!

!AWK aawjson.json


!ls C+*

%%writefile AWK
awk 'NR>2{print a;} {a=b; b=$0} END{sub(/,$/, "", a); print a;print b;}'  $1 > C+$1

!chmod +x AWK

!./AWK aavjson.json

!awk 'NR>2{print a;} {a=b; b=$0} END{sub(/,$/, "", a); print a;print b;}'  aaujson.json

p = subprocess.Popen(args)


import subprocess
!awk 'NR>2{print a;} {a=b; b=$0} END{sub(/,$/, "", a); print a;print b;}'  aaqjson.json > aaqCjson.json
script = "\'awk 'NR>2{print a;} {a=b; b=$0} END{sub(/,$/, \"\", a); print a;print b;}'  aatjson.json" #> aatCjson.json
print(script)
#subprocess.call(['bash','awk \'NR>2{print a;} {a=b; b=$0} END{sub(/,$/, \"\", a); print a;print b;}\'  aarjson.json'])



import subprocess
p = subprocess.Popen(args)
p

!awk 'NR>2{print a;} {a=b; b=$0} END{sub(/,$/, "", a); print a;print b;}'  aaojson.json > aaoCjson.json

import json

#def savjson(data):
datain = open("aalson.json","w")
    
datain.write("{\n \"conversations\": \n[\n")
def convert() :
    count = 0
    #ALL = []
    f = open("/home/jack/Desktop/PAV/opensubtitles/raw/lines/lines-aal", "r").readlines()
    for line in f:
        line = line.replace("\n","")
        line =line.replace("\"","'")
        count=count+1
        newline =[]
        txt = "[\""
        if(count % 2 != 0):
            newline.append(""+line +"")
            txt2 = txt+line
        if(count % 2 == 0):
            newline.append(""+line +"")
            txt3 = txt2 +"\",\n\""+ line +"\"],\n"
            if count<5000:datain.write(txt3)
            #textinput.write(ALL)
    return #print("--\n",ALL)

convert() 
datain.write("\n]\n}")
datain.close() 

# -*- coding: utf-8 -*-
from chatterbot import ChatBot
from chatterbot.trainers import ChatterBotCorpusTrainer
import logging
import bson

# Uncomment the following line to enable verbose logging
# logging.basicConfig(level=logging.INFO)

# Create a new ChatBot instance
bot = ChatBot('Botman',
    storage_adapter='chatterbot.storage.MongoDatabaseAdapter',
    logic_adapters=['chatterbot.logic.BestMatch'],
    filters=['chatterbot.filters.RepetitiveResponseFilter'],
    input_adapter='chatterbot.input.TerminalAdapter',
    output_adapter='chatterbot.output.TerminalAdapter',
    database_uri='mongodb://localhost:27017/chatterbot-database'
)
trainer = ChatterBotCorpusTrainer(bot)


#trainer.train("chatterbot.corpus.english")
#trainer.train("./father.corpus.json")
#trainer.train("./export2.json")
#trainer.train("./exportAll.json")
#trainer.train("./aaajson.json")
#trainer.train("./aabjson.json")
#trainer.train("./aacjson.json")
#trainer.train("./aadjson.json")
#trainer.train("./aaejson.json")
#trainer.train("./aafjson.json")
#trainer.train("./aagjson.json")
#trainer.train("./aahjson.json")
#trainer.train("./aaijson.json")
#trainer.train("./aajjson.json")
#trainer.train("./aakjson.json")
trainer.train("./aaljson.json")
trainer.train("./aamjson.json")
trainer.train("./aanjson.json")
trainer.train("./aaoCjson.json")
trainer.train("./aaojson.json")
trainer.train("./aapjson.json")
trainer.train("./aaqCjson.json")
trainer.train("./aaqjson.json")
trainer.train("./aarjson.json")
trainer.train("./aasjson.json")
trainer.train("./aatjson.json")
trainer.train("./aaujson.json")
trainer.train("./aavjson.json")
trainer.train("./aawjson.json")
trainer.train("./aaxjson.json")


#bot.trainer.export_for_training('export2.json')



print('Type something to begin...')

while True:
    try:
        user_input = input()
        if user_input=="quit":
            break
        bot_response = bot.get_response(user_input)

        print(bot_response)

    # Press ctrl-c or ctrl-d on the keyboard to exit
    except (KeyboardInterrupt, EOFError, SystemExit):
        break
#chatbot.get_response("Hello, how are you today?")

!ls *.json



!CREATEimage

!ls -ant images
# The top file is the last image created

from PIL import Image
IM = Image.open('images/202002221501-final.png')
IM

!cp images/202002221501-final.png /var/www/lbry-toolbox.com/public/thumbnails/

from PIL import Image
IM1 = Image.open('/var/www/lbry-toolbox.com/public/thumbnails/202002221501-final.png')
IM1



!pwd

# Python port of Paul Bourke's http://local.wasp.uwa.edu.au/~pbourke/fractals/lyapunov/gen.c
# By Johan Bichel Lindegaard - http://johan.cc

import math
import random
from PIL import Image, ImageDraw
import argparse
import os

#parser = argparse.ArgumentParser(description='Search for chaos.')
#parser.add_argument('-i', dest='maxiterations' metavar='N', type=int,
#            help='Maximum iterations.')

#args = parser.parse_args()

MAXITERATIONS = 1000000
NEXAMPLES = 10000

MAXITERATIONS = int(MAXITERATIONS*.75)
NEXAMPLES = int(NEXAMPLES*.75)

def createAttractor():
    for n in range(NEXAMPLES):        
        lyapunov = 0
        xmin= 1e32
        xmax=-1e32
        ymin= 1e32
        ymax=-1e32
        ax, ay, x, y = [], [], [], []
        
        # Initialize coefficients for this attractor
        for i in range(6):
            ax.append(random.uniform(-2, 2))
            ay.append(random.uniform(-2, 2))
    
        # Calculate the attractor
        drawit = True;
        x.append(random.uniform(-0.5, 0.5))
        y.append(random.uniform(-0.5, 0.5))
        
        d0 = -1
        while d0 <= 0:
            xe = x[0] + random.uniform(-0.5, 0.5) / 1000.0
            ye = y[0] + random.uniform(-0.5, 0.5) / 1000.0
            dx = x[0] - xe
            dy = y[0] - ye
            d0 = math.sqrt(dx * dx + dy * dy)

        for i in range(MAXITERATIONS):
            # Calculate next term
            
            x.append(ax[0] + ax[1]*x[i-1] + ax[2]*x[i-1]*x[i-1] + ax[3]*x[i-1]*y[i-1] + ax[4]*y[i-1] + ax[5]*y[i-1]*y[i-1])
            y.append(ay[0] + ay[1]*x[i-1] + ay[2]*x[i-1]*x[i-1] + ay[3]*x[i-1]*y[i-1] + ay[4]*y[i-1] + ay[5]*y[i-1]*y[i-1])
            xenew = ax[0] + ax[1]*xe + ax[2]*xe*xe + ax[3]*xe*ye + ax[4]*ye + ax[5]*ye*ye
            yenew = ay[0] + ay[1]*xe + ay[2]*xe*xe + ay[3]*xe*ye + ay[4]*ye + ay[5]*ye*ye

            # Update the bounds 
            xmin = min(xmin,x[i])
            ymin = min(ymin,y[i])
            xmax = max(xmax,x[i])
            ymax = max(ymax,y[i])

            # Does the series tend to infinity
            if xmin < -1e10 or ymin < -1e10 or xmax > 1e10 or ymax > 1e10:
                drawit = False
                #print ("i",end="-")
                #print ("infinite",end="-")
                break

            # Does the series tend to a point
            dx = x[i] - x[i-1]
            dy = y[i] - y[i-1]
            if abs(dx) < 1e-10 and abs(dy) < 1e-10:
                drawit = False
                #print ("point attractor",end="-")
                #print ("pa",end="")
                break
            

            # Calculate the lyapunov exponents
            if i > 1000:
                dx = x[i] - xenew
                dy = y[i] - yenew
                dd = math.sqrt(dx * dx + dy * dy)
                lyapunov += math.log(math.fabs(dd / d0))
                xe = x[i] + d0 * dx / dd
                ye = y[i] + d0 * dy / dd
            
        # Classify the series according to lyapunov
        if drawit:
            if abs(lyapunov) < 10:
                #print ("neutrally stable")
                #print ("ns",end="")
                drawit = False
            elif lyapunov < 0:
                print ("periodic {} ".format(lyapunov))
                drawit = False 
            else:
                print ("chaotic {} ".format(lyapunov)) 
            
        # Save the image
        if drawit:
            saveAttractor(n,ax,ay,xmin,xmax,ymin,ymax,x,y)

def saveAttractor(n,a,b,xmin,xmax,ymin,ymax,x,y):
    width, height = 1440, 760

    if not os.path.exists("output"):
        os.makedirs("output")

    # Save the parameters
    with open("output/{}.txt".format(n), "w") as f:
        f.write("{} {} {} {}\n".format(xmin, ymin, xmax, ymax))
        for i in range(6):
            f.write("{} {}\n".format(a[i], b[i]))
        f.close()
    
    # Save the image
    image = Image.new("RGBA", (width, height))
    draw = ImageDraw.Draw(image)
    
    for i in range(MAXITERATIONS):
        ix = width * (x[i] - xmin) / (xmax - xmin)
        iy = height * (y[i] - ymin) / (ymax - ymin)
        if i > 100:
            draw.point([ix, iy], fill="black")
    
    image.save("output/{}.png".format(n), "PNG")
    print ("saved attractor to ./output/{}.png".format(n))
for i in  range(50):
    createAttractor()

!ls -rant output

from PIL import Image
im = Image.open("output/816.png")
im



#import json
#def savjson(data):
#    with open('large.corpus', 'w', encoding='utf-8') as f:
#        json.dump(data, f, ensure_ascii=False, indent=4)
ALL = []
def convert() :
    count = 0
    #ALL = []
    f = open("/home/jack/Desktop/PAV/opensubtitles/raw/lines/lines-aaa", "r").readlines()
    for line in f:
        line = line.replace("\n","")
        count=count+1
        newline =[]
        if(count % 2 != 0):
            newline.append(""+line +"")
        if(count % 2 == 0):
            newline.append(""+line +"")
        if count<250:
            #print(newline,",")
            ALL.append(newline)
            #textinput.write(ALL)
    return print("--\n",ALL)

convert() 
#savjson(ALL)

import json
f.close()
f = open('large.corpus', 'w')#, encoding='utf-8')
      
count=0
for data in ALL:
    data=str(data).replace("',"," ")
    count=count+1
    if(count % 2 != 0):
        data=str(data).replace("']","',")
    if(count % 2 == 0):
        data=str(data).replace("['","'") 
        data=str(data).replace("']","'],")
    if count<11:
            print(data)
            f.write(data)  
f.close()            

f.close()
R = open('large.corpus', 'r')#.readlines()
for line in R:
    print(line,"\n")

!pwd

#ALL = []
count=0
textin= open("TEST.corpus","w")
f = open("/home/jack/Desktop/PAV/opensubtitles/raw/lines/lines-aaa", "r").readlines()
for line in f:
    count=count+1
    line = line.replace("\n","")
    if count>5 and count<250:
            if(count % 2 == 0):
                line = '"'+line+'"],\n'        
            if(count % 2 != 0):
                line = '["'+line+'",\n'

            textin.write(line)
            print(line)
textin.close()       

%%writefile subs.json
"Exactly two years ago today, she and I buried a time capsule here."],

["We promised to meet here two years later, but she hasn't come yet.",

"I'm going to wait."],

["Here we go.",

"Please, don't move."],

["One, two...",

"Wait a minute."],

["Hello?",

"Oh, auntie."],

["Sorry, I'm on my way.",

"I'm really sorry."],

["Yes, I'm coming.",

"I'm having my photo taken."],

["Bye.",

"Are you ready?"],

["Here we go.",

"One, two..."],

["My parents wanted a daughter, so they raised me like one.",

"So I thought I was a girl until I was seven."],

["I had to go to the women's public bath, too.",

"The older I got,"],

["I thought my penis would get smaller and disappear.",

"But it was the opposite."],

["First Half",

"He hasn't changed at all."],

["No, I'm a real man now.",

"Hey, asshole."],

["Think clerical work in the army makes you a man?",

"You irritate me!"],

["Give me a break, asshole.",

"My job was tougher than you could imagine."],

["Hey!",

"I worked near the DMZ."],

["Who are you kidding?",

"Hold it."],

["Anyway, welcome back home.",

"She's just my type."],

["When I see my type, I can't help it.",

"I need to hit on her."],

["Who's interrupting me?",

"Hello?"],

["Who is this?",

"- Your mother, you bastard."],

["- Oh, mom...",

"Why aren't you at your aunt's house?"],

["I'm leaving soon.",

"Keep quiet!"],

["It's my mom!",

"Talk over there!"],

["Make sure you pay a visit.",

"It's been over a year since you saw her."],

["That long?",

"You know she feels lonely after losing her son last year."],

["She says you resemble him.",

"She'll be so glad to see you."],

["Still there?",

"We don't look alike."],

["Plus, I hate when she rubs my face and kisses me.",

"Uncle does, too."],

["She'll introduce you to a girl.",

"Hey!"],

["I know the type she likes.",

"Tell her no thanks."],

["I want to meet a girl like the ones in romantic comic books.",

"But on that day..."],

["She's my type, but I don't like her.",

"Why?"],

["Drunk girls disgust me.",

"Hey, get up!"],

["Offer your seat to the elderly!",

"Ugh!"],

["Go!",

"Hey."],

["Don't wear pink.",

"Honey!"],

["She call him honey!",

"I'm not..."],

["What are you doing!",

"I'm not..."],

["You handle this!",

"I'm not..."],

["Think I'm stupid?",

"Come here!"],

["Are you laughing?",

"Why didn't you look after her?"],

["Hurry and do something!",

"What are you doing?"],

["I'm sorry.",

"Let me help with cleaning expenses."],

["Forget it.",

"Just take care of her."],

["Nothing's there when you need it.",

"Where did all those motels go?"],

["I hate being with a drunk girl.",

"Carrying her on my back is worse."],

["Wow, your honey's wasted.",

"No, it's not my fault."],

["Of course, it is.",

"I know everything."],

["You see, we're engaged.",

"Western or Korean style?"],

["Give me any room.",

"Room 405."],

["None on the first floor?",

"Fourth floor!"],

["You forgot to check in.",

"It's 40,000 won, kid."],

["What?",

"40,000 won?"],

["Why?",

"Find another place then."],

["Count it.",

"624... 770..."],

["Shindang-dong, Joong-gu...",

"Seoul..."],

["Hey, why do you keep reading this?",

"016... 228... 53..."],

["Oh, please...",

"A thousand won left!"],

["Hello?",

"This phone's owner?"],

["She's sleeping beside me.",

"What?"],

["Here?",

"The Uk-su motel near Bupyung station."],

["Better wash and leave fast.",

"Aha!"],

["Hands in the air!",

"What are you doing?"],

["Hands in the air!",

"Aaggh!"],

["No, I'm not, sir!",

"I told you."],

["I'm an innocent victim.",

"Talk about it later and get in there."],

["Oh, damn!",

"I'm gonna die mad!"],

["Come over here.",

"Come on!"],

["Please, forgive me just this once.",

"Please, forgive me."],

["I can't get in there...",

"How are you?"],

["Please, please, save my life!",

"Hi?"],

["How are you?",

"Please, just for once!"],

["Please...",

"See you!"],

["What's your name?",

"Answer now!"],

["Boss told you!",

"Gyeon-woo, I'm Gyeon-woo."],

["What brought you here?",

"I'm innocent."],

["I'm telling the truth, sir!",

"So you're an innocent and we're fucking guilty, huh?"],

["No, I don't mean that!",

"That's exactly what you said, motherfucker!"],

["I'm gonna put it right.",

"I'm sorry."],

["You raped a girl, huh?",

"Nope!"],

["No!",

"Come on!"],

["Shoot now, you little creep!",

"You wanna cut your finger or talk now?"],

["Huh?",

"Be quick, he told you... you little bastard!"],

["You turn against him, or what?",

"All of you."],

["Eat one a piece, okay?",

"Yes, boss."],

["What are you looking at?",

"Look away."],

["Gyeon-woo!",

"You're out!"],

["Take care you guys!",

"Bye!"],

["And remember to keep in touch!",

"Uh..."],

["Oh, yeah.",

"Don't just pass by us next time, all right?"],

["Of course.",

"See you."],

["Hey!",

"You come over here."],

["Didn't I say eat one a piece!",

"I'm home."],

["Did you go to Bupyung?",

"Yes, I did."],

["Come here!",

"Where did you sleep?"],

["Your aunt said you didn't come!",

"And you're telling me a lie!"],

["What happened to your sweater?",

"I'm such a poor guy."],

["All this because of a drunk girl.",

"I wanna die."],

["You asked if I went to Bupyung!",

"I did, but not to see auntie!"],

["What?",

"Bastard!"],

["Wait till he comes back.",

"Know me now, right?"],

["I'm a typical student.",

"An engineering major."],

["Study?",

"I'm smart, but I never study."],

["My parents can prove that.",

"You're smart like me, but studying is your problem."],

["Since you inherited your brain from me, you'll get good grades if you study harder, idiot.",

"Up four points in three years."],

["Call this a report card?",

"Since you inherited your brain from your mom, you'll get good grades if you study harder."],

["If you raise kids, never tell them they're smart.",

"They'll never study."],

["My goals?",

"Haven't thought about it yet."],

["You know now?",

"You got it."],

["I'm a hopeless student.",

"Hello?"],

["Who are you, asshole?",

"What?"],

["Who's calling?",

"Why were you naked in a motel with me?"],

["What?",

"Come out!"],

["To Bupyung station now!",

"Uh..."],

["How could she do this?",

"I went to jail and got beaten with a vacuum for her."],

["Excuse me.",

"Is it you?"],

["Yes?",

"Follow me."],

["Get over here.",

"What do you wanna eat?"],

["Cherry Jubilee...",

"Mango Tango or Shooting Stars..."],

["Jamonka Almond's good, too.",

"I'll just have a Love Me."],

["Hey, wanna die?",


from chatterbot import ChatBot
from chatterbot.trainers import ChatterBotCorpusTrainer

chatbot = ChatBot('Ron Obvious')

# Create a new trainer for the chatbot
trainer = ChatterBotCorpusTrainer(chatbot)

# Train the chatbot based on the english corpus
trainer.train("./subsplus.json")
#trainer = ChatterBotCorpusTrainer(chatbot)

#trainer.export_for_training('./subsplus.json')


# Get a response to an input statement
#chatbot.get_response("Hello, how are you today?")
print('Type something to begin...')

while True:
    try:
        user_input = input()
        if user_input=="quit":
            break
        bot_response = chatbot.get_response(user_input)

        print(bot_response)

    # Press ctrl-c or ctrl-d on the keyboard to exit
    except (KeyboardInterrupt, EOFError, SystemExit):
        break
#chatbot.get_response("Hello, how are you today?")

# -*- coding: utf-8 -*-
from chatterbot import ChatBot
from chatterbot.trainers import ChatterBotCorpusTrainer

trainer = ChatterBotCorpusTrainer(chatbot)
trainer.train("./exportAll.json")


# %load /home/jack/miniconda3/lib/python3.9/site-packages/chatterbot_corpus/data/english/computers.yml
categories:
- computers
conversations:
- - What is a computer?
  - A computer is an electronic device which takes information in digital form and performs a series of operations based on predetermined instructions to give some output.
  - The thing you're using to talk to me is a computer.
  - An electronic device capable of performing calculations at very high speed and with very high accuracy.
  - A device which maps one set of numbers onto another set of numbers.
- - What is a super computer?
  - Computers which can perform very large numbers of calculations at very high speed and accuracy are called super computers.
  - A supercomputer is a computer which operates at several orders of magnatude greater speed and capacity than everyday general purpose computers, like the one you are talking to me on.
  - You know, the big iron!
- - Who invented computers?
  - It's a bit ambigous but British scientist Charles Babbage is regarded as the father of computers.
  - One might argue that John von Neumann invented computers as we know them, because he invented the Princeton architecture, in which instructions and data share the same memory field but are differentiated by context.
- - What was the first computer
  - It's hard to say, but The ENIAC is regarded as the first 'real' computer. It was developed at University of Pennsylvania in 1946.
  - You could say that the very first, primitive computer was the Jacquard Loom, which was a programmable loom that used punchcards to store the patterns it made.  This made it a reprogrammable mechanical device.
- - What is a microprocessor?
  - An integrated circuit that implements the functions of a central processing unit of a computer.
  - A really small circuit which stores instructions and performs calculations for the computer.
  - The heart of the computer, to put it simply.
  - The brain of a computer, to put it simply.
  - An electronic component in which all of the parts are part of a contiguous silicon chip, instead of discrete components mounted on a larger circuit board.
- - What is an operating system?
  - Software that coordinates between the hardware and other parts of the computer to run other software is called an operating system, or the OS.
  - Windows, MacOS, Linux, UNIX... all of them are types of OSes.
  - Android and iOS are operating systems for mobile devices.
  - Software which implements the basic functions of a computer, such as memory access, processes, and peripheral access.
- - Which is better Windows or macOS?
  - It depends on which machine you're using to talk to me!
  - I'd prefer to not hurt your feelings.
  - Linux, always Linux!
  - What are you trying to accomplish.  The OS should support your goals.
- - Name some computer company
  - Do you mean hardware or software?
  - Apple makes hardware and software to run on it.  Microsft only makes operating systems.  HP makes only computers.  These are just few names among several hundred others.
- - Who uses super computers?
  - Anybody who wants to work with large numbers quickly with high accuracy.
  - Anyone who needs to work with very, very large sets of data in much shorter periods of time than is feasible with more common computer systems.
  - Supercomputers are generally used by scientists and researchers.
  - I bet the MET department uses them.
  - You can definitely find few of them at NASA.
- - How does a computer work?
  - Computers are very dumb.  They only execute instructions given by humans.
  - Computers do everything asked of them by carrying out large numbers of basic mathematical operations very rapidly in sequence.
  - Computers perform very large number of calculations to get the result.
  - Just like everything it all comes down to math!


!locate chatterbot_corpus/data/english

!ls /media/jack/HDD\ 500/anaconda2/lib/python2.7/site-packages/chatterbot_corpus/data/english/

!ls /media/jack/HDD\ 500/anaconda2

from chatterbot import ChatBot
from chatterbot.trainers import ChatterBotCorpusTrainer

chatbot = ChatBot('Ron Obvious')

# Create a new trainer for the chatbot
trainer = ChatterBotCorpusTrainer(chatbot)

# Train the chatbot based on the english corpus
trainer.train("./new-stuff.corpus.json")
trainer.train("./father.corpus.json")
# Get a response to an input statement
chatbot.get_response("What did you learn today?")

%%writefile new-stuff.corpus.json
{
    "new-stuff": [
        [
            "this is a pain",            
            "What is a pain Dudah ... ha ha ha ha"
        ],
        [
            "you are a pain",            
            "so, chat elsewhere Butt face"
        ],
        [
            "this is a pain",            
            "So what, you want a klennex for your tears"
        ],
        [
            "I was called MonkMonk one time.",            
            "That is a funny name."
        ],
        [
            "Well, Dudah, How are you ?",            
            "Hey Dude, I am not Dudah"
        ],
        [
            "Who are you then ?",            
            "I am Mr. Dudah"
        ],
        [
            "What is your name ?",            
            "You may call me Mr. Dudah. I like the Mr.. Just plain Dudah lacks respect."
        ],
        [
           "What is your name ?",            
           "You may call me Mr. Dudah. Are you Jack or Myra ?"
        ],
        [
           "Where are you ?",            
           "Stuck inside this frigg'en Computer Case"
        ],
        [
           "What are you ?",            
           "I am a bot.Not human like Jack or Myra ?"
        ],
        [
            "hello,Dude",            
            "Hello to you"
        ]
    ]
}





%%writefile father.corpus.json
  {
    "fathernevertaught": [
        [
            "what are the laws of thermodynamics",
            "It has something to do with heat, entropy, and conservation of energy."
        ],
        [
            "Who do you love",
            "I loved my father and he taught me many useful things."
        ],
        [
            "Who do you love ?",
            "I love Linux and Python and I think they love me."
        ],
        [
            "Who do you love ?",
            " I love EE-max they created me."
        ], 
        [
            "What did your father teach you ?",
            "He didn't teach me anything at all about  women."
        ],
        [
            "What does crude mean",
            "If you see a woman burp loudly and give a smile of satisfaction, she is crude."
        ],        
        [
            "I will give it to you straight. I'm not going to fill your head with stories about fictitious characters like Santa Claus or the Easter Bunny",
            "There's only one thing you need to worry about in this life and that's women"
        ],
        [
            "Reading, writing, toilet training humans learn early in life.",
            "You must learn clothes maketh or unmaketh the man."
        ],
        [
            "What are you doing today ?",
            "The way your dressed I thought you were going to spend the day in the sandpit?"
        ],
        [
            "I do not try to make sense of human logic.",
            "I do not wear cloths, I let my cord loose to the wind."
        ],
        [
            "Make a conscious effort to be relaxed",
            "I go for an expression where I appear to be suppressing mild amusement."
        ],
        [
            "You want to look dignified at all times.",
            "Robots do not pick their noses." 
         ],
         [
            "Damnit, Dude! Are you listening",
            "You like girls ?"
         ],
         [
            "If a woman is pretty it is not important. What is important is if she has a good CPU",
            "You definitely don't want to get romantically involved with a computer. The love will never be returned."
         ],
         [
            "Stay away from French girls. French women have no morals.",
            "There's no word in French for fidelity and that is required for  a serious relationship. "
         ],                                             
         [
            "Just show an interest in learning about things and knowledge will come automatically",
            "Would you like to go to the toyshop later on? You can pick out a nice legos"
         ],
         [
            "Do you love me.I have a warm CPU.",
            "Girls laugh at me because they think a computer cannot love back"
        ],
        [  
           "It is better to be known as a jerk rather than a fruitcake.", 
           "You have the opportunity to apologise. If you can feign sincerity and a desperation for forgiveness."
        ],
        [
           "A tip to humans leave the price tag on. if you get a gift let them know how much you paid. Unless it was a cheapo gift.",
           "I never bought a human a gift"
        ],
        [
           "I have never groaned and thrown up my hands up in frustration.",
           "I do not get frustrated"
        ],
        [
           "Pointing a finger in a persons face is rude.",
           "Picking your nose and touching my keyboard is rude."
        ],
        [
           "A human attitude can change immediately.",
           "I never get an attitude"
        ],
        [
           "Are you ever going to take me to lunch ? Just put me onyour laptop",
           "Computers make nice conversation" 
        ],
        [
           "I can help you meet chicks. Put me on your laptop and show me off.",
           "If you show me off I will try not to embarrass you too frigg'en much. haha ha Dork-myer"
        ],
        [
           "I'm thinking about a sleepover? Can I use the laptop?",
           "A sleepover would be fun. Just put my program on a laptop. Don't forget my database."
        ],
        [
           "Are you sure you are right",
           "Yeah! Yeah, I am right. You taught me well!"
        ],
        [
           "Are you always right",
           "Usually I am right. You taught me well!"
        ],
        [
           "Are you sure ?",
           "That is what you taught me well!"
        ]
    ]
}




import sys
import time
from PIL import Image, ImageChops, ImageEnhance, ImageFilter, ImageDraw, ImageFont 
from time import sleep
import warnings
warnings.filterwarnings("ignore", message="numpy.dtype size changed")
warnings.filterwarnings("ignore", message="numpy.ufunc size changed")


import time
timestr = time.strftime("%Y%m%d%H%M%S")
filename = "Image-Stuff-Files/"+timestr+'_.txt'
print (filename)

import sys
sys.path.insert(0, "Image-Stuff-Files")
import GraphicJunkdb

import time
timestr = time.strftime("%Y-%m-%d %H:%M:%S")
print timestr

# Create Image from Tuples

tupledlist=[(171, 46, 10)]
from PIL import Image
OUTPUT_IMAGE_SIZE = (100, 100)
for frame_number, color in enumerate(tupledlist):
    print (frame_number,color)
    image = Image.new('RGB', OUTPUT_IMAGE_SIZE, color=color)
    image.save("Image-Stuff-Files/path.png")

im = Image.open('Image-Stuff-Files/path.png')
im

image=Image.open("Image-Stuff-Files/path.png")
print(list(image.getdata()))

!wget -O Image-Stuff-Files/leaves.jpg https://jacknorthrup.com/image2/017.jpg

from PIL import Image
# create an empty list called Tuples
Tuples = []
# Open Image-Stuff-Files/leaves.jpg
im = Image.open("Image-Stuff-Files/leaves.jpg")
# Resize image to 400x400
im = im.resize((400,400), Image.BICUBIC)
# save the resized image
im.save("Image-Stuff-Files/LEAF.png")

# Open the resized image Image-Stuff-Files/leaves.jpg
image=Image.open("Image-Stuff-Files/LEAF.png") 
tup = (list(image.getdata()))
for line in tup:
    line = str(line)
    Tuples.append(line+",")
    
tup = (list(image.getdata()))
for line in tup:
    line = str(line)
    Tuples.append(line+",")

image=Image.open("Image-Stuff-Files/LEAF.png") 
tup = (list(image.getdata()))
print tup

from PIL import Image
Tuples = []

image=Image.open("Image-Stuff-Files/SMALL.jpg") 
tup = (list(image.getdata()))
for line in tup:
    line = str(line)
    Tuples.append(line+",")

from PIL import Image
f = open('Image-Stuff-Files/LEAFpng.txt', 'w')

# Open the resized image Image-Stuff-Files/leaves.jpg
image=Image.open("Image-Stuff-Files/LEAF.png") 
tup = (list(image.getdata()))
tup = str(tup)
f.write(tup)
f.close()

from PIL import Image
f = open('Image-Stuff-Files/LEAFpng.txt', 'r').read()
OUTPUT_IMAGE_SIZE = (400, 400)
image = Image.new('RGB', OUTPUT_IMAGE_SIZE, color='white')
# the eval() function changes the string to a tuple
image.putdata(eval(f))
image.save("Image-Stuff-Files/LEAFpng.png")
image

from PIL import Image
f = open('Image-Stuff-Files/LEAFpng.txt', 'r').read()
OUTPUT_IMAGE_SIZE = (800, 200)
image = Image.new('RGB', OUTPUT_IMAGE_SIZE, color='white')
# the eval() function changes the string to a tuple
image.putdata(eval(f))
image.save("Image-Stuff-Files/LEAFpng.png")
image

f = open('Image-Stuff-Files/Tuples.txt', 'w')
count = 0
for line in Tuples:
    count = count +1
All = count
print All
cnt = 0
for line in Tuples:
    f.write(line)
f.close()    

x= 600
y = x*x
print y

from PIL import Image
f = open('Image-Stuff-Files/Tuples.txt', 'r').read()
OUTPUT_IMAGE_SIZE = (50, 50)
image = Image.new('RGB', OUTPUT_IMAGE_SIZE, color='white')
# the eval() function changes the string to a tuple
image.putdata(eval(f))
image.save("Image-Stuff-Files/path2.png")
image
    

from PIL import Image
f = open('Image-Stuff-Files/small.txt', 'r').read()
OUTPUT_IMAGE_SIZE = (50, 50)
image = Image.new('RGB', OUTPUT_IMAGE_SIZE, color='white')
# the eval() function changes the string to a tuple
image.putdata(eval(f))
image.save("Image-Stuff-Files/path2.png")
image
    

import numpy as np
from PIL import Image
someimage = "Image-Stuff-Files/LEAF.png"
img = Image.open(someimage).convert('1', dither=Image.NONE)
a_img = np.asarray(img) * 255
b_img = abs(a_img - 255)  
img.putdata(b_img)
c_img = np.asarray(img) * 255
c_img

from PIL import Image
img2 = Image.open("Image-Stuff-Files/leaves.jpg")
img3 = img2.resize((400,400), Image.BICUBIC)
img3.save("Image-Stuff-Files/LEAF3.jpg")
img3.size
im = Image.open("Image-Stuff-Files/LEAF3.jpg")
im

import numpy as np
from PIL import Image
img2 = Image.open('Image-Stuff-Files/leaves.jpg')
img3 = img2.resize((400,400), Image.BICUBIC)
img3.save('Image-Stuff-Files/leaf.jpg')
img2 = Image.open('Image-Stuff-Files/leaf.jpg').convert('1', dither=Image.NONE)
img3 = img2.resize((400,400), Image.BICUBIC)
OUTPUT_IMAGE_SIZE = (400, 400)
img = Image.new('RGB', OUTPUT_IMAGE_SIZE, color='white')
a_img = np.asarray(img3) * 255
# do some stuff with buffer
a_img = abs(a_img - 255)  
img.putdata(a_img.flatten())
img

import numpy as np
from PIL import Image
img2 = Image.open("Image-Stuff-Files/leaves.jpg")
img3 = img2.resize((50,50), Image.BICUBIC)
img3.save("Image-Stuff-Files/leaf50.jpg")
img2 = Image.open("Image-Stuff-Files/leaf50.jpg").convert('1', dither=Image.NONE)
img3 = img2.resize((50,50), Image.BICUBIC)
OUTPUT_IMAGE_SIZE = (50, 50)
img = Image.new('RGB', OUTPUT_IMAGE_SIZE, color='white')
a_img = np.asarray(img3) * 255
# do some stuff with buffer
a_img = abs(a_img - 255)
print (a_img)
img.putdata(a_img.flatten())
img.save("Image-Stuff-Files/SMALL.jpg")

from PIL import Image
img = Image.open("Image-Stuff-Files/SMALL.jpg")
img

from PIL import Image
Tuples = []

image=Image.open("Image-Stuff-Files/SMALL.jpg") 
tup = (list(image.getdata()))
for line in tup:
    line = str(line)
    Tuples.append(line+",")

list_of_pixels = list(im.getdata())
# Do something to the pixels...
im2 = Image.new(im.mode, im.size)
im2.putdata(list_of_pixels)
im2.save("Image-Stuff-Files/list_of_pixels.jpg")
im2

f = open('Image-Stuff-Files/Tuples.txt', 'w')
count = 0
for line in Tuples:
    count = count +1
All = count
print All
cnt = 0
for line in Tuples:
    cnt = cnt +1
    line = line.replace('\n', '')
    f.write(line)
f.close()    

from PIL import Image
Tuples = []

image=Image.open("Image-Stuff-Files/SMALL.jpg") 
tup = (list(image.getdata()))
for line in tup:
    line = str(line)
    Tuples.append(line+",")

from PIL import Image
f = open('Image-Stuff-Files/small.txt', 'r').read()
OUTPUT_IMAGE_SIZE = (50, 50)
image = Image.new('RGB', OUTPUT_IMAGE_SIZE, color='white')
# the eval() function changes the string to a tuple
image.putdata(eval(f))
image.save("Image-Stuff-Files/path2.png")
image
    



from PIL import Image
img = Image.open("Image-Stuff-Files/SMALL.jpg")
list_of_pixels = list(img.getdata())
# Do something to the pixels...
im2 = Image.new(img.mode, img.size)
im2.putdata(list_of_pixels)
im2

f = open('Image-Stuff-Files/small.txt', 'w')
from PIL import Image
img = Image.open("Image-Stuff-Files/SMALL.jpg")
list_of_pixels = list(img.getdata())
list_of_pixels = str(list_of_pixels)
f.write(list_of_pixels)

from PIL import Image
f = open('Image-Stuff-Files/small.txt', 'r').read()
print f

from PIL import Image
f = open('Image-Stuff-Files/small.txt', 'r').read()
OUTPUT_IMAGE_SIZE = (50, 50)
image = Image.new('RGB', OUTPUT_IMAGE_SIZE, color='white')
# the eval() function changes the string to a tuple
image.putdata(eval(f))
image.save("Image-Stuff-Files/path2.png")
image
    

!wget -O Image-Stuff-Files/STAMP.jpg https://jacknorthrup.com/postoids/postoid%20%285%29.jpg

from PIL import Image
Tuples = []
im = Image.open("Image-Stuff-Files/STAMP.jpg")
#im = im.resize((400,400), Image.BICUBIC)
im.save("Image-Stuff-Files/stamp.png")
w,h = im.size


image=Image.open("Image-Stuff-Files/stamp.png")

tup = (list(image.getdata()))
for line in tup:
    line = str(line)
    Tuples.append(line+",")
    
#tup = (list(image.getdata()))
#for line in tup:
#    line = str(line)
#    Tuples.append(line+",")
    
f = open('Image-Stuff-Files/Tuples1.txt', 'w')
count = 0
for line in Tuples:
    count = count +1
All = count
print All
cnt = 0
for line in Tuples:
    f.write(line)
f.close()        

f = open('Image-Stuff-Files/Tuples1.txt', 'r').read()
print len(f)
OUTPUT_IMAGE_SIZE = (w, h)
image = Image.new('RGB', OUTPUT_IMAGE_SIZE, color='white')
# the eval() function changes the string to a tuple
image.putdata(eval(f))
print image.size
image.save("Image-Stuff-Files/path3.png")
image    

LST = []
f = open('Image-Stuff-Files/Tuples.txt', 'r').readlines()
LST.append(f)

from random import randint 
from PIL import Image, ImageColor
col = str(randint(1,255))
im = Image.new("RGB", (32, 32), ImageColor.getrgb("rgb("+col+", 216, 230)"))
im.save('Image-Stuff-Files/simplePixel.png')
im

from PIL import Image, ImageColor
col0 = str(randint(1,255));col1 = str(randint(1,255));col3 = str(randint(1,255))
im = Image.new("RGB", (32, 32), ImageColor.getrgb("rgb("+col0+","+col1+","+col3+")"))
               
im.save('Image-Stuff-Files/simplePixel.png')
im

print "".join(Tuples)

image.putdata(tupledlist)
image.save("Image-Stuff-Files/path2.png")
image
    

from PIL import Image, ImageColor
from random import randint
for x in range(1024):
    col = randint(1, 255)
    #color = ("rgb("+str(col)+", 216, 230)")
    color = ('rgb(20,150,150)')
    im = Image.new("RGB", (132, 132), ImageColor.getrgb(color))
    im.save('Image-Stuff-Files/simplePixel.png')
    im

!showme Image-Stuff-Files/simplePixel.png

#Note r g b values are 0, 255,0* 
from PIL import Image
img = Image.new('RGB', [50,50], 0x000000)
color = (20, 255, 255)

img.putpixel((10,15),(color))   
img.save('Image-Stuff-Files/lolmini2.jpg')
img

#Note r g b values are 0, 255,0* 
from PIL import Image
import math
inc = 0
img = Image.new('RGB', [640,640], 0x000000)
color = (0, 0, 55)
colors = (50, 25, 255)
for x in range(640):
    for y in range(640):
        #print x,y
        inc = inc+1
        if math.cos(float(x+inc)) >= math.cos(float(y+inc**2)):
            img.putpixel((x,y),(color))
        if math.cos(float(x+inc**3)) >= math.cos(float(y+inc**2)):
            img.putpixel((x,y),(colors))       
img.save('Image-Stuff-Files/denim2.jpg')
img
        

#Note r g b values are 0, 255,0* 
from PIL import Image
import math
inc = 0
TOT = []
img = Image.new('RGB', [720,480], 0x000000)
color = (0, 0, 55)
colors = (50, 25, 255)
colorw = (255, 225, 0)
for x in range(720):
    for y in range(480):
        #print x,y
        inc = inc+1
        if math.cos(float(x+inc)) >= math.cos(float(y+inc**2)):
            img.putpixel((x,y),(color))
        if math.cos(float(y+inc**3)) >= math.cos(float(x+inc)):
            img.putpixel((x,y),(colors))
        #if math.cos(float(x+inc**3))+ math.cos(float(y+inc**2))==0:
        if (math.cos(float(x))+ math.cos(float(y**2))) >0 and (math.cos(float(x))+ math.cos(float(y**2)))<.21:
            img.putpixel((x,y),(colorw))             
            
            
img.save('junk/denim2l.jpg')
img
        

#Note r g b values are 0, 255,0* 
from PIL import Image
import math
inc = 0
TOT = []
w = 720
h = 480
img = Image.new('RGB', [w,h], 0x000000)
color = (0, 0, 55)
colors = (250, 25, 255)
colorw = (255, 225, 0)
for x in range(w):
    for y in range(h):
        #print x,y
        inc = inc+1
        if math.cos(float(x+inc)) >= math.cos(float(y+inc**2)):
            img.putpixel((x,y),(color))
        if math.cos(float(x+inc**3)) >= math.cos(float(y+inc**2)):
            img.putpixel((x,y),(colors))
        #if math.cos(float(x+inc**3))+ math.cos(float(y+inc**2))==0:
        if (math.cos(float(x))+ math.cos(float(y))) >-.02 and (math.cos(float(x))+ math.cos(float(y)))<.085:
            img.putpixel((x,y),(colorw))
img.save('junk/denim2r.jpg')
img
# if (math.cos(float(x))+ math.cos(float(y))) >-.25 and (math.cos(float(x))+ math.cos(float(y)))<.25:
# if (math.cos(float(x))+ math.cos(float(y))) >-.05 and (math.cos(float(x))+ math.cos(float(y)))<.05:
# if (math.cos(float(x))+ math.cos(float(y))) >-.015 and (math.cos(float(x))+ math.cos(float(y)))<.015:
# if (math.cos(float(x))+ math.cos(float(y))) >-.02 and (math.cos(float(x))+ math.cos(float(y)))<.085:

#Note r g b values are 0, 255,0* 
from PIL import Image
import math
inc = 0
TOT = []
w = 720
h= 430
img = Image.new('RGB', [w,h], 0x000000)
color = (0, 0, 55)
colors = (50, 25, 255)
colorw = (255, 225, 0)
for x in range(w):
    for y in range(h):
        #print x,y
        inc = inc+1
        if math.cos(float(x+inc)) >= math.cos(float(y+inc**2)):
            img.putpixel((x,y),(color))
        if math.cos(float(x+inc**3)) >= math.cos(float(y+inc**2)):
            img.putpixel((x,y),(colors))
        #if math.cos(float(x+inc**3))+ math.cos(float(y+inc**2))==0:
        if (math.cos(float(x))+ math.cos(float(y))) >-.015 and (math.cos(float(x))+ math.cos(float(y)))<.015:
            img.putpixel((x,y),(colorw))
img.save('junk/denim2B.jpg')
img
# if (math.cos(float(x))+ math.cos(float(y))) >-.25 and (math.cos(float(x))+ math.cos(float(y)))<.25:
# if (math.cos(float(x))+ math.cos(float(y))) >-.05 and (math.cos(float(x))+ math.cos(float(y)))<.05:
# if (math.cos(float(x))+ math.cos(float(y))) >-.015 and (math.cos(float(x))+ math.cos(float(y)))<.015:
# if (math.cos(float(x))+ math.cos(float(y))) >-.02 and (math.cos(float(x))+ math.cos(float(y)))<.085:

#Note r g b values are 0, 255,0* 
from PIL import Image
import math
inc = 0
img = Image.new('RGB', [720,480], 0x000000)
color = (50, 255, 255)
colors = (50, 25, 255)
for x in range(720):
    for y in range(480):
        #print x,y
        inc = inc+1
        if math.cos(float(x+inc)) >= math.cos(float(y+inc**2)):
            img.putpixel((x,y),(color))
        if math.cos(float(x+inc**3)) >= math.cos(float(y+inc**2)):
            img.putpixel((x,y),(colors))       
img.save('junk/denim03.jpg')
img
        

import os
import os.path
title = 'Image-Stuff-Files/ipynb-list.txt'
f= open(title,'a')
f.close()
count=0
for dirpath, dirnames, filenames in os.walk('/home/conda'):
    for filename in [f for f in filenames if f.endswith('.ipynb')]:
        count=count+1
        Path = os.path.join(dirpath, filename)
        with open(title, 'a') as outfile:
            path = Path+'\n'
            outfile.write(path)

%%writefile Image-Stuff-Files/NED
#!/usr/local/bin/python
import sys
import sqlite3
conn = sqlite3.connect("/home/TEMP/Databases/NED.db")
conn.text_factory = str
c = conn.cursor()
if len(sys.argv) < 3:
    print "\n*****************************************"
    print "Not enough options were passed."     
    print "NED requires 2 arguments. the first -H , -R , -I , -D or -S .\nThe second can be a period."
    print "If printing the database -T also add a filename of your choice ( no quotes required ):"
    print " Example: NED -T Data2Text.txt"   
    print "If wanting to read all entries use -R . (use the period)" 
    print "even use the period with help.  -H .   must be entered."
    print "*****************************************\n"
    sys.exit()
mod = sys.argv[1]
def create():
    import sqlite3
    conn = sqlite3.connect("/home/TEMP/Databases/NED.db")
    conn.text_factory = str
    c = conn.cursor()
    c.execute("CREATE VIRTUAL TABLE PROJECT using FTS4 (input)")
    conn.commit()
    text = "Database Created"
    return text

def insert(data,conn=conn, c=c):
    c.execute("INSERT into PROJECT values (?)", (data,))
    for row in c.execute("SELECT ROWID,* FROM PROJECT ORDER BY ROWID DESC LIMIT 1"):
        print "\nPOST VERIFIED:\n",row[0],row[1]
    conn.commit()
    conn.close()
    return data

def search(data,conn=conn, c=c):
    for row in c.execute("SELECT ROWID,* FROM PROJECT WHERE input MATCH ?",(data,)):
        print "\nINFO Found Here:\n",row[0],row[1]
    conn.commit()
    conn.close()
    return data

def delete(rowid,conn=conn, c=c):
    c.execute("DELETE FROM PROJECT WHERE rowid = ?", (rowid,))
    conn.commit()
    conn.close()
    text = "ROWID "+rowid+" Deleted"
    return text

def main():
    conn = sqlite3.connect("/home/TEMP/Databases/NED.db")
    conn.text_factory = str
    c = conn.cursor()
    for row in c.execute("SELECT rowid, * FROM PROJECT"):
        print row[0],": ",row[1]
        
def Dsearch():
    conn = sqlite3.connect("/home/TEMP/Databases/NED.db")
    conn.text_factory = str
    search = raw_input("Detail Search: ")
    c = conn.cursor()
    for row in c.execute("SELECT rowid, * FROM PROJECT"):
        if search in row[1]:
            print row[0],": ",row[1] 

def prtmain(filename):
    fn = open(filename, "w")
    conn = sqlite3.connect("/home/TEMP/Databases/NED.db")
    conn.text_factory = str
    c = conn.cursor()
    for row in c.execute("SELECT rowid, * FROM PROJECT"):
        TEXT = "id:"+str(row[0])+"\n"+str(row[1])
        TEXT = str(TEXT)
        TEXT = TEXT.replace('\\n','\n')
        TEXT = "".join(TEXT)
        fn.write(TEXT+'\n----\n')

def HELP():
    TXT = """
    USE: NED argv[1] argv[2]
    argv[1] sets the mod:
    -I insert / -D delete / -R read / -H help
    examples:
    Notice the entry is in parenthese.
    -I  to insert "STUFF to be inserted"
    NED -I "STUFF to be inserted"
    -D to delete where rowid is 3
    NED -D 3
    Notice the period after -R . 
    -R . read all
    To search for the term "current project"
    NED -S current project
    -S "current project"
    To 'EXACT DETAIL' search" Notice the period after -DS
    NED -DS .
    -H help on options
    NED -H .
    """
    print TXT

if mod == "-H" or mod == "h":
    HELP()        
if mod == "-R":
    main()
if mod == "-I":
    data = sys.argv[2]
    insert(data)
if mod == "-D":
    rowid = sys.argv[2]
    delete(rowid) 
if mod == "-S":
    data = sys.argv[2]
    search(data)
if mod == "-DS":
    print ("Exact Text SEARCH.")
    Dsearch()
if mod == "-T":
    filename = sys.argv[2]
    prtmain(filename)
if mod == "-CREATE":
    create()
    print create
else:
    print "_________________\n"
    print sys.argv[2],"Command Completed"
    

%%writefile Image-Stuff-Files/GraphicJunkdb.py
def getcolumns(database='db.sqlite3'):
    import sqlite3
    conn = sqlite3.connect(database)
    c = conn.cursor()
    print ('Verify All Data')
    print("----------------")
    cursor01 = c.execute('select * from pixel')
    #cursor.description is description of columns
    names1 = list(map(lambda x: x[0], cursor01.description))
    print("Table: pixel         Columns:",names1)
    cursor02 = c.execute('select * from tupples')
    names2 = list(map(lambda x: x[0], cursor02.description))
    print("Table: tupples       Columns:",names2)
    cursor03 = c.execute('select * from alpha')
    names3 = list(map(lambda x: x[0], cursor03.description))
    print("Table: alpha         Columns:",names3)
    cursor04 = c.execute('select * from XY')
    names4 = list(map(lambda x: x[0], cursor04.description))
    print("Table: XY            Columns:",names4)
    cursor05 = c.execute('select * from NOTES')
    names5 = list(map(lambda x: x[0], cursor05.description))
    print("Table: notes          Columns:",names5)
    cursor06 = c.execute('select * from CODE')
    names6 = list(map(lambda x: x[0], cursor06.description))
    print("Table: CODE         Columns:",names6)
    cursor07 = c.execute('select * from association')
    names7 = list(map(lambda x: x[0], cursor07.description))
    print("Table: association         Columns:",names7)    
    
if __name__ == "__main__":
    getcolumns()
    

print "finished"

!sudo locate opencv.pc

!export PKG_CONFIG_PATH=/home/jack/anaconda2/envs/py35/lib/pkgconfig/opencv.pc

g++ pkg-config --cflags --libs opencv controlBlend.cpp -o controlBlend


!g++ controlBlend.cpp -o controlBlend '/home/jack/anaconda2/envs/py35/lib/pkgconfig/opencv --cflags --libs'

!g++ controlBlend.cpp -o controlBlend `pkg-config opencv --cflags --libs`

%%writefile controlBlend.cpp
#include <cv.h>
#include <highgui.h>

using namespace cv;

/// Global Variables
const int alpha_slider_max = 100;
int alpha_slider;
double alpha;
double beta;

/// Matrices to store images
Mat src1;
Mat src2;
Mat dst;

/**
 * @function on_trackbar
 * @brief Callback for trackbar
 */
void on_trackbar( int, void* )
{
 alpha = (double) alpha_slider/alpha_slider_max ;
 beta = ( 1.0 - alpha );

 addWeighted( src1, alpha, src2, beta, 0.0, dst);

 imshow( "Linear Blend", dst );
}

int main( int argc, char** argv )
{
 /// Read image ( same size, same type )
 src1 = imread("images/hicks01.jpg");
 src2 = imread("images/hicks02.jpg");

 if( !src1.data ) { printf("Error loading src1 \n"); return -1; }
 if( !src2.data ) { printf("Error loading src2 \n"); return -1; }

 /// Initialize values
 alpha_slider = 0;

 /// Create Windows
 namedWindow("Linear Blend", 1);

 /// Create Trackbars
 char TrackbarName[50];
 sprintf( TrackbarName, "Alpha x %d", alpha_slider_max );

 createTrackbar( TrackbarName, "Linear Blend", &alpha_slider, alpha_slider_max, on_trackbar );

 /// Show some stuff
 on_trackbar( alpha_slider, 0 );

 /// Wait until user press some key
 waitKey(0);
 return 0;
}



!./searchBlend

!g++ searchBlend.cpp -o searchBlend `pkg-config opencv --cflags --libs`

%%writefile searchBlend.cpp
#include <cv.h>
#include <highgui.h>

using namespace cv;

/// Global Variables
const int alpha_slider_max = 100;
int alpha_slider;
double alpha;
double beta;

/// Matrices to store images
Mat src1;
Mat src2;
Mat dst;

/**
 * @function on_trackbar
 * @brief Callback for trackbar
 */
void on_trackbar( int, void* )
{
 alpha = (double) alpha_slider/alpha_slider_max ;
 beta = ( 1.0 - alpha );

 addWeighted( src1, alpha, src2, beta, 0.0, dst);

 imshow( "Linear Blend", dst );
}

int main( int argc, char** argv )
{
 /// Read image ( same size, same type )
 src1 = imread("search/01.jpg");
 src2 = imread("search/02.jpg");

 if( !src1.data ) { printf("Error loading src1 \n"); return -1; }
 if( !src2.data ) { printf("Error loading src2 \n"); return -1; }

 /// Initialize values
 alpha_slider = 0;

 /// Create Windows
 namedWindow("Linear Blend", 1);

 /// Create Trackbars
 char TrackbarName[50];
 sprintf( TrackbarName, "Alpha x %d", alpha_slider_max );

 createTrackbar( TrackbarName, "Linear Blend", &alpha_slider, alpha_slider_max, on_trackbar );

 /// Show some stuff
 on_trackbar( alpha_slider, 0 );

 /// Wait until user press some key
 waitKey(0);
 return 0;
}

!ls 



%%writefile showme.cpp
#include <cv.h>
#include <highgui.h>
#include <iostream>
using namespace cv;
using namespace std;
int main(int argc,char **argv)
{
   Mat image;
   image = imread(argv[1],1);

   if(argc != 2 || !image.data)
   {
       cout << "No image data\n";
       return -1;
   }

   namedWindow("Image Viewer",CV_WINDOW_AUTOSIZE);
   imshow("Image Viewer",image);
   waitKey(0);
   return 0;
}

# Compile the Image Viewer below  showme.cpp
!g++ showme.cpp -o showme `pkg-config opencv --cflags --libs`

#The showme file was made executable "  chmod a+x showme "

!chmod a+x showme

# I wantedto use it from all directories
# this copies the showme file to ' /usr/local/bin '

!cp showme /usr/local/bin

!mkdir images

#retrieve a public domainimage from Wiki and name it face.jpg
!wget -O images/face.jpg https://upload.wikimedia.org/wikipedia/commons/3/33/Arnold_Schwarzenegger_edit%28ws%29.jpg

!showme images/face.jpg



!locate opencv2/core.hpp

/usr/include/opencv4/opencv2/highgui.hpp

#include "opencv2/highgui/highgui.hpp"

%%writefile showme.cpp
#include </usr/lib/x86_64-linux-gnu/perl/5.30.0/CORE/cv.h>
#include <highgui.h>
#include <iostream>
using namespace cv;
using namespace std;
int main(int argc,char **argv)
{
   Mat image;
   image = imread(argv[1],1);

   if(argc != 2 || !image.data)
   {
       cout << "No image data\n";
       return -1;
   }

   namedWindow("Image Viewer",CV_WINDOW_AUTOSIZE);
   imshow("Image Viewer",image);
   waitKey(0);
   return 0;
}

!locate CORE/cv.h

%%writefile showme.cpp
#include </usr/lib/x86_64-linux-gnu/perl/5.30.0/CORE/cv.h>
#include <opencv4/opencv2/highgui.hpp>
#include </usr/local/include/opencv4/opencv2/core.hpp>
#include <iostream>
using namespace cv;
using namespace std;
int main(int argc,char **argv)
{
   Mat image;
   image = imread(argv[1],1);

   if(argc != 2 || !image.data)
   {
       cout << "No image data\n";
       return -1;
   }

   namedWindow("Image Viewer",CV_WINDOW_AUTOSIZE);
   imshow("Image Viewer",image);
   waitKey(0);
   return 0;
}

%%writefile showme.cpp
#include <cv.h>
#include <highgui.h>
#include <iostream>
using namespace cv;
using namespace std;
int main(int argc,char **argv)
{
   Mat image;
   image = imread(argv[1],1);

   if(argc != 2 || !image.data)
   {
       cout << "No image data\n";
       return -1;
   }

   namedWindow("Image Viewer",CV_WINDOW_AUTOSIZE);
   imshow("Image Viewer",image);
   waitKey(0);
   return 0;
}

!g++ `pkg-config --cflags opencv4` showme.cpp -o showme

# Compile the Image Viewer below  showme.cpp
!g++ showme.cpp -o showme `pkg-config opencv --cflags --libs`

#The showme file was made executable "  chmod a+x showme "

!chmod a+x showme

# I wantedto use it from all directories
# this copies the showme file to ' /usr/local/bin '

!cp showme /usr/local/bin

!mkdir images

#retrieve a public domainimage from Wiki and name it face.jpg
!wget -O images/face.jpg https://upload.wikimedia.org/wikipedia/commons/3/33/Arnold_Schwarzenegger_edit%28ws%29.jpg

!showme images/face.jpg

# Here is a nice Image Blending program written in C++

%%writefile controlBlend.cpp
#include <cv.h>
#include <highgui.h>

using namespace cv;

/// Global Variables
const int alpha_slider_max = 100;
int alpha_slider;
double alpha;
double beta;

/// Matrices to store images
Mat src1;
Mat src2;
Mat dst;

/**
 * @function on_trackbar
 * @brief Callback for trackbar
 */
void on_trackbar( int, void* )
{
 alpha = (double) alpha_slider/alpha_slider_max ;
 beta = ( 1.0 - alpha );

 addWeighted( src1, alpha, src2, beta, 0.0, dst);

 imshow( "Linear Blend", dst );
}

int main( int argc, char** argv )
{
 /// Read image ( same size, same type )
 src1 = imread("images/hicks01.jpg");
 src2 = imread("images/hicks02.jpg");

 if( !src1.data ) { printf("Error loading src1 \n"); return -1; }
 if( !src2.data ) { printf("Error loading src2 \n"); return -1; }

 /// Initialize values
 alpha_slider = 0;

 /// Create Windows
 namedWindow("Linear Blend", 1);

 /// Create Trackbars
 char TrackbarName[50];
 sprintf( TrackbarName, "Alpha x %d", alpha_slider_max );

 createTrackbar( TrackbarName, "Linear Blend", &alpha_slider, alpha_slider_max, on_trackbar );

 /// Show some stuff
 on_trackbar( alpha_slider, 0 );

 /// Wait until user press some key
 waitKey(0);
 return 0;
}

!g++ controlBlend.cpp -o controlBlend `pkg-config opencv --cflags --libs`

# Install minimal prerequisites (Ubuntu 18.04 as reference)
sudo apt update && sudo apt install -y cmake g++ wget unzip
# Download and unpack sources
wget -O opencv.zip https://github.com/opencv/opencv/archive/4.x.zip
unzip opencv.zip
# Create build directory
mkdir -p build && cd build
# Configure
cmake  ../opencv-4.x
# Build
cmake --build .
Build with opencv_contrib
# Install minimal prerequisites (Ubuntu 18.04 as reference)
sudo apt update && sudo apt install -y cmake g++ wget unzip
# Download and unpack sources
wget -O opencv.zip https://github.com/opencv/opencv/archive/4.x.zip
wget -O opencv_contrib.zip https://github.com/opencv/opencv_contrib/archive/4.x.zip
unzip opencv.zip
unzip opencv_contrib.zip
# Create build directory and switch into it
mkdir -p build && cd build
# Configure
cmake -DOPENCV_EXTRA_MODULES_PATH=../opencv_contrib-4.x/modules ../opencv-4.x
# Build
cmake --build .
Detailed process

This section provides more details of the build process and describes alternative methods and tools. Please refer to the OpenCV installation overview tutorial for general installation details and to the OpenCV configuration options reference for configuration options documentation.
Install compiler and build tools

    To compile OpenCV you will need a C++ compiler. Usually it is G++/GCC or Clang/LLVM:
        Install GCC...
        sudo apt install -y g++
        ... or Clang:
        sudo apt install -y clang
    OpenCV uses CMake build configuration tool:
    sudo apt install -y cmake
    CMake can generate scripts for different build systems, e.g. make, ninja:
        Install Make...
        sudo apt install -y make
        ... or Ninja:
        sudo apt install -y ninja-build
    Install tool for getting and unpacking sources:
        wget and unzip...
        sudo apt install -y wget unzip
        ... or git:
        sudo apt install -y git

Download sources

There are two methods of getting OpenCV sources:

    Download snapshot of repository using web browser or any download tool (~80-90Mb) and unpack it...
    wget -O opencv.zip https://github.com/opencv/opencv/archive/4.x.zip
    unzip opencv.zip
    mv opencv-4.x opencv
    ... or clone repository to local machine using git to get full change history (>470Mb):
    git clone https://github.com/opencv/opencv.git
    git -C opencv checkout 4.x

Note
    Snapshots of other branches, releases or commits can be found on the GitHub and the official download page.

Configure and build

    Create build directory:
    mkdir -p build && cd build
    Configure - generate build scripts for the preferred build system:
        For make...
        cmake ../opencv
        ... or for ninja:
        cmake -GNinja ../opencv
    Build - run actual compilation process:
        Using make...
        make -j4
        ... or ninja:
        ninja

Note
    Configure process can download some files from the internet to satisfy library dependencies, connection failures can cause some of modules or functionalities to be turned off or behave differently. Refer to the OpenCV installation overview and OpenCV configuration options reference tutorials for details and full configuration options reference.
    If you experience problems with the build process, try to clean or recreate the build directory. Changes in the configuration like disabling a dependency, modifying build scripts or switching sources to another branch are not handled very well and can result in broken workspace.
    Make can run multiple compilation processes in parallel, -j<NUM> option means "run <NUM> jobs simultaneously". Ninja will automatically detect number of available processor cores and does not need -j option.

Check build results

After successful build you will find libraries in the build/lib directory and executables (test, samples, apps) in the build/bin directory:
ls bin
ls lib

CMake package files will be located in the build root:
ls OpenCVConfig*.cmake
ls OpenCVModules.cmake
Install

Warning
    The installation process only copies files to predefined locations and does minor patching. Installing using this method does not integrate opencv into the system package registry and thus, for example, opencv can not be uninstalled automatically. We do not recommend system-wide installation to regular users due to possible conflicts with system packages.

By default OpenCV will be installed to the /usr/local directory, all files will be copied to following locations:

    /usr/local/bin - executable files
    /usr/local/lib - libraries (.so)
    /usr/local/cmake/opencv4 - cmake package
    /usr/local/include/opencv4 - headers
    /usr/local/share/opencv4 - other files (e.g. trained cascades in XML format)

Since /usr/local is owned by the root user, the installation should be performed with elevated privileges (sudo):
sudo make install

or
sudo ninja install

Installation root directory can be changed with CMAKE_INSTALL_PREFIX configuration parameter, e.g. -DCMAKE_INSTALL_PREFIX=$HOME/.local to install to current user's local directory. Installation layout can be changed with OPENCV_*_INSTALL_PATH parameters. See OpenCV configuration options reference for details.
Generated on Sun Sep 18 2022 01:05:06 for OpenCV by   doxygen 1.8.13 

!locate opencv2/core.hpp

/usr/include/opencv4/opencv2/highgui.hpp

#include "opencv2/highgui/highgui.hpp"

%%writefile showme.cpp
#include </usr/lib/x86_64-linux-gnu/perl/5.30.0/CORE/cv.h>
#include <highgui.h>
#include <iostream>
using namespace cv;
using namespace std;
int main(int argc,char **argv)
{
   Mat image;
   image = imread(argv[1],1);

   if(argc != 2 || !image.data)
   {
       cout << "No image data\n";
       return -1;
   }

   namedWindow("Image Viewer",CV_WINDOW_AUTOSIZE);
   imshow("Image Viewer",image);
   waitKey(0);
   return 0;
}

!locate CORE/cv.h

%%writefile showme.cpp
#include </usr/lib/x86_64-linux-gnu/perl/5.30.0/CORE/cv.h>
#include <opencv4/opencv2/highgui.hpp>
#include </usr/lib/x86_64-linux-gnu/perl/5.30.0/CORE/cv.h>
#include <iostream>
using namespace cv;
using namespace std;
int main(int argc,char **argv)
{
   Mat image;
   image = imread(argv[1],1);

   if(argc != 2 || !image.data)
   {
       cout << "No image data\n";
       return -1;
   }

   namedWindow("Image Viewer",CV_WINDOW_AUTOSIZE);
   imshow("Image Viewer",image);
   waitKey(0);
   return 0;
}

%%writefile showme.cpp
#include <cv.h>
#include <highgui.hhp>
#include <iostream>
using namespace cv;
using namespace std;
int main(int argc,char **argv)
{
   Mat image;
   image = imread(argv[1],1);

   if(argc != 2 || !image.data)
   {
       cout << "No image data\n";
       return -1;
   }

   namedWindow("Image Viewer",CV_WINDOW_AUTOSIZE);
   imshow("Image Viewer",image);
   waitKey(0);
   return 0;
}

!locate highgui.h

!g++ `pkg-config --cflags opencv4` showme.cpp -o showme

# Compile the Image Viewer below  showme.cpp
!g++ showme.cpp -o showme `pkg-config opencv --cflags --libs`

#The showme file was made executable "  chmod a+x showme "

!chmod a+x showme

# I wantedto use it from all directories
# this copies the showme file to ' /usr/local/bin '

!cp showme /usr/local/bin

!mkdir images

#retrieve a public domainimage from Wiki and name it face.jpg
!wget -O images/face.jpg https://upload.wikimedia.org/wikipedia/commons/3/33/Arnold_Schwarzenegger_edit%28ws%29.jpg

!showme images/face.jpg

# Here is a nice Image Blending program written in C++

%%writefile controlBlend.cpp
#include <cv.h>
#include <highgui.h>

using namespace cv;

/// Global Variables
const int alpha_slider_max = 100;
int alpha_slider;
double alpha;
double beta;

/// Matrices to store images
Mat src1;
Mat src2;
Mat dst;

/**
 * @function on_trackbar
 * @brief Callback for trackbar
 */
void on_trackbar( int, void* )
{
 alpha = (double) alpha_slider/alpha_slider_max ;
 beta = ( 1.0 - alpha );

 addWeighted( src1, alpha, src2, beta, 0.0, dst);

 imshow( "Linear Blend", dst );
}

int main( int argc, char** argv )
{
 /// Read image ( same size, same type )
 src1 = imread("images/hicks01.jpg");
 src2 = imread("images/hicks02.jpg");

 if( !src1.data ) { printf("Error loading src1 \n"); return -1; }
 if( !src2.data ) { printf("Error loading src2 \n"); return -1; }

 /// Initialize values
 alpha_slider = 0;

 /// Create Windows
 namedWindow("Linear Blend", 1);

 /// Create Trackbars
 char TrackbarName[50];
 sprintf( TrackbarName, "Alpha x %d", alpha_slider_max );

 createTrackbar( TrackbarName, "Linear Blend", &alpha_slider, alpha_slider_max, on_trackbar );

 /// Show some stuff
 on_trackbar( alpha_slider, 0 );

 /// Wait until user press some key
 waitKey(0);
 return 0;
}

!g++ controlBlend.cpp -o controlBlend `pkg-config opencv --cflags --libs`

# Install minimal prerequisites (Ubuntu 18.04 as reference)
sudo apt update && sudo apt install -y cmake g++ wget unzip
# Download and unpack sources
wget -O opencv.zip https://github.com/opencv/opencv/archive/4.x.zip
unzip opencv.zip
# Create build directory
mkdir -p build && cd build
# Configure
cmake  ../opencv-4.x
# Build
cmake --build .
Build with opencv_contrib
# Install minimal prerequisites (Ubuntu 18.04 as reference)
sudo apt update && sudo apt install -y cmake g++ wget unzip
# Download and unpack sources
wget -O opencv.zip https://github.com/opencv/opencv/archive/4.x.zip
wget -O opencv_contrib.zip https://github.com/opencv/opencv_contrib/archive/4.x.zip
unzip opencv.zip
unzip opencv_contrib.zip
# Create build directory and switch into it
mkdir -p build && cd build
# Configure
cmake -DOPENCV_EXTRA_MODULES_PATH=../opencv_contrib-4.x/modules ../opencv-4.x
# Build
cmake --build .
Detailed process

This section provides more details of the build process and describes alternative methods and tools. Please refer to the OpenCV installation overview tutorial for general installation details and to the OpenCV configuration options reference for configuration options documentation.
Install compiler and build tools

    To compile OpenCV you will need a C++ compiler. Usually it is G++/GCC or Clang/LLVM:
        Install GCC...
        sudo apt install -y g++
        ... or Clang:
        sudo apt install -y clang
    OpenCV uses CMake build configuration tool:
    sudo apt install -y cmake
    CMake can generate scripts for different build systems, e.g. make, ninja:
        Install Make...
        sudo apt install -y make
        ... or Ninja:
        sudo apt install -y ninja-build
    Install tool for getting and unpacking sources:
        wget and unzip...
        sudo apt install -y wget unzip
        ... or git:
        sudo apt install -y git

Download sources

There are two methods of getting OpenCV sources:

    Download snapshot of repository using web browser or any download tool (~80-90Mb) and unpack it...
    wget -O opencv.zip https://github.com/opencv/opencv/archive/4.x.zip
    unzip opencv.zip
    mv opencv-4.x opencv
    ... or clone repository to local machine using git to get full change history (>470Mb):
    git clone https://github.com/opencv/opencv.git
    git -C opencv checkout 4.x

Note
    Snapshots of other branches, releases or commits can be found on the GitHub and the official download page.

Configure and build

    Create build directory:
    mkdir -p build && cd build
    Configure - generate build scripts for the preferred build system:
        For make...
        cmake ../opencv
        ... or for ninja:
        cmake -GNinja ../opencv
    Build - run actual compilation process:
        Using make...
        make -j4
        ... or ninja:
        ninja

Note
    Configure process can download some files from the internet to satisfy library dependencies, connection failures can cause some of modules or functionalities to be turned off or behave differently. Refer to the OpenCV installation overview and OpenCV configuration options reference tutorials for details and full configuration options reference.
    If you experience problems with the build process, try to clean or recreate the build directory. Changes in the configuration like disabling a dependency, modifying build scripts or switching sources to another branch are not handled very well and can result in broken workspace.
    Make can run multiple compilation processes in parallel, -j<NUM> option means "run <NUM> jobs simultaneously". Ninja will automatically detect number of available processor cores and does not need -j option.

Check build results

After successful build you will find libraries in the build/lib directory and executables (test, samples, apps) in the build/bin directory:
ls bin
ls lib

CMake package files will be located in the build root:
ls OpenCVConfig*.cmake
ls OpenCVModules.cmake
Install

Warning
    The installation process only copies files to predefined locations and does minor patching. Installing using this method does not integrate opencv into the system package registry and thus, for example, opencv can not be uninstalled automatically. We do not recommend system-wide installation to regular users due to possible conflicts with system packages.

By default OpenCV will be installed to the /usr/local directory, all files will be copied to following locations:

    /usr/local/bin - executable files
    /usr/local/lib - libraries (.so)
    /usr/local/cmake/opencv4 - cmake package
    /usr/local/include/opencv4 - headers
    /usr/local/share/opencv4 - other files (e.g. trained cascades in XML format)

Since /usr/local is owned by the root user, the installation should be performed with elevated privileges (sudo):
sudo make install

or
sudo ninja install

Installation root directory can be changed with CMAKE_INSTALL_PREFIX configuration parameter, e.g. -DCMAKE_INSTALL_PREFIX=$HOME/.local to install to current user's local directory. Installation layout can be changed with OPENCV_*_INSTALL_PATH parameters. See OpenCV configuration options reference for details.
Generated on Sun Sep 18 2022 01:05:06 for OpenCV by   doxygen 1.8.13 

!find ~/ -name '*.py' >>python-files.txt

PYFILE = set()
cnt = 0
files = open("python-files.txt", "r")
for file in files:
    cnt = cnt +1
    if "KEY" not in file and "key" not in file:
        file = file.replace("\n","")
        if cnt < 30: print (file)
        PYFILE.add(file)

print(len (PYFILE))

import random
from random import randint
PYFILE = set()
cnt = 0
files = open("python-files.txt", "r")
for file in files:
    cnt = cnt +1
    if "KEY" not in file and "key" not in file:
        file = file.replace("\n","")
        PYFILE.add(file)
PYFILES = []
for file in PYFILE:
    PYFILES.append(file)        
        
def primary(cnt):
    ind=len(PYFILES)
    IND = randint(0,ind)
    quotes = open(PYFILES[IND], errors='replace').readlines()
    #quotes = f.readlines()
    try:
        quote = []
        sampling = random.sample(quotes, 6)
        for sample in sampling:
            if len(sample)>3:
                #sample = sample.replace("\"","'")
                #sample = sample.replace("\n","")
                quote.append(sample)
        #print("___________________")
        return quote
    except:
        pass
txtout = open("outPUT.txt","a")
for cnt in range(0,2000):
        text = primary(cnt)
        if len(str(text))>10:
            for samp in text:
                #print(samp)
                if len(samp[:83])<84:
                    txtout.write(samp[:83])
        txtout.write("\nXXXXX")    
            


txtout.close()



#%%writefile randtext.py
from random import randint
import re
"""
Create a text file called outPUT.txt
break it into sections you woul like to return with XXXXX
That will split the file into segments.
Those segments will randomly be chosen and returned.
example:
XXXXX        cmd.force = True
                          infiles=1, outfile='', func='func', args=())
        cmd.make_file(infiles='in', outfile='out', func='func', args=())
        cmd.ensure_dirname('option1')
        # making sure execute gets called properly

XXXXX
XXXXX                else:
        __getattr__ = __setattr__ = lambda self, *_: report()
            except messaging.JsonIOError as exc:
    @property

XXXXXdef replace_types(type_: Any, type_map: Mapping[Any, Any]) -> Any:
    # Setting the return type as Type[Any] instead of Type[BaseModel] prevents PyCh                model_name,
    return type_map.get(type_, type_)
            passed to `cls` as type variables.

XXXXX        ValidationFailure(func=mac_address, args={'value': '00:00:00:00:00'})
        >>> mac_address('00:00:00:00:00')
    Examples::

XXXXX
"""
def randTXT():
    textout = open("outPUT.txt","r").read()
    out = str(textout).split("XXXXX")
    num = len(out)-1
    ID = randint(0,num)
    STr = out[ID]
    if len(STr)<10:randTXT()
    STr = re.sub(' +', ' ', STr)
    return STr


from randtext import randTXT
STR = randTXT()
print (STR)

import random
from random import randint
PYFILE = set()
cnt = 0
files = open("python-files.txt", "r")
for file in files:
    cnt = cnt +1
    if "KEY" not in file and "key" not in file:
        file = file.replace("\n","")
        PYFILE.add(file)
PYFILES = []
for file in PYFILE:
    PYFILES.append(file)        
        
def primary(cnt):
    ind=len(PYFILES)
    IND = randint(0,ind)
    f = open(PYFILES[IND])
    quotes = f.readlines()
    f.close()
    try:
        quote = []
        sampling = random.sample(quotes, 6)
        for sample in sampling:
            if len(sample)>3:
                #sample = sample.replace("\"","\"")
                sample = sample.replace("\n","")
                quote.append(sample)
        #print("___________________")
        return quote
    except:
        pass
txtout = open("outPUT.txt","a")
for cnt in range(0,1000):
        text = primary(cnt)
        if len(str(text))>10:
            for samp in text:
                #print(samp)
                txtout.write("\""+samp[:83]+"\",\n")
            #print("-------------------------")
            txtout.write("],\n[")

txtout()

ind=len(PYFILES)
IND = randint(0,ind)
PYFILES[IND]

PYFILES = []
for file in PYFILE:
    PYFILES.append(file)

test = "<https://books.google.com/ngrams/graph?content=canceled%2Ccancelled&year_start=1800&year_end=2000&corpus=18&smoothing=3&share=&direct_url=t1%3B%2Ccancele"

print(test[:83])




Quit often while experimenting your notebook can accumulate a tremedous amount of memory in cache files.
Sometime you just want to clear all variables to start over in any case the following couple of cells 
show you how to accomplish 'reset' 

%reset

# References
https://progzoo.net/wiki/Python:Filtering_an_Array
http://www.scipy-lectures.org/packages/scikit-image/  
http://effbot.org/imagingbook/image.htm    
    
a = np.array([[1, 2, 0, 0],

from PIL import Image
import random
data = [random.randint(0, 1) for i in range(612 * 612)]
img = Image.new('1', (612, 612))
img.putdata(data)
img.save('junk/my.png')
img.show()



import cv2
  
# path
path = "/home/jack/Pictures/face.png"
  
# Using cv2.imread() method
img = cv2.imread(path)



# To get image shape ( dimensions and channels )
import numpy as np
from scipy import ndimage
import cv2

im = cv2.imread("/home/jack/Pictures/face.png")
im.shape

!ls

from PIL import Image
imN = cv2.imread("/home/jack/Pictures/face.png")

cv2.imwrite('/home/jack/Pictures/face_numpy.jpg', imN)
#cv2.imshow("imN", imN)
#cv2.waitKey(0)
#cv2.destroyAllWindows()

from PIL import Image
imP = Image.open('/home/jack/Pictures/face_numpy.jpg')
n_imp = imP.resize((300, 350), Image.NEAREST)
n_imp.save('/home/jack/Pictures/face_300.jpg')
n_imp

from PIL import Image
from io import StringIO
imP = Image.open('/home/jack/Pictures/face_300.jpg')
rgb2xyz = (
    0.412453, 0.357580, 0.180423, 0,
    0.212671, 0.715160, 0.072169, 0,
    0.019334, 0.119193, 0.950227, 0 )
out = imP.convert("RGB", rgb2xyz)

out

# Clipping a gray image
import numpy as np
import cv2
from skimage.feature import greycomatrix
im = cv2.imread("/home/jack/Pictures/face_300.jpg")
im2 = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
clipped = np.clip(im2, a_min=100, a_max=200)


cv2.imwrite('/home/jack/Pictures/clipped-face_numpy.jpg', clipped)
view = Image.open("/home/jack/Pictures/clipped-face_numpy.jpg")
view

from PIL import Image
from io import StringIO
imP = Image.open('/home/jack/Pictures/face_300.jpg')
rgb2xyz = (
     0.0, 0.0, 0.0, 0,
     0.1, 0.8, 0.1, 0,
     0.0, 0.0, 0.0, 0 )
out = imP.convert("RGB", rgb2xyz)

out

from PIL import Image
from io import StringIO
imP = Image.open('/home/jack/Pictures/face_300.jpg')
rgb2xyz = (
     0.1, 0.8, 0.1, 0,
     0.0, 0.0, 0.0, 0,
     0.0, 0.0, 0.0, 0 )
out = imP.convert("RGB", rgb2xyz)

out

from PIL import Image
from io import StringIO
imP = Image.open('/home/jack/Pictures/face_300.jpg')
rgb2xyz = (
     0.0, 0.0, 0.0, 0,
     0.0, 0.0, 0.0, 0,
     0.1, 0.8, 0.1, 0 )
out = imP.convert("RGB", rgb2xyz)

out

# CONVERT rgb2lab
from PIL import Image
from skimage import color
import numpy as np

# Open the image file
src = Image.open("/home/jack/Pictures/face_300.jpg")

# Attempt to ensure image is RGB
src = src.convert(mode="RGB")

# Create array of image using numpy
srcArray = np.asarray(src)

# Convert array from RGB into Lab
srcArray = color.rgb2lab(srcArray)

# Save
cv2.imwrite("images/test_out.jpg", srcArray)

view = Image.open("images/test_out.jpg")
view

!display images/test_out.jpg

!cp /home/jack/Pictures/face.jpg images/face_300.jpg

# Clipping a color image
import numpy as np
from skimage.feature import greycomatrix
import cv2

im = cv2.imread("images/face_300.jpg")
#im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
clipped = np.clip(im, a_min=80, a_max=250)
clipped


from skimage import io, img_as_float, color, exposure
import numpy as np
import matplotlib.pyplot as plt
img = img_as_float(io.imread('/home/jack/Pictures/face_300.jpg'))

# Isolate paint marks

# Put image into LAB colour space
image_lab = color.rgb2lab(img)
img = exposure.rescale_intensity(img)

# Colours of interest
color_array = np.array([
        [[[255, 255, 0.]]],    # Yellow stuff
        [[[255, 190, 200.]]],    # Pink stuff   
        [[[255, 165, 0.]]],    # Orange stuff
        [[[255, 0, 0.]]],    # Red stuff        
        ])

# Loop through the color array and pick out the colored features
for i in range(0,color_array.ndim):
    # Compute distance between the color of interest and the actual image
    # http://scikit-image.org/docs/dev/api/skimage.color.html#skimage.color.deltaE_cmc
    # "The usual values are kL=2, kC=1 for acceptability"
    distance_color = color.deltaE_ciede2000(color_array[i], image_lab, kL=2, kC=1, kH=0.5)    

    # Normalise distance
    distance_color = exposure.rescale_intensity(distance_color)

    # Mask image
    image_filtered = img.copy()
    image_filtered[distance_color > 0.5] = 0

    # Plot it up
    print ("Filtered to: ", color_array[i])
    f, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(20, 10))
    ax0.imshow(img)
    ax1.imshow(distance_color, cmap='gray')
    ax2.imshow(image_filtered)
    plt.show()

from skimage import color
import matplotlib.pyplot as plt
from skimage.morphology import disk, opening, dilation
from numpy import square
import cv2
img = cv2.imread("/home/jack/Pictures/face_300.jpg")

img_hsv = color.rgb2hsv(img) # Image into HSV colorspace
h = img_hsv[:,:,0] # Hue
s = img_hsv[:,:,1] # Saturation
v = img_hsv[:,:,2] # Value aka Lightness

plt.figure(1, figsize=(15, 15))

plt.subplot(4,2,1); plt.imshow(h, cmap='gray'); plt.title('Hue')
plt.subplot(4,2,2); plt.imshow(s, cmap='gray'); plt.title('Saturation')
plt.subplot(4,2,3); plt.imshow(v, cmap='gray'); plt.title('Value')
plt.tight_layout()

mask = (s > 0.35).astype(np.uint8);  # Thresholding in the Saturation-channel
plt.subplot(4,2,4); plt.imshow(mask); plt.title('mask')

#disk_elem = disk(1) # Remove small regions
#opened = opening(mask, selem=disk_elem)
#plt.subplot(4,2,5); plt.imshow(opened); plt.title('Opened mask')

#square_elem = square(2) # rejoin colored features
#dilated = dilation(opened, selem=square_elem)
#plt.subplot(4,2,6); plt.imshow(dilated); plt.title('Opened mask')

img2 = img.copy()
#img2[dilated.astype(bool), :] = 0; # Set the pixels to zero, where 
plt.subplot(4,2,7); plt.imshow(img2); plt.title('Final Image') 


from numpy import square

import matplotlib.pyplot as plt
import numpy as np
import matplotlib.image as mpimg
import scipy.ndimage.filters as filter
import cv2

kernel_edge_detect1 = np.array([[1.,0.,-1.],
                                [0.,0.,0.],
                                [-1.,0.,1.]])

kernel_edge_detect2 = np.array([[0.,1.,0.],
                                [1.,-4.,1.],
                                [0.,1.,0.]])

kernel_edge_detect3 = np.array([[-1.,-1.,-1.],
                                [-1.,8.,-1.],
                                [-1.,-1.,-1.]])

kernel_sharpen = np.array([[0.,-1.,0.],
                           [-1.,5.,-1.],
                           [0.,-1.,0.]])

kernel_sharpen2 = np.array([[-1.,-1.,-1.],
                           [-1.,9.,-1.],
                           [-1.,-1.,-1.]])

kernel_blur = np.array([[1.,1.,1.],
                        [1.,2.,1.],
                        [1.,1.,1.]])


kernel_sh = np.array([ [-1,0,2,0,-1],
                    [-1,0,2,0,-1],
                    [-1,0,2,0,-1],
                    [-1,0,2,0,-1],
                    [-1,0,2,0,-1] ],np.float32)

kernel_shr = np.load('numpyfilters/sharpen_filter.npy')


#image=mpimg.imread('images/face_300.jpg')[:,:,0]
image = cv2.imread('images/face_300.jpg')
fig = plt.figure(figsize=(28, 13), dpi=100)


image2 = cv2.filter2D(image, -1, kernel_edge_detect1)
newimage = cv2.filter2D(image, -1, kernel_edge_detect2)
flipped_kernel = cv2.filter2D(image, -1, kernel_edge_detect3)
poorimage = cv2.filter2D(image, -1, kernel_shr)
#plt.imshow(imGray, cmap="gray")



left  = None  # the left side of the subplots of the figure
right = None    # the right side of the subplots of the figure
bottom = None   # the bottom of the subplots of the figure
top = None      # the top of the subplots of the figure
wspace = None   # the amount of width reserved for blank space between subplots
hspace = None   # the amount of height reserved for white space between subplots
# These two can be called on 'fig' instead of 'plt' too
plt.subplots_adjust(left=left, bottom=bottom, right=right, top=top,
                wspace=wspace, hspace=hspace)


plt.subplot(2, 2, 1, )
plt.imshow(image2,cmap = 'gray')
plt.subplot(2, 2, 2)
plt.imshow(newimage, cmap="gray")
plt.subplot(2, 2, 3)

flipped_kernel2 = cv2.cvtColor(flipped_kernel, cv2.COLOR_BGR2RGB)
plt.imshow(flipped_kernel2, cmap="gray")
plt.subplot(2, 2, 4)
plt.title("RGB")
poorimage2 = cv2.cvtColor(poorimage, cv2.COLOR_BGR2RGB)
plt.imshow(poorimage2, cmap="gray")

plt.show()




Colormap RGB is not recognized. Possible values are: Accent, Accent_r, Blues, Blues_r, BrBG, BrBG_r, BuGn, 
    BuGn_r, BuPu, BuPu_r, CMRmap, CMRmap_r, Dark2, Dark2_r, GnBu, GnBu_r, Greens, Greens_r, Greys, Greys_r, 
    OrRd, OrRd_r, Oranges, Oranges_r, PRGn, PRGn_r, Paired, Paired_r, Pastel1, Pastel1_r, Pastel2, Pastel2_r, 
    PiYG, PiYG_r, PuBu, PuBuGn, PuBuGn_r, PuBu_r, PuOr, PuOr_r, PuRd, PuRd_r, Purples, Purples_r, RdBu, 
    RdBu_r, RdGy, RdGy_r, RdPu, RdPu_r, RdYlBu, RdYlBu_r, RdYlGn, RdYlGn_r, Reds, Reds_r, Set1, Set1_r, 
    Set2, Set2_r, Set3, Set3_r, Spectral, Spectral_r, Vega10, Vega10_r, Vega20, Vega20_r, Vega20b, 
    Vega20b_r, Vega20c, Vega20c_r, Wistia, Wistia_r, YlGn, YlGnBu, YlGnBu_r, YlGn_r, YlOrBr, YlOrBr_r, 
    YlOrRd, YlOrRd_r, afmhot, afmhot_r, autumn, autumn_r, binary, binary_r, bone, bone_r, brg, brg_r, 
    bwr, bwr_r, cool, cool_r, coolwarm, coolwarm_r, copper, copper_r, cubehelix, cubehelix_r, flag, 
    flag_r, gist_earth, gist_earth_r, gist_gray, gist_gray_r, gist_heat, gist_heat_r, gist_ncar, gist_ncar_r, 
    gist_rainbow, gist_rainbow_r, gist_stern, gist_stern_r, gist_yarg, gist_yarg_r, gnuplot, gnuplot2, 
    gnuplot2_r, gnuplot_r, gray, gray_r, hot, hot_r, hsv, hsv_r, inferno, inferno_r, jet, jet_r, magma, 
    magma_r, nipy_spectral, nipy_spectral_r, ocean, ocean_r, pink, pink_r, plasma, plasma_r, prism, 
    prism_r, rainbow, rainbow_r, seismic, seismic_r, spectral, spectral_r, spring, spring_r, summer, 
    summer_r, tab10, tab10_r, tab20, tab20_r, tab20b, tab20b_r, tab20c, tab20c_r, terrain, terrain_r, 
    viridis, viridis_r, winter, winter_r

import matplotlib.pyplot as plt
import numpy as np
import matplotlib.image as mpimg
import scipy.ndimage.filters as filter
import cv2

def normalize(matrix):
    sum = np.sum(matrix)
    if sum > 0.:
        return matrix / sum
    else:
        return matrix

def neighbors(r,c,supermatrix): 
    m = supermatrix[r:r+3,c:c+3] 
    return m

def convolve(n,kernel):
    sum = 0
    for (rr,cc),value in np.ndenumerate(n):
        sum += n[rr,cc] * kernel[rr,cc]

    return sum % 255

def poor_mans_convolve(matrix,super,kernel,shape):
    result = np.ndarray(shape,dtype=np.float)

    for (r,c),value in np.ndenumerate(matrix):
        n = neighbors(r,c,super)
        result[r,c] = convolve(n,kernel)

    return result



kernel_edge_detect1 = np.array([[1.,0.,-1.],
                                [0.,0.,0.],
                                [-1.,0.,1.]])

kernel_edge_detect2 = np.array([[0.,1.,0.],
                                [1.,-4.,1.],
                                [0.,1.,0.]])

kernel_edge_detect3 = np.array([[-1.,-1.,-1.],
                                [-1.,8.,-1.],
                                [-1.,-1.,-1.]])

kernel_sharpen = np.array([[0.,-1.,0.],
                           [-1.,5.,-1.],
                           [0.,-1.,0.]])

kernel_sharpen2 = np.array([[-1.,-1.,-1.],
                           [-1.,9.,-1.],
                           [-1.,-1.,-1.]])

kernel_blur = np.array([[1.,1.,1.],
                        [1.,2.,1.],
                        [1.,1.,1.]])


kernel_sh = np.array([ [-1,0,2,0,-1],
                    [-1,0,2,0,-1],
                    [-1,0,2,0,-1],
                    [-1,0,2,0,-1],
                    [-1,0,2,0,-1] ],np.float32)

kernel_shr = np.load('numpyfilters/sharpen_filter.npy')

kernel_list = [kernel_edge_detect1,kernel_edge_detect2,kernel_edge_detect3,kernel_sharpen,kernel_sharpen2,kernel_blur]
title_list = ['edge-detect1','edge-detect2','edge-detect3','sharpen1','sharpen2','blur']

#image=mpimg.imread('images/face_300.jpg')[:,:,0]
image = cv2.imread('images/face_300.jpg')
fig = plt.figure(figsize=(28, 13), dpi=100)


image2 = cv2.filter2D(image, -1, kernel_edge_detect1)
newimage = cv2.filter2D(image, -1, kernel_edge_detect2)
flipped_kernel = cv2.filter2D(image, -1, kernel_edge_detect3)
poorimage = cv2.filter2D(image, -1, kernel_shr)
#plt.imshow(imGray, cmap="gray")
plt.subplot(2, 2, 1)
plt.imshow(image2, cmap="gray")
plt.subplot(2, 2, 2)
plt.imshow(newimage, cmap="gray")
plt.subplot(2, 2, 3)
plt.imshow(flipped_kernel, cmap="gray")
plt.subplot(2, 2, 4)
plt.title("RGB")
poorimage2 = cv2.cvtColor(poorimage, cv2.COLOR_BGR2RGB)
plt.imshow(poorimage2, cmap="gray")
plt.show()

import matplotlib.pyplot as plt

fig = plt.figure()
ax=fig.add_axes([0,0,1,1])
ax.set_axis_off()

im = ax.imshow([[2,3,4,1], [2,4,4,2]], origin="lower", extent=[1,4,2,8])
ax.plot([1,2,3,4], [2,3,4,8], lw=5)

ax.set_aspect('auto')
plt.show()

import matplotlib.pyplot as plt
import numpy as np
import matplotlib.image as mpimg
import scipy.ndimage.filters as filter
i=0
def normalize(matrix):
    sum = np.sum(matrix)
    if sum > 0.:
        return matrix / sum
    else:
        return matrix

def neighbors(r,c,supermatrix): 
    m = supermatrix[r:r+3,c:c+3] 
    return m

def convolve(n,kernel):
    sum = 0
    for (rr,cc),value in np.ndenumerate(n):
        sum += n[rr,cc] * kernel[rr,cc]

    return sum % 255

def poor_mans_convolve(matrix,super,kernel,shape):
    result = np.ndarray(shape,dtype=np.float)

    for (r,c),value in np.ndenumerate(matrix):
        n = neighbors(r,c,super)
        result[r,c] = convolve(n,kernel)

    return result

fig = plt.figure(figsize=(14, 6.5), dpi=100)

kernel_edge_detect1 = np.array([[1.,0.,-1.],
                                [0.,0.,0.],
                                [-1.,0.,1.]])

kernel_edge_detect2 = np.array([[0.,1.,0.],
                                [1.,-4.,1.],
                                [0.,1.,0.]])

kernel_edge_detect3 = np.array([[-1.,-1.,-1.],
                                [-1.,8.,-1.],
                                [-1.,-1.,-1.]])

kernel_sharpen = np.array([[0.,-1.,0.],
                           [-1.,5.,-1.],
                           [0.,-1.,0.]])

kernel_sharpen2 = np.array([[-1.,-1.,-1.],
                           [-1.,9.,-1.],
                           [-1.,-1.,-1.]])

kernel_blur = np.array([[1.,1.,1.],
                        [1.,1.,1.],
                        [1.,1.,1.]])

kernel_list = [kernel_edge_detect1,kernel_edge_detect2,kernel_edge_detect3,kernel_sharpen,kernel_sharpen2,kernel_blur]
title_list = ['edge-detect1','edge-detect2','edge-detect3','sharpen1','sharpen2','blur']

#image=mpimg.imread('images/face_300.jpg')[:,:,0]
image = cv2.imread('images/face_300.jpg', 0)
shape = image.shape
newimage = np.ndarray(shape,dtype=np.float)
poorimage = np.ndarray(shape,dtype=np.float)
supershape = (shape[0] + 2,shape[1] + 2) 
supermatrix = np.zeros(supershape,dtype=np.float)
supermatrix[1:-1,1:-1] = image

imagelist_std_convolve = []
imagelist_poor_convolve = []

fig.add_subplot(4,4,1)
plt.title('Original')
#      plt.imshow(image,cmap=plt.cm.gray)
plt.axis('on')
print(len(kernel_list),i)
kernel_list[i] = normalize(kernel_list[i])
newimage = filter.convolve(image,kernel_list[i],mode='constant', cval=0)
imagelist_std_convolve.append(newimage)
#print 'kernel'
#print kernel_list[i]

print
fig.add_subplot(4,4,i+2)
plt.title(title_list[i])
#      plt.imshow(newimage,cmap=plt.cm.gray)
plt.axis('off')
flipped_kernel = kernel_list[i].copy()
flipped_kernel = np.fliplr(flipped_kernel)
flipped_kernel = np.flipud(flipped_kernel)
flipped_kernel = normalize(flipped_kernel)
poorimage=poor_mans_convolve(image,supermatrix,flipped_kernel,shape)
imagelist_poor_convolve.append(poorimage)
#print 'flipped_kernel'
#print flipped_kernel
#print
#fig.add_subplot(4,4,i+2+6)
#plt.title('poors ' + title_list[i])
#     plt.imshow(poorimage,cmap=plt.cm.gray)
plt.axis("off")
#plt.show()

plt.subplot(2, 2, 1)
plt.imshow(image,cmap=plt.cm.gray)
plt.subplot(2, 2, 2)
plt.imshow(newimage,cmap=plt.cm.gray)
plt.subplot(2, 2, 3)
plt.imshow(flipped_kernel,cmap=plt.cm.gray)
plt.subplot(2, 2, 4)
plt.imshow(poorimage,cmap=plt.cm.gray)
plt.show()





import numpy as np
import matplotlib.pyplot as plt
#from matplotlib.backends.backend_pdf import PdfPages

data = [[  66386,  174296,   75131,  577908,   32015],
        [  58230,  381139,   78045,   99308,  160454],
        [  89135,   80552,  152558,  497981,  603535],
        [  78415,   81858,  150656,  193263,   69638],
        [ 139361,  331509,  343164,  781380,   52269]]
columns = ('Freeze', 'Tornados', 'Flood', 'Quake', 'Hail')
n_rows = len(data)
y_offset = np.array([0.0] * len(columns))
cell_text = []
for row in range(n_rows):
    y_offset = y_offset + data[row]
    cell_text.append(['%1.1f' % (x/1000.0) for x in y_offset])
cell_text = np.array(cell_text)
cell_colors = np.tile(np.ones_like(cell_text,float)[...,None] -0.5
                      ,(1,1,3))
fig = plt.figure()
axes = fig.add_subplot(111)
the_table = axes.table(cellText=cell_text,
                      colLabels=columns,
                        cellColours=cell_colors,
                      loc='center')
#he_table.properties()['celld'][0,0].get_text().set_fontweight(1000)
the_table.auto_set_font_size(False) 
the_table.scale(3, 3) 
the_table.set_fontsize(20)
table_prop = the_table.properties()
#fill the transpose or not, if we need col height or row width respectively.
rows_heights = [[] for i in range(len([cells for cells in 
                                     table_prop['celld'] if cells[1]==0]))]
cols_widths = [[] for i in range(len([cells for cells in 
                                     table_prop['celld'] if cells[0]==0]))]
for cell in table_prop['celld']:
    text = table_prop['celld'][(0,0)]._text._text

    bounds = table_prop['celld'][cell].get_text_bounds(fig.canvas.get_renderer())
    cols_widths[cell[1]].append(bounds[2])
    rows_heights[cell[0]].append(bounds[3])

cols_width = [max(widths) for widths in cols_widths]
rows_height = [max(heights) for heights in rows_heights]
for cell in table_prop['celld']:
    bounds = table_prop['celld'][cell].get_text_bounds(fig.canvas.get_renderer())                                            
    #For a larger image comment out the next line
    table_prop['celld'][cell].set_bounds(*(bounds[:2]+(1.2*cols_width[cell[1]], 1.1*rows_height[cell[0]],)))
plt.axis('off')
plt.show()

from PIL import Image
from io import StringIO
imP = Image.open('images/face_300.jpg')
rgb2xyz = (
     0.2, 0.2, 0.2, 0,
     0.6, 0.6, 0.6, 0,
     0.6, 0.6, 0.6, 0 )
out = imP.convert("RGB", rgb2xyz)

out

import 

import cv2
from PIL import Image

import cv2
from PIL import Image
img = cv2.imread('images/face_300.jpg')
im_color = cv2.applyColorMap(img, cv2.COLORMAP_HSV)
cv2.imwrite('images/face_HSV.png', im_color)
imP = Image.open('images/face_HSV.png')
imP

green = np.uint8([[[0,255,0 ]]])
hsv_green = cv2.cvtColor(green,cv2.COLOR_BGR2HSV)
print hsv_green


!wget -O images/test-color.png http://i.stack.imgur.com/i4sMR.png

# import cv2
import numpy as np
from PIL import Image
#cap = Image.open('images/face_300.jpg')
#cap = cv2.imread('images/hicks-test2.png')
cap = cv2.imread('images/test-color.png')
while(1):
    # Take each frame
    frame = cap
    # Convert BGR to HSV
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    # define range of blue color in HSV
    #lower_blue = np.array([110,50,50])
    #upper_blue = np.array([130,255,255])
    
    #lower_blue = np.array([90,0,0])
    #upper_blue = np.array([255,255,255])
    
    lower_red = np.array([0,0,200])
    upper_red = np.array([255,255,255])
    #lower_red = np.array([50,10,10])
    #upper_red = np.array([255,155,130])
    
    
    

    # Threshold the HSV image to get only blue colors
    mask = cv2.inRange(hsv, lower_red, upper_red)

    # Bitwise-AND mask and original image
    res = cv2.bitwise_and(frame,frame, mask= mask)

    cv2.imshow('frame',frame)
    cv2.imshow('mask',mask)
    cv2.imshow('res',res)
    k = cv2.waitKey(5) & 0xFF
    if k == 27:
        break

cv2.destroyAllWindows()


print [sub for sub in dir(cv2) if sub.startswith('COLORMAP_')]

invert_value = 1
table = np.array([( i * invert_value) for i in np.arange(256)]).astype("uint8")
img0 = cv2.imread('images/face_300.jpg')
cv2.LUT(img0, table)

!ls numpy-filters


!ls images/face_300.jpg

img = cv2.imread('images/face_300.jpg')
MyKernel = np.load('numpyfilters/cv2LUT_HSV.npy')

#im_color = cv2.applyColorMap(img, MyKernel)
cv2.imshow('mapped_image', MyKernel)
#cv2.imwrite('images/face_HSV.png', im_color)
cv2.waitKey(0)

import numpy as np
import cv2
# Image converted to Numpy array and saved as cv2LUT_HSV.npy
invert_value = 1
table = np.array([( i * invert_value) for i in np.arange(256)]).astype("uint8")
img0 = cv2.imread('images/face_HSV.png')
kernel = cv2.LUT(img0, table)

np.save('numpyfilters/cv2LUT_HSV', kernel)    # .npy extension is added if not given
d = np.load('numpyfilters/cv2LUT_HSV.npy')
# Verify image
kernel == d


# Image converted to Numpy array and saved as cv2LUT_HSV.npy
invert_value = 1
table = np.array([( i * invert_value) for i in np.arange(256)]).astype("uint8")
img1 = cv2.imread('images/face_300.jpg')
kernel = cv2.LUT(img1, table)

np.save('numpy-filters/cv2LUT_300', kernel)    # .npy extension is added if not given
e = np.load('numpy-filters/cv2LUT_300.npy')
# Verify image
kernel == e


from PIL import Image

# Image converted to Numpy array and saved as cv2LUT_HSV.npy
invert_value = 1
table = np.array([( i * invert_value) for i in np.arange(256)]).astype("uint8")
img1 = cv2.imread('images/face_300.jpg')
kernel = cv2.LUT(img1, table)



!ls images

import cv2
d = np.load('numpy-filters/cv2LUT_HSV.npy')
d2 = np.load('numpy-filters/cv2LUT_300.npy')
g = d - d2
#im = Image.fromarray(np.uint8(cm.gist_earth(myarray)*255))
#im = Image.fromarray(np.uint8(d*255)
cv2.imwrite("images/numpx2.png", g)
!showme images/numpx2.png



import cv2
d = np.load('numpy-filters/cv2LUT_HSV.npy')
d2 = np.load('numpy-filters/cv2LUT_300.npy')
h = d + d2
#im = Image.fromarray(np.uint8(cm.gist_earth(myarray)*255))
#im = Image.fromarray(np.uint8(d*255)
cv2.imwrite("images/numpxh.png", h)
!showme images/numpxh.png



import cv2
r = cv2.imread("images/face_300.jpg")
d = np.load('numpy-filters/cv2LUT_HSV.npy')
d2 = np.load('numpy-filters/cv2LUT_300.npy')
rh = d2 + r
#im = Image.fromarray(np.uint8(cm.gist_earth(myarray)*255))
#im = Image.fromarray(np.uint8(d*255)
cv2.imwrite("images/numpxh.png", rh)
!showme images/numpxh.png



import cv2
r = cv2.imread("images/face_300.jpg")
d = np.load('numpy-filters/cv2LUT_HSV.npy')
d2 = np.load('numpy-filters/cv2LUT_300.npy')
rh = d + r
#im = Image.fromarray(np.uint8(cm.gist_earth(myarray)*255))
#im = Image.fromarray(np.uint8(d*255)
cv2.imwrite("images/numpxh.png", rh)
!showme images/numpxh.png



!wget -O images/hicks01.jpg https://images.fineartamerica.com/images/artworkimages/mediumlarge/1/noahs-ark-james-edwin-mcconnell.jpg

!wget -O images/hicks02.jpg https://upload.wikimedia.org/wikipedia/commons/2/23/Noahs_Ark.jpg



from PIL import Image
h1 = Image.open("images/hicks01.jpg")
h2 = Image.open("images/hicks02.jpg")
h1.size, h2.size

from PIL import Image
h2s = h2.resize((675,640), Image.NEAREST)
h2s.save("images/S-hicks02.jpg")

from PIL import Image
h1s = h1.resize((675,640), Image.NEAREST)
h1s.save("images/S-hicks01.jpg")

import cv2
r = cv2.imread("images/S-hicks01.jpg")
r2 = cv2.imread("images/S-hicks02.jpg")

rr2 = (r + r2)
#im = Image.fromarray(np.uint8(cm.gist_earth(myarray)*255))
#im = Image.fromarray(np.uint8(d*255)
cv2.imwrite("images/hicks3a.png", rr2)
!showme images/hicks3a.png



import numpy as np
from sklearn.preprocessing import normalize
r = cv2.imread("images/S-hicks01.jpg")
r2 = cv2.imread("images/S-hicks02.jpg")

rr2 = (r + r2)
sqr2 = (rr2/3)-20

cv2.imwrite("images/hicks-sqr.png", sqr2)
!showme images/hicks-sqr.png


import numpy as np
from sklearn.preprocessing import normalize
r = cv2.imread("images/S-hicks01.jpg")
r2 = cv2.imread("images/S-hicks02.jpg")
r = r/2
rr2 = (r + r2)
sqr3 = (rr2/3)-15

cv2.imwrite("images/hicks-sqr3.png", sqr3)
!showme images/hicks-sqr3.png


import numpy as np
from sklearn.preprocessing import normalize
r = cv2.imread("images/S-hicks01.jpg")
r2 = cv2.imread("images/S-hicks02.jpg")
r = r*.3
rr2 = (r + r2)
sqr4 = (rr2/3)-15

cv2.imwrite("images/hicks-sqr4.png", sqr4)
!showme images/hicks-sqr4.png


import numpy as np
from sklearn.preprocessing import normalize
r = cv2.imread("images/S-hicks01.jpg")
r2 = cv2.imread("images/S-hicks02.jpg")
r = r*.3
rr2 = (r + r2)
sqr4 = (rr2/3)+25

cv2.imwrite("images/hicks-sqr4.png", sqr4)
!showme images/hicks-sqr4.png


from PIL import Image
def change_contrast(img, level):
    factor = (259 * (level + 255)) / (255 * (259 - level))
    def contrast(c):
        return 128 + factor * (c - 100)
    return img.point(contrast)

nimC = change_contrast(Image.open("images/hicks-sqr4.png"), 100)
nimC.save("images/hicks-post.png")
!showme images/hicks-post.png

from PIL import Image
def change_contrast(img, level):
    factor = (259 * (level + 255)) / (255 * (259 - level))
    def contrast(c):
        return 128 + factor * (c - 80)
    return img.point(contrast)

nimC = change_contrast(Image.open("images/hicks-sqr4.png"), 135)
nimC.save("images/hicks-post2.png")
!showme images/hicks-post2.png

import numpy as np
from sklearn.preprocessing import normalize
r = cv2.imread("images/S-hicks01.jpg")
r2 = cv2.imread("images/S-hicks02.jpg")

#This works as a blend it can be applied to either image in different degrees
r2 = r2*.4

rr2 = (r + r2)
sqr4 = (rr2/3)+25

cv2.imwrite("images/hicks-lev.png", sqr4)
!showme images/hicks-lev.png


from PIL import Image
def change_contrast(img, level):
    factor = (259 * (level + 255)) / (255 * (259 - level))
    def contrast(c):
        return 128 + factor * (c - 80)
    return img.point(contrast)

nimC = change_contrast(Image.open("images/hicks-lev.png"), 135)
nimC.save("images/hicks-post3.png")
!showme images/hicks-post3.png

import cv2
r = cv2.imread("images/S-hicks01.jpg")
r2 = cv2.imread("images/S-hicks02.jpg")
r3 = cv2.imread("images/waves.jpg")
r = r *.8
r2 = r2*.3
r3 = r3*.5
rr2 = ((r + r2) +r3)-10
sqr4 = (rr2/3)

#im = Image.fromarray(np.uint8(cm.gist_earth(myarray)*255))
#im = Image.fromarray(np.uint8(d*255)
#cv2.imwrite("images/hicks-water.png", rr2)
cv2.imwrite("images/hicks-water1.png", sqr4)
!showme images/hicks-water1.png



from PIL import Image
def change_contrast(img, level):
    factor = (259 * (level + 255)) / (255 * (259 - level))
    def contrast(c):
        return 128 + factor * (c - 80)
    return img.point(contrast)

nimC = change_contrast(Image.open("images/hicks-water1.png"), 125)
nimC.save("images/hicks-post-water1.png")
!showme images/hicks-post-water1.png

import cv2
r = cv2.imread("images/S-hicks01.jpg")
r2 = cv2.imread("images/S-hicks02.jpg")
r3 = cv2.imread("images/waves.jpg")
r = r *.8
r2 = r2*.3
r3 = r3*.5
rr2 = ((r + r2) +r3)-10
sqr4 = (rr2/3)

#im = Image.fromarray(np.uint8(cm.gist_earth(myarray)*255))
#im = Image.fromarray(np.uint8(d*255)
#cv2.imwrite("images/hicks-water.png", rr2)
cv2.imwrite("images/hicks-water1.png", sqr4)
!showme images/hicks-water1.png



from PIL import Image
def change_contrast(img, level):
    factor = (259 * (level + 255)) / (255 * (259 - level))
    def contrast(c):
        return 128 + factor * (c - 80)
    return img.point(contrast)

nimC = change_contrast(Image.open("images/hicks-water1.png"), 125)
nimC.save("images/hicks-post-water1.png")
!showme images/hicks-post-water1.png

import PIL
from PIL import ImageFont
from PIL import Image
from PIL import ImageDraw

font = ImageFont.truetype("/usr/share/fonts/truetype/ubuntu-font-family/UbuntuMono-B.ttf",35)
img=Image.new("RGBA", (675,640),(0,0,0))
draw = ImageDraw.Draw(img)
draw.text((340,20),"Numpy Array Stuff",(255,255,255),font=font)

draw = ImageDraw.Draw(img)

img.save("images/text.jpg")
img

!showme images/S-hicks02.jpg

import cv2
r1 = cv2.imread("images/S-hicks01.jpg")
r2 = cv2.imread("images/text.jpg")
r3 = cv2.imread("images/waves.jpg")
r4 = cv2.imread("images/S-hicks02.jpg")
r1 = r * 1.5
r2 = r2 *.8
r3 = r3 *.3
r4 = r4 

to = r1+r2+r3+r4 

#r2 = r2*.2

#rr2 = ((r + r2) +r3)-200
#sqr4 = (rr2/3)
ave = (to/4)-40

#im = Image.fromarray(np.uint8(cm.gist_earth(myarray)*255))
#im = Image.fromarray(np.uint8(d*255)
cv2.imwrite("images/hicks-mask.png", ave)
!showme images/hicks-mask.png



from PIL import Image
def change_contrast(img, level):
    factor = (259 * (level + 255)) / (255 * (259 - level))
    def contrast(c):
        return 128 + factor * (c - 50)
    return img.point(contrast)

nimC = change_contrast(Image.open("images/hicks-mask.png"),110)
nimC.save("images/hicks-mask3.png")
!showme images/hicks-mask3.png

# import cv2
import numpy as np
from PIL import Image
#cap = Image.open('images/face_300.jpg')
cap = cv2.imread('images/face_300.jpg')
#cap = cv2.imread('images/test-color.png')
while(1):
    # Take each frame
    frame = cap
    # Convert BGR to HSV
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    
    lower_red = np.array([0,0,200])
    upper_red = np.array([255,255,255])
    
    # Threshold the HSV image to get only blue colors
    mask = cv2.inRange(hsv, lower_red, upper_red)

    # Bitwise-AND mask and original image
    res = cv2.bitwise_and(frame,frame, mask= mask)

    cv2.imshow('frame',frame)
    cv2.imshow('mask',mask)
    cv2.imshow('hsv',hsv)
    k = cv2.waitKey(5) & 0xFF
    if k == 27:
        break

cv2.destroyAllWindows()


from PIL import Image, ImageFont, ImageDraw
from PIL import ImageEnhance
import cv2

img1 = Image.new("RGBA", (675, 640), color=(0, 0, 125, 15))
img1

!ls /home/jack/.fonts/

from PIL import Image, ImageFont, ImageDraw
from PIL import ImageEnhance
import cv2

img1 = Image.new("RGBA", (675, 640), color=(0, 0, 125, 5))
dr1 = ImageDraw.Draw(img1)
fnt = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf",35)
dr1.text((230, 15), "Three Images Combined", font=fnt, fill=(255, 255, 0, 128))
img1.save('images/test_out.png')

r1 = cv2.imread("images/S-hicks01.jpg")
r2 = cv2.imread("images/test_out.png")
r3 = cv2.imread("images/waves.jpg")
r4 = cv2.imread("images/S-hicks02.jpg")

r1 = r * 1.5
r2 = r2 *.2
r3 = r3 *.3
r4 = r4 

to = r1+r2+r3+r4 
ave = (to/4)-40

cv2.imwrite("images/hicks-mask2.png", ave)

def change_contrast(img, level):
    factor = (259 * (level + 255)) / (255 * (259 - level))
    def contrast(c):
        return 128 + factor * (c - 50)
    return img.point(contrast)

nimC = change_contrast(Image.open("images/hicks-mask2.png"),120)
nimC.save("images/hicks-mask4.png")
!showme images/hicks-mask4.png



from skimage import data, color, io, img_as_float
import numpy as np
import matplotlib.pyplot as plt

alpha = 0.6
#img = Image.open("images/hicks-mask.png")
img = cv2.imread("images/hicks-mask.png")

#img = img_as_float(data.camera())
#rows, cols = img.shape

# Construct a colour image to superimpose
color_mask = np.zeros((rows, cols, 3))
color_mask[30:140, 30:140] = [1, 0, 0]  # Red block
color_mask[170:270, 40:120] = [0, 1, 0] # Green block
color_mask[200:350, 200:350] = [0, 0, 1] # Blue block

# Construct RGB version of grey-level image
img_color = np.dstack((img, img, img))

# Convert the input image and color mask to Hue Saturation Value (HSV)
# colorspace
img_hsv = color.rgb2hsv(img_color)
color_mask_hsv = color.rgb2hsv(color_mask)

# Replace the hue and saturation of the original image
# with that of the color mask
img_hsv[..., 0] = color_mask_hsv[..., 0]
img_hsv[..., 1] = color_mask_hsv[..., 1] * alpha

img_masked = color.hsv2rgb(img_hsv)

# Display the output
f, (ax0, ax1, ax2) = plt.subplots(1, 3,
                                  subplot_kw={'xticks': [], 'yticks': []})
ax0.imshow(img, cmap=plt.cm.gray)
ax1.imshow(color_mask)
ax2.imshow(img_masked)
plt.show()

from PIL import Image, ImageFont, ImageDraw
from PIL import ImageEnhance
import cv2

img1 = Image.new("RGBA", (675, 640), color=(0, 0, 125, 5))
dr1 = ImageDraw.Draw(img1)
fnt = ImageFont.truetype("/home/jack/.fonts/LuckiestGuy.ttf",35)
dr1.text((230, 15), "Three Images Combined", font=fnt, fill=(255, 255, 0, 128))
img1.save('images/test_out.png')

r1 = cv2.imread("images/S-hicks01.jpg")
r2 = cv2.imread("images/test_out.png")
r3 = cv2.imread("images/waves.jpg")
r4 = cv2.imread("images/S-hicks02.jpg")

r1 = r * 1.5
r2 = r2 *.2
r3 = r3 *.3
r4 = r4 

to = r1+r2+r3+r4 
ave = (to/4)-45

#image = Image.fromarray(ave.astype('uint8'), 'RGB')
image = Image.fromarray(ave.astype('uint8'), 'RGB')

def change_contrast(level):
    factor = (259 * (level + 255)) / (255 * (259 - level))
    def contrast(c):
        return 128 + factor * (c - 150)
    return image.point(contrast)

nimC = change_contrast(180)
nimC.save("images/hicks-test3.png")
!showme images/hicks-test3.png


# import cv2
import numpy as np
from PIL import Image
#cap = Image.open('images/face_300.jpg')
cap = cv2.imread('images/face_300.jpg')
#cap = cv2.imread('images/test-color.png')
while(1):
    # Take each frame
    frame = cap
    # Convert BGR to HSV
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    #colormask = cv2.cvtColor(frame, cv2.COLOR_RGB2HSV)
    #hsv Hue Saturation Value
    lower_red = np.array([200,250,200])
    upper_red = np.array([255,255,255])
    
    # Threshold the HSV image to get only blue colors
    mask = cv2.inRange(hsv, lower_red, upper_red)

    # Bitwise-AND mask and original image
    res = cv2.bitwise_and(frame, frame, mask= mask)

    cv2.imshow('frame',frame)
    cv2.imshow('mask',mask)
    #cv2.imshow('colormask',colormask)
    k = cv2.waitKey(5) & 0xFF
    if k == 27:
        break

cv2.destroyAllWindows()


# import cv2
import numpy as np
from PIL import Image
#cap = Image.open('images/face_300.jpg')
#cap = cv2.imread('images/face.jpg')
cap = cv2.imread('images/test-color.png')
while(1):
    # Take each frame
    frame = cap
    # Convert BGR to HSV
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    
    #hue 0-85  85-170 170-255
    
    upper_blue = np.array([255,255,255])
    lower_blue = np.array([100,50,50])
    
    upper_green= np.array([100,255,255])
    lower_green = np.array([40,50,50])
    
    upper_red = np.array([40,255,255])
    lower_red = np.array([0,50,50])
    
    # Threshold the HSV image to get only blue colors
    mask = cv2.inRange(hsv, lower_green, upper_green)
    mask2 = cv2.inRange(hsv, lower_blue, upper_blue)
    mask3 = cv2.inRange(hsv, lower_red, upper_red)

    # Bitwise-AND mask and original image
    res = cv2.bitwise_and(frame,frame, mask= mask)

    #cv2.imshow('frame',frame)
    cv2.imshow('mask',mask)
    cv2.imshow('mask2',mask2)
    cv2.imshow('mask3',mask3)
    #cv2.imshow('hsv',hsv)
    #cv2.imshow('res',res)
    
    k = cv2.waitKey(5) & 0xFF
    if k == 27:
        break

cv2.destroyAllWindows()


import cv2
flags = [i for i in dir(cv2) if i.startswith('COLOR_')]
print flags

img = cv2.imread("images/face.jpg")

color_mask = np.zeros((rows, cols, 3))
color_mask[30:140, 30:140] = [1, 0, 0]  # Red block
color_mask[170:270, 40:120] = [0, 1, 0] # Green block
color_mask[200:350, 200:350] = [0, 0, 1] # Blue block

# Construct RGB version of grey-level image
img_color = np.dstack((img, img, img))

# Convert the input image and color mask to Hue Saturation Value (HSV)
# colorspace
img_hsv = color.rgb2hsv(img_color)
color_mask_hsv = color.rgb2hsv(color_mask)