-



#base = Image.open('images/NewFolder/lightning01.jpg').convert('RGBA')
#8 5 4 6 3 2
# make a blank image for the text, initialized to transparent text color
txt = Image.new('RGBA', base.size, (255,255,255,0))

# get a font
font = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 20)
# get a drawing context
#d = ImageDraw.Draw(txt)




width, height = base.size
# calculate the x,y coordinates of the text
#marginx = 325
#marginy = 75
marginx = 225
marginy = 50
x = width - marginx
y = height - marginy
signature_ = "The TwitterBot Project" 
d.text((x,y), signature_, font=fnt, fill=(0,0,0,256))

out = Image.alpha_composite(base, txt)
out.save("tmp/tmp.jpg", "JPEG")
# save the image then reopen to put a title
#base = Image.open('tmp/tmp.jpg').convert('RGBA')


if __name__ == '__main__':
    img0 = Image.open('tmp/tmp.jpg').convert('RGBA')
    font = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 50)
    txt = 'The TwitterBot Project'
    text_col = (0, 0,0) # bright green
    halo_col = (255,255,255)   # black
    i2 = draw_text_with_halo(img0, (90, 10), txt, font, text_col, halo_col)



#8 5 4 6 3 2
# make a blank image for the text, initialized to transparent text color
txt = Image.new('RGBA', base.size, (255,255,255,0))

# get a font
fnt = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 30)
# get a drawing context
#d = ImageDraw.Draw(txt)
d= draw_text_with_halo(img0, (90, 10), txt, font, text_col, halo_col)
width, height = base.size
# calculate the x,y coordinates of the text
#marginx = 325
#marginy = 75
x = 90
y = 10
#generate a title
title = (generate_the_word("titles.txt"))
d.text((x,y), title , font=fnt, fill=(0,0,0,250))
out2 = Image.alpha_composite(base, i2)
out2.save("tmp/TM_POST.jpg", "JPEG")

filenameP = time.strftime("posted/%Y%m%d%H%M%S.jpg")
out2.save(filenameP, "JPEG")
#removed keys for privacy reasons
CONSUMER_KEY = 'YazCRIfWX4VICiRCOiph08jDL'
CONSUMER_SECRET = 'QOkLHou6NMwkghSHjMFXMdffQKJlDzttKtP6uBCcZ4VlQtvJyc'
ACCESS_KEY = '296906916-AWggjhqpEWIS7EzXXhc2pOPBeCVJczpOm11cQGIf'
ACCESS_SECRET = 'zFrCiyaPt8gCBVVs1bLCmdCSyQQ3DKxT5wHJq2tOu2AMj'

twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)
#path = 'images/NewFolder'
f = open("art.txt")
text = f.read()
# Build the model.
text_model = markovify.Text(text)
# Print randomly-generated sentences of no more than 140 characters
#http://paulbourke.net/fractals/
STR = (text_model.make_short_sentence(140))
#STR = ("#All_in_One - #WordCloud #Create - Added ability to randomly choose an image background  #Automated")
#PATH = "/home/jack/Desktop/deep-dream-generator/notebooks/STUFF/experiment/experiment8.jpg"
PATH = "tmp/TM_POST.jpg"
# 1 , 2, 3, 12, 5, 15, 8, 6
#photo = open('/home/jack/Desktop/deep-dream-generator/notebooks/images/'+file_list[rnd]+'.jpg','rb')

#photo = open(PATH,'rb')
#response = twitter.upload_media(media=photo)
#twitter.update_status(status=STR, media_ids=[response['media_id']])
out2

import sys
from PIL import Image, ImageChops, ImageDraw, ImageFont, ImageFilter
path = r"publish/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
filename0=(path+base_image)
def generate_the_word(infile):
        with open(infile) as f:
            contents_of_file = f.read()
        lines = contents_of_file.splitlines()
        line_number = random.randrange(0, len(lines))
        return lines[line_number]

def draw_text_with_halo(img, position, text, font, col, halo_col):
    halo = Image.new('RGBA', img.size, (0, 0, 0, 0))
    ImageDraw.Draw(halo).text(position, text, font = font, fill = halo_col)
    blurred_halo = halo.filter(ImageFilter.BLUR)
    ImageDraw.Draw(blurred_halo).text(position, text, font = font, fill = col)
    return Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))

if __name__ == '__main__':
    i = Image.open(filename0)
    font = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 50)
    text_col = (255, 255,230) # bright green
    halo_col = (0, 0, 0)   # black
    textin = (generate_the_word("wordcloud.txt"))
    i2 = draw_text_with_halo(i, (20, 20), textin, font, text_col, halo_col)
    
    txt = Image.new('RGBA', base.size, (255,255,255,0))

    # get a font
    fnt = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 30)
    # get a drawing context
    d = ImageDraw.Draw(txt)
    
    width, height = i.size
    marginx = 325
    marginy = 50
    x = width - marginx
    y = height - marginy
    signature_ = "The TwitterBot Project" 
    d.text((x,y), signature_, font=fnt, fill=(0,0,0,256))

    out = Image.alpha_composite(i2, txt)

    filename = time.strftime("tmp/%Y%m%d%H%M%S.jpg")


out

out.save(filename)

%%writefile titlenpost.py
#!/home/jack/anaconda2/python
import random
from random import randint
import time
import markovify
import os
import sys
sys.path.insert(1, "/home/jack/anaconda2/envs/py27/lib/python2.7/site-packages")
import twython
from twython import Twython
from PIL import Image, ImageChops, ImageDraw, ImageFont, ImageFilter
nap = randint(10,35)
time.sleep(nap)
path = r"publish/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
filename0=(path+base_image)
def generate_the_word(infile):
        with open(infile) as f:
            contents_of_file = f.read()
        lines = contents_of_file.splitlines()
        line_number = random.randrange(0, len(lines))
        return lines[line_number]

def draw_text_with_halo(img, position, text, font, col, halo_col):
    halo = Image.new('RGBA', img.size, (0, 0, 0, 0))
    ImageDraw.Draw(halo).text(position, text, font = font, fill = halo_col)
    blurred_halo = halo.filter(ImageFilter.BLUR)
    ImageDraw.Draw(blurred_halo).text(position, text, font = font, fill = col)
    return Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))

if __name__ == '__main__':
    inp = Image.open(filename0)
    font = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 40)
    text_col = (255, 255,230) # bright green
    halo_col = (0, 0, 0)   # black
    textin = (generate_the_word("wordcloud.txt"))
    i2 = draw_text_with_halo(inp, (15, 8), textin, font, text_col, halo_col)
    
    #txt = Image.new('RGBA', i.size, (255,255,255,0))

    # get a font
    fnt = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 20)
    # get a drawing context
    width, height = inp.size
    marginx = 225
    marginy = 35
    x = width - marginx
    y = height - marginy
    signature_ = "The TwitterBot Project" 
    #text_col2 = (150, 255, 150) # bright green
    #halo_col2 = (0, 0, 0)   # black
    text_col2 = (255, 255,230) # bright green
    halo_col2 = (0, 0, 0)   # black
    txt=draw_text_with_halo(i2,(x,y), signature_, fnt, text_col2, halo_col2)
    out = Image.alpha_composite(i2, txt)
    out.save("tmp/TM_POST.jpg")

#removed keys for privacy reasons
CONSUMER_KEY = 'YazCRIfWX4VICiRCOiph08jDL'
CONSUMER_SECRET = 'QOkLHou6NMwkghSHjMFXMdffQKJlDzttKtP6uBCcZ4VlQtvJyc'
ACCESS_KEY = '296906916-AWggjhqpEWIS7EzXXhc2pOPBeCVJczpOm11cQGIf'
ACCESS_SECRET = 'zFrCiyaPt8gCBVVs1bLCmdCSyQQ3DKxT5wHJq2tOu2AMj'

twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)
#path = 'images/NewFolder'
f = open("art.txt")
text = f.read()
# Build the model.
text_model = markovify.Text(text)
# Print randomly-generated sentences of no more than 140 characters
#http://paulbourke.net/fractals/
STR = (text_model.make_short_sentence(140))
#STR = ("#All_in_One - #WordCloud #Create - Added ability to randomly choose an image background  #Automated")
#PATH = "/home/jack/Desktop/deep-dream-generator/notebooks/STUFF/experiment/experiment8.jpg"
PATH = "tmp/TM_POST.jpg"
# 1 , 2, 3, 12, 5, 15, 8, 6
#photo = open('/home/jack/Desktop/deep-dream-generator/notebooks/images/'+file_list[rnd]+'.jpg','rb')

photo = open(PATH,'rb')
response = twitter.upload_media(media=photo)
twitter.update_status(status=STR, media_ids=[response['media_id']])

#%%writefile titlenpost2.py
#!/home/jack/anaconda2/python
import sys
import random
from random import randint
import time
import markovify
import os
import sys
sys.path.insert(1, "/home/jack/anaconda2/envs/py27/lib/python2.7/site-packages")
import twython
from twython import Twython
from PIL import Image, ImageChops, ImageDraw, ImageFont, ImageFilter
nap = randint(10,35)
time.sleep(nap)
path = r"publish/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
filename0=(path+base_image)
def generate_the_word(infile):
        with open(infile) as f:
            contents_of_file = f.read()
        lines = contents_of_file.splitlines()
        line_number = random.randrange(0, len(lines))
        return lines[line_number]

def draw_text_with_halo(img, position, text, font, col, halo_col):
    halo = Image.new('RGBA', tit.size, (0, 0, 0, 0))
    ImageDraw.Draw(halo).text(position, text, font = font, fill = halo_col)
    blurred_halo = halo.filter(ImageFilter.BLUR)
    ImageDraw.Draw(blurred_halo).text(position, text, font = font, fill = col)
    return Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))

if __name__ == '__main__':
    tit = Image.open(filename0)
    font = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 50)
    #textin = 'Python Generated'
    text_col = (255, 255,230) # bright green
    halo_col = (0, 0, 0)   # black
    textin = (generate_the_word("wordcloud.txt"))
    i2 = draw_text_with_halo(tit, (20, 10), textin, font, text_col, halo_col)
    txt = Image.new('RGBA', tit.size, (255,255,255,0))
    # get a font
    fnt = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 30)
    # get a drawing context
    d = ImageDraw.Draw(txt)
    
    width, height = tit.size
    marginx = 325
    marginy = 50
    x = width - marginx
    y = height - marginy
    out = Image.alpha_composite(i2, txt)
    out.save("tmp/TM_XXX.jpg", "JPEG")
    
    signature_ = "The TwitterBot Project"
    #i3 = draw_text_with_halo( out, (x,y), signature_, font, text_col, halo_col)
    #out = Image.alpha_composite(i3, out)
    

filenameP = time.strftime("posted/%Y%m%d%H%M%S.jpg")
out.save(filenameP, "JPEG")
#removed keys for privacy reasons
CONSUMER_KEY = 'YazCRIfWX4VICiRCOiph08jDL'
CONSUMER_SECRET = 'QOkLHou6NMwkghSHjMFXMdffQKJlDzttKtP6uBCcZ4VlQtvJyc'
ACCESS_KEY = '296906916-AWggjhqpEWIS7EzXXhc2pOPBeCVJczpOm11cQGIf'
ACCESS_SECRET = 'zFrCiyaPt8gCBVVs1bLCmdCSyQQ3DKxT5wHJq2tOu2AMj'

twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)
#path = 'images/NewFolder'
f = open("art.txt")
text = f.read()
# Build the model.
text_model = markovify.Text(text)
# Print randomly-generated sentences of no more than 140 characters
#http://paulbourke.net/fractals/
STR = (text_model.make_short_sentence(140))
#STR = ("#All_in_One - #WordCloud #Create - Added ability to randomly choose an image background  #Automated")
#PATH = "/home/jack/Desktop/deep-dream-generator/notebooks/STUFF/experiment/experiment8.jpg"
PATH = "tmp/TM_POST.jpg"
# 1 , 2, 3, 12, 5, 15, 8, 6
#photo = open('/home/jack/Desktop/deep-dream-generator/notebooks/images/'+file_list[rnd]+'.jpg','rb')

#photo = open(PATH,'rb')
#response = twitter.upload_media(media=photo)
#twitter.update_status(status=STR, media_ids=[response['media_id']])
out



!ls

%%writefile titles.txt
Python Fun
Python Graphics
Generator
Word Cloud
Graphics
Fun w/Python
Python Stuff
PYTHON !!!
Love`en Python
Creative Python
Graphic Fun
ImageBot
Programming

%%writefile wordcloud.txt
Python
Programming
ImageBot
Enjoy
Just for You
Good Stuff
Computer Graphics
Python Fun
Python Graphics
Generator
Word Cloud
Graphics
Fun w/Python
Python Stuff
PYTHON !!!
Love`en Python
Creative Python
Graphic Fun
ImageBot
Programming

%%writefile titlenpost
#!/bin/bash

while true; do
  python titlenpost.py
  echo "posted :"
  date
  sleep 1800s
done



import sys
from PIL import Image, ImageChops, ImageDraw, ImageFont, ImageFilter
path = r"publish/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
filename0=(path+base_image)
def generate_the_word(infile):
        with open(infile) as f:
            contents_of_file = f.read()
        lines = contents_of_file.splitlines()
        line_number = random.randrange(0, len(lines))
        return lines[line_number]

def draw_text_with_halo(img, position, text, font, col, halo_col):
    halo = Image.new('RGBA', i.size, (0, 0, 0, 0))
    ImageDraw.Draw(halo).text(position, text, font = font, fill = halo_col)
    blurred_halo = halo.filter(ImageFilter.BLUR)
    ImageDraw.Draw(blurred_halo).text(position, text, font = font, fill = col)
    return Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))

if __name__ == '__main__':
    i = Image.open(filename0)
    font = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 50)
    text_col = (255, 255,230) # bright green
    halo_col = (0, 0, 0)   # black
    textin = (generate_the_word("wordcloud.txt"))
    i2 = draw_text_with_halo(i, (20, 20), textin, font, text_col, halo_col)
    
    txt = Image.new('RGBA', i.size, (255,255,255,0))

    # get a font
    fnt = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 30)
    # get a drawing context
    d = ImageDraw.Draw(txt)
    
    width, height = i.size
    marginx = 325
    marginy = 50
    x = width - marginx
    y = height - marginy
    signature_ = "The TwitterBot Project" 
    d.text((x,y), signature_, font=fnt, fill=(0,0,0,256))

    out = Image.alpha_composite(i2, txt)

    #filename = time.strftime("tmp/%Y%m%d%H%M%S.jpg")
    
    font2 = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 15)
    text = "TwitterBot Project"
    # get text size
    text_size = font.getsize(text)
    # set button size + 10px margins
    button_size = (text_size[0]+8, text_size[1]+8)
    # create image with correct size and black background
    button_img = Image.new('RGBA', button_size, "black")
    # put text on button with 10px margins
    button_draw = ImageDraw.Draw(button_img)
    button_draw.text((x,y), text, font=font2)
    opacity=0.5
    bands=list(button_img.split())
    if len(bands)==4:
        bands[3]=bands[3].point(lambda x:x*opacity)
        new_image=Image.merge(button_img.mode,bands)
    # put button on source image in position (0, 0)
    out.paste(new_image, (15,15))
    # save in new file
    #source_img.save("junk/output.jpg", "JPEG")
    #source_img    

    
        
    
    
    
    
    
    
    


out

#Great title n signature

#Great signature
import sys
from PIL import Image, ImageChops, ImageDraw, ImageFont, ImageFilter
path = r"publish/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
filename0=(path+base_image)
def generate_the_word(infile):
        with open(infile) as f:
            contents_of_file = f.read()
        lines = contents_of_file.splitlines()
        line_number = random.randrange(0, len(lines))
        return lines[line_number]

def draw_text_with_halo(img, position, text, font, col, halo_col):
    halo = Image.new('RGBA', img.size, (0, 0, 0, 0))
    ImageDraw.Draw(halo).text(position, text, font = font, fill = halo_col)
    blurred_halo = halo.filter(ImageFilter.BLUR)
    ImageDraw.Draw(blurred_halo).text(position, text, font = font, fill = col)
    return Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))

if __name__ == '__main__':
    inp = Image.open(filename0)
    font = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 40)
    text_col = (255, 255,230) # bright green
    halo_col = (0, 0, 0)   # black
    textin = (generate_the_word("wordcloud.txt"))
    i2 = draw_text_with_halo(inp, (15, 8), textin, font, text_col, halo_col)
    
    #txt = Image.new('RGBA', i.size, (255,255,255,0))

    # get a font
    fnt = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 20)
    # get a drawing context
    d = ImageDraw.Draw(txt)
    width, height = inp.size
    marginx = 225
    marginy = 35
    x = width - marginx
    y = height - marginy
    signature_ = "The TwitterBot Project" 
    #text_col2 = (150, 255, 150) # bright green
    #halo_col2 = (0, 0, 0)   # black
    text_col2 = (255, 255,230) # bright green
    halo_col2 = (0, 0, 0)   # black
    txt=draw_text_with_halo(i2,(x,y), signature_, fnt, text_col2, halo_col2)
    out = Image.alpha_composite(i2, txt)
    filename = time.strftime("tmp/%Y%m%d%H%M%S.jpg")


out



#%%writefile titlenpost.py
#!/home/jack/anaconda2/python
import random
from random import randint
import time
import markovify
import os
import sys
sys.path.insert(1, "/home/jack/anaconda2/envs/py27/lib/python2.7/site-packages")
import twython
from twython import Twython
from PIL import Image, ImageChops, ImageDraw, ImageFont, ImageFilter
nap = randint(10,35)
time.sleep(nap)
path = r"publish/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
filename0=(path+base_image)
def generate_the_word(infile):
        with open(infile) as f:
            contents_of_file = f.read()
        lines = contents_of_file.splitlines()
        line_number = random.randrange(0, len(lines))
        return lines[line_number]

def draw_text_with_halo(img, position, text, font, col, halo_col):
    halo = Image.new('RGBA', img.size, (0, 0, 0, 0))
    ImageDraw.Draw(halo).text(position, text, font = font, fill = halo_col)
    blurred_halo = halo.filter(ImageFilter.BLUR)
    ImageDraw.Draw(blurred_halo).text(position, text, font = font, fill = col)
    return Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))

if __name__ == '__main__':
    inp = Image.open(filename0)
    font = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 40)
    text_col = (255, 255,230) # bright green
    halo_col = (0, 0, 0)   # black
    textin = (generate_the_word("wordcloud.txt"))
    i2 = draw_text_with_halo(inp, (15, 8), textin, font, text_col, halo_col)
    
    #txt = Image.new('RGBA', i.size, (255,255,255,0))

    # get a font
    fnt = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 20)
    # get a drawing context
    width, height = inp.size
    marginx = 225
    marginy = 35
    x = width - marginx
    y = height - marginy
    signature_ = "The TwitterBot Project" 
    #text_col2 = (150, 255, 150) # bright green
    #halo_col2 = (0, 0, 0)   # black
    text_col2 = (255, 255,230) # bright green
    halo_col2 = (0, 0, 0)   # black
    txt=draw_text_with_halo(i2,(x,y), signature_, fnt, text_col2, halo_col2)
    out = Image.alpha_composite(i2, txt)
    out.save("tmp/TM_POST.jpg")

#removed keys for privacy reasons
CONSUMER_KEY = 'YazCRIfWX4VICiRCOiph08jDL'
CONSUMER_SECRET = 'QOkLHou6NMwkghSHjMFXMdffQKJlDzttKtP6uBCcZ4VlQtvJyc'
ACCESS_KEY = '296906916-AWggjhqpEWIS7EzXXhc2pOPBeCVJczpOm11cQGIf'
ACCESS_SECRET = 'zFrCiyaPt8gCBVVs1bLCmdCSyQQ3DKxT5wHJq2tOu2AMj'

twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)
#path = 'images/NewFolder'
f = open("art.txt")
text = f.read()
# Build the model.
text_model = markovify.Text(text)
# Print randomly-generated sentences of no more than 140 characters
#http://paulbourke.net/fractals/
STR = (text_model.make_short_sentence(140))
#STR = ("#All_in_One - #WordCloud #Create - Added ability to randomly choose an image background  #Automated")
#PATH = "/home/jack/Desktop/deep-dream-generator/notebooks/STUFF/experiment/experiment8.jpg"
PATH = "tmp/TM_POST.jpg"
# 1 , 2, 3, 12, 5, 15, 8, 6
#photo = open('/home/jack/Desktop/deep-dream-generator/notebooks/images/'+file_list[rnd]+'.jpg','rb')

#photo = open(PATH,'rb')
#response = twitter.upload_media(media=photo)
#twitter.update_status(status=STR, media_ids=[response['media_id']])
out

%%writefile titlenpost.py
#!/home/jack/anaconda2/python
import random
from random import randint
import time
import markovify
import os
import sys
sys.path.insert(1, "/home/jack/anaconda2/envs/py27/lib/python2.7/site-packages")
import twython
from twython import Twython
from PIL import Image, ImageChops, ImageDraw, ImageFont, ImageFilter
nap = randint(10,35)
time.sleep(nap)
path = r"publish/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
filename0=(path+base_image)
def generate_the_word(infile):
        with open(infile) as f:
            contents_of_file = f.read()
        lines = contents_of_file.splitlines()
        line_number = random.randrange(0, len(lines))
        return lines[line_number]

def draw_text_with_halo(img, position, text, font, col, halo_col):
    halo = Image.new('RGBA', img.size, (0, 0, 0, 0))
    ImageDraw.Draw(halo).text(position, text, font = font, fill = halo_col)
    blurred_halo = halo.filter(ImageFilter.BLUR)
    ImageDraw.Draw(blurred_halo).text(position, text, font = font, fill = col)
    return Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))

if __name__ == '__main__':
    inp = Image.open(filename0)
    font = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 40)
    text_col = (255, 255,230) # bright green
    halo_col = (0, 0, 0)   # black
    textin = (generate_the_word("wordcloud.txt"))
    i2 = draw_text_with_halo(inp, (15, 8), textin, font, text_col, halo_col)
    
    #txt = Image.new('RGBA', i.size, (255,255,255,0))

    # get a font
    fnt = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 20)
    # get a drawing context
    width, height = inp.size
    marginx = 225
    marginy = 35
    x = width - marginx
    y = height - marginy
    signature_ = "The TwitterBot Project" 
    #text_col2 = (150, 255, 150) # bright green
    #halo_col2 = (0, 0, 0)   # black
    text_col2 = (255, 255,230) # bright green
    halo_col2 = (0, 0, 0)   # black
    txt=draw_text_with_halo(i2,(x,y), signature_, fnt, text_col2, halo_col2)
    out = Image.alpha_composite(i2, txt)
    out.save("tmp/TM_POST.jpg")

#removed keys for privacy reasons
CONSUMER_KEY = 'YazCRIfWX4VICiRCOiph08jDL'
CONSUMER_SECRET = 'QOkLHou6NMwkghSHjMFXMdffQKJlDzttKtP6uBCcZ4VlQtvJyc'
ACCESS_KEY = '296906916-AWggjhqpEWIS7EzXXhc2pOPBeCVJczpOm11cQGIf'
ACCESS_SECRET = 'zFrCiyaPt8gCBVVs1bLCmdCSyQQ3DKxT5wHJq2tOu2AMj'

twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)
#path = 'images/NewFolder'
f = open("art.txt")
text = f.read()
# Build the model.
text_model = markovify.Text(text)
# Print randomly-generated sentences of no more than 140 characters
#http://paulbourke.net/fractals/
STR = (text_model.make_short_sentence(140))
#STR = ("#All_in_One - #WordCloud #Create - Added ability to randomly choose an image background  #Automated")
#PATH = "/home/jack/Desktop/deep-dream-generator/notebooks/STUFF/experiment/experiment8.jpg"
PATH = "tmp/TM_POST.jpg"
# 1 , 2, 3, 12, 5, 15, 8, 6
#photo = open('/home/jack/Desktop/deep-dream-generator/notebooks/images/'+file_list[rnd]+'.jpg','rb')

photo = open(PATH,'rb')
response = twitter.upload_media(media=photo)
twitter.update_status(status=STR, media_ids=[response['media_id']])

from Immanip import SwapPalettes
filename0 = '/home/jack/Desktop/text_stuff/instagram/PalletteTemp.png'
filename1 = '/home/jack/Desktop/text_stuff/instagram/colors.jpg'
filename = 'instagram/post-056.jpg'
SwapPalettes.swappalettes(filename0,filename1,filename)

from selenium import webdriver
from selenium.webdriver.common.keys import Keys
import os
import json
import urllib2
import sys
import time
# adding path to geckodriver to the OS environment variable
# assuming that it is stored at the same path as this script
#os.environ["PATH"] += os.pathsep + os.getcwd()
download_path = "search/"

def main():
    #searchtext = sys.argv[1] # the search query
    #num_requested = int(sys.argv[2]) # number of images to download
    searchtext=raw_input("search")
    num_requested =int(raw_input("how many"))
    
    number_of_scrolls = num_requested / 400 + 1 
    # number_of_scrolls * 400 images will be opened in the browser

    if not os.path.exists(download_path + searchtext.replace(" ", "_")):
        os.makedirs(download_path + searchtext.replace(" ", "_"))

    url = "https://www.google.co.in/search?q="+searchtext+"&source=lnms&tbm=isch"
    #url = "https://duckduckgo.com/?q="+searchtext+"&t=hb&iax=1&ia=images"
    driver = webdriver.Firefox()
    driver.get(url)

    headers = {}
    headers['User-Agent'] = "Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36"
    extensions = {"jpg", "jpeg", "png", "gif"}
    img_count = 0
    downloaded_img_count = 0

    for _ in xrange(number_of_scrolls):
        for __ in xrange(10):
            # multiple scrolls needed to show all 400 images
            driver.execute_script("window.scrollBy(0, 1000000)")
            time.sleep(0.2)
        # to load next 400 images
        time.sleep(0.5)
        try:
            driver.find_element_by_xpath("//input[@value='Show more results']").click()
        except Exception as e:
            print "Less images found:", e
            break

    # imges = driver.find_elements_by_xpath('//div[@class="rg_meta"]') # not working anymore
    imges = driver.find_elements_by_xpath('//div[contains(@class,"rg_meta")]')
    print "Total images:", len(imges), "\n"
    for img in imges:
        img_count += 1
        img_url = json.loads(img.get_attribute('innerHTML'))["ou"]
        img_type = json.loads(img.get_attribute('innerHTML'))["ity"]
        print "Downloading image", img_count, ": ", img_url
        try:
            if img_type not in extensions:
                img_type = "jpg"
            req = urllib2.Request(img_url, headers=headers)
            raw_img = urllib2.urlopen(req).read()
            f = open(download_path+searchtext.replace(" ", "_")+"/"+str(downloaded_img_count)+"."+img_type, "wb")
            f.write(raw_img)
            f.close
            downloaded_img_count += 1
        except Exception as e:
            print "Download failed:", e
        finally:
            print
        if downloaded_img_count >= num_requested:
            break

    print "Total downloaded: ", downloaded_img_count, "/", img_count
    driver.quit()

if __name__ == "__main__":
    main()

import os
import sys
from PIL import Image
import shutil
import time
import random
filename0= '/home/jack/Desktop/3DFRACT/Mandelbulb3Dv199/post-052.jpg'
filename1='/home/jack/Desktop/3DFRACT/Mandelbulb3Dv199/captain.jpg'
shutil.copy2(filename0, 'instagram/')
shutil.copy2(filename1, 'instagram/')
aa = Image.open(filename0).convert("RGB")
bb = Image.open(filename1).convert("RGB")
xx=aa.resize((640,640), Image.NEAREST)
yy=bb.resize((640,640), Image.NEAREST)
xx.save("junk/aa.png")
yy.save("junk/bb.png")
src = Image.open('junk/aa.png').convert('RGB')
dst = Image.open('junk/bb.png').convert('RGB')
src.save("junk/aa.png")
dst.save("junk/bb.png")
n = 5 #number of partitions per channel.
src_handle = Image.open("junk/bb.png")
dst_handle = Image.open("junk/aa.png")
src = src_handle.load()
dst = dst_handle.load()
assert src_handle.size[0]*src_handle.size[1] == dst_handle.size[0]*dst_handle.size[1],"images must be same size"
def makePixelList(img):
    l = []
    for x in range(img.size[0]):
        for y in range(img.size[1]):
            l.append((x,y))
    return l
lsrc = makePixelList(src_handle)
ldst = makePixelList(dst_handle)
def sortAndDivide(coordlist,pixelimage,channel): #core
    global src,dst,n
    retlist = []
    #sort
    coordlist.sort(key=lambda t: pixelimage[t][channel])
    #divide
    partitionLength = int(len(coordlist)/n)
    if partitionLength <= 0:
        partitionLength = 1
    if channel < 2:
        for i in range(0,len(coordlist),partitionLength):
            retlist += sortAndDivide(coordlist[i:i+partitionLength],pixelimage,channel+1)
    else:
        retlist += coordlist
    return retlist

print(src[lsrc[0]])
lsrc = sortAndDivide(lsrc,src,0)
ldst = sortAndDivide(ldst,dst,0)
for i in range(len(ldst)):
    dst[ldst[i]] = src[lsrc[i]]
filename = time.strftime("/home/jack/Desktop/3DFRACT/Mandelbulb3Dv199/post-053.jpg")
dst_handle.save(filename)
shutil.copy2(filename, "instagram/")
print filename

from PIL import Image
overlay = Image.open('/home/jack/Desktop/text_stuff/instagram/post-054.jpg').convert("RGBA") 
overlay.load()
overlay.split()
base = Image.open('/home/jack/Desktop/text_stuff/instagram/use001.png').convert("RGBA")
base.load()
base.split()
"""
card = Image.new("RGBA", (220, 220), (255, 255, 255))
img = Image.open("/Users/paulvorobyev/test.png").convert("RGBA")
x, y = img.size
card.paste(img, (0, 0, x, y), img)
card.save("test.png", format="png")
"""

bands = list(overlay.split())
if len(bands) == 4:
    # Assuming alpha is the last band
    bands[3] = bands[3].point(lambda x: x*0.4)
overlay = Image.merge(overlay.mode, bands)

base.paste(overlay, (0, 0), overlay)
base.save('result.png')

!showme result.png

from PIL import Image
import time
import numpy as np
mv = 0
for i in xrange(600): 
    background = Image.open("/home/jack/Desktop/text_stuff/instagram/post-054.jpg")
    foreground = Image.open("/home/jack/Desktop/text_stuff/instagram/use001.png")

    background.paste(foreground, (1*mv, 1*mv), foreground)
    background.save("abc.png")
    mv = mv + 1
    #time.sleep(2)
    #filename = datetime.datetime.now().strftime("/notebooks/%d_%m_%Y_%H:%M:%S.jpg")
    filename = ("video/%004d.jpg"%mv)
    
    Image.fromarray(np.uint8(background)).save(filename)  
    
from PIL import Image
merge =Image.open("abc.png")
merge

# Making one blended image
from PIL import Image
background = Image.open("instagram/conduit.jpg")
background = background.convert("RGBA")
overlay = Image.open("instagram/MutaGen.png")
overlay = overlay.convert("RGBA")
new_img = Image.blend(background, overlay, 0.5)
#new_img.save("snakewave.png","PNG")
new_img.save("snakewave.jpg","JPEG")

from PIL import Image, ImageOps
mask = Image.open('instagram/post-color5.png').convert('L')
im = Image.open('instagram/MutaGen.png')
output = ImageOps.fit(im, mask.size, centering=(0.5, 0.5))
output.putalpha(mask)
output.save('output2.jpg')

from PIL import Image, ImageOps
mask = Image.open('instagram/post-color5.png').convert('L')
im = Image.open('instagram/MutaGen.png')
output = ImageOps.fit(im, mask.size, centering=(0.5, 0.5))
output.putalpha(mask)
output.save('output2.png')

!wget -O oceanlarge.jpg https://static.pexels.com/photos/37403/bora-bora-french-polynesia-sunset-ocean.jpg

from PIL import Image
im = Image.open('oceanlarge.jpg')
im.size

from PIL import Image
im = Image.open('reducedsize.jpg')

y0,x0 = im.size
r = float(x0/640)
x = x0/float(r)
y= y0/float(r)
x = int(x)
y= int(y)
imn = im.resize((y,x), Image.NEAREST)
imn.save("reducedsize.jpg")
image = cv2.imread("reducedsize.jpg")
imn.size

y0,x0 = im.size
rs = x0-640
print rs

from PIL import Image
im = Image.open('reducedsize.jpg')

y0,x0 = im.size
r = float(x0/640)
x = x0/float(r)
y= y0/float(r)
x = int(x)
y= int(y)
imn = im.resize((y,x), Image.NEAREST)
imn.save("reducedsize.jpg")
image = cv2.imread("reducedsize.jpg")
imn.size

y0,x0 = im.size
rs = x0-640

x = x0 - rs
y = y0 - rs

#xx = x - 640
#yy = y - 640

cropped = image[0:x, 0:y]
#htop hbottom   wleft wright

r = 640.0 / image.shape[1]
dim = (640, int(image.shape[0] * r))
resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)

cv2.imshow("cropped", cropped)
cv2.imshow("resized", resized)
cv2.imwrite("01a.jpg",cropped)
cv2.imwrite("02a.jpg",resized)
cv2.waitKey(0)


import cv2
from PIL import Image

image = cv2.imread("oceanlarge.jpg")
im = Image.open('oceanlarge.jpg')

y0,x0 = im.size
x = x0 - 1000
y = y0 - 3000

xx = x - 640
yy = y - 640

cropped = image[xx:x, yy:y]
#cropped = image[1600:2070, 2700:3240]
#htop hbottom   wleft wright

r = 640.0 / image.shape[1]
dim = (640, int(image.shape[0] * r))
resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)

cv2.imshow("cropped", cropped)
cv2.imshow("resized", resized)

cv2.imwrite("01.jpg",cropped)
cv2.imwrite("02.jpg",resized)
cv2.waitKey(0)

!ls instagram

#Making a series os blended images
from PIL import Image
background = Image.open("instagram/post-005.jpg")
overlay = Image.open("instagram/post-022.jpg")
background = background.convert("RGBA")
overlay = overlay.convert("RGBA")
#auto encrement while changing alpha value of overlay
for i in range(10):
    imagea = i *.1
    new_img = Image.blend(background, overlay, imagea)
    new_img.save('video/morph_001%d.jpg'%(i,),"JPEG")

from PIL import Image
img = Image.open('instagram/post-022.jpg', 'r')
img_w, img_h = img.size
background = Image.new('RGBA', (680, 680), (255, 255, 235, 255))
bg_w, bg_h = background.size
offset = ((bg_w - img_w) / 2, (bg_h - img_h) / 2)
background.paste(img, offset)
background.save('instagram/post-022-BORDER.jpg')

import PIL
from PIL import ImageFont
from PIL import Image
from PIL import ImageDraw
font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf", 15)
#img = Image.new("RGBA", (200,200), (120,20,20))
img = Image.open("instagram/post-022-BORDER.jpg")
draw = ImageDraw.Draw(img)
draw.text((50,5), "PYTHON _ Draw a border and add text", (0,0,0), font=font)
draw = ImageDraw.Draw(img)
img.save("instagram/post-022-BORDER-txt.jpg")

#! /usr/bin/env python
import urllib
SAT_ZOOM_LEVEL = 0.0001389 #Like in request form
def retrieveImage(coordinates, image_size, name):
    """Retrieve satellite images from the Nasa's site
    coordinates: tuple (longitude, latitude) in decimal degrees
        image_size: tuple (width, height)
        name: output filename
        """
    request1 = "http://onearth.jpl.nasa.gov/landsat.cgi?" \
        "zoom=%f&x0=%f&y0=%f&x=%i&y=%i&action=pan&layer=modis%%252Cglobal_mosaic&pwidth=%i&pheight=%i" % \
        (SAT_ZOOM_LEVEL,
        coordinates[0],
        coordinates[1],
        image_size[0]/2,
        image_size[1]/2,
        image_size[0],
        image_size[1])
    for line in urllib.urlopen(request1):
        if line.startswith("<td align=left><input type=image src="):
            request2 = "http://onearth.jpl.nasa.gov/%s" % (line.split("\"")[1],)
            break
            urllib.urlretrieve(request2, name)

if __name__ == '__main__':
    retrieveImage((60.7376856, 56.5757572), (800,600), "test.jpg")
    # Specified coordinates is the point accurately at the image center


########################################################################
#
#        Infrared Global Geostationary Composite Quick View
#
#        Description: This code generates a PNG image of an Infrared 
#                Global Geostationary Composite data file
#
#        Authors: Matthew Smith, Leigh Sinclair
#        Information and Technology Systems Center (ITSC)
#        University of Alabama in Huntsville
#
#        Last Edited: 5 July 2017
#
#
########################################################################

#Import Python packages
import sys
import os
import struct
import matplotlib.pyplot as plt
 
# Define the file path to the desired date file 
globir="C:/Users/lsinclair/Desktop/globalIR/globir.17019.0545" #Place path to file here using forward slashes
try:
    IN=open(globir, 'rb')
except:
    print 'Error: opening file', globir
    exit(1)

# Read the first 768 bytes of the file containing the header and navigation information
dataOffset=768
header=struct.unpack('<192I', IN.read(768))
 
# Extract the data parameters
lines=header[8]
elements=header[9]
arraySize=lines*elements
format="%4dB" % (arraySize)
dataOffset=header[33]   # offset to data array (bytes)
 
# Read image array into a 1D array
IN.seek(dataOffset)
array=struct.unpack(format, IN.read(arraySize))
IN.close()
 
# Set up 2D array and reshape to 2D array to plot the data
array2D=[]
for n in range(0,lines):
    array2D.append(array[n*elements:(n+1)*elements])
 
# Create a plot of the data. The generated PNG image will save to the same folder where the data file is saved.
fig=plt.imshow(array2D, cmap='gray', interpolation='none')
plt.axis('off')
fig.axes.get_xaxis().set_visible(False)
fig.axes.get_yaxis().set_visible(False)
try:
    plt.savefig(globir+".png", dpi=400, bbox_inches='tight', pad_inches=0)
except:
    print 'Error: saving figure to',globir+".png"
    exit(1)
else:
    print 'Success, saved to', globir+".png"
plt.close('all')
exit(0)

print "Image created"


from PIL import Image, ImageFilter
import os
import cv2
import random
import time
path = r"instagram/"
#path = r"crawler4/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
    ])
filename0=(path+base_image)
im = Image.open(filename0)
imP = im.convert('RGB').convert('P', palette=Image.ADAPTIVE, colors=6)
imP.putpalette([
     243,164,10,
     157,17,17,
     66,99,166,
     70,155,53,
     0,0,0,
     70,70,140,
     ])


im2 = Image.open(filename0)
mask0 = im2.convert('L') # need a greyscale image to create a mask
mask = Image.eval(mask0, lambda a: 255 if a == 0 else 0)
mask = mask.filter(ImageFilter.MinFilter(3))
imP.paste(2, mask) # Paste the color of index 2 using image2 as a mask
filename = time.strftime("search/PILStuff%Y%m%d%H%M%S.png")
imP.save(filename)

print filename
imP

jacknorthrup
Lloyd1948

path = "."
files = (file for file in os.listdir(path) 
         if os.path.isfile(os.path.join(path, file)))
for file in files:
    if "." not in file:
        print(file)

import os 
for file in os.listdir("."):
    if "." not in file:
        print(file)

!ls *.py

filename = "mkimag.py"
f= open(filename, "r").readlines()
for line in f:
    line = line.replace("\n","")
    print (line)

filenam = "Tweetme2"
fn= open(filenam, "r").readlines()
for linen in fn:
    linen = linen.replace("\n","")
    print (linen)

#%%writefile Tweetme2
import cv2
import numpy as np
import time
import random
import twython
from twython import Twython
import shutil
import os
from random import randint
from PIL import Image, ImageFont, ImageDraw, ImageFilter
from skimage import io
from randtext import randTXT
STR = randTXT()
#print (STR)
import cv2
from PIL import Image
randomframes = []
images=[]
count = 0
def vid2img(filename, count):
    vidcap = cv2.VideoCapture(filename)
    # get total number of frames
    totalFrames = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)

    randomFrameNumber=random.randint(0, totalFrames)
    randomframes.append(randomFrameNumber)
    # set frame position
    vidcap.set(cv2.CAP_PROP_POS_FRAMES,randomFrameNumber)
    success, image = vidcap.read()
    if success:
        print(".",end="|")
        cv2.imwrite("junk/archived-images.jpg", image)
    IM = Image.open("junk/archived-images.jpg")
    im = IM.resize((720,480))
    timestr = time.strftime("%Y%m%d-%H%M%S")
    filename = "onevid/"+str(count)+".jpg"
    images.append(filename)
    im.save(filename)
    nim = Image.open(filename)
    print(filename)
    return nim
#/home/jack/Desktop/dockercommands/complete-videos/24sept-output-slow-3per-sec-jpgs.mp4
#filename ="/home/jack/Desktop/dockercommands/complete-videos/24sept-output-slow-3per-sec-jpgs.mp4"
#filename ="/media/jack/HDD500/LinuxtoyboxVideos/test001.mp4"
filename ="/media/jack/HDD500/LinuxtoyboxVideos/Man_Ray_Style_Art_Video_Bot_Generated_Images_Us.mp4"
for count in range(0,3):
    vid2img(filename, count)
    
print(randomframes)    

def creatmased(count):
    dim = (720, 480)
    
    img1 = cv2.imread("onevid/0.jpg")
    im1 = cv2.resize(img1, dim, interpolation = cv2.INTER_AREA)

    img2 = cv2.imread(images[1])
    im2 = cv2.resize(img2, dim, interpolation = cv2.INTER_AREA)
    # read saliency mask as grayscale and resize to same size as img1
    
    mask = io.imread("onevid/1.jpg")
    #conn = cv2.imread(images[2])
    #cv2.imwrite("onevid/3.jpg", conn)
    mask = io.imread(images[2])
    mask = cv2.imread("onevid/2.jpg")
    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)
    mask = cv2.resize(mask, dim, interpolation = cv2.INTER_AREA)

    # add img1 and img2
    img12 = cv2.add(img1, img2)

    # get mean of mask and shift mean to mid-gray
    # desirable for hard light compositing
    # add bias as needed
    mean = np.mean(mask)
    bias = -32
    shift = 128 - mean + bias
    mask = cv2.add(mask, shift)
    mask = cv2.merge([mask,mask,mask])

    # threshold mask at mid gray and convert to 3 channels
    # (needed to use as src < 0.5 "if" condition in hard light)
    thresh = cv2.threshold(mask, 128, 255, cv2.THRESH_BINARY)[1]

    # do hard light composite of img12 and mask
    # see CSS specs at https://www.w3.org/TR/compositing-1/#blendinghardlight
    img12f = img12.astype(np.uint8)/255
    maskf =  mask.astype(np.uint8)/255
    threshf =  thresh.astype(np.uint8)/255
    threshf_inv = 1 - threshf
    low = 2.0 * img12f * maskf
    high = 1 - 2.0 * (1-img12f) * (1-maskf)
    result = ( 255 * (low * threshf_inv + high * threshf) ).clip(0, 255).astype(np.uint8)
    timestr = time.strftime("%Y%m%d-%H%M%S")
    file = "onevid/"+timestr+"_"+str(count)+".png"
    cv2.imwrite(file, result)
    cv2.imwrite("onevid/temp.png", img1)
    text = "NFT TwitterBot Project"
    
    # Create font
    font = ImageFont.truetype('/snap/gnome-3-38-2004/99/usr/share/fonts/\
    truetype/dejavu/DejaVuSans-Bold.ttf', 18)
    # Create piece of canvas to draw text on and blur
    imgsize = Image.open("onevid/temp.png")
    imgsize=imgsize.resize((720,480), Image.NEAREST)
    bg= imgsize
    ##overlay ="/home/jack/Desktop/dockercommands/toplayer/3020220925140724.png"
    #mask=Image.open(overlay)#.convert('RGBA')
    #imgsize.paste(mask, (0,0), mask=mask)  
    #overlay ="/home/jack/Desktop/dockercommands/toplayer/14320220925140747.png"
    #overlay ="/home/jack/Desktop/dockercommands/toplayer/23620220925140804.png"
    #mask=Image.open(overlay).convert('RGBA')
    #imgsize.paste(mask, (0,0), mask=mask)      
    #STR = randTXT()
    Hash = ["#AIart #Tensorflow #twitme #100DaysOfCode\n",
            "#styletransfer #PythonGraphics #PIL\n",
            "#NFTartist #NFTProject #NEARnft #nearNFTs\n",
            "#NFT #NFTs #NFTCommunity #NFTdrop #nftart\n",
            "#CreativeCoding #AI #genart","#p5js #Generative\n",
            "#codefor30days #Python #100DaysOfCode\n",
            "#Python #100DaysOfCode #PythonBots #twitme\n"]
    hashnum = randint(0,len(Hash)-1)
    hashs =Hash[hashnum] 
    # add the hash to STR generated with randTXT()

    # Open background image and work out centre
    x = 720//2
    y = 480//2

    # The text we want to add
    #text = "NFT TwitterBot Project"
    text = hashs
    
    
    
    x = imgsize.width//2
    y = imgsize.height//2
    blurred = Image.new('RGBA', imgsize.size)
    draw = ImageDraw.Draw(blurred)
    """
    draw.text(xy=(x,y+230), text=text, fill='white', font=font, anchor='mm')
    draw.text(xy=(x,y+231), text=text, fill='white', font=font, anchor='mm')
    draw.text(xy=(x,y+232), text=text, fill='white', font=font, anchor='mm')
    draw.text(xy=(x,y+230), text=text, fill='white', font=font, anchor='mm')
    draw.text(xy=(x,y+231), text=text, fill='white', font=font, anchor='mm')
    draw.text(xy=(x,y+232), text=text, fill='white', font=font, anchor='mm')
    blurred = blurred.filter(ImageFilter.BoxBlur(2))
    # Paste soft text onto background
    imgsize.paste(blurred,blurred)
    # Draw on sharp text
    draw = ImageDraw.Draw(imgsize)
    draw.text(xy=(x,y+231), text=text, fill='black', font=font, anchor='mm') 
    """
    CH = randint(0,1)
    if CH == 0:COLor = ["white","black"]
    elif CH == 1:COLor = ["black","white"]  
    draw.text(xy=(x+20,y+230), text=text, fill=COLor[0], font=font, anchor='mm')
    draw.text(xy=(x+21,y+231), text=text, fill=COLor[0], font=font, anchor='mm')
    draw.text(xy=(x+22,y+229), text=text, fill=COLor[0], font=font, anchor='mm')
    draw.text(xy=(x+20,y+228), text=text, fill=COLor[0], font=font, anchor='mm')
    blurred = blurred.filter(ImageFilter.BoxBlur(2))
    # Paste soft text onto background
    bg.paste(blurred,blurred)
    # Draw on sharp text
    draw = ImageDraw.Draw(bg)
    draw.text(xy=(x+20,y+230), text=text, fill=COLor[1], font=font, anchor='mm')

    
    
    
    #postage = ["perferations.png","perferations+.png","usa-perferations.png","usar-perferations.png","usal-perferations.png"]
    #Num = randint( 0, len(postage)-1)
    #BOARDER = postage[Num]
    frames =["wood-blur-frame.png","frames.png","lined-frame.png","black-blur-frame.png", "white-blur-frame.png","beige-blur-frame.png","frame-lite.png"]
    Num = randint( 0, len(frames)-1)
    BOARDER = frames[Num]

    
    #overlay ="/home/jack/Desktop/dockercommands/toplayer/4020220925140726.png"
    #mask=Image.open(overlay).convert('RGBA')
    #imgsize.paste(mask, (0,0), mask=mask)  
    
    
    
    mask=Image.open(BOARDER).convert('RGBA') 
    imgsize.paste(mask, (0,0), mask=mask)
    # save results
    timestr = time.strftime("%Y%m%d-%H%M%S")
    file = "onevid/"+timestr+"_"+str(count+1)+".png"
    
    imgsize.save(file)
    imgsize.save("onevid/temp.png")
    #im = Image.open(filename)
    #im
    STR = randTXT()
    STR = hashs+STR
    STR= STR[:240]
    print(STR)
    return (STR)
#for count in range(0,1500):
count = 1
creatmased(count)
print(count,end=".")

from OutlineImage import outlineP
filename1 = "onevid/temp.png" 
outfile_png = "onevid/temp.png" 
outlineP(filename1,outfile_png)


CONSUMER_KEY = 'APIkey()[0]'
CONSUMER_SECRET = 'APIkey()[1]'
ACCESS_KEY = 'APIkey()[2]'
ACCESS_SECRET = 'APIkey()[3]'

twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)
PATH = "onevid/temp.png"
#PATH = "Screenshot_2022-09-29_23-06-02.png"
photo = open(PATH,'rb')

Hash = ["#AIart #Tensorflow #twitme #100DaysOfCode\n",     
        "#styletransfer #PythonGraphics #PIL\n",
        "#NFTartist #NFTProject #NEARnft #nearNFTs\n",
        "#NFT #NFTs #NFTCommunity #NFTdrop #nftart\n",
        "#CreativeCoding #AI #genart","#p5js #Generative\n",
        "#codefor30days #Python #100DaysOfCode\n",
        "#Python #100DaysOfCode #PythonBots #twitme\n"]
hashnum = randint(0,len(Hash)-1)
hashs =Hash[hashnum] 
STR = randTXT()
STR = hashs+STR
STR= STR[:240]
print("STR: ",STR)
#response = twitter.upload_media(media=photo)
#twitter.update_status(status=STR, media_ids=[response['media_id']])


PATH = "onevid/temp.png"
from PIL import Image
im = Image.open(PATH)
im

response = twitter.upload_media(media=photo)
twitter.update_status(status=STR, media_ids=[response['media_id']])

%%writefile mkimag.py
#import Image and ImageEnhance modules
from PIL import Image, ImageEnhance, ImageChops
from random import randint
import random
import os
import time
import shutil
import cv2   
def mkimag(videofile):
    vidcap = cv2.VideoCapture(videofile)
    # get total number of frames
    cnt = 0
    totalFrames = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)
    randomFrameNumber=random.randint(0, totalFrames)
    # set frame position
    vidcap.set(cv2.CAP_PROP_POS_FRAMES,randomFrameNumber)
    success, image = vidcap.read()
    if success:
           cv2.imwrite("junk/archived-images.jpg", image)
    IM = Image.open("junk/archived-images.jpg")
    im = IM.resize((720,480))
    timestr = time.strftime("%Y%m%d-%H%M%S")
    filename = "onevid/temp.jpg"
    im.save(filename)
    im = Image.open(filename)
    print(filename)
    im = im.resize((960,960), Image.ANTIALIAS)
    #print(im.size)
    Brighten = ImageEnhance.Brightness(im) # Create a Brightness class
    brightimage = Brighten.enhance(1.1)
    brightimage.save("junk/temp-brightened.jpg") # Save results
    im = Image.open("junk/temp-brightened.jpg") # Open the Image
    sharpened = ImageEnhance.Sharpness(im) # Create an object using Sharpness
    sharpenedimage = sharpened.enhance(1.1)
    sharpenedimage.save("junk/temp-sharpenedimage.jpg") # Save results
    im = Image.open('junk/temp-sharpenedimage.jpg') # Open the Image
    contrast = ImageEnhance.Contrast(im) # Create an object using Sharpness
    contrastedimage = contrast.enhance(1.1)
    contrastedimage.save('junk/temp-contrastedimage.jpg') # Save results
    im = Image.open("junk/temp-contrastedimage.jpg")
    width, height = im.size   # Get dimensions
    #im = im.resize((2*width,2*height), "Image.NEAREST" (0))
    #im = im.resize((2*width,2*height), Image.ANTIALIAS)
    Choose = ["insta-usa-perferations.png", "insta-philippines-perferations.png","insta-perferations.png"]
    num = randint(0,2)
    border = (Choose[num])
    mask=Image.open(border).convert('RGBA') 
    im.paste(mask, (0,0), mask=mask)
    timestr = time.strftime("%Y%m%d-%H%M%S")
    filename = "junk/insta"+timestr+"_.jpg"
    im.save(filename)
    im.save('junk/temp1.jpg')
    return im
   


!ls /media/jack/HDD500/LinuxtoyboxVideos/

"/media/jack/HDD500/LinuxtoyboxVideos/Man_Ray_Style_Art_Video_Bot_Generated_Images_Us.mp4"

from mkimag import mkimag
videofile ="/media/jack/HDD500/LinuxtoyboxVideos/JACK.mp4"
im = mkimag(videofile)
im

!mkdir insta-posted

%%writefile videoimage.py
import cv2
from PIL import Image, ImageEnhance, ImageChops
from random import randint
import random
import os
import time
import shutil
def vid4img(filename):
    vidcap = cv2.VideoCapture(filename)
    # get total number of frames
    totalFrames = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)
    randomFrameNumber=random.randint(0, totalFrames)
    # set frame position
    vidcap.set(cv2.CAP_PROP_POS_FRAMES,randomFrameNumber)
    success, image = vidcap.read()
    if success:
           cv2.imwrite("junk/archived-images.jpg", image)
    IM = Image.open("junk/archived-images.jpg")
    im = IM.resize((720,480))
    timestr = time.strftime("%Y%m%d-%H%M%S")
    filename = "onevid/"+str(count)+".jpg"
    im.save(filename)
    im = Image.open(filename)
    print(filename)
    return im

  

from videoimage import vid4img
filename ="/media/jack/HDD500/LinuxtoyboxVideos/Man_Ray_Style_Art_Video_Bot_Generated_Images_Us.mp4"
count = 1
file = vid4img(filename)
print (file)  

from PIL import Image
im = Image.open("onevid/1.jpg")
im

# %load InstaBot
#!/bin/bash

while true; do
  ./use-post-to-instagram.py
  echo "posted to instagram:"
  date
  sleep 3600s
done


from mkimag import mkimag
im = mkimag()


# %load use-post-to-instagram.py
#!/home/jack/miniconda3/envs/cloned_base/bin/python
from instabot import Bot
import os
import shutil
import markovify
from PIL import Image, ImageEnhance, ImageChops
from mkimag import mkimag
from randtext import randTXT
from time import sleep
from random import randint
STR = randTXT()
print(STR)
im = mkimag()


with open("sart.txt") as f:
    data = f.read()
data_model = markovify.Text(data)
#STR = data_model.make_sentence()



def clean_up(i):
    dir = "config"
    remove_me = "imgs\{}.REMOVE_ME".format(i)
    # checking whether config folder exists or not
    if os.path.exists(dir):
        try:
            # removing it so we can upload new image
            shutil.rmtree(dir)
        except OSError as e:
            print("Error: %s - %s." % (e.filename, e.strerror))
    if os.path.exists(remove_me):
        src = os.path.realpath("junk/{}".format(i))
        os.rename(remove_me, src)


def upload_post(i):
    bot = Bot()

    bot.login(username="jacklnorthrup", password="Pxyackjs22")
    bot.upload_photo("junk/{}".format(i), caption=STR)


#if __name__ == '__main__':
# enter name of your image bellow
image_name = "temp1.jpg"
clean_up(image_name)
upload_post(image_name)
tm = randint(1200,3800)
sleep(tm)
print("sleeping: ",tm, " seconds")
print(image_name)





path = "."
files = (file for file in os.listdir(path) 
         if os.path.isfile(os.path.join(path, file)))
for file in files:
    if "." not in file:
        print(file)

import os 
for file in os.listdir("."):
    if "." not in file:
        print(file)

!ls *.py

filename = "mkimag.py"
f= open(filename, "r").readlines()
for line in f:
    line = line.replace("\n","")
    print (line)

filenam = "Tweetme2"
fn= open(filenam, "r").readlines()
for linen in fn:
    linen = linen.replace("\n","")
    print (linen)

# %load Tweetme2
import cv2
import numpy as np
import time
import random
import twython
from twython import Twython
import shutil
import os
from random import randint
from PIL import Image, ImageFont, ImageDraw, ImageFilter
from skimage import io
from randtext import randTXT
STR = randTXT()
#print (STR)
import cv2
from PIL import Image
randomframes = []
images=[]
count = 0
def vid2img(filename, count):
    vidcap = cv2.VideoCapture(filename)
    # get total number of frames
    totalFrames = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)

    randomFrameNumber=random.randint(0, totalFrames)
    randomframes.append(randomFrameNumber)
    # set frame position
    vidcap.set(cv2.CAP_PROP_POS_FRAMES,randomFrameNumber)
    success, image = vidcap.read()
    if success:
        print(".",end="|")
        cv2.imwrite("junk/archived-images.jpg", image)
    IM = Image.open("junk/archived-images.jpg")
    im = IM.resize((720,480))
    timestr = time.strftime("%Y%m%d-%H%M%S")
    filename = "onevid/"+str(count)+".jpg"
    images.append(filename)
    im.save(filename)
    nim = Image.open(filename)
    print(filename)
    return nim
#/home/jack/Desktop/dockercommands/complete-videos/24sept-output-slow-3per-sec-jpgs.mp4
#filename ="/home/jack/Desktop/dockercommands/complete-videos/24sept-output-slow-3per-sec-jpgs.mp4"
#filename ="/media/jack/HDD500/LinuxtoyboxVideos/test001.mp4"
filename ="/media/jack/HDD500/LinuxtoyboxVideos/Man_Ray_Style_Art_Video_Bot_Generated_Images_Us.mp4"
for count in range(0,3):
    vid2img(filename, count)
    
print(randomframes)    

def creatmased(count):
    dim = (720, 480)
    
    img1 = cv2.imread("onevid/0.jpg")
    im1 = cv2.resize(img1, dim, interpolation = cv2.INTER_AREA)

    img2 = cv2.imread(images[1])
    im2 = cv2.resize(img2, dim, interpolation = cv2.INTER_AREA)
    # read saliency mask as grayscale and resize to same size as img1
    
    mask = io.imread("onevid/1.jpg")
    #conn = cv2.imread(images[2])
    #cv2.imwrite("onevid/3.jpg", conn)
    mask = io.imread(images[2])
    mask = cv2.imread("onevid/2.jpg")
    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)
    mask = cv2.resize(mask, dim, interpolation = cv2.INTER_AREA)

    # add img1 and img2
    img12 = cv2.add(img1, img2)

    # get mean of mask and shift mean to mid-gray
    # desirable for hard light compositing
    # add bias as needed
    mean = np.mean(mask)
    bias = -32
    shift = 128 - mean + bias
    mask = cv2.add(mask, shift)
    mask = cv2.merge([mask,mask,mask])

    # threshold mask at mid gray and convert to 3 channels
    # (needed to use as src < 0.5 "if" condition in hard light)
    thresh = cv2.threshold(mask, 128, 255, cv2.THRESH_BINARY)[1]

    # do hard light composite of img12 and mask
    # see CSS specs at https://www.w3.org/TR/compositing-1/#blendinghardlight
    img12f = img12.astype(np.uint8)/255
    maskf =  mask.astype(np.uint8)/255
    threshf =  thresh.astype(np.uint8)/255
    threshf_inv = 1 - threshf
    low = 2.0 * img12f * maskf
    high = 1 - 2.0 * (1-img12f) * (1-maskf)
    result = ( 255 * (low * threshf_inv + high * threshf) ).clip(0, 255).astype(np.uint8)
    timestr = time.strftime("%Y%m%d-%H%M%S")
    file = "onevid/"+timestr+"_"+str(count)+".png"
    cv2.imwrite(file, result)
    cv2.imwrite("onevid/temp.png", img1)
    text = "NFT TwitterBot Project"
    
    # Create font
    font = ImageFont.truetype('/snap/gnome-3-38-2004/99/usr/share/fonts/\
    truetype/dejavu/DejaVuSans-Bold.ttf', 18)
    # Create piece of canvas to draw text on and blur
    imgsize = Image.open("onevid/temp.png")
    imgsize=imgsize.resize((720,480), Image.NEAREST)
    bg= imgsize
    ##overlay ="/home/jack/Desktop/dockercommands/toplayer/3020220925140724.png"
    #mask=Image.open(overlay)#.convert('RGBA')
    #imgsize.paste(mask, (0,0), mask=mask)  
    #overlay ="/home/jack/Desktop/dockercommands/toplayer/14320220925140747.png"
    #overlay ="/home/jack/Desktop/dockercommands/toplayer/23620220925140804.png"
    #mask=Image.open(overlay).convert('RGBA')
    #imgsize.paste(mask, (0,0), mask=mask)      
    #STR = randTXT()
    Hash = ["#AIart #Tensorflow #twitme #100DaysOfCode\n",
            "#styletransfer #PythonGraphics #PIL\n",
            "#NFTartist #NFTProject #NEARnft #nearNFTs\n",
            "#NFT #NFTs #NFTCommunity #NFTdrop #nftart\n",
            "#CreativeCoding #AI #genart","#p5js #Generative\n",
            "#codefor30days #Python #100DaysOfCode\n",
            "#Python #100DaysOfCode #PythonBots #twitme\n"]
    hashnum = randint(0,len(Hash)-1)
    hashs =Hash[hashnum] 
    # add the hash to STR generated with randTXT()

    # Open background image and work out centre
    x = 720//2
    y = 480//2

    # The text we want to add
    #text = "NFT TwitterBot Project"
    text = hashs
    
    
    
    x = imgsize.width//2
    y = imgsize.height//2
    blurred = Image.new('RGBA', imgsize.size)
    draw = ImageDraw.Draw(blurred)
    """
    draw.text(xy=(x,y+230), text=text, fill='white', font=font, anchor='mm')
    draw.text(xy=(x,y+231), text=text, fill='white', font=font, anchor='mm')
    draw.text(xy=(x,y+232), text=text, fill='white', font=font, anchor='mm')
    draw.text(xy=(x,y+230), text=text, fill='white', font=font, anchor='mm')
    draw.text(xy=(x,y+231), text=text, fill='white', font=font, anchor='mm')
    draw.text(xy=(x,y+232), text=text, fill='white', font=font, anchor='mm')
    blurred = blurred.filter(ImageFilter.BoxBlur(2))
    # Paste soft text onto background
    imgsize.paste(blurred,blurred)
    # Draw on sharp text
    draw = ImageDraw.Draw(imgsize)
    draw.text(xy=(x,y+231), text=text, fill='black', font=font, anchor='mm') 
    """
    CH = randint(0,1)
    if CH == 0:COLor = ["white","black"]
    elif CH == 1:COLor = ["black","white"]  
    draw.text(xy=(x+20,y+230), text=text, fill=COLor[0], font=font, anchor='mm')
    draw.text(xy=(x+21,y+231), text=text, fill=COLor[0], font=font, anchor='mm')
    draw.text(xy=(x+22,y+229), text=text, fill=COLor[0], font=font, anchor='mm')
    draw.text(xy=(x+20,y+228), text=text, fill=COLor[0], font=font, anchor='mm')
    blurred = blurred.filter(ImageFilter.BoxBlur(2))
    # Paste soft text onto background
    bg.paste(blurred,blurred)
    # Draw on sharp text
    draw = ImageDraw.Draw(bg)
    draw.text(xy=(x+20,y+230), text=text, fill=COLor[1], font=font, anchor='mm')

    
    
    
    #postage = ["perferations.png","perferations+.png","usa-perferations.png","usar-perferations.png","usal-perferations.png"]
    #Num = randint( 0, len(postage)-1)
    #BOARDER = postage[Num]
    frames =["wood-blur-frame.png","frames.png","lined-frame.png","black-blur-frame.png", "white-blur-frame.png","beige-blur-frame.png","frame-lite.png"]
    Num = randint( 0, len(frames)-1)
    BOARDER = frames[Num]

    
    #overlay ="/home/jack/Desktop/dockercommands/toplayer/4020220925140726.png"
    #mask=Image.open(overlay).convert('RGBA')
    #imgsize.paste(mask, (0,0), mask=mask)  
    
    
    
    mask=Image.open(BOARDER).convert('RGBA') 
    imgsize.paste(mask, (0,0), mask=mask)
    # save results
    timestr = time.strftime("%Y%m%d-%H%M%S")
    file = "onevid/"+timestr+"_"+str(count+1)+".png"
    
    imgsize.save(file)
    imgsize.save("onevid/temp.png")
    #im = Image.open(filename)
    #im
    STR = randTXT()
    STR = hashs+STR
    STR= STR[:240]
    print(STR)
    return (STR)
#for count in range(0,1500):
count = 1
creatmased(count)
print(count,end=".")

from OutlineImage import outlineP
filename1 = "onevid/temp.png" 
outfile_png = "onevid/temp.png" 
outlineP(filename1,outfile_png)


CONSUMER_KEY = 'APIkey()[0]'
CONSUMER_SECRET = 'APIkey()[1]'
ACCESS_KEY = 'APIkey()[2]'
ACCESS_SECRET = 'APIkey()[3]'

twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)
PATH = "onevid/temp.png"
#PATH = "Screenshot_2022-09-29_23-06-02.png"
photo = open(PATH,'rb')

Hash = ["#AIart #Tensorflow #twitme #100DaysOfCode\n",     
        "#styletransfer #PythonGraphics #PIL\n",
        "#NFTartist #NFTProject #NEARnft #nearNFTs\n",
        "#NFT #NFTs #NFTCommunity #NFTdrop #nftart\n",
        "#CreativeCoding #AI #genart","#p5js #Generative\n",
        "#codefor30days #Python #100DaysOfCode\n",
        "#Python #100DaysOfCode #PythonBots #twitme\n"]
hashnum = randint(0,len(Hash)-1)
hashs =Hash[hashnum] 
STR = randTXT()
STR = hashs+STR
STR= STR[:240]
print("STR: ",STR)
response = twitter.upload_media(media=photo)
twitter.update_status(status=STR, media_ids=[response['media_id']])


PATH = "onevid/temp.png"
from PIL import Image
im = Image.open(PATH)
im

response = twitter.upload_media(media=photo)
twitter.update_status(status=STR, media_ids=[response['media_id']])

%%writefile mkimag.py
#import Image and ImageEnhance modules
from PIL import Image, ImageEnhance, ImageChops
from random import randint
import random
import os
import time
import shutil
import cv2   
def mkimag(videofile):
    vidcap = cv2.VideoCapture(videofile)
    # get total number of frames
    cnt = 0
    totalFrames = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)
    randomFrameNumber=random.randint(0, totalFrames)
    # set frame position
    vidcap.set(cv2.CAP_PROP_POS_FRAMES,randomFrameNumber)
    success, image = vidcap.read()
    if success:
           cv2.imwrite("junk/archived-images.jpg", image)
    IM = Image.open("junk/archived-images.jpg")
    im = IM.resize((720,480))
    timestr = time.strftime("%Y%m%d-%H%M%S")
    filename = "onevid/temp.jpg"
    im.save(filename)
    im = Image.open(filename)
    print(filename)
    im = im.resize((960,960), Image.ANTIALIAS)
    #print(im.size)
    Brighten = ImageEnhance.Brightness(im) # Create a Brightness class
    brightimage = Brighten.enhance(1.1)
    brightimage.save("junk/temp-brightened.jpg") # Save results
    im = Image.open("junk/temp-brightened.jpg") # Open the Image
    sharpened = ImageEnhance.Sharpness(im) # Create an object using Sharpness
    sharpenedimage = sharpened.enhance(1.1)
    sharpenedimage.save("junk/temp-sharpenedimage.jpg") # Save results
    im = Image.open('junk/temp-sharpenedimage.jpg') # Open the Image
    contrast = ImageEnhance.Contrast(im) # Create an object using Sharpness
    contrastedimage = contrast.enhance(1.1)
    contrastedimage.save('junk/temp-contrastedimage.jpg') # Save results
    im = Image.open("junk/temp-contrastedimage.jpg")
    width, height = im.size   # Get dimensions
    #im = im.resize((2*width,2*height), "Image.NEAREST" (0))
    #im = im.resize((2*width,2*height), Image.ANTIALIAS)
    Choose = ["insta-usa-perferations.png", "insta-philippines-perferations.png","insta-perferations.png"]
    num = randint(0,2)
    border = (Choose[num])
    mask=Image.open(border).convert('RGBA') 
    im.paste(mask, (0,0), mask=mask)
    timestr = time.strftime("%Y%m%d-%H%M%S")
    filename = "junk/insta"+timestr+"_.jpg"
    im.save(filename)
    im.save('junk/temp1.jpg')
    return im
   


!ls /media/jack/HDD500/LinuxtoyboxVideos/

"/media/jack/HDD500/LinuxtoyboxVideos/Man_Ray_Style_Art_Video_Bot_Generated_Images_Us.mp4"

from mkimag import mkimag
videofile ="/media/jack/HDD500/LinuxtoyboxVideos/JACK.mp4"
im = mkimag(videofile)
im

!mkdir insta-posted

%%writefile videoimage.py
import cv2
from PIL import Image, ImageEnhance, ImageChops
from random import randint
import random
import os
import time
import shutil
def vid4img(filename):
    vidcap = cv2.VideoCapture(filename)
    # get total number of frames
    totalFrames = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)
    randomFrameNumber=random.randint(0, totalFrames)
    # set frame position
    vidcap.set(cv2.CAP_PROP_POS_FRAMES,randomFrameNumber)
    success, image = vidcap.read()
    if success:
           cv2.imwrite("junk/archived-images.jpg", image)
    IM = Image.open("junk/archived-images.jpg")
    im = IM.resize((720,480))
    timestr = time.strftime("%Y%m%d-%H%M%S")
    filename = "onevid/"+str(count)+".jpg"
    im.save(filename)
    im = Image.open(filename)
    print(filename)
    return im

  

from videoimage import vid4img
filename ="/media/jack/HDD500/LinuxtoyboxVideos/Man_Ray_Style_Art_Video_Bot_Generated_Images_Us.mp4"
count = 1
file = vid4img(filename)
print (file)  

from PIL import Image
im = Image.open("onevid/1.jpg")
im

# %load InstaBot
#!/bin/bash

while true; do
  ./use-post-to-instagram.py
  echo "posted to instagram:"
  date
  sleep 3600s
done


from mkimag import mkimag
im = mkimag()


# %load use-post-to-instagram.py
#!/home/jack/miniconda3/envs/cloned_base/bin/python
from instabot import Bot
import os
import shutil
import markovify
from PIL import Image, ImageEnhance, ImageChops
from mkimag import mkimag
from randtext import randTXT
from time import sleep
from random import randint
STR = randTXT()
print(STR)
im = mkimag()


with open("sart.txt") as f:
    data = f.read()
data_model = markovify.Text(data)
#STR = data_model.make_sentence()



def clean_up(i):
    dir = "config"
    remove_me = "imgs\{}.REMOVE_ME".format(i)
    # checking whether config folder exists or not
    if os.path.exists(dir):
        try:
            # removing it so we can upload new image
            shutil.rmtree(dir)
        except OSError as e:
            print("Error: %s - %s." % (e.filename, e.strerror))
    if os.path.exists(remove_me):
        src = os.path.realpath("junk/{}".format(i))
        os.rename(remove_me, src)


def upload_post(i):
    bot = Bot()

    bot.login(username="jacklnorthrup", password="Pxyackjs22")
    bot.upload_photo("junk/{}".format(i), caption=STR)


#if __name__ == '__main__':
# enter name of your image bellow
image_name = "temp1.jpg"
clean_up(image_name)
upload_post(image_name)
tm = randint(1200,3800)
sleep(tm)
print("sleeping: ",tm, " seconds")
print(image_name)





import sys
import time
from PIL import Image, ImageChops, ImageEnhance, ImageFilter, ImageDraw, ImageFont 
from time import sleep
import warnings
warnings.filterwarnings("ignore", message="numpy.dtype size changed")
warnings.filterwarnings("ignore", message="numpy.ufunc size changed")


import time
timestr = time.strftime("%Y%m%d%H%M%S")
filename = "Image-Stuff-Files/"+timestr+'_.txt'
print (filename)

import sys
sys.path.insert(0, "Image-Stuff-Files")
import GraphicJunkdb

import time
timestr = time.strftime("%Y-%m-%d %H:%M:%S")
print timestr

# Create Image from Tuples

tupledlist=[(171, 46, 10)]
from PIL import Image
OUTPUT_IMAGE_SIZE = (100, 100)
for frame_number, color in enumerate(tupledlist):
    print (frame_number,color)
    image = Image.new('RGB', OUTPUT_IMAGE_SIZE, color=color)
    image.save("Image-Stuff-Files/path.png")

im = Image.open('Image-Stuff-Files/path.png')
im

image=Image.open("Image-Stuff-Files/path.png")
print(list(image.getdata()))

!wget -O Image-Stuff-Files/leaves.jpg https://jacknorthrup.com/image2/017.jpg

from PIL import Image
# create an empty list called Tuples
Tuples = []
# Open Image-Stuff-Files/leaves.jpg
im = Image.open("Image-Stuff-Files/leaves.jpg")
# Resize image to 400x400
im = im.resize((400,400), Image.BICUBIC)
# save the resized image
im.save("Image-Stuff-Files/LEAF.png")

# Open the resized image Image-Stuff-Files/leaves.jpg
image=Image.open("Image-Stuff-Files/LEAF.png") 
tup = (list(image.getdata()))
for line in tup:
    line = str(line)
    Tuples.append(line+",")
    
tup = (list(image.getdata()))
for line in tup:
    line = str(line)
    Tuples.append(line+",")

image=Image.open("Image-Stuff-Files/LEAF.png") 
tup = (list(image.getdata()))
print tup

from PIL import Image
Tuples = []

image=Image.open("Image-Stuff-Files/SMALL.jpg") 
tup = (list(image.getdata()))
for line in tup:
    line = str(line)
    Tuples.append(line+",")

from PIL import Image
f = open('Image-Stuff-Files/LEAFpng.txt', 'w')

# Open the resized image Image-Stuff-Files/leaves.jpg
image=Image.open("Image-Stuff-Files/LEAF.png") 
tup = (list(image.getdata()))
tup = str(tup)
f.write(tup)
f.close()

from PIL import Image
f = open('Image-Stuff-Files/LEAFpng.txt', 'r').read()
OUTPUT_IMAGE_SIZE = (400, 400)
image = Image.new('RGB', OUTPUT_IMAGE_SIZE, color='white')
# the eval() function changes the string to a tuple
image.putdata(eval(f))
image.save("Image-Stuff-Files/LEAFpng.png")
image

from PIL import Image
f = open('Image-Stuff-Files/LEAFpng.txt', 'r').read()
OUTPUT_IMAGE_SIZE = (800, 200)
image = Image.new('RGB', OUTPUT_IMAGE_SIZE, color='white')
# the eval() function changes the string to a tuple
image.putdata(eval(f))
image.save("Image-Stuff-Files/LEAFpng.png")
image

f = open('Image-Stuff-Files/Tuples.txt', 'w')
count = 0
for line in Tuples:
    count = count +1
All = count
print All
cnt = 0
for line in Tuples:
    f.write(line)
f.close()    

x= 600
y = x*x
print y

from PIL import Image
f = open('Image-Stuff-Files/Tuples.txt', 'r').read()
OUTPUT_IMAGE_SIZE = (50, 50)
image = Image.new('RGB', OUTPUT_IMAGE_SIZE, color='white')
# the eval() function changes the string to a tuple
image.putdata(eval(f))
image.save("Image-Stuff-Files/path2.png")
image
    

from PIL import Image
f = open('Image-Stuff-Files/small.txt', 'r').read()
OUTPUT_IMAGE_SIZE = (50, 50)
image = Image.new('RGB', OUTPUT_IMAGE_SIZE, color='white')
# the eval() function changes the string to a tuple
image.putdata(eval(f))
image.save("Image-Stuff-Files/path2.png")
image
    

import numpy as np
from PIL import Image
someimage = "Image-Stuff-Files/LEAF.png"
img = Image.open(someimage).convert('1', dither=Image.NONE)
a_img = np.asarray(img) * 255
b_img = abs(a_img - 255)  
img.putdata(b_img)
c_img = np.asarray(img) * 255
c_img

from PIL import Image
img2 = Image.open("Image-Stuff-Files/leaves.jpg")
img3 = img2.resize((400,400), Image.BICUBIC)
img3.save("Image-Stuff-Files/LEAF3.jpg")
img3.size
im = Image.open("Image-Stuff-Files/LEAF3.jpg")
im

import numpy as np
from PIL import Image
img2 = Image.open('Image-Stuff-Files/leaves.jpg')
img3 = img2.resize((400,400), Image.BICUBIC)
img3.save('Image-Stuff-Files/leaf.jpg')
img2 = Image.open('Image-Stuff-Files/leaf.jpg').convert('1', dither=Image.NONE)
img3 = img2.resize((400,400), Image.BICUBIC)
OUTPUT_IMAGE_SIZE = (400, 400)
img = Image.new('RGB', OUTPUT_IMAGE_SIZE, color='white')
a_img = np.asarray(img3) * 255
# do some stuff with buffer
a_img = abs(a_img - 255)  
img.putdata(a_img.flatten())
img

import numpy as np
from PIL import Image
img2 = Image.open("Image-Stuff-Files/leaves.jpg")
img3 = img2.resize((50,50), Image.BICUBIC)
img3.save("Image-Stuff-Files/leaf50.jpg")
img2 = Image.open("Image-Stuff-Files/leaf50.jpg").convert('1', dither=Image.NONE)
img3 = img2.resize((50,50), Image.BICUBIC)
OUTPUT_IMAGE_SIZE = (50, 50)
img = Image.new('RGB', OUTPUT_IMAGE_SIZE, color='white')
a_img = np.asarray(img3) * 255
# do some stuff with buffer
a_img = abs(a_img - 255)
print (a_img)
img.putdata(a_img.flatten())
img.save("Image-Stuff-Files/SMALL.jpg")

from PIL import Image
img = Image.open("Image-Stuff-Files/SMALL.jpg")
img

from PIL import Image
Tuples = []

image=Image.open("Image-Stuff-Files/SMALL.jpg") 
tup = (list(image.getdata()))
for line in tup:
    line = str(line)
    Tuples.append(line+",")

list_of_pixels = list(im.getdata())
# Do something to the pixels...
im2 = Image.new(im.mode, im.size)
im2.putdata(list_of_pixels)
im2.save("Image-Stuff-Files/list_of_pixels.jpg")
im2

f = open('Image-Stuff-Files/Tuples.txt', 'w')
count = 0
for line in Tuples:
    count = count +1
All = count
print All
cnt = 0
for line in Tuples:
    cnt = cnt +1
    line = line.replace('\n', '')
    f.write(line)
f.close()    

from PIL import Image
Tuples = []

image=Image.open("Image-Stuff-Files/SMALL.jpg") 
tup = (list(image.getdata()))
for line in tup:
    line = str(line)
    Tuples.append(line+",")

from PIL import Image
f = open('Image-Stuff-Files/small.txt', 'r').read()
OUTPUT_IMAGE_SIZE = (50, 50)
image = Image.new('RGB', OUTPUT_IMAGE_SIZE, color='white')
# the eval() function changes the string to a tuple
image.putdata(eval(f))
image.save("Image-Stuff-Files/path2.png")
image
    



from PIL import Image
img = Image.open("Image-Stuff-Files/SMALL.jpg")
list_of_pixels = list(img.getdata())
# Do something to the pixels...
im2 = Image.new(img.mode, img.size)
im2.putdata(list_of_pixels)
im2

f = open('Image-Stuff-Files/small.txt', 'w')
from PIL import Image
img = Image.open("Image-Stuff-Files/SMALL.jpg")
list_of_pixels = list(img.getdata())
list_of_pixels = str(list_of_pixels)
f.write(list_of_pixels)

from PIL import Image
f = open('Image-Stuff-Files/small.txt', 'r').read()
print f

from PIL import Image
f = open('Image-Stuff-Files/small.txt', 'r').read()
OUTPUT_IMAGE_SIZE = (50, 50)
image = Image.new('RGB', OUTPUT_IMAGE_SIZE, color='white')
# the eval() function changes the string to a tuple
image.putdata(eval(f))
image.save("Image-Stuff-Files/path2.png")
image
    

!wget -O Image-Stuff-Files/STAMP.jpg https://jacknorthrup.com/postoids/postoid%20%285%29.jpg

from PIL import Image
Tuples = []
im = Image.open("Image-Stuff-Files/STAMP.jpg")
#im = im.resize((400,400), Image.BICUBIC)
im.save("Image-Stuff-Files/stamp.png")
w,h = im.size


image=Image.open("Image-Stuff-Files/stamp.png")

tup = (list(image.getdata()))
for line in tup:
    line = str(line)
    Tuples.append(line+",")
    
#tup = (list(image.getdata()))
#for line in tup:
#    line = str(line)
#    Tuples.append(line+",")
    
f = open('Image-Stuff-Files/Tuples1.txt', 'w')
count = 0
for line in Tuples:
    count = count +1
All = count
print All
cnt = 0
for line in Tuples:
    f.write(line)
f.close()        

f = open('Image-Stuff-Files/Tuples1.txt', 'r').read()
print len(f)
OUTPUT_IMAGE_SIZE = (w, h)
image = Image.new('RGB', OUTPUT_IMAGE_SIZE, color='white')
# the eval() function changes the string to a tuple
image.putdata(eval(f))
print image.size
image.save("Image-Stuff-Files/path3.png")
image    

LST = []
f = open('Image-Stuff-Files/Tuples.txt', 'r').readlines()
LST.append(f)

from random import randint 
from PIL import Image, ImageColor
col = str(randint(1,255))
im = Image.new("RGB", (32, 32), ImageColor.getrgb("rgb("+col+", 216, 230)"))
im.save('Image-Stuff-Files/simplePixel.png')
im

from PIL import Image, ImageColor
col0 = str(randint(1,255));col1 = str(randint(1,255));col3 = str(randint(1,255))
im = Image.new("RGB", (32, 32), ImageColor.getrgb("rgb("+col0+","+col1+","+col3+")"))
               
im.save('Image-Stuff-Files/simplePixel.png')
im

print "".join(Tuples)

image.putdata(tupledlist)
image.save("Image-Stuff-Files/path2.png")
image
    

from PIL import Image, ImageColor
from random import randint
for x in range(1024):
    col = randint(1, 255)
    #color = ("rgb("+str(col)+", 216, 230)")
    color = ('rgb(20,150,150)')
    im = Image.new("RGB", (132, 132), ImageColor.getrgb(color))
    im.save('Image-Stuff-Files/simplePixel.png')
    im

!showme Image-Stuff-Files/simplePixel.png

#Note r g b values are 0, 255,0* 
from PIL import Image
img = Image.new('RGB', [50,50], 0x000000)
color = (20, 255, 255)

img.putpixel((10,15),(color))   
img.save('Image-Stuff-Files/lolmini2.jpg')
img

#Note r g b values are 0, 255,0* 
from PIL import Image
import math
inc = 0
img = Image.new('RGB', [640,640], 0x000000)
color = (0, 0, 55)
colors = (50, 25, 255)
for x in range(640):
    for y in range(640):
        #print x,y
        inc = inc+1
        if math.cos(float(x+inc)) >= math.cos(float(y+inc**2)):
            img.putpixel((x,y),(color))
        if math.cos(float(x+inc**3)) >= math.cos(float(y+inc**2)):
            img.putpixel((x,y),(colors))       
img.save('Image-Stuff-Files/denim2.jpg')
img
        

#Note r g b values are 0, 255,0* 
from PIL import Image
import math
inc = 0
TOT = []
img = Image.new('RGB', [300,300], 0x000000)
color = (0, 0, 55)
colors = (50, 25, 255)
colorw = (255, 225, 0)
for x in range(300):
    for y in range(300):
        #print x,y
        inc = inc+1
        if math.cos(float(x+inc)) >= math.cos(float(y+inc**2)):
            img.putpixel((x,y),(color))
        if math.cos(float(y+inc**3)) >= math.cos(float(x+inc)):
            img.putpixel((x,y),(colors))
        #if math.cos(float(x+inc**3))+ math.cos(float(y+inc**2))==0:
        if (math.cos(float(x))+ math.cos(float(y**2))) >0 and (math.cos(float(x))+ math.cos(float(y**2)))<.21:
            img.putpixel((x,y),(colorw))             
            
            
img.save('Image-Stuff-Files/denim2l.jpg')
img
        

#Note r g b values are 0, 255,0* 
from PIL import Image
import math
inc = 0
TOT = []
size = 500
img = Image.new('RGB', [size,size], 0x000000)
color = (0, 0, 55)
colors = (250, 25, 255)
colorw = (255, 225, 0)
for x in range(size):
    for y in range(size):
        #print x,y
        inc = inc+1
        if math.cos(float(x+inc)) >= math.cos(float(y+inc**2)):
            img.putpixel((x,y),(color))
        if math.cos(float(x+inc**3)) >= math.cos(float(y+inc**2)):
            img.putpixel((x,y),(colors))
        #if math.cos(float(x+inc**3))+ math.cos(float(y+inc**2))==0:
        if (math.cos(float(x))+ math.cos(float(y))) >-.02 and (math.cos(float(x))+ math.cos(float(y)))<.085:
            img.putpixel((x,y),(colorw))
img.save('Image-Stuff-Files/denim2r.jpg')
img
# if (math.cos(float(x))+ math.cos(float(y))) >-.25 and (math.cos(float(x))+ math.cos(float(y)))<.25:
# if (math.cos(float(x))+ math.cos(float(y))) >-.05 and (math.cos(float(x))+ math.cos(float(y)))<.05:
# if (math.cos(float(x))+ math.cos(float(y))) >-.015 and (math.cos(float(x))+ math.cos(float(y)))<.015:
# if (math.cos(float(x))+ math.cos(float(y))) >-.02 and (math.cos(float(x))+ math.cos(float(y)))<.085:

#Note r g b values are 0, 255,0* 
from PIL import Image
import math
inc = 0
TOT = []
size = 500
img = Image.new('RGB', [size,size], 0x000000)
color = (0, 0, 55)
colors = (50, 25, 255)
colorw = (255, 225, 0)
for x in range(size):
    for y in range(size):
        #print x,y
        inc = inc+1
        if math.cos(float(x+inc)) >= math.cos(float(y+inc**2)):
            img.putpixel((x,y),(color))
        if math.cos(float(x+inc**3)) >= math.cos(float(y+inc**2)):
            img.putpixel((x,y),(colors))
        #if math.cos(float(x+inc**3))+ math.cos(float(y+inc**2))==0:
        if (math.cos(float(x))+ math.cos(float(y))) >-.015 and (math.cos(float(x))+ math.cos(float(y)))<.015:
            img.putpixel((x,y),(colorw))
img.save('Image-Stuff-Files/denim2B.jpg')
img
# if (math.cos(float(x))+ math.cos(float(y))) >-.25 and (math.cos(float(x))+ math.cos(float(y)))<.25:
# if (math.cos(float(x))+ math.cos(float(y))) >-.05 and (math.cos(float(x))+ math.cos(float(y)))<.05:
# if (math.cos(float(x))+ math.cos(float(y))) >-.015 and (math.cos(float(x))+ math.cos(float(y)))<.015:
# if (math.cos(float(x))+ math.cos(float(y))) >-.02 and (math.cos(float(x))+ math.cos(float(y)))<.085:

#Note r g b values are 0, 255,0* 
from PIL import Image
import math
inc = 0
img = Image.new('RGB', [640,640], 0x000000)
color = (50, 255, 255)
colors = (50, 25, 255)
for x in range(640):
    for y in range(640):
        #print x,y
        inc = inc+1
        if math.cos(float(x+inc)) >= math.cos(float(y+inc**2)):
            img.putpixel((x,y),(color))
        if math.cos(float(x+inc**3)) >= math.cos(float(y+inc**2)):
            img.putpixel((x,y),(colors))       
img.save('Image-Stuff-Files/denim03.jpg')
img
        

import os
import os.path
title = 'Image-Stuff-Files/ipynb-list.txt'
f= open(title,'a')
f.close()
count=0
for dirpath, dirnames, filenames in os.walk('/home/conda'):
    for filename in [f for f in filenames if f.endswith('.ipynb')]:
        count=count+1
        Path = os.path.join(dirpath, filename)
        with open(title, 'a') as outfile:
            path = Path+'\n'
            outfile.write(path)

%%writefile Image-Stuff-Files/NED
#!/usr/local/bin/python
import sys
import sqlite3
conn = sqlite3.connect("/home/TEMP/Databases/NED.db")
conn.text_factory = str
c = conn.cursor()
if len(sys.argv) < 3:
    print "\n*****************************************"
    print "Not enough options were passed."     
    print "NED requires 2 arguments. the first -H , -R , -I , -D or -S .\nThe second can be a period."
    print "If printing the database -T also add a filename of your choice ( no quotes required ):"
    print " Example: NED -T Data2Text.txt"   
    print "If wanting to read all entries use -R . (use the period)" 
    print "even use the period with help.  -H .   must be entered."
    print "*****************************************\n"
    sys.exit()
mod = sys.argv[1]
def create():
    import sqlite3
    conn = sqlite3.connect("/home/TEMP/Databases/NED.db")
    conn.text_factory = str
    c = conn.cursor()
    c.execute("CREATE VIRTUAL TABLE PROJECT using FTS4 (input)")
    conn.commit()
    text = "Database Created"
    return text

def insert(data,conn=conn, c=c):
    c.execute("INSERT into PROJECT values (?)", (data,))
    for row in c.execute("SELECT ROWID,* FROM PROJECT ORDER BY ROWID DESC LIMIT 1"):
        print "\nPOST VERIFIED:\n",row[0],row[1]
    conn.commit()
    conn.close()
    return data

def search(data,conn=conn, c=c):
    for row in c.execute("SELECT ROWID,* FROM PROJECT WHERE input MATCH ?",(data,)):
        print "\nINFO Found Here:\n",row[0],row[1]
    conn.commit()
    conn.close()
    return data

def delete(rowid,conn=conn, c=c):
    c.execute("DELETE FROM PROJECT WHERE rowid = ?", (rowid,))
    conn.commit()
    conn.close()
    text = "ROWID "+rowid+" Deleted"
    return text

def main():
    conn = sqlite3.connect("/home/TEMP/Databases/NED.db")
    conn.text_factory = str
    c = conn.cursor()
    for row in c.execute("SELECT rowid, * FROM PROJECT"):
        print row[0],": ",row[1]
        
def Dsearch():
    conn = sqlite3.connect("/home/TEMP/Databases/NED.db")
    conn.text_factory = str
    search = raw_input("Detail Search: ")
    c = conn.cursor()
    for row in c.execute("SELECT rowid, * FROM PROJECT"):
        if search in row[1]:
            print row[0],": ",row[1] 

def prtmain(filename):
    fn = open(filename, "w")
    conn = sqlite3.connect("/home/TEMP/Databases/NED.db")
    conn.text_factory = str
    c = conn.cursor()
    for row in c.execute("SELECT rowid, * FROM PROJECT"):
        TEXT = "id:"+str(row[0])+"\n"+str(row[1])
        TEXT = str(TEXT)
        TEXT = TEXT.replace('\\n','\n')
        TEXT = "".join(TEXT)
        fn.write(TEXT+'\n----\n')

def HELP():
    TXT = """
    USE: NED argv[1] argv[2]
    argv[1] sets the mod:
    -I insert / -D delete / -R read / -H help
    examples:
    Notice the entry is in parenthese.
    -I  to insert "STUFF to be inserted"
    NED -I "STUFF to be inserted"
    -D to delete where rowid is 3
    NED -D 3
    Notice the period after -R . 
    -R . read all
    To search for the term "current project"
    NED -S current project
    -S "current project"
    To 'EXACT DETAIL' search" Notice the period after -DS
    NED -DS .
    -H help on options
    NED -H .
    """
    print TXT

if mod == "-H" or mod == "h":
    HELP()        
if mod == "-R":
    main()
if mod == "-I":
    data = sys.argv[2]
    insert(data)
if mod == "-D":
    rowid = sys.argv[2]
    delete(rowid) 
if mod == "-S":
    data = sys.argv[2]
    search(data)
if mod == "-DS":
    print ("Exact Text SEARCH.")
    Dsearch()
if mod == "-T":
    filename = sys.argv[2]
    prtmain(filename)
if mod == "-CREATE":
    create()
    print create
else:
    print "_________________\n"
    print sys.argv[2],"Command Completed"
    

%%writefile Image-Stuff-Files/GraphicJunkdb.py
def getcolumns(database='db.sqlite3'):
    import sqlite3
    conn = sqlite3.connect(database)
    c = conn.cursor()
    print ('Verify All Data')
    print("----------------")
    cursor01 = c.execute('select * from pixel')
    #cursor.description is description of columns
    names1 = list(map(lambda x: x[0], cursor01.description))
    print("Table: pixel         Columns:",names1)
    cursor02 = c.execute('select * from tupples')
    names2 = list(map(lambda x: x[0], cursor02.description))
    print("Table: tupples       Columns:",names2)
    cursor03 = c.execute('select * from alpha')
    names3 = list(map(lambda x: x[0], cursor03.description))
    print("Table: alpha         Columns:",names3)
    cursor04 = c.execute('select * from XY')
    names4 = list(map(lambda x: x[0], cursor04.description))
    print("Table: XY            Columns:",names4)
    cursor05 = c.execute('select * from NOTES')
    names5 = list(map(lambda x: x[0], cursor05.description))
    print("Table: notes          Columns:",names5)
    cursor06 = c.execute('select * from CODE')
    names6 = list(map(lambda x: x[0], cursor06.description))
    print("Table: CODE         Columns:",names6)
    cursor07 = c.execute('select * from association')
    names7 = list(map(lambda x: x[0], cursor07.description))
    print("Table: association         Columns:",names7)    
    
if __name__ == "__main__":
    getcolumns()
    

print "finished"

%matplotlib inline

# sphinx_gallery_thumbnail_number = 3
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import Normalize


def normal_pdf(x, mean, var):
    return np.exp(-(x - mean)**2 / (2*var))


# Generate the space in which the blobs will live
xmin, xmax, ymin, ymax = (0, 100, 0, 100)
n_bins = 100
xx = np.linspace(xmin, xmax, n_bins)
yy = np.linspace(ymin, ymax, n_bins)

# Generate the blobs. The range of the values is roughly -.0002 to .0002
means_high = [20, 50]
means_low = [50, 60]
var = [150, 200]

gauss_x_high = normal_pdf(xx, means_high[0], var[0])
gauss_y_high = normal_pdf(yy, means_high[1], var[0])

gauss_x_low = normal_pdf(xx, means_low[0], var[1])
gauss_y_low = normal_pdf(yy, means_low[1], var[1])

weights_high = np.array(np.meshgrid(gauss_x_high, gauss_y_high)).prod(0)
weights_low = -1 * np.array(np.meshgrid(gauss_x_low, gauss_y_low)).prod(0)
weights = weights_high + weights_low

# We'll also create a grey background into which the pixels will fade
greys = np.ones(weights.shape + (3,)) * 70

# First we'll plot these blobs using only ``imshow``.
vmax = np.abs(weights).max()
vmin = -vmax
cmap = plt.cm.RdYlBu

fig, ax = plt.subplots()
ax.imshow(greys)
ax.imshow(weights, extent=(xmin, xmax, ymin, ymax), cmap=cmap)
ax.set_axis_off()

# Create an alpha channel of linearly increasing values moving to the right.
alphas = np.ones(weights.shape)
alphas[:, 30:] = np.linspace(1, 0, 70)

# Normalize the colors b/w 0 and 1, we'll then pass an MxNx4 array to imshow
colors = Normalize(vmin, vmax, clip=True)(weights)
colors = cmap(colors)

# Now set the alpha channel to the one we created above
colors[..., -1] = alphas

# Create the figure and image
# Note that the absolute values may be slightly different
fig, ax = plt.subplots()
ax.imshow(greys)
ax.imshow(colors, extent=(xmin, xmax, ymin, ymax))
ax.set_axis_off()

# Create an alpha channel based on weight values
# Any value whose absolute value is > .0001 will have zero transparency
alphas = Normalize(0, .3, clip=True)(np.abs(weights))
alphas = np.clip(alphas, .4, 1)  # alpha value clipped at the bottom at .4

# Normalize the colors b/w 0 and 1, we'll then pass an MxNx4 array to imshow
colors = Normalize(vmin, vmax)(weights)
colors = cmap(colors)

# Now set the alpha channel to the one we created above
colors[..., -1] = alphas

# Create the figure and image
# Note that the absolute values may be slightly different
fig, ax = plt.subplots()
ax.imshow(greys)
ax.imshow(colors, extent=(xmin, xmax, ymin, ymax))

# Add contour lines to further highlight different levels.
ax.contour(weights[::-1], levels=[-.1, .1], colors='k', linestyles='-')
ax.set_axis_off()
plt.show()

ax.contour(weights[::-1], levels=[-.0001, .0001], colors='k', linestyles='-')
ax.set_axis_off()
plt.show()

import cv2

!rm Immanip/*.pyc

!ls Immanip

!mkdir output

import sys
sys.path.insert(0,"/home/jack/script")
from Immanip import blendoverlay
from Immanip import datename
new_img = blendoverlay.blend_overlay("photos/","TEMP/")
PATH = "ManRay/"
new_img.save(PATH+datename.date_name())
print PATH+datename.date_name()
new_img

# %load Immanip/blendoverlay.py
#!/usr/bin/python
import PIL
import time
from PIL import Image
import random, os
from random import randint
import random, os
# Randomly choose two images. The default directories are images/. The images may be two 
# different directories.
def blend_overlay(Opath="images/", Bpath="images/"):
    #path = r"bugs/advertisements/"

    random_filename1 = random.choice([
        x for x in os.listdir(Opath)
        if os.path.isfile(os.path.join(Opath, x))
    ])
  
    img1 = Opath+random_filename1
    im1 = Image.open(img1)
    longer_side = max(im1.size)
    basewidth = 800
    img = Image.open(img1)
    wpercent = (basewidth / float(img.size[0]))
    hsize = int((float(img.size[1]) * float(wpercent)))
    img = img.resize((basewidth, hsize), PIL.Image.ANTIALIAS)
    half_the_width = img.size[0] / 2
    half_the_height = img.size[1] / 2
    im = img.crop(
        (
            half_the_width - 320,
            half_the_height - 320,
            half_the_width + 320,
            half_the_height + 320
        )
    ) 
    
    im.save("output/"+"TEMP-img4.png") 
    #path2 = r"bugs/butterflies/"
    #path2 = r"bugs/advertisements1800/"
    random_filename2 = random.choice([
        y for y in os.listdir(Bpath)
        if os.path.isfile(os.path.join(Bpath, y))
    ])

    img1a = Bpath+"/"+random_filename2
    im1a=Image.open(img1a)
    basewidth = 640
    imga = Image.open(img1a)
    wpercent = (basewidth / float(imga.size[0]))
    hsize = int((float(img.size[1]) * float(wpercent)))
    imga = imga.resize((basewidth, hsize), PIL.Image.ANTIALIAS)
    half_the_width = imga.size[0] / 2
    half_the_height = imga.size[1] / 2
    img4a = imga.crop(
        (
            half_the_width - 320,
            half_the_height - 320,
            half_the_width + 320,
            half_the_height + 320
        )
    )
    img4a.save("output/"+"TEMP-img4a.png")

    
    background = Image.open("output/"+"TEMP-img4.png").convert("RGBA")
    overlay = Image.open("output/"+"TEMP-img4a.png").convert("RGBA")
 
    background = background.resize((640, 640), PIL.Image.ANTIALIAS)
    overlay = overlay.resize((640, 640), PIL.Image.ANTIALIAS)


    Alpha=(randint(1, 9))*0.1
    new_img = Image.blend(background, overlay, 0.4)

    
    return new_img

blend_overlay(Opath="images/", Bpath="images/")

# %load Immanip/randsize.py
#!/usr/bin/python
import PIL
import time
from PIL import Image
import random, os
from random import randint
# rand_size(imp_path='STUFF/new/', minS=150, maxS=300, output="STUFF/Temp.jpg")
# Picks a ranom image in a directory, and distorts it  
# Default path images/ default minimum width random(250-400), height random(250-400) intentionally\
# distorting the aspect.
def rand_size(imp_path='images/', minS=250, maxS=500, output="output/Temp.jpg"):
    path3 = imp_path
    random_filename3 = random.choice([
        x for x in os.listdir(path3)
        if os.path.isfile(os.path.join(path3, x))
    ])
    sidea=(randint(minS, maxS))
    
    sideb=(randint(minS, maxS))
    img1 = path3+"/"+random_filename3
    im1=Image.open(img1)
    img = im1.resize((sidea,sideb), PIL.Image.ANTIALIAS)
    img.save(output)
    return img 
 

rand_size(imp_path='images', minS=250, maxS=500, output="output/Temp.png")

# %load Immanip/rmblack.py
#!/usr/bin/python
def rm_black(image_in ="output/Temp.png", image_out = "XCXCXC.png"):
    import cv2    
    src = cv2.imread(image_in, 1)
    tmp = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)
    _,alpha = cv2.threshold(tmp,0,255,cv2.THRESH_BINARY)
    b, g, r = cv2.split(src)
    rgba = [b,g,r, alpha]
    dst = cv2.merge(rgba,4)
    cv2.imwrite(image_out, dst)
    return dst

rm_black(image_in ="output/Temp.png", image_out = "XCXCXC.png")

from PIL import Image
image_out = "XCXCXC.png"
im = Image.open(image_out)
im

# %load Immanip/randim.py
#!/usr/bin/python
# randim(inpath = "images/") Finds random images in a directory 
#Default directory is: images/
import PIL
import time
from PIL import Image
import random, os
from random import randint
def rand_im(inpath = "photos/"):
    random_filename2 = random.choice([
        x for x in os.listdir(inpath)
        if os.path.isfile(os.path.join(inpath, x))
    ])

    #img1 = inpath+"/"+random_filename2
    img1 = inpath+random_filename2
    im1=Image.open(img1)
    longer_side = max(im1.size)
    basewidth = longer_side
    img = Image.open(img1)
    wpercent = (basewidth / float(img.size[0]))
    hsize = int((float(img.size[1]) * float(wpercent)))
    img = img.resize((basewidth, hsize), PIL.Image.ANTIALIAS)
    half_the_width = img.size[0] / 2
    half_the_height = img.size[1] / 2
    img4 = img.crop(
        (
            half_the_width - 320,
            half_the_height - 320,
            half_the_width + 320,
            half_the_height + 320
        )
    )
    return img4
if __name__ == '__main__':
    rand_im()

rand_im().save("photos/photos.png")



# %load Immanip/c_rmblack.py
#!/usr/bin/python
# Works Great makes black transparent
import cv2

image_in = "photos/photos.png"
image_out = "TEMP/NB-T-20170621-152227.png"

src = cv2.imread(image_in, 1)
tmp = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)
_, alpha = cv2.threshold(tmp, 0, 255, cv2.THRESH_BINARY)
b, g, r = cv2.split(src)
rgba = [b, g, r, alpha]
dst = cv2.merge(rgba, 4)
cv2.imwrite(image_out, dst)


image_out = "TEMP/NB-T-20170621-152227.png"
view = Image.open(image_out)
view



<a href='#the_destination'>Link to the destination'</a>

<a id='the_destination'></a>



# Bible_Search.ipynb
Complete SQLite with FTS3<b
Search by words/term
search by line number
search chapter and verse
search by line span start line and stopline

colorific.ipynb

Crawler.ipynb

Dream-and-Post-to-Twitter.ipynb makes dreams but is not compley topost

GO-Simple-Example.ipynb

ImageBot1.py.ipynb

ImageBot_Triangles.ipynb
ImageBot1.py
Turns images into triangles

ImageEffectsBot-bak.ipynb

ImageEffectsBot-Copy1.ipynb

Image-Maker.ipynb
GOOD RANDOM resize and crop  Sepia experiment
emboss -EXPERIMENT
colage maker
PIL filters
Large collagemaker.py

imfractal.ipynb

INDEX.ipynb

MaskGenerator-Copy1.ipynb

create a sharp and a blurred mask from random images 

MEAN_Graphics.ipynb

Meanshift Image Segmentation.ipynb

Meanshift In 2D.ipynb

Palett_Swap_ARRAY_STUFF.ipynb

Pattern-Recognition.ipynb

PIL-ONLY.ipynb

POST_NOW.ipynb

pygame.ipynb

rand-palette-post.ipynb

Rorschach-ImageMaker.ipynb

Filtering twitter text</br>
Formating Twitter Text</br>
Using a Key.py for authorization<b />
Saving results to a text file<b />

Picks a Random Image and Random Titles
Also and Signs and Posts to Twitter

TwitterBot.ipynb
Images and more

Introduction to markovify 
twitterpost.py

twitterpost

# Twitter-image-and-comment-manual-upload.ipynb
#%%writefile twitterpost.py
ALL IN ONE: Get image, place text in it and publish

Twitter-Wordcloud-Image-Generator.ipynb
Wordcloud-Image
post an image file of your choice with text that you enter.
open to view ImageChops.py

TXT_and_CSV-Copy1.ipynb

TXT_and_CSV.ipynb

Utilities.ipynb


Wordcloud-Image-Generator-for github.ipynb


NewNotebook1.ipynb
NewNotebook2.ipynb
NewNotebook.ipynb



TwitterBot.ipynb


TXT_and_CSV-Copy1.ipynb
TXT_and_CSV.ipynb
Utilities.ipynb
Wordcloud-Image-Generator-for github.ipynb




!ls images/

# an Explinatione with examples of the terms argv and if __name__ == "__main__"
import sys
a = sys.argv[2]
print a 

also:
    Dec2Year.py Change a decimal year into full readable year
    and a little about Formating 

import glob
print glob.glob("/home/jack/*.txt")

#list files only
import os
print os.walk('../imagebot').next()[2]

import os
import glob
image_list = []

for ext in ('jpg', 'jpeg', 'bmp', 'png', 'gif'):
    search_str = os.path.join('../imagebot/','*.%s' % ext)
    image_list.extend(glob.glob(search_str))

#out = open(os.path.join('../imagebot/', 'index.txt'), 'w')
print image_list

!mkdir bak

#list directories only
import os
print os.walk('../imagebot').next()[1]

#copy all files to a new location
import os
import shutil
src = '../imagebot/'
dest = '../imagebot/bak/'
src_files = os.listdir(src)
for file_name in src_files:
    full_file_name = os.path.join(src, file_name)
    if (os.path.isfile(full_file_name)):
        shutil.copy(full_file_name, dest)

#to copy a file 
from shutil import copyfile
copyfile(src, dst)

#list all jpg and png in imagebot nad subdirectories
import os
def fileList():
    matches = []
    for root, dirnames, filenames in os.walk('../imagebot/'):
        for filename in filenames:
            if filename.endswith(('.jpg', '.png')):
                matches.append(os.path.join(root, filename))
    return matches
fileList()

GetRandDir.py

%%writefile GetRandDir.py
import os
from random import randint
def GetRandDir():
    DIRS =[]
    directories = next(os.walk('.'))[1]
    for directory in directories:
        # Exclude Directories: ".", "chromedrive" and "AutoImageCrawler"
        if "." not in directory and "_" not in directory and "chromedrive" not in directory and "AutoImageCrawler" not in directory:
            if "-images"in directory:
                DIRS.append(directory)
    Num = len(DIRS)-1
    ID = randint(0,Num) 

    DIRectory = (DIRS[ID])
    return DIRectory

from GetRandDir import GetRandDir
DIR = GetRandDir()
DIR

%%writefile getdirfromlist.py
from random import randint
def getdirfromlist(dirLIST):
    num= len(dirLIST)-1
    DirId = randint(0,num)
    Imdir = dirLIST[DirId]
    return Imdir

from getdirfromlist import *
dirLIST = ["antique%20art/","art%20nouveau/","ancient%20manuscript%20art/","antique%20book%20covers/"]
use = getdirfromlist(dirLIST)  
use

!ls . -d a*/

%%writefile FileName.py
import time
def FilenameByTime(directory):
    timestr = time.strftime("%Y%m%d-%H%M%S")
    filename = directory+"/"+timestr+"_.jpg"
    return filename    

from FileName import *
directory = "tmp"
filename = FilenameByTime(directory)
print(filename)

from PIL import Image
import random
import os
from GetRandDir import GetRandDir

DN = GetRandDir() 
def GetRandomImage(path):
    base_image = random.choice([
        x for x in os.listdir(path)
        if os.path.isfile(os.path.join(path, x))
        ])
    filename0=(path+base_image)
    image = Image.open(filename0)
    return image

path = DN+"/"
im = GetRandomImage(path)
im

%%writefile GetRandDir.py
import os
from random import randint
def GetRandDir():
    DIRS =[]
    directories = next(os.walk('.'))[1]
    for directory in directories:
        if "." not in directory and "_" not in directory and "chromedrive" not in directory and "AutoImageCrawler" not in directory:
            DIRS.append(directory)
        Num = len(DIRS)-1
    ID = randint(0,Num) 

    DIRectory = (DIRS[ID])
    return DIRectory

from GetRandDir import GetRandDir
DN = GetRandDir() 
print(DN)

import os
from random import randint
DIRS =[]
directories = next(os.walk('.'))[1]
for directory in directories:
    if "." not in directory and "_" not in directory and "chromedrive" not in directory and "AutoImageCrawler" not in directory:
        DIRS.append(directory)
        print(directory)

Num = len(DIRS)-1
ID = randint(0,Num) 

DIRectory = (DIRS[ID])
print (DIRectory)

import os
from random import randint
DIRS =[]
directories = next(os.walk('.'))[1]
for directory in directories:
    dlst=["_","chromedrive","AutoImageCrawler"]
    if dlst[0] not in directory and dlst[1] not in directory and dlst[2] not in directory:
        DIRS.append(directory)
        print(directory)
    
Num = len(DIRS)-1
ID = randint(0,Num) 


# debug
dlst=["_","chromedrive","AutoImageCrawler"]
print (dlst[0], dlst[1], dlst[2])



%%writefile GetRandDir.py
import os
from random import randint
def GetRandDir():
    DIRS =[]
    directories = next(os.walk('.'))[1]
    for directory in directories:
        # Exclude Directories: ".", "chromedrive" and "AutoImageCrawler"
        if "." not in directory and "_" not in directory:
            if "-images"in directory:
                DIRS.append(directory)
    Num = len(DIRS)-1
    ID = randint(0,Num) 
    print(Num,ID)
    DIRectory = (DIRS[ID])
    return DIRectory

from GetRandDir import GetRandDir
DIR = GetRandDir()
DIR

%%writefile getdirfromlist.py
from random import randint
def getdirfromlist(dirLIST):
    num= len(dirLIST)-1
    DirId = randint(0,num)
    Imdir = dirLIST[DirId]
    return Imdir

from getdirfromlist import *
dirLIST = ["vintage-bottle-labels","vintage-advertisments","vintage-clothing-patterns"]
use = getdirfromlist(dirLIST)  
use

!ls . -d v*/

%%writefile FileName.py
import time
def FilenameByTime(directory):
    timestr = time.strftime("%Y%m%d-%H%M%S")
    filename = directory+"/"+timestr+"_.jpg"
    return filename    

from FileName import *
directory = "tmp"
filename = FilenameByTime(directory)
print(filename)

%%writefile GetRandomImage.py
from PIL import Image
import random
import os
from GetRandDir import GetRandDir

DN = GetRandDir() 
def GetRandomImage(path):
    base_image = random.choice([
        x for x in os.listdir(path)
        if os.path.isfile(os.path.join(path, x))
        ])
    filename0=(path+base_image)
    image = Image.open(filename0)
    return image

def getone():
    path = DN+"/"
    from GetRandDir import GetRandDir
    DIR = GetRandDir()+"/"
    im = GetRandomImage(DIR)
    return im

from GetRandomImage import *
im = getone()
im

# Remember The "/" thay follows the directory name
from GetRandomImage import GetRandomImage
path = "vintage-clothing-patterns/"
IM= GetRandomImage(path)
IM

!ls *.py



#!/home/jack/miniconda3/envs/cloned_base/bin/python
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import numpy as np
import random
from random import randint
from PIL import Image, ImageDraw, ImageFont, ImageChops, ImageFilter 
import os
import sys
import markovify
import twython
from twython import Twython
import time
# Open background image and work out centre

path = r"publish/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
filename0=(path+base_image)


bg = Image.open(filename0).convert('RGB')
x = bg.width//2
y = bg.height//2

# The text we want to add
text = "NFT TwitterBot Project"

# Create font
font = ImageFont.truetype('/snap/gnome-3-38-2004/99/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', 40)

# Create piece of canvas to draw text on and blur
blurred = Image.new('RGBA', bg.size)
draw = ImageDraw.Draw(blurred)
draw.text(xy=(x,y+190), text=text, fill='black', font=font, anchor='mm')
blurred = blurred.filter(ImageFilter.BoxBlur(7))

# Paste soft text onto background
bg.paste(blurred,blurred)

# Draw on sharp text
draw = ImageDraw.Draw(bg)
draw.text(xy=(x,y+190), text=text, fill='white', font=font, anchor='mm')
#xx=0
#yy=0
#bg.paste("peferations.png", (xx,yy)) 
# paste an onerlay image
#perferations.png
#mask=Image.open("perferations.png").convert('RGBA') 
#bg.paste(mask, (x,y), mask=mask)
#bg.paste("peferations.png", box=(0, 0) + original.size) 
bg.save('result.png')
timestr = time.strftime("%Y%m%d-%H%M%S")
filename = "records/"+timestr+"_.png"
bg.save(filename)
im =Image.open('result.png')
im



#nap=randint(10,400)
#time.sleep(nap)
path = r"publish/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
filename0=(path+base_image)

bg = Image.open(filename0).convert('RGB')
x = bg.width//2
y = bg.height//2

# The text we want to add
text = "NFT TwitterBot Project"


# Create font
font = ImageFont.truetype('/snap/gnome-3-38-2004/99/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', 40)

# Create piece of canvas to draw text on and blur
blurred = Image.new('RGBA', bg.size)
draw = ImageDraw.Draw(blurred)
draw.text(xy=(x,y+190), text=text, fill='black', font=font, anchor='mm')
blurred = blurred.filter(ImageFilter.BoxBlur(7))

# Paste soft text onto background
bg.paste(blurred,blurred)

# Draw on sharp text
draw = ImageDraw.Draw(bg)
draw.text(xy=(x,y+190), text=text, fill='white', font=font, anchor='mm')
mask=Image.open("perferations.png").convert('RGBA') 
bg.paste(mask, (0,0), mask=mask)
bg.save('result.png')
#removed keys for privacy reasons
CONSUMER_KEY = 'APIkey()[0]'
CONSUMER_SECRET = 'APIkey()[1]'
ACCESS_KEY = 'APIkey()[2]'
ACCESS_SECRET = 'APIkey()[3]'

twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)
#path = 'images/NewFolder'
with open("sart.txt") as f:
    data = f.read()
data_model = markovify.Text(data)
STR = data_model.make_sentence()
#STR = ("#All_in_One - #WordCloud #Create - Added ability to randomly choose an image background  #Automated")
#PATH = "/home/jack/Desktop/deep-dream-generator/notebooks/STUFF/experiment/experiment8.jpg"
#PATH = "images/TM_POST.png"
PATH = "result.png"
# 1 , 2, 3, 12, 5, 15, 8, 6
#photo = open('/home/jack/Desktop/deep-dream-generator/notebooks/images/'+file_list[rnd]+'.jpg','rb')

photo = open(PATH,'rb')
response = twitter.upload_media(media=photo)
twitter.update_status(status=STR, media_ids=[response['media_id']])


#!/home/jack/miniconda3/envs/cloned_base/bin/python
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import numpy as np
import random
from random import randint
from PIL import Image, ImageDraw, ImageFont, ImageChops, ImageFilter 
import os
import sys
import markovify
import twython
from twython import Twython
import time


CONSUMER_KEY = 'APIkey()[0]'
CONSUMER_SECRET = 'APIkey()[1]'
ACCESS_KEY = 'APIkey()[2]'
ACCESS_SECRET = 'APIkey()[3]'

twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)
#path = 'images/NewFolder'
with open("sart.txt") as f:
    data = f.read()
data_model = markovify.Text(data)
STR = data_model.make_sentence()

PATH = "result7.png"
# 1 , 2, 3, 12, 5, 15, 8, 6
#photo = open('/home/jack/Desktop/deep-dream-generator/notebooks/images/'+file_list[rnd]+'.jpg','rb')

photo = open(PATH,'rb')
response = twitter.upload_media(media=photo)
twitter.update_status(status=STR, media_ids=[response['media_id']])




ls junk/*

Choose = ["insta-usa-perferations.png", "insta-philippines-perferations.png","insta-perferations.png"]
from random import randint
num = randint(0,2)
print (Choose[num])


PatH=["publish/", "output/", "posterize/", "marblepaper/", "old_photo/", "texture/", "polarized/"]
num2 = randint(0,6)
print (PatH[num2])

#import Image and ImageEnhance modules
from PIL import Image, ImageEnhance, ImageChops
from random import randint
PatH=["publish/", "output/", "posterize/", "marblepaper/", "old_photo/", "texture/", "polarized/"]
num2 = randint(0,6)
path = PatH[num2]
base_image = random.choice([
x for x in os.listdir(path)
if os.path.isfile(os.path.join(path, x))
    ])
file=(path+base_image)

im = Image.open(file)# Open an Image file
im = im.resize((960,960), Image.ANTIALIAS)
print(im.size)
Brighten = ImageEnhance.Brightness(im) # Create a Brightness class
brightimage = Brighten.enhance(1.1)
brightimage.save("junk/temp-brightened.jpg") # Save results
 
im = Image.open("junk/temp-brightened.jpg") # Open the Image
sharpened = ImageEnhance.Sharpness(im) # Create an object using Sharpness
sharpenedimage = sharpened.enhance(1.1)
sharpenedimage.save("junk/temp-sharpenedimage.jpg") # Save results
 
im = Image.open('junk/temp-sharpenedimage.jpg') # Open the Image
contrast = ImageEnhance.Contrast(im) # Create an object using Sharpness
contrastedimage = contrast.enhance(1.1)
contrastedimage.save('junk/temp-contrastedimage.jpg') # Save results
 
im = Image.open("junk/temp-contrastedimage.jpg")
width, height = im.size   # Get dimensions
#im = im.resize((2*width,2*height), "Image.NEAREST" (0))
#im = im.resize((2*width,2*height), Image.ANTIALIAS)
Choose = ["insta-usa-perferations.png", "insta-philippines-perferations.png","insta-perferations.png"]
num = randint(0,2)
border = (Choose[num])
mask=Image.open(border).convert('RGBA') 
im.paste(mask, (0,0), mask=mask)
im.save('junk/temp1.jpg')
im    

%%writefile mkimag.py
#import Image and ImageEnhance modules
from PIL import Image, ImageEnhance, ImageChops
from random import randint
import random
import os
import time
def mkimag():
    PatH=["publish/", "output/", "posterize/", "marblepaper/", "old_photo/", "texture/", "polarized/"]
    num2 = randint(0,6)
    path = PatH[num2]
    base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
        ])
    file=(path+base_image)

    im = Image.open(file)# Open an Image file
    im = im.resize((960,960), Image.ANTIALIAS)
    #print(im.size)
    Brighten = ImageEnhance.Brightness(im) # Create a Brightness class
    brightimage = Brighten.enhance(1.1)
    brightimage.save("junk/temp-brightened.jpg") # Save results
 
    im = Image.open("junk/temp-brightened.jpg") # Open the Image
    sharpened = ImageEnhance.Sharpness(im) # Create an object using Sharpness
    sharpenedimage = sharpened.enhance(1.1)
    sharpenedimage.save("junk/temp-sharpenedimage.jpg") # Save results
 
    im = Image.open('junk/temp-sharpenedimage.jpg') # Open the Image
    contrast = ImageEnhance.Contrast(im) # Create an object using Sharpness
    contrastedimage = contrast.enhance(1.1)
    contrastedimage.save('junk/temp-contrastedimage.jpg') # Save results
 
    im = Image.open("junk/temp-contrastedimage.jpg")
    width, height = im.size   # Get dimensions
    #im = im.resize((2*width,2*height), "Image.NEAREST" (0))
    #im = im.resize((2*width,2*height), Image.ANTIALIAS)
    Choose = ["insta-usa-perferations.png", "insta-philippines-perferations.png","insta-perferations.png"]
    num = randint(0,2)
    border = (Choose[num])
    mask=Image.open(border).convert('RGBA') 
    im.paste(mask, (0,0), mask=mask)
    timestr = time.strftime("%Y%m%d-%H%M%S")
    filename = "junk/insta"+timestr+"_.jpg"
    im.save('junk/temp1.jpg')
    return im    

ls *.py

from mkimag import mkimag
im = mkimag()
im

%%writefile post-to-instagram.py
#!/home/jack/miniconda3/envs/cloned_base/bin/python
from instabot import Bot
import os
import shutil
import markovify
from PIL import Image, ImageEnhance, ImageChops
from mkimag import mkimag
import time
im = mkimag()


with open("sart.txt") as f:
    data = f.read()
data_model = markovify.Text(data)
STR = data_model.make_sentence()



def clean_up(i):
    dir = "config"
    remove_me = "imgs\{}.REMOVE_ME".format(i)
    # checking whether config folder exists or not
    if os.path.exists(dir):
        try:
            # removing it so we can upload new image
            shutil.rmtree(dir)
        except OSError as e:
            print("Error: %s - %s." % (e.filename, e.strerror))
    if os.path.exists(remove_me):
        src = os.path.realpath("junk/{}".format(i))
        os.rename(remove_me, src)


def upload_post(i):
    bot = Bot()

    bot.login(username="jacklnorthrup", password="Pxyackjs22")
    bot.upload_photo("junk/{}".format(i), caption=STR)


#if __name__ == '__main__':
# enter name of your image bellow
image_name = "temp1.jpg"
clean_up(image_name)
upload_post(image_name)



!./post-to-instagram.py

#import Image and ImageEnhance modules
from PIL import Image, ImageEnhance
  
file = "junk/temp.jpg"
im = Image.open(file)  # Open an Image file
Brighten = ImageEnhance.Brightness(im) # Create a Brightness class
brightimage = Brighten.enhance(1.2)
brightimage.show() #show results

brightimage.save("junk/temp-brightened.jpg") # Save results

# This will import Image and ImageChops modules
from PIL import Image, ImageEnhance, ImageChops
  
im = Image.open("junk/temp-brightened.jpg") # Open the Image
sharpened = ImageEnhance.Sharpness(im) # Create an object using Sharpness
  
sharpenedimage = sharpened.enhance(4.0)
sharpenedimage.show() #show results
sharpenedimage.save("junk/temp-sharpenedimage.jpg") # Save results

# This will import Image and ImageChops modules
from PIL import Image, ImageEnhance, ImageChops
im = Image.open('junk/temp-sharpenedimage.jpg') # Open the Image
contrast = ImageEnhance.Contrast(im) # Create an object using Sharpness
contrastedimage = contrast.enhance(1.7)
contrastedimage.show() #show results
contrastedimage.save('junk/temp-contrastedimage.jpg') # Save results

from PIL import Image, ImageEnhance, ImageFilter
import random
import os
im = Image.open("junk/temp-contrastedimage.jpg")
width, height = im.size   # Get dimensions
#im = im.resize((2*width,2*height), "Image.NEAREST" (0))
#im = im.resize((2*width,2*height), Image.ANTIALIAS)
print(im.size)

# Crop the center of the image

mask=Image.open("insta-perferations.png").convert('RGBA') 
im.paste(mask, (0,0), mask=mask)
im.save('junk/temp1.jpg')
im    

from instabot import Bot
import os
import shutil
from PIL import Image, ImageEnhance, ImageChops

def clean_up(i):
    dir = "config"
    remove_me = "imgs\{}.REMOVE_ME".format(i)
    # checking whether config folder exists or not
    if os.path.exists(dir):
        try:
            # removing it so we can upload new image
            shutil.rmtree(dir)
        except OSError as e:
            print("Error: %s - %s." % (e.filename, e.strerror))
    if os.path.exists(remove_me):
        src = os.path.realpath("junk/{}".format(i))
        os.rename(remove_me, src)


def upload_post(i):
    bot = Bot()

    bot.login(username="jacklnorthrup", password="Pxyackjs22")
    bot.upload_photo("junk/{}".format(i), caption="""im = Image.open(filename0)
    width, height = im.size   # Get dimensions
    #im = im.resize((2*width,2*height), "Image.NEAREST" (0))
    im = im.resize((2*width,2*height), Image.ANTIALIAS)
    print(im.size)
    width, height = im.size 
    new_width =960
    new_height =960
    left = (width - new_width)/2
    top = (height - new_height)/2
    right = (width + new_width)/2
    bottom = (height + new_height)/2""")


#if __name__ == '__main__':
# enter name of your image bellow
image_name = "temp1.jpg"
clean_up(image_name)
upload_post(image_name)



from PIL import Image, ImageEnhance, ImageFilter
import random
import os
path = r"ManRay/"
def BaseImage(path):
    base_image = random.choice([
        x for x in os.listdir(path)
        if os.path.isfile(os.path.join(path, x))
    ])
    filename0=(path+base_image)

    im = Image.open(filename0)
    width, height = im.size   # Get dimensions
    #im = im.resize((2*width,2*height), "Image.NEAREST" (0))
    im = im.resize((2*width,2*height), Image.ANTIALIAS)
    print(im.size)
    width, height = im.size 
    new_width =960
    new_height =960
    left = (width - new_width)/2
    top = (height - new_height)/2
    right = (width + new_width)/2
    bottom = (height + new_height)/2

    # Crop the center of the image
    im = im.crop((left, top, right, bottom))
    filter = ImageEnhance.Brightness(im)
    enhanced_image = ImageFilter.Filter(1.2)
    mask=Image.open("insta-perferations.png").convert('RGBA') 
    enhanced_image.paste(mask, (0,0), mask=mask)
    enhanced_image.save('junk/temp1.jpg')
    return enhanced_image

path = r"ManRay/"
BaseImage(path)    

Filter = ImageEnhance.Brightness(im)
new_image = im.ImageFilter.Filter(1.2)

new_image.show()

from PIL import Image
import random
import os
path = r"ManRay/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
filename0=(path+base_image)

im = Image.open(filename0)
width, height = im.size   # Get dimensions
#im = im.resize((2*width,2*height), "Image.NEAREST" (0))
im = im.resize((2*width,2*height), Image.ANTIALIAS)
print(im.size)
width, height = im.size 
new_width =960
new_height =960
left = (width - new_width)/2
top = (height - new_height)/2
right = (width + new_width)/2
bottom = (height + new_height)/2

# Crop the center of the image
im = im.crop((left, top, right, bottom))
im.save('junk/temp.jpg')
im

INFO Found Here:
 17 https://www.instagram.com jlnorthrup pxyackjs22

INFO Found Here:
 107 https://instagram.com jacklnorthrup Pxyackjs22

INFO Found Here:
 110 https://instagram.com pxyackjs22


image = image.resize((x, y), Image.ANTIALIAS)

from instabot import Bot
bot=Bot()
 
bot.login(username = "jacklnorthrup",
          password = "Pxyackjs22")
 

from instabot import Bot
bot=Bot()
 
bot.login(username = "jacklnorthrup",
          password = "Pxyackjs22")
 
# Recommended to put the photo
# you want to upload in the same
# directory where this Python code
# is located else you will have
# to provide full path for the photo
bot.upload_photo("junk/temp.jpg",
                 caption ="I just extended my TwitterBot to Instagram")

from instabot import Bot
import random 
 
bot = Bot()
bot.login(username = "jacklnorthrup", password = "Pxyackjs22")
 

path = r"ManRay/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
filename0=(path+base_image)




bot.upload_photo("junk/temp.jpg",
                 caption ="I just extended my TwitterBot to Instagram")

!mkdir instagram

#!/home/jack/miniconda3/envs/cloned_base/bin/python
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import numpy as np
import random
from random import randint
from PIL import Image, ImageDraw, ImageFont, ImageChops, ImageFilter 
import os
import sys
import markovify
import twython
from twython import Twython
import time
# Open background image and work out centre

path = r"publish/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
filename0=(path+base_image)


bg = Image.open(filename0).convert('RGB')
x = bg.width//2
y = bg.height//2

# The text we want to add
text = "NFT Instagram Project"

# Create font
font = ImageFont.truetype('/snap/gnome-3-38-2004/99/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', 40)

# Create piece of canvas to draw text on and blur
blurred = Image.new('RGBA', bg.size)
draw = ImageDraw.Draw(blurred)
draw.text(xy=(x,y+190), text=text, fill='black', font=font, anchor='mm')
blurred = blurred.filter(ImageFilter.BoxBlur(7))

# Paste soft text onto background
bg.paste(blurred,blurred)

# Draw on sharp text
draw = ImageDraw.Draw(bg)
draw.text(xy=(x,y+190), text=text, fill='white', font=font, anchor='mm')
#xx=0
#yy=0
#bg.paste("peferations.png", (xx,yy)) 
# paste an onerlay image
#perferations.png
#mask=Image.open("perferations.png").convert('RGBA') 
#bg.paste(mask, (x,y), mask=mask)
#bg.paste("peferations.png", box=(0, 0) + original.size) 
bg.save('junk/temp.jpg')
timestr = time.strftime("%Y%m%d-%H%M%S")
filename = "instagram/"+timestr+"_.png"
bg.save(filename)
im =Image.open('junk/temp.jpg')
im



#nap=randint(10,400)
#time.sleep(nap)
path = r"publish/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
filename0=(path+base_image)

bg = Image.open(filename0).convert('RGB')
x = bg.width//2
y = bg.height//2

# The text we want to add
text = "NFT TwitterBot Project"


# Create font
font = ImageFont.truetype('/snap/gnome-3-38-2004/99/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', 40)

# Create piece of canvas to draw text on and blur
blurred = Image.new('RGBA', bg.size)
draw = ImageDraw.Draw(blurred)
draw.text(xy=(x,y+190), text=text, fill='black', font=font, anchor='mm')
blurred = blurred.filter(ImageFilter.BoxBlur(7))

# Paste soft text onto background
bg.paste(blurred,blurred)

# Draw on sharp text
draw = ImageDraw.Draw(bg)
draw.text(xy=(x,y+190), text=text, fill='white', font=font, anchor='mm')
mask=Image.open("insta-perferations.png").convert('RGBA') 
bg.paste(mask, (0,0), mask=mask)
bg.save('junk/temp.jpg')
with open("sart.txt") as f:
    data = f.read()
data_model = markovify.Text(data)
STR = data_model.make_sentence()


!ls *.png

from PIL import Image
im = Image.open("junk/temp.jpg")
im





#!/home/jack/miniconda3/envs/cloned_base/bin/python
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import numpy as np
import random
from random import randint
from PIL import Image, ImageDraw, ImageFont, ImageChops, ImageFilter 
import os
import sys
import markovify
import twython
from twython import Twython
import time


CONSUMER_KEY = 'APIkey()[0]'
CONSUMER_SECRET = 'APIkey()[1]'
ACCESS_KEY = 'APIkey()[2]'
ACCESS_SECRET = 'APIkey()[3]'

twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)
#path = 'images/NewFolder'
with open("sart.txt") as f:
    data = f.read()
data_model = markovify.Text(data)
STR = data_model.make_sentence()

PATH = "result7.png"
# 1 , 2, 3, 12, 5, 15, 8, 6
#photo = open('/home/jack/Desktop/deep-dream-generator/notebooks/images/'+file_list[rnd]+'.jpg','rb')

photo = open(PATH,'rb')
response = twitter.upload_media(media=photo)
twitter.update_status(status=STR, media_ids=[response['media_id']])




import (
    "fmt"
)

var sum, i int64
defer func() {
    fmt.Printf("i = %d, sum = %d, i*(i-1)/2 = %d\n", i, sum, i*(i-1)/2)
}()
for i = int64(0);; i++ {
    sum += i
}

import (
    "fmt"
    "time"
)

leaf := 0

func naiveFib(n int64) int64 {
    if n < 2 {
        leaf++
        return 1
    }
    return naiveFib(n-1) + naiveFib(n-2)
}

start := time.Now()
defer func(){
    end := time.Now()
    fmt.Printf("time: %v\n", end.Sub(start))
    fmt.Printf("leaf counter: %d\n", leaf)
    fmt.Printf("avg: %v/cycle\n", end.Sub(start)/time.Duration(leaf))
}()
naiveFib(50)

{
    c := make(chan int)
    // Block forever because no one reads c.
    c <- 10
}

{
    c := make(chan int)
    // Block forever because no one sends an int to c.
    <-c
}

{
    c0, c1 := make(chan int), make(chan int)
    // Block forever because no one read or write c0 and c1.
    select {
    case c0 <- 10:
        fmt.Println("Sent an int to c0")
    case i := <-c1:
        fmt.Println("Received", i)
    }
}

import (
    "fmt"
)

go func() {
    var i int64
    defer func() {
        fmt.Printf("i = %d (in goroutine)\n", i)
    }()
    for i = 0 ;; i++ {}
}()

// This demo demostrates how to use net/http with cancellation in lgo.
import (
    "fmt"
    "io/ioutil"
    "net/http"
)

{
    waitSec := 10
    var err error
    defer func() {
        if err != nil {
            fmt.Printf("Failed: %v", err)
        }
    }()
    url := fmt.Sprintf("https://yunabe-codelab.appspot.com/slow?sec=%d", waitSec)
    req, err := http.NewRequest("GET", url, nil)
    if err != nil {
        return
    }
    res, err := http.DefaultClient.Do(req.WithContext(_ctx))
    if err != nil {
        return
    }
    b, err := ioutil.ReadAll(res.Body)
    if err != nil {
        return
    }
    fmt.Printf("Got: %q", b)
}

print("hello")

from IPython.display import HTML
HTML("""
<script>
console.log("hello");
</script>
<b>HTML</b>
""")

%%javascript
console.log("hi");

from IPython.display import Image
Image("http://ipython.org/_static/IPy_header.png")

#server = 'irc.chat.twitch.tv'
#port = 6667
server="irc.deft.com"
port=6667:
nickname = '<YOUR_USERNAME>'
token = '<YOUR_TOKEN>'
channel = '#ninja'

import socket

sock = socket.socket()

sock.connect((server, port))

sock.send(f"PASS {token}\n".encode('utf-8'))
sock.send(f"NICK {nickname}\n".encode('utf-8'))
sock.send(f"JOIN {channel}\n".encode('utf-8'))

resp = sock.recv(2048).decode('utf-8')

resp

#sock.close()

import logging

logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s — %(message)s',
                    datefmt='%Y-%m-%d_%H:%M:%S',
                    handlers=[logging.FileHandler('chat.log', encoding='utf-8')])

logging.info(resp)

from emoji import demojize

while True:
    resp = sock.recv(2048).decode('utf-8')

    if resp.startswith('PING'):
        sock.send("PONG\n".encode('utf-8'))
    
    elif len(resp) > 0:
        logging.info(demojize(resp))

msg = '2018-12-10_11:26:40 — :spappygram!spappygram@spappygram.tmi.twitch.tv PRIVMSG #ninja :Chat, let Ninja play solos'

from datetime import datetime

time_logged = msg.split()[0].strip()

time_logged = datetime.strptime(time_logged, '%Y-%m-%d_%H:%M:%S')

time_logged

username_message = msg.split('—')[1:]
username_message = '—'.join(username_message).strip()

username_message

import re

username, channel, message = re.search(':(.*)\!.*@.*\.tmi\.twitch\.tv PRIVMSG #(.*) :(.*)', username_message).groups()

print(f"Channel: {channel} \nUsername: {username} \nMessage: {message}")

import pandas as pd

def get_chat_dataframe(file):
    data = []

    with open(file, 'r', encoding='utf-8') as f:
        lines = f.read().split('\n\n\n')
        
        for line in lines:
            try:
                time_logged = line.split('—')[0].strip()
                time_logged = datetime.strptime(time_logged, '%Y-%m-%d_%H:%M:%S')

                username_message = line.split('—')[1:]
                username_message = '—'.join(username_message).strip()

                username, channel, message = re.search(
                    ':(.*)\!.*@.*\.tmi\.twitch\.tv PRIVMSG #(.*) :(.*)', username_message
                ).groups()

                d = {
                    'dt': time_logged,
                    'channel': channel,
                    'username': username,
                    'message': message
                }

                data.append(d)
            
            except Exception:
                pass
            
    return pd.DataFrame().from_records(data)
        
    
df = get_chat_dataframe('chat.log')

df.set_index('dt', inplace=True)

print(df.shape)

df.head()

#server = 'irc.chat.twitch.tv'
#port = 6667
server="irc.deft.com"
port=6667
nickname = 'jahral'
channel = '#experiments'

import socket

sock = socket.socket()

sock.connect((server, port))

#sock.send(f"PASS {token}\n".encode('utf-8'))
sock.send(f"NICK {nickname}\n".encode('utf-8'))
sock.send(f"JOIN {channel}\n".encode('utf-8'))

resp = sock.recv(2048).decode('utf-8')

resp

#sock.close()

import logging

logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s — %(message)s',
                    datefmt='%Y-%m-%d_%H:%M:%S',
                    handlers=[logging.FileHandler('chat.log', encoding='utf-8')])

logging.info(resp)

#!pip install emoji 

from emoji import demojize

while True:
    resp = sock.recv(2048).decode('utf-8')

    if resp.startswith('PING'):
        sock.send("PONG\n".encode('utf-8'))
    
    elif len(resp) > 0:
        logging.info(demojize(resp))

import datetime
print (datetime.datetime.now())
print(datetime.date.today())



dt = datetime.datetime.now()

print(dt.strftime('%Y-%m-%d_%H:%M:%S'))
timenow=dt.strftime('%Y-%m-%d_%H:%M:%S')
print(timenow)

from datetime import datetime

time_logged = msg.split()[0].strip()
time_logged = datetime.strptime(time_logged, '%Y-%m-%d_%H:%M:%S')
time_logged

#msg = '2018-12-10_11:26:40 — :spappygram!spappygram@spappygram.tmi.twitch.tv PRIVMSG #ninja :Chat, let Ninja play solos'
msg = timenow+" :jack PRIVMSG #experiments :Chat, let the games begin"
print (msg)

username_message = msg.split('—')[1:]
username_message = '—'.join(username_message).strip()

username_message

import re

username, channel, message = re.search(':(.*)\!.*@.*\.tmi\.twitch\.tv PRIVMSG #(.*) :(.*)', username_message).groups()

print(f"Channel: {channel} \nUsername: {username} \nMessage: {message}")

import pandas as pd

def get_chat_dataframe(file):
    data = []

    with open(file, 'r', encoding='utf-8') as f:
        lines = f.read().split('\n\n\n')
        
        for line in lines:
            try:
                time_logged = line.split('—')[0].strip()
                time_logged = datetime.strptime(time_logged, '%Y-%m-%d_%H:%M:%S')

                username_message = line.split('—')[1:]
                username_message = '—'.join(username_message).strip()

                username, channel, message = re.search(
                    ':(.*)\!.*@.*\.tmi\.twitch\.tv PRIVMSG #(.*) :(.*)', username_message
                ).groups()

                d = {
                    'dt': time_logged,
                    'channel': channel,
                    'username': username,
                    'message': message
                }

                data.append(d)
            
            except Exception:
                pass
            
    return pd.DataFrame().from_records(data)
        
    
df = get_chat_dataframe('chat.log')

df.set_index('dt', inplace=True)

print(df.shape)

df.head()

#@title Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import tensorflow as tf
tf.compat.v1.enable_eager_execution()

# Size of each input image, 28 x 28 pixels
IMAGE_SIZE = 28 * 28
# Number of distinct number labels, [0..9]
NUM_CLASSES = 10
# Number of examples in each training batch (step)
TRAIN_BATCH_SIZE = 100
# Number of training steps to run
TRAIN_STEPS = 1000

# Loads MNIST dataset.
train, test = tf.keras.datasets.mnist.load_data()
train_ds = tf.data.Dataset.from_tensor_slices(train).batch(TRAIN_BATCH_SIZE).repeat()

# Casting from raw data to the required datatypes.
def cast(images, labels):
  images = tf.cast(
      tf.reshape(images, [-1, IMAGE_SIZE]), tf.float32)
  labels = tf.cast(labels, tf.int64)
  return (images, labels)

layer = tf.keras.layers.Dense(NUM_CLASSES)
optimizer = tf.keras.optimizers.Adam()

@tf.function(jit_compile=True)
def train_mnist(images, labels):
    images, labels = cast(images, labels)

    with tf.GradientTape() as tape:
      predicted_labels = layer(images)
      loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(
          logits=predicted_labels, labels=labels
      ))
    layer_variables = layer.trainable_variables
    grads = tape.gradient(loss, layer_variables)
    optimizer.apply_gradients(zip(grads, layer_variables))

for images, labels in train_ds:
  if optimizer.iterations > TRAIN_STEPS:
    break
  train_mnist(images, labels)

images, labels = cast(test[0], test[1])
predicted_labels = layer(images)
correct_prediction = tf.equal(tf.argmax(predicted_labels, 1), labels)
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
print("Prediction accuracy after training: %s" % accuracy)

print(train_mnist.experimental_get_compiler_ir(images, labels)(stage='hlo'))

!ls *.ipynb >>ipynb2.list

from time import sleep
title = "ipynb2.list"
NOTEBOOK = []
lines = open(title,"r")
for line in lines.readlines():
    line = line.replace("\n","") 
    print (line)
    NOTEBOOK.append(line)

import json
import sys
from time import sleep
import sqlite3
import csv
database = "oct1_IPNB.list.db"
conn = sqlite3.connect(database)
conn.text_factory=str 
c = conn.cursor()
count=1
search = input("Title: ")
# ONLY the DATA table can use MATCH
for row in c.execute('SELECT rowid,* FROM ipynb WHERE ipynb MATCH ?',(search,)):
    if search in row[1] or search in row[3]:
        print (row[0],row[1],row[3],"\n----------------------")
        count=count+1
        if count>20:break
c.close()
conn.close()


        

import json
import sys
from time import sleep
import sqlite3
import csv
database = "oct1_IPNB.list.db"
conn = sqlite3.connect(database)
conn.text_factory=str 
c = conn.cursor()
count=1
search = input("Title :")
# ONLY the DATA table can use MATCH
for row in c.execute('SELECT rowid, file, content, description FROM ipynb WHERE description MATCH ?',(search,)):
    print (row[0],row[1],row[3],"\n----------------------")
    count=count+1
    if count>13:break
c.close()
conn.close()


        

import json
import sys
from time import sleep
import sqlite3
import csv
database = "oct1_IPNB.list.db"
conn = sqlite3.connect(database)
conn.text_factory=str 
c = conn.cursor()
search = input("ROWID :")
for row in c.execute('SELECT rowid, file, content, description FROM ipynb WHERE rowid = ?',(search,)):
    print (row[2])
c.close()
conn.close()

import json
import sys
from time import sleep
import sqlite3
import csv
database = "oct1_IPNB.list.db"

conn = sqlite3.connect(database)
conn.text_factory=str 
c = conn.cursor()
search = input("ID :")
#filename = search+"DB.ipynb"
#f= open(filename,"w");f.close()
SEARCH = int(search)+1
for row in c.execute('SELECT content FROM ipynb WHERE rowid == ?', (SEARCH,)):
        filename = "Database-reprint_"+row[0]
print (filename)        
with open(filename, 'w') as outfile:
    for row in c.execute('SELECT content FROM ipynb WHERE rowid == ?', (search,)):
        row0 = row[0]
        row0 =str(row0)+"\n"
        row0=row0.replace("\\\\","\\")
        outfile.write(row0)
        #print row0
print (filename)        
conn.close()
outfile.close()


  # 427      