-



#base = Image.open('images/NewFolder/lightning01.jpg').convert('RGBA')
#8 5 4 6 3 2
# make a blank image for the text, initialized to transparent text color
txt = Image.new('RGBA', base.size, (255,255,255,0))

# get a font
font = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 20)
# get a drawing context
#d = ImageDraw.Draw(txt)




width, height = base.size
# calculate the x,y coordinates of the text
#marginx = 325
#marginy = 75
marginx = 225
marginy = 50
x = width - marginx
y = height - marginy
signature_ = "The TwitterBot Project" 
d.text((x,y), signature_, font=fnt, fill=(0,0,0,256))

out = Image.alpha_composite(base, txt)
out.save("tmp/tmp.jpg", "JPEG")
# save the image then reopen to put a title
#base = Image.open('tmp/tmp.jpg').convert('RGBA')


if __name__ == '__main__':
    img0 = Image.open('tmp/tmp.jpg').convert('RGBA')
    font = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 50)
    txt = 'The TwitterBot Project'
    text_col = (0, 0,0) # bright green
    halo_col = (255,255,255)   # black
    i2 = draw_text_with_halo(img0, (90, 10), txt, font, text_col, halo_col)



#8 5 4 6 3 2
# make a blank image for the text, initialized to transparent text color
txt = Image.new('RGBA', base.size, (255,255,255,0))

# get a font
fnt = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 30)
# get a drawing context
#d = ImageDraw.Draw(txt)
d= draw_text_with_halo(img0, (90, 10), txt, font, text_col, halo_col)
width, height = base.size
# calculate the x,y coordinates of the text
#marginx = 325
#marginy = 75
x = 90
y = 10
#generate a title
title = (generate_the_word("titles.txt"))
d.text((x,y), title , font=fnt, fill=(0,0,0,250))
out2 = Image.alpha_composite(base, i2)
out2.save("tmp/TM_POST.jpg", "JPEG")

filenameP = time.strftime("posted/%Y%m%d%H%M%S.jpg")
out2.save(filenameP, "JPEG")
#removed keys for privacy reasons
CONSUMER_KEY = 'YazCRIfWX4VICiRCOiph08jDL'
CONSUMER_SECRET = 'QOkLHou6NMwkghSHjMFXMdffQKJlDzttKtP6uBCcZ4VlQtvJyc'
ACCESS_KEY = '296906916-AWggjhqpEWIS7EzXXhc2pOPBeCVJczpOm11cQGIf'
ACCESS_SECRET = 'zFrCiyaPt8gCBVVs1bLCmdCSyQQ3DKxT5wHJq2tOu2AMj'

twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)
#path = 'images/NewFolder'
f = open("art.txt")
text = f.read()
# Build the model.
text_model = markovify.Text(text)
# Print randomly-generated sentences of no more than 140 characters
#http://paulbourke.net/fractals/
STR = (text_model.make_short_sentence(140))
#STR = ("#All_in_One - #WordCloud #Create - Added ability to randomly choose an image background  #Automated")
#PATH = "/home/jack/Desktop/deep-dream-generator/notebooks/STUFF/experiment/experiment8.jpg"
PATH = "tmp/TM_POST.jpg"
# 1 , 2, 3, 12, 5, 15, 8, 6
#photo = open('/home/jack/Desktop/deep-dream-generator/notebooks/images/'+file_list[rnd]+'.jpg','rb')

#photo = open(PATH,'rb')
#response = twitter.upload_media(media=photo)
#twitter.update_status(status=STR, media_ids=[response['media_id']])
out2

import sys
from PIL import Image, ImageChops, ImageDraw, ImageFont, ImageFilter
path = r"publish/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
filename0=(path+base_image)
def generate_the_word(infile):
        with open(infile) as f:
            contents_of_file = f.read()
        lines = contents_of_file.splitlines()
        line_number = random.randrange(0, len(lines))
        return lines[line_number]

def draw_text_with_halo(img, position, text, font, col, halo_col):
    halo = Image.new('RGBA', img.size, (0, 0, 0, 0))
    ImageDraw.Draw(halo).text(position, text, font = font, fill = halo_col)
    blurred_halo = halo.filter(ImageFilter.BLUR)
    ImageDraw.Draw(blurred_halo).text(position, text, font = font, fill = col)
    return Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))

if __name__ == '__main__':
    i = Image.open(filename0)
    font = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 50)
    text_col = (255, 255,230) # bright green
    halo_col = (0, 0, 0)   # black
    textin = (generate_the_word("wordcloud.txt"))
    i2 = draw_text_with_halo(i, (20, 20), textin, font, text_col, halo_col)
    
    txt = Image.new('RGBA', base.size, (255,255,255,0))

    # get a font
    fnt = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 30)
    # get a drawing context
    d = ImageDraw.Draw(txt)
    
    width, height = i.size
    marginx = 325
    marginy = 50
    x = width - marginx
    y = height - marginy
    signature_ = "The TwitterBot Project" 
    d.text((x,y), signature_, font=fnt, fill=(0,0,0,256))

    out = Image.alpha_composite(i2, txt)

    filename = time.strftime("tmp/%Y%m%d%H%M%S.jpg")


out

out.save(filename)

%%writefile titlenpost.py
#!/home/jack/anaconda2/python
import random
from random import randint
import time
import markovify
import os
import sys
sys.path.insert(1, "/home/jack/anaconda2/envs/py27/lib/python2.7/site-packages")
import twython
from twython import Twython
from PIL import Image, ImageChops, ImageDraw, ImageFont, ImageFilter
nap = randint(10,35)
time.sleep(nap)
path = r"publish/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
filename0=(path+base_image)
def generate_the_word(infile):
        with open(infile) as f:
            contents_of_file = f.read()
        lines = contents_of_file.splitlines()
        line_number = random.randrange(0, len(lines))
        return lines[line_number]

def draw_text_with_halo(img, position, text, font, col, halo_col):
    halo = Image.new('RGBA', img.size, (0, 0, 0, 0))
    ImageDraw.Draw(halo).text(position, text, font = font, fill = halo_col)
    blurred_halo = halo.filter(ImageFilter.BLUR)
    ImageDraw.Draw(blurred_halo).text(position, text, font = font, fill = col)
    return Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))

if __name__ == '__main__':
    inp = Image.open(filename0)
    font = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 40)
    text_col = (255, 255,230) # bright green
    halo_col = (0, 0, 0)   # black
    textin = (generate_the_word("wordcloud.txt"))
    i2 = draw_text_with_halo(inp, (15, 8), textin, font, text_col, halo_col)
    
    #txt = Image.new('RGBA', i.size, (255,255,255,0))

    # get a font
    fnt = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 20)
    # get a drawing context
    width, height = inp.size
    marginx = 225
    marginy = 35
    x = width - marginx
    y = height - marginy
    signature_ = "The TwitterBot Project" 
    #text_col2 = (150, 255, 150) # bright green
    #halo_col2 = (0, 0, 0)   # black
    text_col2 = (255, 255,230) # bright green
    halo_col2 = (0, 0, 0)   # black
    txt=draw_text_with_halo(i2,(x,y), signature_, fnt, text_col2, halo_col2)
    out = Image.alpha_composite(i2, txt)
    out.save("tmp/TM_POST.jpg")

#removed keys for privacy reasons
CONSUMER_KEY = 'YazCRIfWX4VICiRCOiph08jDL'
CONSUMER_SECRET = 'QOkLHou6NMwkghSHjMFXMdffQKJlDzttKtP6uBCcZ4VlQtvJyc'
ACCESS_KEY = '296906916-AWggjhqpEWIS7EzXXhc2pOPBeCVJczpOm11cQGIf'
ACCESS_SECRET = 'zFrCiyaPt8gCBVVs1bLCmdCSyQQ3DKxT5wHJq2tOu2AMj'

twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)
#path = 'images/NewFolder'
f = open("art.txt")
text = f.read()
# Build the model.
text_model = markovify.Text(text)
# Print randomly-generated sentences of no more than 140 characters
#http://paulbourke.net/fractals/
STR = (text_model.make_short_sentence(140))
#STR = ("#All_in_One - #WordCloud #Create - Added ability to randomly choose an image background  #Automated")
#PATH = "/home/jack/Desktop/deep-dream-generator/notebooks/STUFF/experiment/experiment8.jpg"
PATH = "tmp/TM_POST.jpg"
# 1 , 2, 3, 12, 5, 15, 8, 6
#photo = open('/home/jack/Desktop/deep-dream-generator/notebooks/images/'+file_list[rnd]+'.jpg','rb')

photo = open(PATH,'rb')
response = twitter.upload_media(media=photo)
twitter.update_status(status=STR, media_ids=[response['media_id']])

#%%writefile titlenpost2.py
#!/home/jack/anaconda2/python
import sys
import random
from random import randint
import time
import markovify
import os
import sys
sys.path.insert(1, "/home/jack/anaconda2/envs/py27/lib/python2.7/site-packages")
import twython
from twython import Twython
from PIL import Image, ImageChops, ImageDraw, ImageFont, ImageFilter
nap = randint(10,35)
time.sleep(nap)
path = r"publish/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
filename0=(path+base_image)
def generate_the_word(infile):
        with open(infile) as f:
            contents_of_file = f.read()
        lines = contents_of_file.splitlines()
        line_number = random.randrange(0, len(lines))
        return lines[line_number]

def draw_text_with_halo(img, position, text, font, col, halo_col):
    halo = Image.new('RGBA', tit.size, (0, 0, 0, 0))
    ImageDraw.Draw(halo).text(position, text, font = font, fill = halo_col)
    blurred_halo = halo.filter(ImageFilter.BLUR)
    ImageDraw.Draw(blurred_halo).text(position, text, font = font, fill = col)
    return Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))

if __name__ == '__main__':
    tit = Image.open(filename0)
    font = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 50)
    #textin = 'Python Generated'
    text_col = (255, 255,230) # bright green
    halo_col = (0, 0, 0)   # black
    textin = (generate_the_word("wordcloud.txt"))
    i2 = draw_text_with_halo(tit, (20, 10), textin, font, text_col, halo_col)
    txt = Image.new('RGBA', tit.size, (255,255,255,0))
    # get a font
    fnt = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 30)
    # get a drawing context
    d = ImageDraw.Draw(txt)
    
    width, height = tit.size
    marginx = 325
    marginy = 50
    x = width - marginx
    y = height - marginy
    out = Image.alpha_composite(i2, txt)
    out.save("tmp/TM_XXX.jpg", "JPEG")
    
    signature_ = "The TwitterBot Project"
    #i3 = draw_text_with_halo( out, (x,y), signature_, font, text_col, halo_col)
    #out = Image.alpha_composite(i3, out)
    

filenameP = time.strftime("posted/%Y%m%d%H%M%S.jpg")
out.save(filenameP, "JPEG")
#removed keys for privacy reasons
CONSUMER_KEY = 'YazCRIfWX4VICiRCOiph08jDL'
CONSUMER_SECRET = 'QOkLHou6NMwkghSHjMFXMdffQKJlDzttKtP6uBCcZ4VlQtvJyc'
ACCESS_KEY = '296906916-AWggjhqpEWIS7EzXXhc2pOPBeCVJczpOm11cQGIf'
ACCESS_SECRET = 'zFrCiyaPt8gCBVVs1bLCmdCSyQQ3DKxT5wHJq2tOu2AMj'

twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)
#path = 'images/NewFolder'
f = open("art.txt")
text = f.read()
# Build the model.
text_model = markovify.Text(text)
# Print randomly-generated sentences of no more than 140 characters
#http://paulbourke.net/fractals/
STR = (text_model.make_short_sentence(140))
#STR = ("#All_in_One - #WordCloud #Create - Added ability to randomly choose an image background  #Automated")
#PATH = "/home/jack/Desktop/deep-dream-generator/notebooks/STUFF/experiment/experiment8.jpg"
PATH = "tmp/TM_POST.jpg"
# 1 , 2, 3, 12, 5, 15, 8, 6
#photo = open('/home/jack/Desktop/deep-dream-generator/notebooks/images/'+file_list[rnd]+'.jpg','rb')

#photo = open(PATH,'rb')
#response = twitter.upload_media(media=photo)
#twitter.update_status(status=STR, media_ids=[response['media_id']])
out



!ls

%%writefile titles.txt
Python Fun
Python Graphics
Generator
Word Cloud
Graphics
Fun w/Python
Python Stuff
PYTHON !!!
Love`en Python
Creative Python
Graphic Fun
ImageBot
Programming

%%writefile wordcloud.txt
Python
Programming
ImageBot
Enjoy
Just for You
Good Stuff
Computer Graphics
Python Fun
Python Graphics
Generator
Word Cloud
Graphics
Fun w/Python
Python Stuff
PYTHON !!!
Love`en Python
Creative Python
Graphic Fun
ImageBot
Programming

%%writefile titlenpost
#!/bin/bash

while true; do
  python titlenpost.py
  echo "posted :"
  date
  sleep 1800s
done



import sys
from PIL import Image, ImageChops, ImageDraw, ImageFont, ImageFilter
path = r"publish/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
filename0=(path+base_image)
def generate_the_word(infile):
        with open(infile) as f:
            contents_of_file = f.read()
        lines = contents_of_file.splitlines()
        line_number = random.randrange(0, len(lines))
        return lines[line_number]

def draw_text_with_halo(img, position, text, font, col, halo_col):
    halo = Image.new('RGBA', i.size, (0, 0, 0, 0))
    ImageDraw.Draw(halo).text(position, text, font = font, fill = halo_col)
    blurred_halo = halo.filter(ImageFilter.BLUR)
    ImageDraw.Draw(blurred_halo).text(position, text, font = font, fill = col)
    return Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))

if __name__ == '__main__':
    i = Image.open(filename0)
    font = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 50)
    text_col = (255, 255,230) # bright green
    halo_col = (0, 0, 0)   # black
    textin = (generate_the_word("wordcloud.txt"))
    i2 = draw_text_with_halo(i, (20, 20), textin, font, text_col, halo_col)
    
    txt = Image.new('RGBA', i.size, (255,255,255,0))

    # get a font
    fnt = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 30)
    # get a drawing context
    d = ImageDraw.Draw(txt)
    
    width, height = i.size
    marginx = 325
    marginy = 50
    x = width - marginx
    y = height - marginy
    signature_ = "The TwitterBot Project" 
    d.text((x,y), signature_, font=fnt, fill=(0,0,0,256))

    out = Image.alpha_composite(i2, txt)

    #filename = time.strftime("tmp/%Y%m%d%H%M%S.jpg")
    
    font2 = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 15)
    text = "TwitterBot Project"
    # get text size
    text_size = font.getsize(text)
    # set button size + 10px margins
    button_size = (text_size[0]+8, text_size[1]+8)
    # create image with correct size and black background
    button_img = Image.new('RGBA', button_size, "black")
    # put text on button with 10px margins
    button_draw = ImageDraw.Draw(button_img)
    button_draw.text((x,y), text, font=font2)
    opacity=0.5
    bands=list(button_img.split())
    if len(bands)==4:
        bands[3]=bands[3].point(lambda x:x*opacity)
        new_image=Image.merge(button_img.mode,bands)
    # put button on source image in position (0, 0)
    out.paste(new_image, (15,15))
    # save in new file
    #source_img.save("junk/output.jpg", "JPEG")
    #source_img    

    
        
    
    
    
    
    
    
    


out

#Great title n signature

#Great signature
import sys
from PIL import Image, ImageChops, ImageDraw, ImageFont, ImageFilter
path = r"publish/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
filename0=(path+base_image)
def generate_the_word(infile):
        with open(infile) as f:
            contents_of_file = f.read()
        lines = contents_of_file.splitlines()
        line_number = random.randrange(0, len(lines))
        return lines[line_number]

def draw_text_with_halo(img, position, text, font, col, halo_col):
    halo = Image.new('RGBA', img.size, (0, 0, 0, 0))
    ImageDraw.Draw(halo).text(position, text, font = font, fill = halo_col)
    blurred_halo = halo.filter(ImageFilter.BLUR)
    ImageDraw.Draw(blurred_halo).text(position, text, font = font, fill = col)
    return Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))

if __name__ == '__main__':
    inp = Image.open(filename0)
    font = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 40)
    text_col = (255, 255,230) # bright green
    halo_col = (0, 0, 0)   # black
    textin = (generate_the_word("wordcloud.txt"))
    i2 = draw_text_with_halo(inp, (15, 8), textin, font, text_col, halo_col)
    
    #txt = Image.new('RGBA', i.size, (255,255,255,0))

    # get a font
    fnt = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 20)
    # get a drawing context
    d = ImageDraw.Draw(txt)
    width, height = inp.size
    marginx = 225
    marginy = 35
    x = width - marginx
    y = height - marginy
    signature_ = "The TwitterBot Project" 
    #text_col2 = (150, 255, 150) # bright green
    #halo_col2 = (0, 0, 0)   # black
    text_col2 = (255, 255,230) # bright green
    halo_col2 = (0, 0, 0)   # black
    txt=draw_text_with_halo(i2,(x,y), signature_, fnt, text_col2, halo_col2)
    out = Image.alpha_composite(i2, txt)
    filename = time.strftime("tmp/%Y%m%d%H%M%S.jpg")


out



#%%writefile titlenpost.py
#!/home/jack/anaconda2/python
import random
from random import randint
import time
import markovify
import os
import sys
sys.path.insert(1, "/home/jack/anaconda2/envs/py27/lib/python2.7/site-packages")
import twython
from twython import Twython
from PIL import Image, ImageChops, ImageDraw, ImageFont, ImageFilter
nap = randint(10,35)
time.sleep(nap)
path = r"publish/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
filename0=(path+base_image)
def generate_the_word(infile):
        with open(infile) as f:
            contents_of_file = f.read()
        lines = contents_of_file.splitlines()
        line_number = random.randrange(0, len(lines))
        return lines[line_number]

def draw_text_with_halo(img, position, text, font, col, halo_col):
    halo = Image.new('RGBA', img.size, (0, 0, 0, 0))
    ImageDraw.Draw(halo).text(position, text, font = font, fill = halo_col)
    blurred_halo = halo.filter(ImageFilter.BLUR)
    ImageDraw.Draw(blurred_halo).text(position, text, font = font, fill = col)
    return Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))

if __name__ == '__main__':
    inp = Image.open(filename0)
    font = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 40)
    text_col = (255, 255,230) # bright green
    halo_col = (0, 0, 0)   # black
    textin = (generate_the_word("wordcloud.txt"))
    i2 = draw_text_with_halo(inp, (15, 8), textin, font, text_col, halo_col)
    
    #txt = Image.new('RGBA', i.size, (255,255,255,0))

    # get a font
    fnt = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 20)
    # get a drawing context
    width, height = inp.size
    marginx = 225
    marginy = 35
    x = width - marginx
    y = height - marginy
    signature_ = "The TwitterBot Project" 
    #text_col2 = (150, 255, 150) # bright green
    #halo_col2 = (0, 0, 0)   # black
    text_col2 = (255, 255,230) # bright green
    halo_col2 = (0, 0, 0)   # black
    txt=draw_text_with_halo(i2,(x,y), signature_, fnt, text_col2, halo_col2)
    out = Image.alpha_composite(i2, txt)
    out.save("tmp/TM_POST.jpg")

#removed keys for privacy reasons
CONSUMER_KEY = 'YazCRIfWX4VICiRCOiph08jDL'
CONSUMER_SECRET = 'QOkLHou6NMwkghSHjMFXMdffQKJlDzttKtP6uBCcZ4VlQtvJyc'
ACCESS_KEY = '296906916-AWggjhqpEWIS7EzXXhc2pOPBeCVJczpOm11cQGIf'
ACCESS_SECRET = 'zFrCiyaPt8gCBVVs1bLCmdCSyQQ3DKxT5wHJq2tOu2AMj'

twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)
#path = 'images/NewFolder'
f = open("art.txt")
text = f.read()
# Build the model.
text_model = markovify.Text(text)
# Print randomly-generated sentences of no more than 140 characters
#http://paulbourke.net/fractals/
STR = (text_model.make_short_sentence(140))
#STR = ("#All_in_One - #WordCloud #Create - Added ability to randomly choose an image background  #Automated")
#PATH = "/home/jack/Desktop/deep-dream-generator/notebooks/STUFF/experiment/experiment8.jpg"
PATH = "tmp/TM_POST.jpg"
# 1 , 2, 3, 12, 5, 15, 8, 6
#photo = open('/home/jack/Desktop/deep-dream-generator/notebooks/images/'+file_list[rnd]+'.jpg','rb')

#photo = open(PATH,'rb')
#response = twitter.upload_media(media=photo)
#twitter.update_status(status=STR, media_ids=[response['media_id']])
out

%%writefile titlenpost.py
#!/home/jack/anaconda2/python
import random
from random import randint
import time
import markovify
import os
import sys
sys.path.insert(1, "/home/jack/anaconda2/envs/py27/lib/python2.7/site-packages")
import twython
from twython import Twython
from PIL import Image, ImageChops, ImageDraw, ImageFont, ImageFilter
nap = randint(10,35)
time.sleep(nap)
path = r"publish/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
filename0=(path+base_image)
def generate_the_word(infile):
        with open(infile) as f:
            contents_of_file = f.read()
        lines = contents_of_file.splitlines()
        line_number = random.randrange(0, len(lines))
        return lines[line_number]

def draw_text_with_halo(img, position, text, font, col, halo_col):
    halo = Image.new('RGBA', img.size, (0, 0, 0, 0))
    ImageDraw.Draw(halo).text(position, text, font = font, fill = halo_col)
    blurred_halo = halo.filter(ImageFilter.BLUR)
    ImageDraw.Draw(blurred_halo).text(position, text, font = font, fill = col)
    return Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))

if __name__ == '__main__':
    inp = Image.open(filename0)
    font = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 40)
    text_col = (255, 255,230) # bright green
    halo_col = (0, 0, 0)   # black
    textin = (generate_the_word("wordcloud.txt"))
    i2 = draw_text_with_halo(inp, (15, 8), textin, font, text_col, halo_col)
    
    #txt = Image.new('RGBA', i.size, (255,255,255,0))

    # get a font
    fnt = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 20)
    # get a drawing context
    width, height = inp.size
    marginx = 225
    marginy = 35
    x = width - marginx
    y = height - marginy
    signature_ = "The TwitterBot Project" 
    #text_col2 = (150, 255, 150) # bright green
    #halo_col2 = (0, 0, 0)   # black
    text_col2 = (255, 255,230) # bright green
    halo_col2 = (0, 0, 0)   # black
    txt=draw_text_with_halo(i2,(x,y), signature_, fnt, text_col2, halo_col2)
    out = Image.alpha_composite(i2, txt)
    out.save("tmp/TM_POST.jpg")

#removed keys for privacy reasons
CONSUMER_KEY = 'YazCRIfWX4VICiRCOiph08jDL'
CONSUMER_SECRET = 'QOkLHou6NMwkghSHjMFXMdffQKJlDzttKtP6uBCcZ4VlQtvJyc'
ACCESS_KEY = '296906916-AWggjhqpEWIS7EzXXhc2pOPBeCVJczpOm11cQGIf'
ACCESS_SECRET = 'zFrCiyaPt8gCBVVs1bLCmdCSyQQ3DKxT5wHJq2tOu2AMj'

twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)
#path = 'images/NewFolder'
f = open("art.txt")
text = f.read()
# Build the model.
text_model = markovify.Text(text)
# Print randomly-generated sentences of no more than 140 characters
#http://paulbourke.net/fractals/
STR = (text_model.make_short_sentence(140))
#STR = ("#All_in_One - #WordCloud #Create - Added ability to randomly choose an image background  #Automated")
#PATH = "/home/jack/Desktop/deep-dream-generator/notebooks/STUFF/experiment/experiment8.jpg"
PATH = "tmp/TM_POST.jpg"
# 1 , 2, 3, 12, 5, 15, 8, 6
#photo = open('/home/jack/Desktop/deep-dream-generator/notebooks/images/'+file_list[rnd]+'.jpg','rb')

photo = open(PATH,'rb')
response = twitter.upload_media(media=photo)
twitter.update_status(status=STR, media_ids=[response['media_id']])

import numpy
numpy.version.version
#'1.16.6' bakup-clonebase

%%writefile tweetout
#!/home/jack/miniconda3/envs/cloned_base/bin/python
import numpy as np
import random
from random import randint
from PIL import Image, ImageDraw, ImageFont, ImageChops, ImageFilter 
import os
import sys
import markovify
import twython
from twython import Twython
import time
import shutil
from randtext import randTXT
STR = randTXT()
Hash = ["#twitme #Python #100DaysOfCode\n","#Python #100DaysOfCode #PythonBots #codefor30days\n" ]
hashnum = randint(0,len(Hash)-1)
hashs =Hash[hashnum]
# add the hash to STR generated with randTXT()
STR = hashs+STR
STR= STR[:225]
print(STR)
# Open background image and work out centre
x = 720//2
y = 480//2

# The text we want to add
#text = "NFT TwitterBot Project"
text = STR
# Create font
font = ImageFont.truetype('/snap/gnome-3-38-2004/99/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', 12)

#nap=randint(10,400)
#time.sleep(nap)
path = r"4-publish-images/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
filename1=(path+base_image)

bg = Image.open(filename1).convert('RGB')
x = bg.width//2
y = bg.height//2
src_path = filename1
dst_path = "3-resource_images/"
shutil.move(src_path, dst_path)
# The text we want to add
text = "NFT TwitterBot Project"
text=STR[:249]
print("len(text): ",len(text))
# Create font
font = ImageFont.truetype('/snap/gnome-3-38-2004/99/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', 12)

# Create piece of canvas to draw text on and blur
blurred = Image.new('RGBA', bg.size)
draw = ImageDraw.Draw(blurred)
CH = randint(0,1)
if CH == 0:COLor = ["white","black"]
elif CH == 1:COLor = ["black","white"]  
draw.text(xy=(x-20,y+130), text=text, fill=COLor[0], font=font, anchor='mm')
draw.text(xy=(x-21,y+131), text=text, fill=COLor[0], font=font, anchor='mm')
draw.text(xy=(x-19,y+129), text=text, fill=COLor[0], font=font, anchor='mm')
draw.text(xy=(x-20,y+130), text=text, fill=COLor[0], font=font, anchor='mm')
blurred = blurred.filter(ImageFilter.BoxBlur(2))

# Paste soft text onto background
bg.paste(blurred,blurred)

# Draw on sharp text
draw = ImageDraw.Draw(bg)
draw.text(xy=(x-20,y+130), text=text, fill=COLor[1], font=font, anchor='mm')
postage = ["perferations.png","perferations+.png","usa-perferations.png","usar-perferations.png","usal-perferations.png"]
Num = randint( 0, len(postage)-1)
BOARDER = postage[Num]
mask=Image.open(BOARDER).convert('RGBA') 
bg.paste(mask, (0,0), mask=mask)
bg.save('result.png')
#removed keys for privacy reasons
CONSUMER_KEY = 'APIkey()[0]'
CONSUMER_SECRET = 'APIkey()[1]'
ACCESS_KEY = 'APIkey()[2]'
ACCESS_SECRET = 'APIkey()[3]'

twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)
PATH = "result.png"
# 1 , 2, 3, 12, 5, 15, 8, 6
#photo = open('/home/jack/Desktop/deep-dream-generator/notebooks/images/'+file_list[rnd]+'.jpg','rb')

photo = open(PATH,'rb')
response = twitter.upload_media(media=photo)
twitter.update_status(status=STR, media_ids=[response['media_id']])

from PIL import Image
im = Image.open(PATH)
im



!ls 

#!/home/jack/miniconda3/envs/cloned_base/bin/python
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import numpy as np
import random
from random import randint
from PIL import Image, ImageDraw, ImageFont, ImageChops, ImageFilter 
import os
import sys
import markovify
import twython
from twython import Twython
import time
# Open background image and work out centre

path = r"2-resource_images/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
filename0=(path+base_image)


bg = Image.open(filename0).convert('RGB')
bg =bg.resize((720,480),Image.ANTIALIAS)
x = bg.width//2
y = bg.height//2

# The text we want to add
text = "NFT TwitterBot Project"

# Create font
font = ImageFont.truetype('/snap/gnome-3-38-2004/99/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', 40)

# Create piece of canvas to draw text on and blur
blurred = Image.new('RGBA', bg.size)
draw = ImageDraw.Draw(blurred)
draw.text(xy=(x,y+190), text=text, fill='black', font=font, anchor='mm')
blurred = blurred.filter(ImageFilter.BoxBlur(7))

# Paste soft text onto background
bg.paste(blurred,blurred)

# Draw on sharp text
draw = ImageDraw.Draw(bg)
draw.text(xy=(x,y+190), text=text, fill='white', font=font, anchor='mm')
#xx=0
#yy=0
#bg.paste("peferations.png", (xx,yy)) 
# paste an onerlay image
#perferations.png
#mask=Image.open("perferations.png").convert('RGBA') 
#bg.paste(mask, (x,y), mask=mask)
#bg.paste("peferations.png", box=(0, 0) + original.size) 
bg.save('result.png')
timestr = time.strftime("%Y%m%d-%H%M%S")
filename = "records/"+timestr+"_.png"
bg.save(filename)
im =Image.open('result.png')
im



#nap=randint(10,400)
#time.sleep(nap)
path = r"3-resource_images/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
filename0=(path+base_image)

bg = Image.open(filename0).convert('RGB')
x = bg.width//2
y = bg.height//2

# The text we want to add
text = "NFT TwitterBot Project"


# Create font
font = ImageFont.truetype('/snap/gnome-3-38-2004/99/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', 40)

# Create piece of canvas to draw text on and blur
blurred = Image.new('RGBA', bg.size)
draw = ImageDraw.Draw(blurred)
draw.text(xy=(x,y+190), text=text, fill='black', font=font, anchor='mm')
blurred = blurred.filter(ImageFilter.BoxBlur(7))

# Paste soft text onto background
bg.paste(blurred,blurred)

# Draw on sharp text
draw = ImageDraw.Draw(bg)
draw.text(xy=(x,y+190), text=text, fill='white', font=font, anchor='mm')
mask=Image.open("perferations.png").convert('RGBA') 
bg.paste(mask, (0,0), mask=mask)
bg.save('result.png')
#removed keys for privacy reasons
CONSUMER_KEY = 'APIkey()[0]'
CONSUMER_SECRET = 'APIkey()[1]'
ACCESS_KEY = 'APIkey()[2]'
ACCESS_SECRET = 'APIkey()[3]'

twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)
#path = 'images/NewFolder'
with open("sart.txt") as f:
    data = f.read()
data_model = markovify.Text(data)
STR = data_model.make_sentence()
#STR = ("#All_in_One - #WordCloud #Create - Added ability to randomly choose an image background  #Automated")
#PATH = "/home/jack/Desktop/deep-dream-generator/notebooks/STUFF/experiment/experiment8.jpg"
PATH = "/home/jack/Desktop/dockercommands/newtest/NEwtest2.png"
#PATH = "result.png"
# 1 , 2, 3, 12, 5, 15, 8, 6
#photo = open('/home/jack/Desktop/deep-dream-generator/notebooks/images/'+file_list[rnd]+'.jpg','rb')

photo = open(PATH,'rb')
response = twitter.upload_media(media=photo)
twitter.update_status(status=STR, media_ids=[response['media_id']])


from PIL import Image
im = Image.open("result.png")
im

#!/home/jack/miniconda3/envs/cloned_base/bin/python
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import numpy as np
import random
from random import randint
from PIL import Image, ImageDraw, ImageFont, ImageChops, ImageFilter 
import os
import sys
import markovify
import twython
from twython import Twython
import time


CONSUMER_KEY = 'APIkey()[0]'
CONSUMER_SECRET = 'APIkey()[1]'
ACCESS_KEY = 'APIkey()[2]'
ACCESS_SECRET = 'APIkey()[3]'

twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)
#path = 'images/NewFolder'
with open("sart.txt") as f:
    data = f.read()
data_model = markovify.Text(data)
STR = data_model.make_sentence()

PATH = "result7.png"
# 1 , 2, 3, 12, 5, 15, 8, 6
#photo = open('/home/jack/Desktop/deep-dream-generator/notebooks/images/'+file_list[rnd]+'.jpg','rb')

photo = open(PATH,'rb')
response = twitter.upload_media(media=photo)
twitter.update_status(status=STR, media_ids=[response['media_id']])


Hash = ["#twitme #Python #100DaysOfCode\n","#Python #100DaysOfCode #PythonBots #codefor30days\n" ]
hashnum = randint(0,len(Hash)-1)
hashs =Hash[hashnum]
hashs

tweet="UUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUuu'place': None, 'contributors': None,\
'is_quote_status': False, 'retweet_count': 0, 'favorite_count': 0, 'favorite_count': 0, \
'favorited': False0, 'favorited': False, 'retweeted': False, 'possibly_sensitive': False, 'lang': 'en'}"
Text = (tweet[:240])

print("len(Text): ",len(Text),"\n",Text)

st

import os
import tensorflow as tf
# Load compressed models from tensorflow_hub
os.environ['TFHUB_MODEL_LOAD_FORMAT'] = 'COMPRESSED'


import IPython.display as display

import matplotlib.pyplot as plt
import matplotlib as mpl
mpl.rcParams['figure.figsize'] = (12, 12)
mpl.rcParams['axes.grid'] = False

import numpy as np
import PIL.Image
import time
import functools

def tensor_to_image(tensor):
  tensor = tensor*255
  tensor = np.array(tensor, dtype=np.uint8)
  if np.ndim(tensor)>3:
    assert tensor.shape[0] == 1
    tensor = tensor[0]
  return PIL.Image.fromarray(tensor)


content_path = tf.keras.utils.get_file('YellowLabradorLooking_new.jpg', 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg')
style_path = tf.keras.utils.get_file('kandinsky5.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg')


def load_img(path_to_img):
  max_dim = 512
  img = tf.io.read_file(path_to_img)
  img = tf.image.decode_image(img, channels=3)
  img = tf.image.convert_image_dtype(img, tf.float32)

  shape = tf.cast(tf.shape(img)[:-1], tf.float32)
  long_dim = max(shape)
  scale = max_dim / long_dim

  new_shape = tf.cast(shape * scale, tf.int32)

  img = tf.image.resize(img, new_shape)
  img = img[tf.newaxis, :]
  return img

def imshow(image, title=None):
  if len(image.shape) > 3:
    image = tf.squeeze(image, axis=0)

  plt.imshow(image)
  if title:
    plt.title(title)


content_image = load_img(content_path)
style_image = load_img(style_path)

plt.subplot(1, 2, 1)
imshow(content_image, 'Content Image')

plt.subplot(1, 2, 2)
imshow(style_image, 'Style Image')


!wget https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2

import tensorflow_hub as hub
hub_model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')
stylized_image = hub_model(tf.constant(content_image), tf.constant(style_image))[0]
tensor_to_image(stylized_image)




from ipykernel.comm import Comm

comm = Comm('this-comm-tests-a-missing-handler', data={'id': 'foo'})

comm.send(data={'id': 'bar'})

from ipykernel.comm import Comm

comm = Comm('this-comm-tests-a-missing-handler', data={'id': 'foo'})

comm.send(data={'id': 'bar'})

import ipywidgets as widgets
from IPython.display import clear_output
output1 = widgets.Output()
output1

print("hi")
with output1:
    print("in output")

with output1:
    raise ValueError("trigger msg_type=error")

import ipywidgets as widgets
output2 = widgets.Output()
output2

print("hi2")
with output2:
    print("in output2")
    clear_output(wait=True)

import ipywidgets as widgets
output3 = widgets.Output()
output3

print("hi3")
with output3:
    print("hello")
    clear_output(wait=True)
    print("world")

import ipywidgets as widgets
output4 = widgets.Output()
output4

print("hi4")
with output4:
    print("hello world")
    clear_output()

import ipywidgets as widgets
output5 = widgets.Output()
output5

print("hi5")
with output5:
    display("hello world") # this is not a stream but plain text
clear_output()

import ipywidgets as widgets
output_outer = widgets.Output()
output_inner = widgets.Output()
output_inner

output_outer

with output_inner:
    print('in inner')
    with output_outer:
        print('in outer')
    print('also in inner')

import ipywidgets as widgets
from IPython.display import clear_output
output1 = widgets.Output()
output1

print("hi")
with output1:
    print("in output")

with output1:
    raise ValueError("trigger msg_type=error")

import ipywidgets as widgets
output2 = widgets.Output()
output2

print("hi2")
with output2:
    print("in output2")
    clear_output(wait=True)

import ipywidgets as widgets
output3 = widgets.Output()
output3

print("hi3")
with output3:
    print("hello")
    clear_output(wait=True)
    print("world")

import ipywidgets as widgets
output4 = widgets.Output()
output4

print("hi4")
with output4:
    print("hello world")
    clear_output()

import ipywidgets as widgets
output5 = widgets.Output()
output5

print("hi5")
with output5:
    display("hello world") # this is not a stream but plain text
clear_output()

import ipywidgets as widgets
output_outer = widgets.Output()
output_inner = widgets.Output()
output_inner

output_outer

with output_inner:
    print('in inner')
    with output_outer:
        print('in outer')
    print('also in inner')

#@title Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

!pip install matplotlib tensorflow tensorflow-hub

import tensorflow as tf
import tensorflow_hub as hub
import matplotlib.pyplot as plt
print(tf.__version__)

model = hub.load("https://tfhub.dev/captain-pool/esrgan-tf2/1")
concrete_func = model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]

@tf.function(input_signature=[tf.TensorSpec(shape=[1, 50, 50, 3], dtype=tf.float32)])
def f(input):
  return concrete_func(input);

converter = tf.lite.TFLiteConverter.from_concrete_functions([f.get_concrete_function()], model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

# Save the TF Lite model.
with tf.io.gfile.GFile('ESRGAN.tflite', 'wb') as f:
  f.write(tflite_model)

esrgan_model_path = './ESRGAN.tflite'

test_img_path = tf.keras.utils.get_file('lr.jpg', 'https://raw.githubusercontent.com/tensorflow/examples/master/lite/examples/super_resolution/android/app/src/main/assets/lr-1.jpg')

lr = tf.io.read_file(test_img_path)
lr = tf.image.decode_jpeg(lr)
lr = tf.expand_dims(lr, axis=0)
lr = tf.cast(lr, tf.float32)

# Load TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_path=esrgan_model_path)
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Run the model
interpreter.set_tensor(input_details[0]['index'], lr)
interpreter.invoke()

# Extract the output and postprocess it
output_data = interpreter.get_tensor(output_details[0]['index'])
sr = tf.squeeze(output_data, axis=0)
sr = tf.clip_by_value(sr, 0, 255)
sr = tf.round(sr)
sr = tf.cast(sr, tf.uint8)

lr = tf.cast(tf.squeeze(lr, axis=0), tf.uint8)
plt.figure(figsize = (1, 1))
plt.title('LR')
plt.imshow(lr.numpy());

plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 1)        
plt.title(f'ESRGAN (x4)')
plt.imshow(sr.numpy());

bicubic = tf.image.resize(lr, [200, 200], tf.image.ResizeMethod.BICUBIC)
bicubic = tf.cast(bicubic, tf.uint8)
plt.subplot(1, 2, 2)   
plt.title('Bicubic')
plt.imshow(bicubic.numpy());

#@title Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf

print("TensorFlow version:", tf.__version__)

IMG_SIZE = 28

class Model(tf.Module):

  def __init__(self):
    self.model = tf.keras.Sequential([
        tf.keras.layers.Flatten(input_shape=(IMG_SIZE, IMG_SIZE), name='flatten'),
        tf.keras.layers.Dense(128, activation='relu', name='dense_1'),
        tf.keras.layers.Dense(10, name='dense_2')
    ])

    self.model.compile(
        optimizer='sgd',
        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True))

  # The `train` function takes a batch of input images and labels.
  @tf.function(input_signature=[
      tf.TensorSpec([None, IMG_SIZE, IMG_SIZE], tf.float32),
      tf.TensorSpec([None, 10], tf.float32),
  ])
  def train(self, x, y):
    with tf.GradientTape() as tape:
      prediction = self.model(x)
      loss = self.model.loss(y, prediction)
    gradients = tape.gradient(loss, self.model.trainable_variables)
    self.model.optimizer.apply_gradients(
        zip(gradients, self.model.trainable_variables))
    result = {"loss": loss}
    return result

  @tf.function(input_signature=[
      tf.TensorSpec([None, IMG_SIZE, IMG_SIZE], tf.float32),
  ])
  def infer(self, x):
    logits = self.model(x)
    probabilities = tf.nn.softmax(logits, axis=-1)
    return {
        "output": probabilities,
        "logits": logits
    }

  @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])
  def save(self, checkpoint_path):
    tensor_names = [weight.name for weight in self.model.weights]
    tensors_to_save = [weight.read_value() for weight in self.model.weights]
    tf.raw_ops.Save(
        filename=checkpoint_path, tensor_names=tensor_names,
        data=tensors_to_save, name='save')
    return {
        "checkpoint_path": checkpoint_path
    }

  @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])
  def restore(self, checkpoint_path):
    restored_tensors = {}
    for var in self.model.weights:
      restored = tf.raw_ops.Restore(
          file_pattern=checkpoint_path, tensor_name=var.name, dt=var.dtype,
          name='restore')
      var.assign(restored)
      restored_tensors[var.name] = restored
    return restored_tensors

fashion_mnist = tf.keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

train_images = (train_images / 255.0).astype(np.float32)
test_images = (test_images / 255.0).astype(np.float32)

train_labels = tf.keras.utils.to_categorical(train_labels)
test_labels = tf.keras.utils.to_categorical(test_labels)

NUM_EPOCHS = 100
BATCH_SIZE = 100
epochs = np.arange(1, NUM_EPOCHS + 1, 1)
losses = np.zeros([NUM_EPOCHS])
m = Model()

train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))
train_ds = train_ds.batch(BATCH_SIZE)

for i in range(NUM_EPOCHS):
  for x,y in train_ds:
    result = m.train(x, y)

  losses[i] = result['loss']
  if (i + 1) % 10 == 0:
    print(f"Finished {i+1} epochs")
    print(f"  loss: {losses[i]:.3f}")

# Save the trained weights to a checkpoint.
m.save('/tmp/model.ckpt')

plt.plot(epochs, losses, label='Pre-training')
plt.ylim([0, max(plt.ylim())])
plt.xlabel('Epoch')
plt.ylabel('Loss [Cross Entropy]')
plt.legend();

SAVED_MODEL_DIR = "saved_model"

tf.saved_model.save(
    m,
    SAVED_MODEL_DIR,
    signatures={
        'train':
            m.train.get_concrete_function(),
        'infer':
            m.infer.get_concrete_function(),
        'save':
            m.save.get_concrete_function(),
        'restore':
            m.restore.get_concrete_function(),
    })

# Convert the model
converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL_DIR)
converter.target_spec.supported_ops = [
    tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.
    tf.lite.OpsSet.SELECT_TF_OPS  # enable TensorFlow ops.
]
converter.experimental_enable_resource_variables = True
tflite_model = converter.convert()

interpreter = tf.lite.Interpreter(model_content=tflite_model)
interpreter.allocate_tensors()

infer = interpreter.get_signature_runner("infer")

logits_original = m.infer(x=train_images[:1])['logits'][0]
logits_lite = infer(x=train_images[:1])['logits'][0]

#@title
def compare_logits(logits):
  width = 0.35
  offset = width/2
  assert len(logits)==2

  keys = list(logits.keys())
  plt.bar(x = np.arange(len(logits[keys[0]]))-offset,
      height=logits[keys[0]], width=0.35, label=keys[0])
  plt.bar(x = np.arange(len(logits[keys[1]]))+offset,
      height=logits[keys[1]], width=0.35, label=keys[1])
  plt.legend()
  plt.grid(True)
  plt.ylabel('Logit')
  plt.xlabel('ClassID')

  delta = np.sum(np.abs(logits[keys[0]] - logits[keys[1]]))
  plt.title(f"Total difference: {delta:.3g}")

compare_logits({'Original': logits_original, 'Lite': logits_lite})

train = interpreter.get_signature_runner("train")

NUM_EPOCHS = 50
BATCH_SIZE = 100
more_epochs = np.arange(epochs[-1]+1, epochs[-1] + NUM_EPOCHS + 1, 1)
more_losses = np.zeros([NUM_EPOCHS])


for i in range(NUM_EPOCHS):
  for x,y in train_ds:
    result = train(x=x, y=y)
  more_losses[i] = result['loss']
  if (i + 1) % 10 == 0:
    print(f"Finished {i+1} epochs")
    print(f"  loss: {more_losses[i]:.3f}")

plt.plot(epochs, losses, label='Pre-training')
plt.plot(more_epochs, more_losses, label='On device')
plt.ylim([0, max(plt.ylim())])
plt.xlabel('Epoch')
plt.ylabel('Loss [Cross Entropy]')
plt.legend();

save = interpreter.get_signature_runner("save")

save(checkpoint_path=np.array("/tmp/model.ckpt", dtype=np.string_))

another_interpreter = tf.lite.Interpreter(model_content=tflite_model)
another_interpreter.allocate_tensors()

infer = another_interpreter.get_signature_runner("infer")
restore = another_interpreter.get_signature_runner("restore")

logits_before = infer(x=train_images[:1])['logits'][0]

# Restore the trained weights from /tmp/model.ckpt
restore(checkpoint_path=np.array("/tmp/model.ckpt", dtype=np.string_))

logits_after = infer(x=train_images[:1])['logits'][0]

compare_logits({'Before': logits_before, 'After': logits_after})

infer = another_interpreter.get_signature_runner("infer")
result = infer(x=test_images)
predictions = np.argmax(result["output"], axis=1)

true_labels = np.argmax(test_labels, axis=1)

result['output'].shape

class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

def plot(images, predictions, true_labels):
  plt.figure(figsize=(10,10))
  for i in range(25):
      plt.subplot(5,5,i+1)
      plt.xticks([])
      plt.yticks([])
      plt.grid(False)
      plt.imshow(images[i], cmap=plt.cm.binary)
      color = 'b' if predictions[i] == true_labels[i] else 'r'
      plt.xlabel(class_names[predictions[i]], color=color)
  plt.show()

plot(test_images, predictions, true_labels)

predictions.shape

#@title Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

!pip install tf-nightly --upgrade
!pip install jax --upgrade
!pip install jaxlib --upgrade

import numpy as np
import tensorflow as tf
import functools

import time
import itertools

import numpy.random as npr

import jax.numpy as jnp
from jax import jit, grad, random
from jax.example_libraries import optimizers
from jax.example_libraries import stax


def _one_hot(x, k, dtype=np.float32):
  """Create a one-hot encoding of x of size k."""
  return np.array(x[:, None] == np.arange(k), dtype)

(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()
train_images, test_images = train_images / 255.0, test_images / 255.0
train_images = train_images.astype(np.float32)
test_images = test_images.astype(np.float32)

train_labels = _one_hot(train_labels, 10)
test_labels = _one_hot(test_labels, 10)

def loss(params, batch):
  inputs, targets = batch
  preds = predict(params, inputs)
  return -jnp.mean(jnp.sum(preds * targets, axis=1))

def accuracy(params, batch):
  inputs, targets = batch
  target_class = jnp.argmax(targets, axis=1)
  predicted_class = jnp.argmax(predict(params, inputs), axis=1)
  return jnp.mean(predicted_class == target_class)

init_random_params, predict = stax.serial(
    stax.Flatten,
    stax.Dense(1024), stax.Relu,
    stax.Dense(1024), stax.Relu,
    stax.Dense(10), stax.LogSoftmax)

rng = random.PRNGKey(0)

step_size = 0.001
num_epochs = 10
batch_size = 128
momentum_mass = 0.9


num_train = train_images.shape[0]
num_complete_batches, leftover = divmod(num_train, batch_size)
num_batches = num_complete_batches + bool(leftover)

def data_stream():
  rng = npr.RandomState(0)
  while True:
    perm = rng.permutation(num_train)
    for i in range(num_batches):
      batch_idx = perm[i * batch_size:(i + 1) * batch_size]
      yield train_images[batch_idx], train_labels[batch_idx]
batches = data_stream()

opt_init, opt_update, get_params = optimizers.momentum(step_size, mass=momentum_mass)

@jit
def update(i, opt_state, batch):
  params = get_params(opt_state)
  return opt_update(i, grad(loss)(params, batch), opt_state)

_, init_params = init_random_params(rng, (-1, 28 * 28))
opt_state = opt_init(init_params)
itercount = itertools.count()

print("\nStarting training...")
for epoch in range(num_epochs):
  start_time = time.time()
  for _ in range(num_batches):
    opt_state = update(next(itercount), opt_state, next(batches))
  epoch_time = time.time() - start_time

  params = get_params(opt_state)
  train_acc = accuracy(params, (train_images, train_labels))
  test_acc = accuracy(params, (test_images, test_labels))
  print("Epoch {} in {:0.2f} sec".format(epoch, epoch_time))
  print("Training set accuracy {}".format(train_acc))
  print("Test set accuracy {}".format(test_acc))

serving_func = functools.partial(predict, params)
x_input = jnp.zeros((1, 28, 28))
converter = tf.lite.TFLiteConverter.experimental_from_jax(
    [serving_func], [[('input1', x_input)]])
tflite_model = converter.convert()
with open('jax_mnist.tflite', 'wb') as f:
  f.write(tflite_model)

expected = serving_func(train_images[0:1])

# Run the model with TensorFlow Lite
interpreter = tf.lite.Interpreter(model_content=tflite_model)
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
interpreter.set_tensor(input_details[0]["index"], train_images[0:1, :, :])
interpreter.invoke()
result = interpreter.get_tensor(output_details[0]["index"])

# Assert if the result of TFLite model is consistent with the JAX model.
np.testing.assert_almost_equal(expected, result, 1e-5)

def representative_dataset():
  for i in range(1000):
    x = train_images[i:i+1]
    yield [x]

converter = tf.lite.TFLiteConverter.experimental_from_jax(
    [serving_func], [[('x', x_input)]])
tflite_model = converter.convert()
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
tflite_quant_model = converter.convert()
with open('jax_mnist_quant.tflite', 'wb') as f:
  f.write(tflite_quant_model)

expected = serving_func(train_images[0:1])

# Run the model with TensorFlow Lite
interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
interpreter.set_tensor(input_details[0]["index"], train_images[0:1, :, :])
interpreter.invoke()
result = interpreter.get_tensor(output_details[0]["index"])

# Assert if the result of TFLite model is consistent with the Jax model.
np.testing.assert_almost_equal(expected, result, 1e-5)

!du -h jax_mnist.tflite
!du -h jax_mnist_quant.tflite

#@title Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import tensorflow as tf
print(tf.__version__)

import IPython.display as display

import matplotlib.pyplot as plt
import matplotlib as mpl
mpl.rcParams['figure.figsize'] = (12,12)
mpl.rcParams['axes.grid'] = False

import numpy as np
import time
import functools

content_path = tf.keras.utils.get_file('belfry.jpg','https://storage.googleapis.com/khanhlvg-public.appspot.com/arbitrary-style-transfer/belfry-2611573_1280.jpg')
style_path = tf.keras.utils.get_file('style23.jpg','https://storage.googleapis.com/khanhlvg-public.appspot.com/arbitrary-style-transfer/style23.jpg')

style_predict_path = tf.keras.utils.get_file('style_predict.tflite', 'https://tfhub.dev/google/lite-model/magenta/arbitrary-image-stylization-v1-256/int8/prediction/1?lite-format=tflite')
style_transform_path = tf.keras.utils.get_file('style_transform.tflite', 'https://tfhub.dev/google/lite-model/magenta/arbitrary-image-stylization-v1-256/int8/transfer/1?lite-format=tflite')

# Function to load an image from a file, and add a batch dimension.
def load_img(path_to_img):
  img = tf.io.read_file(path_to_img)
  img = tf.io.decode_image(img, channels=3)
  img = tf.image.convert_image_dtype(img, tf.float32)
  img = img[tf.newaxis, :]

  return img

# Function to pre-process by resizing an central cropping it.
def preprocess_image(image, target_dim):
  # Resize the image so that the shorter dimension becomes 256px.
  shape = tf.cast(tf.shape(image)[1:-1], tf.float32)
  short_dim = min(shape)
  scale = target_dim / short_dim
  new_shape = tf.cast(shape * scale, tf.int32)
  image = tf.image.resize(image, new_shape)

  # Central crop the image.
  image = tf.image.resize_with_crop_or_pad(image, target_dim, target_dim)

  return image

# Load the input images.
content_image = load_img(content_path)
style_image = load_img(style_path)

# Preprocess the input images.
preprocessed_content_image = preprocess_image(content_image, 384)
preprocessed_style_image = preprocess_image(style_image, 256)

print('Style Image Shape:', preprocessed_style_image.shape)
print('Content Image Shape:', preprocessed_content_image.shape)

def imshow(image, title=None):
  if len(image.shape) > 3:
    image = tf.squeeze(image, axis=0)

  plt.imshow(image)
  if title:
    plt.title(title)

plt.subplot(1, 2, 1)
imshow(preprocessed_content_image, 'Content Image')

plt.subplot(1, 2, 2)
imshow(preprocessed_style_image, 'Style Image')

# Function to run style prediction on preprocessed style image.
def run_style_predict(preprocessed_style_image):
  # Load the model.
  interpreter = tf.lite.Interpreter(model_path=style_predict_path)

  # Set model input.
  interpreter.allocate_tensors()
  input_details = interpreter.get_input_details()
  interpreter.set_tensor(input_details[0]["index"], preprocessed_style_image)

  # Calculate style bottleneck.
  interpreter.invoke()
  style_bottleneck = interpreter.tensor(
      interpreter.get_output_details()[0]["index"]
      )()

  return style_bottleneck

# Calculate style bottleneck for the preprocessed style image.
style_bottleneck = run_style_predict(preprocessed_style_image)
print('Style Bottleneck Shape:', style_bottleneck.shape)

# Run style transform on preprocessed style image
def run_style_transform(style_bottleneck, preprocessed_content_image):
  # Load the model.
  interpreter = tf.lite.Interpreter(model_path=style_transform_path)

  # Set model input.
  input_details = interpreter.get_input_details()
  interpreter.allocate_tensors()

  # Set model inputs.
  interpreter.set_tensor(input_details[0]["index"], preprocessed_content_image)
  interpreter.set_tensor(input_details[1]["index"], style_bottleneck)
  interpreter.invoke()

  # Transform content image.
  stylized_image = interpreter.tensor(
      interpreter.get_output_details()[0]["index"]
      )()

  return stylized_image

# Stylize the content image using the style bottleneck.
stylized_image = run_style_transform(style_bottleneck, preprocessed_content_image)

# Visualize the output.
imshow(stylized_image, 'Stylized Image')

# Calculate style bottleneck of the content image.
style_bottleneck_content = run_style_predict(
    preprocess_image(content_image, 256)
    )

# Define content blending ratio between [0..1].
# 0.0: 0% style extracts from content image.
# 1.0: 100% style extracted from content image.
content_blending_ratio = 0.5 #@param {type:"slider", min:0, max:1, step:0.01}

# Blend the style bottleneck of style image and content image
style_bottleneck_blended = content_blending_ratio * style_bottleneck_content \
                           + (1 - content_blending_ratio) * style_bottleneck

# Stylize the content image using the style bottleneck.
stylized_image_blended = run_style_transform(style_bottleneck_blended,
                                             preprocessed_content_image)

# Visualize the output.
imshow(stylized_image_blended, 'Blended Stylized Image')

import hidden

from random import randint
Hash = ["#CreativeCoding #fxhash #p5js #Generative\n","#twitme #Python #100DaysOfCode\n","#Python #PythonBots #codefor30days\n" ]
hashnum = randint(0,len(Hash)-1)
hashs =Hash[hashnum]
hashs         

!ls /home/jack/.local/lib/python3.9/site-packages

/home/jack/hidden

import sys
print(sys.path)
dir(sys)

!ls /home/jack/miniconda3/envs/cloned_base/lib/python3.9/site-packages/ImageGenerator

!mv ~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/ImageGenerator .

from ImageGenerator import *
import ImageGenerator.mkimage
dir (mkimage.mkimage())

import ImageGenerator
#dir (ImageGenerator.__file__)
dir (ImageGenerator)

Create a package

from setuptools import setup, find_packages
find_packages()

from ImageGenerator import *
dir()

from PIL import Image
def cropfromcenter(PATH,new_width,height):
    im = Image.open(PATH)
    width, height = im.size   # Get dimensions

    left = (width - new_width)/2
    top = (height - new_height)/2
    right = (width + new_width)/2
    bottom = (height + new_height)/2
    # Crop the center of the image
    im = im.crop((left, top, right, bottom))
    return im


from PIL import Image
def cropfromcenter(PATH,new_width,height,moveright=0,movedown=0):
    im = Image.open(PATH)
    width, height = im.size   # Get dimensions

    left = ((width - new_width)/2)+moveright
    top = ((height - new_height)/2)+movedown
    right = ((width + new_width)/2)+moveright
    bottom = ((height + new_height)/2)+movedown
    # Crop the center of the image
    im = im.crop((left, top, right, bottom))
    return im


PATH = "processed_images/02594.jpg"
new_width = 200
new_height = 200
nim = cropfromcenter(PATH,new_width,new_height,moveright=160,movedown=-10,)
print(nim.size)
nim



PATH = "processed_images/02594.jpg"
new_width = 350
new_height = 200
nim = cropfromcenter(PATH,new_width,new_height,offsetw=-150,offseth=50,)
nim

PATH = "processed_images/02594.jpg"
new_width = 200
new_height = 200
nim = cropfromcenter(PATH,new_width,new_height)
nim

# I want to crop 640x640 from the center
from PIL import Image
Bp=Image.open("processed_images/02594.jpg")
width, height = Bp.size
wc = int(width/4)
hc = int(height/4)

print (width, height, wc, hc)
# I want to crop 640x640 from the center


!pip freeze >>FREEZE

# %load FREEZE
absl-py==1.2.0
anyio @ file:///tmp/build/80754af9/anyio_1644463572971/work/dist
argon2-cffi @ file:///opt/conda/conda-bld/argon2-cffi_1645000214183/work
argon2-cffi-bindings @ file:///tmp/build/80754af9/argon2-cffi-bindings_1644569679365/work
arrow==1.2.3
asttokens @ file:///opt/conda/conda-bld/asttokens_1646925590279/work
astunparse==1.6.3
async-generator==1.10
attrs @ file:///opt/conda/conda-bld/attrs_1642510447205/work
Babel @ file:///tmp/build/80754af9/babel_1620871417480/work
backcall @ file:///home/ktietz/src/ci/backcall_1611930011877/work
beautifulsoup4 @ file:///opt/conda/conda-bld/beautifulsoup4_1650462163268/work
binaryornot==0.4.4
bleach @ file:///opt/conda/conda-bld/bleach_1641577558959/work
blinker==1.4
brotlipy==0.7.0
cachetools==5.2.0
certifi==2022.9.24
cffi @ file:///opt/conda/conda-bld/cffi_1642701102775/work
chardet==5.0.0
charset-normalizer==2.1.1
chart-studio==1.1.0
click==8.1.3
cloudpickle @ file:///tmp/build/80754af9/cloudpickle_1632508026186/work
colorama @ file:///tmp/build/80754af9/colorama_1607707115595/work
colorific==0.3
colormath==3.0.0
colour==0.1.5
colour-science @ git+https://github.com/crowsonkb/colour@bf653ac17ca57fea0695df114cf785df7161beec
conda-content-trust @ file:///tmp/build/80754af9/conda-content-trust_1617045594566/work
conda-package-handling @ file:///tmp/build/80754af9/conda-package-handling_1649105784853/work
cookiecutter==2.1.1
cookiejar==0.0.3
cryptography @ file:///tmp/build/80754af9/cryptography_1639414572950/work
cycler @ file:///tmp/build/80754af9/cycler_1637851556182/work
cytoolz==0.11.0
dask @ file:///tmp/abs_994957d9-ec12-411f-b953-c010f9d489d10hj3gz4k/croots/recipe/dask-core_1658513209934/work
debugpy @ file:///tmp/build/80754af9/debugpy_1637091799509/work
decorator==4.4.2
defusedxml @ file:///tmp/build/80754af9/defusedxml_1615228127516/work
dill==0.3.5.1
entrypoints @ file:///tmp/build/80754af9/entrypoints_1649926439650/work
etils==0.8.0
executing @ file:///opt/conda/conda-bld/executing_1646925071911/work
fastjsonschema @ file:///opt/conda/conda-bld/python-fastjsonschema_1661371079312/work
filelock==3.8.0
flatbuffers==22.9.24
fonttools==4.25.0
fsspec @ file:///opt/conda/conda-bld/fsspec_1659972197723/work
future==0.18.2
gast==0.4.0
generativepy==3.2
google-auth==2.12.0
google-auth-oauthlib==0.4.6
google-images-download==2.8.0
google-pasta==0.2.0
googleapis-common-protos==1.56.4
grpcio==1.49.1
h11==0.13.0
h5py==3.7.0
huepy==1.2.1
huggingface-hub==0.10.0
idna==3.4
imageio @ file:///tmp/abs_cd920173-f360-47c5-97b0-bf4d1076d5d4dvic0oys/croots/recipe/imageio_1658785036907/work
imageio-ffmpeg==0.4.7
importlib-metadata==5.0.0
importlib-resources==5.9.0
imread==0.7.4
iniconfig==1.1.1
instabot==0.117.0
ipykernel @ file:///tmp/build/80754af9/ipykernel_1647000773790/work/dist/ipykernel-6.9.1-py3-none-any.whl
ipyplot==1.1.1
ipython @ file:///opt/conda/conda-bld/ipython_1657652213665/work
ipython-genutils @ file:///tmp/build/80754af9/ipython_genutils_1606773439826/work
ipywidgets @ file:///tmp/build/80754af9/ipywidgets_1634143127070/work
jedi @ file:///tmp/build/80754af9/jedi_1644297102865/work
Jinja2 @ file:///opt/conda/conda-bld/jinja2_1647436528585/work
jinja2-time==0.2.0
joblib==1.2.0
json5 @ file:///tmp/build/80754af9/json5_1624432770122/work
jsonschema @ file:///tmp/build/80754af9/jsonschema_1650025953207/work
jupyter @ file:///tmp/abs_33h4eoipez/croots/recipe/jupyter_1659349046347/work
jupyter-client @ file:///opt/conda/conda-bld/jupyter_client_1643638337975/work
jupyter-console @ file:///opt/conda/conda-bld/jupyter_console_1647002188872/work
jupyter-core @ file:///opt/conda/conda-bld/jupyter_core_1651671229925/work
jupyter-server @ file:///tmp/abs_b88b31b8-83b9-476d-a46d-e563c421f38fvsnyi1ur/croots/recipe/jupyter_server_1658754481507/work
jupyterlab @ file:///tmp/abs_12f3h01vmy/croots/recipe/jupyterlab_1658907535764/work
jupyterlab-pygments @ file:///tmp/build/80754af9/jupyterlab_pygments_1601490720602/work
jupyterlab-server @ file:///opt/conda/conda-bld/jupyterlab_server_1650462180599/work
jupyterlab-widgets @ file:///tmp/build/80754af9/jupyterlab_widgets_1609884341231/work
keras==2.10.0
Keras-Preprocessing==1.1.2
kiwisolver @ file:///opt/conda/conda-bld/kiwisolver_1653292039266/work
libclang==14.0.6
locket @ file:///opt/conda/conda-bld/locket_1652903118915/work
mahotas==1.4.13
Markdown==3.4.1
markovify==0.9.4
MarkupSafe==2.1.1
matplotlib @ file:///tmp/build/80754af9/matplotlib-suite_1634667019719/work
matplotlib-inline @ file:///opt/conda/conda-bld/matplotlib-inline_1662014470464/work
mistune @ file:///tmp/build/80754af9/mistune_1607364877025/work
mock==4.0.3
moviepy==1.0.3
munkres==1.1.4
nbclassic @ file:///opt/conda/conda-bld/nbclassic_1644943264176/work
nbclient @ file:///tmp/build/80754af9/nbclient_1650290509967/work
nbconvert @ file:///opt/conda/conda-bld/nbconvert_1649751911790/work
nbformat @ file:///tmp/build/80754af9/nbformat_1649826788557/work
nest-asyncio @ file:///tmp/build/80754af9/nest-asyncio_1649847906199/work
networkx @ file:///opt/conda/conda-bld/networkx_1657784097507/work
notebook @ file:///tmp/abs_abf6xa6h6f/croots/recipe/notebook_1659083654985/work
numpy==1.22.4
oauthlib==3.2.1
opt-einsum==3.3.0
outcome==1.2.0
packaging==21.3
pager==3.3
pandas==1.2.4
pandocfilters @ file:///opt/conda/conda-bld/pandocfilters_1643405455980/work
parso @ file:///opt/conda/conda-bld/parso_1641458642106/work
partd @ file:///opt/conda/conda-bld/partd_1647245470509/work
pexpect @ file:///tmp/build/80754af9/pexpect_1605563209008/work
pickleshare @ file:///tmp/build/80754af9/pickleshare_1606932040724/work
Pillow==9.0.1
plotly==5.10.0
pluggy==1.0.0
proglog==0.1.10
prometheus-client @ file:///tmp/abs_d3zeliano1/croots/recipe/prometheus_client_1659455100375/work
promise==2.3
prompt-toolkit @ file:///tmp/build/80754af9/prompt-toolkit_1633440160888/work
protobuf==3.19.6
ptyprocess @ file:///tmp/build/80754af9/ptyprocess_1609355006118/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl
pure-eval @ file:///opt/conda/conda-bld/pure_eval_1646925070566/work
py==1.11.0
pyasn1==0.4.8
pyasn1-modules==0.2.8
pycairo==1.21.0
pycosat==0.6.3
pycparser @ file:///tmp/build/80754af9/pycparser_1636541352034/work
Pygments @ file:///opt/conda/conda-bld/pygments_1644249106324/work
PyJWT @ file:///opt/conda/conda-bld/pyjwt_1657544592787/work
pyOpenSSL @ file:///opt/conda/conda-bld/pyopenssl_1643788558760/work
pyparsing==3.0.9
pyrsistent @ file:///tmp/build/80754af9/pyrsistent_1636110951836/work
PySocks @ file:///tmp/build/80754af9/pysocks_1605305812635/work
pytest==7.1.3
python-dateutil @ file:///tmp/build/80754af9/python-dateutil_1626374649649/work
python-dotenv==0.21.0
python-slugify==6.1.2
pytz @ file:///opt/conda/conda-bld/pytz_1654762638606/work
PyWavelets @ file:///tmp/build/80754af9/pywavelets_1607645421828/work
PyYAML==5.3.1
pyzmq @ file:///tmp/build/80754af9/pyzmq_1638434985866/work
qtconsole @ file:///opt/conda/conda-bld/qtconsole_1662018252641/work
QtPy @ file:///opt/conda/conda-bld/qtpy_1662014892439/work
regex==2022.9.13
requests==2.28.1
requests-oauthlib==1.3.1
requests-toolbelt==0.9.1
responses==0.21.0
retrying==1.3.3
rsa==4.9
ruamel-yaml-conda @ file:///tmp/build/80754af9/ruamel_yaml_1616016711199/work
schedule==1.1.0
scikit-image==0.16.2
scikit-learn==1.1.2
scipy @ file:///tmp/build/80754af9/scipy_1641555002955/work
seaborn @ file:///tmp/build/80754af9/seaborn_1629307859561/work
selenium==4.4.3
Send2Trash @ file:///tmp/build/80754af9/send2trash_1632406701022/work
shortuuid==1.0.9
sip==4.19.13
six==1.16.0
sklearn==0.0
sniffio @ file:///tmp/build/80754af9/sniffio_1614030464178/work
sortedcontainers==2.4.0
soupsieve @ file:///tmp/build/80754af9/soupsieve_1636706018808/work
stack-data @ file:///opt/conda/conda-bld/stack_data_1646927590127/work
tenacity==8.1.0
tensorboard==2.10.1
tensorboard-data-server==0.6.1
tensorboard-plugin-wit==1.8.1
tensorflow @ file:///home/jack/base_tensorflow_pkg/tensorflow-2.11.0-cp39-cp39-linux_x86_64.whl
tensorflow-estimator==2.10.0
tensorflow-hub==0.12.0
tensorflow-io-gcs-filesystem==0.27.0
tensorflow-metadata==1.10.0
termcolor==2.0.1
terminado @ file:///tmp/build/80754af9/terminado_1644322582718/work
testpath @ file:///opt/conda/conda-bld/testpath_1655908557405/work
text-unidecode==1.3
threadpoolctl==3.1.0
tokenizers==0.12.1
toml==0.10.2
tomli==2.0.1
toolz @ file:///tmp/build/80754af9/toolz_1636545406491/work
torch==1.12.1
tornado @ file:///tmp/build/80754af9/tornado_1606942317143/work
tqdm @ file:///opt/conda/conda-bld/tqdm_1647339053476/work
traitlets @ file:///tmp/build/80754af9/traitlets_1636710298902/work
transformers==4.22.2
trio==0.21.0
trio-websocket==0.9.2
twython @ file:///tmp/build/80754af9/twython_1614080287802/work
typing_extensions==4.3.0
Unidecode==1.3.4
urllib3==1.26.12
wcwidth @ file:///Users/ktietz/demo/mc3/conda-bld/wcwidth_1629357192024/work
webdriver-manager==3.8.3
webencodings==0.5.1
websocket-client @ file:///tmp/build/80754af9/websocket-client_1614803975924/work
Werkzeug==2.2.2
widgetsnbextension @ file:///tmp/build/80754af9/widgetsnbextension_1644992802045/work
wrapt==1.14.1
wsproto==1.2.0
zipp==3.8.1


 FILE FORMATS FOR THE MNIST DATABASE
The data is stored in a very simple file format designed for storing vectors and multidimensional matrices. General info on this format is given at the end of this page, but you don't need to read that to use the data files.

All the integers in the files are stored in the MSB first (high endian) format used by most non-Intel processors. Users of Intel processors and other low-endian machines must flip the bytes of the header.

There are 4 files:

train-images-idx3-ubyte: training set images
train-labels-idx1-ubyte: training set labels
t10k-images-idx3-ubyte:  test set images
t10k-labels-idx1-ubyte:  test set labels

The training set contains 60000 examples, and the test set 10000 examples.

The first 5000 examples of the test set are taken from the original NIST training set. The last 5000 are taken from the original NIST test set. The first 5000 are cleaner and easier than the last 5000.
TRAINING SET LABEL FILE (train-labels-idx1-ubyte):
[offset] [type]          [value]          [description]
0000     32 bit integer  0x00000801(2049) magic number (MSB first)
0004     32 bit integer  60000            number of items
0008     unsigned byte   ??               label
0009     unsigned byte   ??               label
........
xxxx     unsigned byte   ??               label

The labels values are 0 to 9.
TRAINING SET IMAGE FILE (train-images-idx3-ubyte):
[offset] [type]          [value]          [description]
0000     32 bit integer  0x00000803(2051) magic number
0004     32 bit integer  60000            number of images
0008     32 bit integer  28               number of rows
0012     32 bit integer  28               number of columns
0016     unsigned byte   ??               pixel
0017     unsigned byte   ??               pixel
........
xxxx     unsigned byte   ??               pixel

Pixels are organized row-wise. Pixel values are 0 to 255. 0 means background (white), 255 means foreground (black).
TEST SET LABEL FILE (t10k-labels-idx1-ubyte):
[offset] [type]          [value]          [description]
0000     32 bit integer  0x00000801(2049) magic number (MSB first)
0004     32 bit integer  10000            number of items
0008     unsigned byte   ??               label
0009     unsigned byte   ??               label
........
xxxx     unsigned byte   ??               label

The labels values are 0 to 9.
TEST SET IMAGE FILE (t10k-images-idx3-ubyte):
[offset] [type]          [value]          [description]
0000     32 bit integer  0x00000803(2051) magic number
0004     32 bit integer  10000            number of images
0008     32 bit integer  28               number of rows
0012     32 bit integer  28               number of columns
0016     unsigned byte   ??               pixel
0017     unsigned byte   ??               pixel
........
xxxx     unsigned byte   ??               pixel

Pixels are organized row-wise. Pixel values are 0 to 255. 0 means background (white), 255 means foreground (black).
 
THE IDX FILE FORMAT
the IDX file format is a simple format for vectors and multidimensional matrices of various numerical types.

The basic format is

magic number
size in dimension 0
size in dimension 1
size in dimension 2
.....
size in dimension N
data

The magic number is an integer (MSB first). The first 2 bytes are always 0.

The third byte codes the type of the data:
0x08: unsigned byte
0x09: signed byte
0x0B: short (2 bytes)
0x0C: int (4 bytes)
0x0D: float (4 bytes)
0x0E: double (8 bytes)

The 4-th byte codes the number of dimensions of the vector/matrix: 1 for vectors, 2 for matrices....

The sizes in each dimension are 4-byte integers (MSB first, high endian, like in most non-Intel processors).

The data is stored like in a C array, i.e. the index in the last dimension changes the fastest.
  

import sys
sys.path.append('/home/jack/Desktop/Imagedata')
from ImageDirectories import imagelist

for num in range(0,17):
    print(str(num)+": ",imagelist(num))

import VID2img

import sys
print(sys.path)
#dir(sys)

from random import randint
Hash = ["#CreativeCoding #fxhash #p5js #Generative\n","#twitme #Python #100DaysOfCode\n","#Python #PythonBots #codefor30days\n" ]
hashnum = randint(0,len(Hash)-1)
hashs =Hash[hashnum]
hashs         

!ls /home/jack/.local/lib/python3.9/site-packages

/home/jack/hidden

!ls /home/jack/miniconda3/envs/cloned_base/lib/python3.9/site-packages/ImageGenerator

!mv ~/miniconda3/envs/cloned_base/lib/python3.9/site-packages/ImageGenerator .

from ImageGenerator import *
import ImageGenerator.mkimage
dir (mkimage.mkimage())

from ImageGenerator import *
#dir (ImageGenerator.__file__)
dir (ImageGenerator)

Create a package

from setuptools import setup, find_packages
find_packages()

from ImageGenerator import *
dir()

from PIL import Image
def cropfromcenter(PATH,new_width,height):
    im = Image.open(PATH)
    width, height = im.size   # Get dimensions

    left = (width - new_width)/2
    top = (height - new_height)/2
    right = (width + new_width)/2
    bottom = (height + new_height)/2
    # Crop the center of the image
    im = im.crop((left, top, right, bottom))
    return im


from PIL import Image
def cropfromcenter(PATH,new_width,height,moveright=0,movedown=0):
    im = Image.open(PATH)
    width, height = im.size   # Get dimensions

    left = ((width - new_width)/2)+moveright
    top = ((height - new_height)/2)+movedown
    right = ((width + new_width)/2)+moveright
    bottom = ((height + new_height)/2)+movedown
    # Crop the center of the image
    im = im.crop((left, top, right, bottom))
    return im


PATH = "processed_images/02594.jpg"
new_width = 200
new_height = 200
nim = cropfromcenter(PATH,new_width,new_height,moveright=160,movedown=-10,)
print(nim.size)
nim



PATH = "processed_images/02594.jpg"
new_width = 350
new_height = 200
nim = cropfromcenter(PATH,new_width,new_height,offsetw=-150,offseth=50,)
nim

PATH = "processed_images/02594.jpg"
new_width = 200
new_height = 200
nim = cropfromcenter(PATH,new_width,new_height)
nim

# I want to crop 640x640 from the center
from PIL import Image
Bp=Image.open("processed_images/02594.jpg")
width, height = Bp.size
wc = int(width/4)
hc = int(height/4)

print (width, height, wc, hc)
# I want to crop 640x640 from the center


!pip freeze >>FREEZE

# %load FREEZE
absl-py==1.2.0
anyio @ file:///tmp/build/80754af9/anyio_1644463572971/work/dist
argon2-cffi @ file:///opt/conda/conda-bld/argon2-cffi_1645000214183/work
argon2-cffi-bindings @ file:///tmp/build/80754af9/argon2-cffi-bindings_1644569679365/work
arrow==1.2.3
asttokens @ file:///opt/conda/conda-bld/asttokens_1646925590279/work
astunparse==1.6.3
async-generator==1.10
attrs @ file:///opt/conda/conda-bld/attrs_1642510447205/work
Babel @ file:///tmp/build/80754af9/babel_1620871417480/work
backcall @ file:///home/ktietz/src/ci/backcall_1611930011877/work
beautifulsoup4 @ file:///opt/conda/conda-bld/beautifulsoup4_1650462163268/work
binaryornot==0.4.4
bleach @ file:///opt/conda/conda-bld/bleach_1641577558959/work
blinker==1.4
brotlipy==0.7.0
cachetools==5.2.0
certifi==2022.9.24
cffi @ file:///opt/conda/conda-bld/cffi_1642701102775/work
chardet==5.0.0
charset-normalizer==2.1.1
chart-studio==1.1.0
click==8.1.3
cloudpickle @ file:///tmp/build/80754af9/cloudpickle_1632508026186/work
colorama @ file:///tmp/build/80754af9/colorama_1607707115595/work
colorific==0.3
colormath==3.0.0
colour==0.1.5
colour-science @ git+https://github.com/crowsonkb/colour@bf653ac17ca57fea0695df114cf785df7161beec
conda-content-trust @ file:///tmp/build/80754af9/conda-content-trust_1617045594566/work
conda-package-handling @ file:///tmp/build/80754af9/conda-package-handling_1649105784853/work
cookiecutter==2.1.1
cookiejar==0.0.3
cryptography @ file:///tmp/build/80754af9/cryptography_1639414572950/work
cycler @ file:///tmp/build/80754af9/cycler_1637851556182/work
cytoolz==0.11.0
dask @ file:///tmp/abs_994957d9-ec12-411f-b953-c010f9d489d10hj3gz4k/croots/recipe/dask-core_1658513209934/work
debugpy @ file:///tmp/build/80754af9/debugpy_1637091799509/work
decorator==4.4.2
defusedxml @ file:///tmp/build/80754af9/defusedxml_1615228127516/work
dill==0.3.5.1
entrypoints @ file:///tmp/build/80754af9/entrypoints_1649926439650/work
etils==0.8.0
executing @ file:///opt/conda/conda-bld/executing_1646925071911/work
fastjsonschema @ file:///opt/conda/conda-bld/python-fastjsonschema_1661371079312/work
filelock==3.8.0
flatbuffers==22.9.24
fonttools==4.25.0
fsspec @ file:///opt/conda/conda-bld/fsspec_1659972197723/work
future==0.18.2
gast==0.4.0
generativepy==3.2
google-auth==2.12.0
google-auth-oauthlib==0.4.6
google-images-download==2.8.0
google-pasta==0.2.0
googleapis-common-protos==1.56.4
grpcio==1.49.1
h11==0.13.0
h5py==3.7.0
huepy==1.2.1
huggingface-hub==0.10.0
idna==3.4
imageio @ file:///tmp/abs_cd920173-f360-47c5-97b0-bf4d1076d5d4dvic0oys/croots/recipe/imageio_1658785036907/work
imageio-ffmpeg==0.4.7
importlib-metadata==5.0.0
importlib-resources==5.9.0
imread==0.7.4
iniconfig==1.1.1
instabot==0.117.0
ipykernel @ file:///tmp/build/80754af9/ipykernel_1647000773790/work/dist/ipykernel-6.9.1-py3-none-any.whl
ipyplot==1.1.1
ipython @ file:///opt/conda/conda-bld/ipython_1657652213665/work
ipython-genutils @ file:///tmp/build/80754af9/ipython_genutils_1606773439826/work
ipywidgets @ file:///tmp/build/80754af9/ipywidgets_1634143127070/work
jedi @ file:///tmp/build/80754af9/jedi_1644297102865/work
Jinja2 @ file:///opt/conda/conda-bld/jinja2_1647436528585/work
jinja2-time==0.2.0
joblib==1.2.0
json5 @ file:///tmp/build/80754af9/json5_1624432770122/work
jsonschema @ file:///tmp/build/80754af9/jsonschema_1650025953207/work
jupyter @ file:///tmp/abs_33h4eoipez/croots/recipe/jupyter_1659349046347/work
jupyter-client @ file:///opt/conda/conda-bld/jupyter_client_1643638337975/work
jupyter-console @ file:///opt/conda/conda-bld/jupyter_console_1647002188872/work
jupyter-core @ file:///opt/conda/conda-bld/jupyter_core_1651671229925/work
jupyter-server @ file:///tmp/abs_b88b31b8-83b9-476d-a46d-e563c421f38fvsnyi1ur/croots/recipe/jupyter_server_1658754481507/work
jupyterlab @ file:///tmp/abs_12f3h01vmy/croots/recipe/jupyterlab_1658907535764/work
jupyterlab-pygments @ file:///tmp/build/80754af9/jupyterlab_pygments_1601490720602/work
jupyterlab-server @ file:///opt/conda/conda-bld/jupyterlab_server_1650462180599/work
jupyterlab-widgets @ file:///tmp/build/80754af9/jupyterlab_widgets_1609884341231/work
keras==2.10.0
Keras-Preprocessing==1.1.2
kiwisolver @ file:///opt/conda/conda-bld/kiwisolver_1653292039266/work
libclang==14.0.6
locket @ file:///opt/conda/conda-bld/locket_1652903118915/work
mahotas==1.4.13
Markdown==3.4.1
markovify==0.9.4
MarkupSafe==2.1.1
matplotlib @ file:///tmp/build/80754af9/matplotlib-suite_1634667019719/work
matplotlib-inline @ file:///opt/conda/conda-bld/matplotlib-inline_1662014470464/work
mistune @ file:///tmp/build/80754af9/mistune_1607364877025/work
mock==4.0.3
moviepy==1.0.3
munkres==1.1.4
nbclassic @ file:///opt/conda/conda-bld/nbclassic_1644943264176/work
nbclient @ file:///tmp/build/80754af9/nbclient_1650290509967/work
nbconvert @ file:///opt/conda/conda-bld/nbconvert_1649751911790/work
nbformat @ file:///tmp/build/80754af9/nbformat_1649826788557/work
nest-asyncio @ file:///tmp/build/80754af9/nest-asyncio_1649847906199/work
networkx @ file:///opt/conda/conda-bld/networkx_1657784097507/work
notebook @ file:///tmp/abs_abf6xa6h6f/croots/recipe/notebook_1659083654985/work
numpy==1.22.4
oauthlib==3.2.1
opt-einsum==3.3.0
outcome==1.2.0
packaging==21.3
pager==3.3
pandas==1.2.4
pandocfilters @ file:///opt/conda/conda-bld/pandocfilters_1643405455980/work
parso @ file:///opt/conda/conda-bld/parso_1641458642106/work
partd @ file:///opt/conda/conda-bld/partd_1647245470509/work
pexpect @ file:///tmp/build/80754af9/pexpect_1605563209008/work
pickleshare @ file:///tmp/build/80754af9/pickleshare_1606932040724/work
Pillow==9.0.1
plotly==5.10.0
pluggy==1.0.0
proglog==0.1.10
prometheus-client @ file:///tmp/abs_d3zeliano1/croots/recipe/prometheus_client_1659455100375/work
promise==2.3
prompt-toolkit @ file:///tmp/build/80754af9/prompt-toolkit_1633440160888/work
protobuf==3.19.6
ptyprocess @ file:///tmp/build/80754af9/ptyprocess_1609355006118/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl
pure-eval @ file:///opt/conda/conda-bld/pure_eval_1646925070566/work
py==1.11.0
pyasn1==0.4.8
pyasn1-modules==0.2.8
pycairo==1.21.0
pycosat==0.6.3
pycparser @ file:///tmp/build/80754af9/pycparser_1636541352034/work
Pygments @ file:///opt/conda/conda-bld/pygments_1644249106324/work
PyJWT @ file:///opt/conda/conda-bld/pyjwt_1657544592787/work
pyOpenSSL @ file:///opt/conda/conda-bld/pyopenssl_1643788558760/work
pyparsing==3.0.9
pyrsistent @ file:///tmp/build/80754af9/pyrsistent_1636110951836/work
PySocks @ file:///tmp/build/80754af9/pysocks_1605305812635/work
pytest==7.1.3
python-dateutil @ file:///tmp/build/80754af9/python-dateutil_1626374649649/work
python-dotenv==0.21.0
python-slugify==6.1.2
pytz @ file:///opt/conda/conda-bld/pytz_1654762638606/work
PyWavelets @ file:///tmp/build/80754af9/pywavelets_1607645421828/work
PyYAML==5.3.1
pyzmq @ file:///tmp/build/80754af9/pyzmq_1638434985866/work
qtconsole @ file:///opt/conda/conda-bld/qtconsole_1662018252641/work
QtPy @ file:///opt/conda/conda-bld/qtpy_1662014892439/work
regex==2022.9.13
requests==2.28.1
requests-oauthlib==1.3.1
requests-toolbelt==0.9.1
responses==0.21.0
retrying==1.3.3
rsa==4.9
ruamel-yaml-conda @ file:///tmp/build/80754af9/ruamel_yaml_1616016711199/work
schedule==1.1.0
scikit-image==0.16.2
scikit-learn==1.1.2
scipy @ file:///tmp/build/80754af9/scipy_1641555002955/work
seaborn @ file:///tmp/build/80754af9/seaborn_1629307859561/work
selenium==4.4.3
Send2Trash @ file:///tmp/build/80754af9/send2trash_1632406701022/work
shortuuid==1.0.9
sip==4.19.13
six==1.16.0
sklearn==0.0
sniffio @ file:///tmp/build/80754af9/sniffio_1614030464178/work
sortedcontainers==2.4.0
soupsieve @ file:///tmp/build/80754af9/soupsieve_1636706018808/work
stack-data @ file:///opt/conda/conda-bld/stack_data_1646927590127/work
tenacity==8.1.0
tensorboard==2.10.1
tensorboard-data-server==0.6.1
tensorboard-plugin-wit==1.8.1
tensorflow @ file:///home/jack/base_tensorflow_pkg/tensorflow-2.11.0-cp39-cp39-linux_x86_64.whl
tensorflow-estimator==2.10.0
tensorflow-hub==0.12.0
tensorflow-io-gcs-filesystem==0.27.0
tensorflow-metadata==1.10.0
termcolor==2.0.1
terminado @ file:///tmp/build/80754af9/terminado_1644322582718/work
testpath @ file:///opt/conda/conda-bld/testpath_1655908557405/work
text-unidecode==1.3
threadpoolctl==3.1.0
tokenizers==0.12.1
toml==0.10.2
tomli==2.0.1
toolz @ file:///tmp/build/80754af9/toolz_1636545406491/work
torch==1.12.1
tornado @ file:///tmp/build/80754af9/tornado_1606942317143/work
tqdm @ file:///opt/conda/conda-bld/tqdm_1647339053476/work
traitlets @ file:///tmp/build/80754af9/traitlets_1636710298902/work
transformers==4.22.2
trio==0.21.0
trio-websocket==0.9.2
twython @ file:///tmp/build/80754af9/twython_1614080287802/work
typing_extensions==4.3.0
Unidecode==1.3.4
urllib3==1.26.12
wcwidth @ file:///Users/ktietz/demo/mc3/conda-bld/wcwidth_1629357192024/work
webdriver-manager==3.8.3
webencodings==0.5.1
websocket-client @ file:///tmp/build/80754af9/websocket-client_1614803975924/work
Werkzeug==2.2.2
widgetsnbextension @ file:///tmp/build/80754af9/widgetsnbextension_1644992802045/work
wrapt==1.14.1
wsproto==1.2.0
zipp==3.8.1


 FILE FORMATS FOR THE MNIST DATABASE
The data is stored in a very simple file format designed for storing vectors and multidimensional matrices. General info on this format is given at the end of this page, but you don't need to read that to use the data files.

All the integers in the files are stored in the MSB first (high endian) format used by most non-Intel processors. Users of Intel processors and other low-endian machines must flip the bytes of the header.

There are 4 files:

train-images-idx3-ubyte: training set images
train-labels-idx1-ubyte: training set labels
t10k-images-idx3-ubyte:  test set images
t10k-labels-idx1-ubyte:  test set labels

The training set contains 60000 examples, and the test set 10000 examples.

The first 5000 examples of the test set are taken from the original NIST training set. The last 5000 are taken from the original NIST test set. The first 5000 are cleaner and easier than the last 5000.
TRAINING SET LABEL FILE (train-labels-idx1-ubyte):
[offset] [type]          [value]          [description]
0000     32 bit integer  0x00000801(2049) magic number (MSB first)
0004     32 bit integer  60000            number of items
0008     unsigned byte   ??               label
0009     unsigned byte   ??               label
........
xxxx     unsigned byte   ??               label

The labels values are 0 to 9.
TRAINING SET IMAGE FILE (train-images-idx3-ubyte):
[offset] [type]          [value]          [description]
0000     32 bit integer  0x00000803(2051) magic number
0004     32 bit integer  60000            number of images
0008     32 bit integer  28               number of rows
0012     32 bit integer  28               number of columns
0016     unsigned byte   ??               pixel
0017     unsigned byte   ??               pixel
........
xxxx     unsigned byte   ??               pixel

Pixels are organized row-wise. Pixel values are 0 to 255. 0 means background (white), 255 means foreground (black).
TEST SET LABEL FILE (t10k-labels-idx1-ubyte):
[offset] [type]          [value]          [description]
0000     32 bit integer  0x00000801(2049) magic number (MSB first)
0004     32 bit integer  10000            number of items
0008     unsigned byte   ??               label
0009     unsigned byte   ??               label
........
xxxx     unsigned byte   ??               label

The labels values are 0 to 9.
TEST SET IMAGE FILE (t10k-images-idx3-ubyte):
[offset] [type]          [value]          [description]
0000     32 bit integer  0x00000803(2051) magic number
0004     32 bit integer  10000            number of images
0008     32 bit integer  28               number of rows
0012     32 bit integer  28               number of columns
0016     unsigned byte   ??               pixel
0017     unsigned byte   ??               pixel
........
xxxx     unsigned byte   ??               pixel

Pixels are organized row-wise. Pixel values are 0 to 255. 0 means background (white), 255 means foreground (black).
 
THE IDX FILE FORMAT
the IDX file format is a simple format for vectors and multidimensional matrices of various numerical types.

The basic format is

magic number
size in dimension 0
size in dimension 1
size in dimension 2
.....
size in dimension N
data

The magic number is an integer (MSB first). The first 2 bytes are always 0.

The third byte codes the type of the data:
0x08: unsigned byte
0x09: signed byte
0x0B: short (2 bytes)
0x0C: int (4 bytes)
0x0D: float (4 bytes)
0x0E: double (8 bytes)

The 4-th byte codes the number of dimensions of the vector/matrix: 1 for vectors, 2 for matrices....

The sizes in each dimension are 4-byte integers (MSB first, high endian, like in most non-Intel processors).

The data is stored like in a C array, i.e. the index in the last dimension changes the fastest.
  



packages="""purrr         NA                                                           
R6            NA                                                           
rappdirs      NA                                                           
rcmdcheck     NA                                                           
RColorBrewer  NA                                                           
Rcpp          NA                                                           
RcppArmadillo NA                                                           
readbitmap    NA                                                           
readr         NA                                                           
readxl        NA                                                           
rematch       NA                                                           
rematch2      NA                                                           
remotes       NA                                                           
repr          "data.table, dplyr, htmlwidgets, vegalite, plotly, geojsonio"
reprex        NA                                                           
reshape2      NA                                                           
rex           NA                                                           
rhub          NA                                                           
rjson         NA                                                           
rlang         "winch"                                                      
rmarkdown     NA                                                           
roxygen2      NA                                                           
rprojroot     NA                                                           
rstudioapi    NA                                                           
rversions     NA                                                           
rvest         NA                                                           
sass          NA                                                           
scales        NA                                                           
selectr       NA                                                           
sessioninfo   NA                                                           
shiny         NA                                                           
SnowballC     NA                                                           
sourcetools   NA                                                           
spelling      NA                                                           
splines       NA                                                           
stats         NA                                                           
stats4        NA                                                           
stringi       NA                                                           
stringr       NA                                                           
sys           NA                                                           
systemfonts   NA                                                           
tcltk         NA                                                           
testthat      NA                                                           
textshaping   NA                                                           
tibble        NA                                                           
tidyr         NA                                                           
tidyselect    NA                                                           
tidytext      NA                                                           
tidyverse     NA                                                           
tiff          NA                                                           
tinytex       NA                                                           
tokenizers    NA                                                           
tools         NA                                                           
twitteR       NA                                                           
tzdb          NA                                                           
urlchecker    NA                                                           
usethis       NA                                                           
utf8          NA                                                           
utils         NA                                                           
uuid          NA                                                           
vctrs         NA                                                           
viridisLite   NA                                                           
vroom         NA                                                           
waldo         NA                                                           
whisker       NA                                                           
whoami        NA                                                           
withr         NA                                                           
xfun          NA                                                           
XML           NA                                                           
xml2          NA                                                           
xmlparsedata  NA                                                           
xopen         NA                                                           
xtable        NA                                                           
yaml          NA                                                           
zip           NA                                                           
              License                                  License_is_FOSS
ambient       "MIT + file LICENSE"                     NA             
askpass       "MIT + file LICENSE"                     NA             
assertthat    "GPL-3"                                  NA             
backports     "GPL-2"                                  NA             
base          "Part of R 3.6.1"                        NA             
base64enc     "GPL-2 | GPL-3"                          NA             
BH            "BSL-1.0"                                NA             
BiocManager   "Artistic-2.0"                           NA             
bit           "GPL-2 | GPL-3"                          NA             
bit64         "GPL-2 | GPL-3"                          NA             
blob          "MIT + file LICENSE"                     NA             
bmp           "GPL (>= 2)"                             NA             
brew          "GPL-2"                                  NA             
brio          "MIT + file LICENSE"                     NA             
broom         "MIT + file LICENSE"                     NA             
bslib         "MIT + file LICENSE"                     NA             
cachem        "MIT + file LICENSE"                     NA             
callr         "MIT + file LICENSE"                     NA             
cellranger    "MIT + file LICENSE"                     NA             
class         "GPL-2 | GPL-3"                          NA             
cli           "MIT + file LICENSE"                     NA             
clipr         "GPL-3"                                  NA             
clisymbols    "MIT + file LICENSE"                     NA             
codetools     "GPL"                                    NA             
colorspace    "BSD_3_clause + file LICENSE"            NA             
colourlovers  "GPL-2"                                  NA             
commonmark    "BSD_2_clause + file LICENSE"            NA             
compiler      "Part of R 3.6.1"                        NA             
covr          "MIT + file LICENSE"                     NA             
cowplot       "GPL-2"                                  NA             
cpp11         "MIT + file LICENSE"                     NA             
crayon        "MIT + file LICENSE"                     NA             
credentials   "MIT + file LICENSE"                     NA             
crosstalk     "MIT + file LICENSE"                     NA             
curl          "MIT + file LICENSE"                     NA             
cyclocomp     "MIT + file LICENSE"                     NA             
data.table    "MPL-2.0 | file LICENSE"                 NA             
datasets      "Part of R 3.6.1"                        NA             
DBI           "LGPL (>= 2)"                            NA             
dbplyr        "MIT + file LICENSE"                     NA             
deldir        "GPL (>= 2)"                             NA             
desc          "MIT + file LICENSE"                     NA             
dichromat     "GPL-2"                                  NA             
diffobj       "GPL-2 | GPL-3"                          NA             
digest        "GPL (>= 2)"                             NA             
downlit       "MIT + file LICENSE"                     NA             
downloader    "GPL-2"                                  NA             
dplyr         "MIT + file LICENSE"                     NA             
DT            "GPL-3 | file LICENSE"                   NA             
dtplyr        "MIT + file LICENSE"                     NA             
e1071         "GPL-2 | GPL-3"                          NA             
ellipsis      "GPL-3"                                  NA             
evaluate      "MIT + file LICENSE"                     NA             
fansi         "GPL (>= 2)"                             NA             
farver        "MIT + file LICENSE"                     NA             
fastmap       "MIT + file LICENSE"                     NA             
fontawesome   "MIT + file LICENSE"                     NA             
forcats       "GPL-3"                                  NA             
fs            "GPL-3"                                  NA             
gargle        "MIT + file LICENSE"                     NA             
generativeart "GPL-3"                                  NA             
generics      "GPL-2"                                  NA             
gert          "MIT + file LICENSE"                     NA             
ggplot2       "MIT + file LICENSE"                     NA             
gh            "MIT + file LICENSE"                     NA             
gitcreds      "MIT + file LICENSE"                     NA             
glue          "MIT + file LICENSE"                     NA             
gmailr        "MIT + file LICENSE"                     NA             
googledrive   "MIT + file LICENSE"                     NA             
googlesheets4 "MIT + file LICENSE"                     NA             
graphics      "Part of R 3.6.1"                        NA             
grDevices     "Part of R 3.6.1"                        NA             
grid          "Part of R 3.6.1"                        NA             
gtable        "GPL-2"                                  NA             
haven         "MIT + file LICENSE"                     NA             
highr         "GPL"                                    NA             
hms           "GPL-3"                                  NA             
htmltools     "GPL (>= 2)"                             NA             
htmlwidgets   "MIT + file LICENSE"                     NA             
httpuv        "GPL (>= 2) | file LICENSE"              NA             
httr          "MIT + file LICENSE"                     NA             
httr2         "MIT + file LICENSE"                     NA             
hunspell      "GPL-2 | LGPL-2.1 | MPL-1.1"             NA             
ids           "MIT + file LICENSE"                     NA             
igraph        "GPL (>= 2)"                             NA             
ini           "GPL-3"                                  NA             
IRdisplay     "MIT + file LICENSE"                     NA             
IRkernel      "MIT + file LICENSE"                     NA             
isoband       "MIT + file LICENSE"                     NA             
janeaustenr   "MIT + file LICENSE"                     NA             
jpeg          "GPL-2 | GPL-3"                          NA             
jquerylib     "MIT + file LICENSE"                     NA             
jsonlite      "MIT + file LICENSE"                     NA             
kknn          "GPL (>= 2)"                             NA             
knitr         "GPL"                                    NA             
labeling      "MIT + file LICENSE | Unlimited"         NA             
later         "MIT + file LICENSE"                     NA             
lattice       "GPL (>= 2)"                             NA             
lazyeval      "GPL-3"                                  NA             
lifecycle     "MIT + file LICENSE"                     NA             
lintr         "MIT + file LICENSE"                     NA             
lubridate     "GPL (>= 2)"                             NA             
magrittr      "MIT + file LICENSE"                     NA             
markdown      "GPL-2"                                  NA             
MASS          "GPL-2 | GPL-3"                          NA             
Matrix        "GPL (>= 2) | file LICENCE"              NA             
memoise       "MIT + file LICENSE"                     NA             
methods       "Part of R 3.6.1"                        NA             
mgcv          "GPL (>= 2)"                             NA             
mime          "GPL"                                    NA             
miniUI        "GPL-3"                                  NA             
mockery       "MIT + file LICENSE"                     NA             
modelr        "GPL-3"                                  NA             
munsell       "MIT + file LICENSE"                     NA             
nlme          "GPL (>= 2) | file LICENCE"              NA             
openssl       "MIT + file LICENSE"                     NA             
parallel      "Part of R 3.6.1"                        NA             
parsedate     "GPL-2"                                  NA             
pbdZMQ        "GPL-3"                                  NA             
pillar        "GPL-3"                                  NA             
pingr         "MIT + file LICENSE"                     NA             
pkgbuild      "MIT + file LICENSE"                     NA             
pkgconfig     "MIT + file LICENSE"                     NA             
pkgload       "GPL-3"                                  NA             
plogr         "MIT + file LICENSE"                     NA             
plyr          "MIT + file LICENSE"                     NA             
png           "GPL-2 | GPL-3"                          NA             
polyclip      "BSL"                                    NA             
praise        "MIT + file LICENSE"                     NA             
prettyunits   "MIT + file LICENSE"                     NA             
processx      "MIT + file LICENSE"                     NA             
profvis       "GPL-3 | file LICENSE"                   NA             
progress      "MIT + file LICENSE"                     NA             
promises      "MIT + file LICENSE"                     NA             
proxy         "GPL-2"                                  NA             
ps            "BSD_3_clause + file LICENSE"            NA             
purrr         "GPL-3 | file LICENSE"                   NA             
R6            "MIT + file LICENSE"                     NA             
rappdirs      "MIT + file LICENSE"                     NA             
rcmdcheck     "MIT + file LICENSE"                     NA             
RColorBrewer  "Apache License 2.0"                     NA             
Rcpp          "GPL (>= 2)"                             NA             
RcppArmadillo "GPL (>= 2)"                             NA             
readbitmap    "GPL (>= 2)"                             NA             
readr         "GPL (>= 2) | file LICENSE"              NA             
readxl        "GPL-3"                                  NA             
rematch       "MIT + file LICENSE"                     NA             
rematch2      "MIT + file LICENSE"                     NA             
remotes       "MIT + file LICENSE"                     NA             
repr          "GPL-3"                                  NA             
reprex        "MIT + file LICENSE"                     NA             
reshape2      "MIT + file LICENSE"                     NA             
rex           "MIT + file LICENSE"                     NA             
rhub          "MIT + file LICENSE"                     NA             
rjson         "GPL-2"                                  NA             
rlang         "MIT + file LICENSE"                     NA             
rmarkdown     "GPL-3"                                  NA             
roxygen2      "MIT + file LICENSE"                     NA             
rprojroot     "MIT + file LICENSE"                     NA             
rstudioapi    "MIT + file LICENSE"                     NA             
rversions     "MIT + file LICENSE"                     NA             
rvest         "GPL-3"                                  NA             
sass          "MIT + file LICENSE"                     NA             
scales        "MIT + file LICENSE"                     NA             
selectr       "BSD_3_clause + file LICENCE"            NA             
sessioninfo   "GPL-2"                                  NA             
shiny         "GPL-3 | file LICENSE"                   NA             
SnowballC     "BSD_3_clause + file LICENSE"            NA             
sourcetools   "MIT + file LICENSE"                     NA             
spelling      "MIT + file LICENSE"                     NA             
splines       "Part of R 3.6.1"                        NA             
stats         "Part of R 3.6.1"                        NA             
stats4        "Part of R 3.6.1"                        NA             
stringi       "file LICENSE"                           "yes"          
stringr       "GPL-2 | file LICENSE"                   NA             
sys           "MIT + file LICENSE"                     NA             
systemfonts   "MIT + file LICENSE"                     NA             
tcltk         "Part of R 3.6.1"                        NA             
testthat      "MIT + file LICENSE"                     NA             
textshaping   "MIT + file LICENSE"                     NA             
tibble        "MIT + file LICENSE"                     NA             
tidyr         "MIT + file LICENSE"                     NA             
tidyselect    "GPL-3"                                  NA             
tidytext      "MIT + file LICENSE"                     NA             
tidyverse     "GPL-3 | file LICENSE"                   NA             
tiff          "GPL-2 | GPL-3"                          NA             
tinytex       "MIT + file LICENSE"                     NA             
tokenizers    "MIT + file LICENSE"                     NA             
tools         "Part of R 3.6.1"                        NA             
twitteR       "Artistic-2.0"                           NA             
tzdb          "MIT + file LICENSE"                     NA             
urlchecker    "GPL-3"                                  NA             
usethis       "MIT + file LICENSE"                     NA             
utf8          "Apache License (== 2.0) | file LICENSE" NA             
utils         "Part of R 3.6.1"                        NA             
uuid          "MIT + file LICENSE"                     NA             
vctrs         "MIT + file LICENSE"                     NA             
viridisLite   "MIT + file LICENSE"                     NA             
vroom         "MIT + file LICENSE"                     NA             
waldo         "MIT + file LICENSE"                     NA             
whisker       "GPL-3"                                  NA             
whoami        "MIT + file LICENSE"                     NA             
withr         "GPL (>= 2)"                             NA             
xfun          "MIT + file LICENSE"                     NA             
XML           "BSD_3_clause + file LICENSE"            NA             
xml2          "GPL (>= 2)"                             NA             
xmlparsedata  "MIT + file LICENSE"                     NA             
xopen         "MIT + file LICENSE"                     NA             
xtable        "GPL (>= 2)"                             NA             
yaml          "BSD_3_clause + file LICENSE"            NA             
zip           "MIT + file LICENSE"                     NA             
              License_restricts_use OS_type MD5sum NeedsCompilation Built  
ambient       NA                    NA      NA     "yes"            "3.6.1"
askpass       NA                    NA      NA     "yes"            "3.6.0"
assertthat    NA                    NA      NA     "no"             "3.6.0"
backports     NA                    NA      NA     "yes"            "3.6.0"
base          NA                    NA      NA     NA               "3.6.1"
base64enc     NA                    NA      NA     "yes"            "3.6.0"
BH            NA                    NA      NA     "no"             "3.6.0"
BiocManager   NA                    NA      NA     "no"             "3.6.1"
bit           NA                    NA      NA     "yes"            "3.6.1"
bit64         NA                    NA      NA     "yes"            "3.6.1"
blob          NA                    NA      NA     "no"             "3.6.1"
bmp           NA                    NA      NA     "no"             "3.6.1"
brew          NA                    NA      NA     "no"             "3.6.1"
brio          NA                    NA      NA     "yes"            "3.6.1"
broom         NA                    NA      NA     "no"             "3.6.0"
bslib         NA                    NA      NA     "no"             "3.6.1"
cachem        NA                    NA      NA     "yes"            "3.6.1"
callr         NA                    NA      NA     "no"             "3.6.0"
cellranger    NA                    NA      NA     "no"             "3.6.0"
class         NA                    NA      NA     "yes"            "3.6.1"
cli           NA                    NA      NA     "no"             "3.6.0"
clipr         NA                    NA      NA     "no"             "3.6.0"
clisymbols    NA                    NA      NA     "no"             "3.6.1"
codetools     NA                    NA      NA     "no"             "3.6.1"
colorspace    NA                    NA      NA     "yes"            "3.6.0"
colourlovers  NA                    NA      NA     "no"             "3.6.1"
commonmark    NA                    NA      NA     "yes"            "3.6.1"
compiler      NA                    NA      NA     NA               "3.6.1"
covr          NA                    NA      NA     "yes"            "3.6.1"
cowplot       NA                    NA      NA     "no"             "3.6.1"
cpp11         NA                    NA      NA     "no"             "3.6.1"
crayon        NA                    NA      NA     "no"             "3.6.1"
credentials   NA                    NA      NA     "no"             "3.6.1"
crosstalk     NA                    NA      NA     "no"             "3.6.1"
curl          NA                    NA      NA     "yes"            "3.6.0"
cyclocomp     NA                    NA      NA     "no"             "3.6.1"
data.table    NA                    NA      NA     "yes"            "3.6.1"
datasets      NA                    NA      NA     NA               "3.6.1"
DBI           NA                    NA      NA     "no"             "3.6.0"
dbplyr        NA                    NA      NA     "no"             "3.6.0"
deldir        NA                    NA      NA     "yes"            "3.6.1"
desc          NA                    NA      NA     "no"             "3.6.1"
dichromat     NA                    NA      NA     NA               "3.6.0"
diffobj       NA                    NA      NA     "yes"            "3.6.1"
digest        NA                    NA      NA     "yes"            "3.6.1"
downlit       NA                    NA      NA     "no"             "3.6.1"
downloader    NA                    NA      NA     "no"             "3.6.1"
dplyr         NA                    NA      NA     "yes"            "3.6.0"
DT            NA                    NA      NA     "no"             "3.6.1"
dtplyr        NA                    NA      NA     "no"             "3.6.1"
e1071         NA                    NA      NA     "yes"            "3.6.1"
ellipsis      NA                    NA      NA     "yes"            "3.6.0"
evaluate      NA                    NA      NA     "no"             "3.6.1"
fansi         NA                    NA      NA     "yes"            "3.6.0"
farver        NA                    NA      NA     "yes"            "3.6.1"
fastmap       NA                    NA      NA     "yes"            "3.6.1"
fontawesome   NA                    NA      NA     "no"             "3.6.1"
forcats       NA                    NA      NA     "no"             "3.6.0"
fs            NA                    NA      NA     "yes"            "3.6.0"
gargle        NA                    NA      NA     "no"             "3.6.1"
generativeart NA                    NA      NA     NA               "3.6.1"
generics      NA                    NA      NA     "no"             "3.6.0"
gert          NA                    NA      NA     "yes"            "3.6.1"
ggplot2       NA                    NA      NA     "no"             "3.6.1"
gh            NA                    NA      NA     "no"             "3.6.1"
gitcreds      NA                    NA      NA     "no"             "3.6.1"
glue          NA                    NA      NA     "yes"            "3.6.0"
gmailr        NA                    NA      NA     "no"             "3.6.1"
googledrive   NA                    NA      NA     "no"             "3.6.1"
googlesheets4 NA                    NA      NA     "no"             "3.6.1"
graphics      NA                    NA      NA     "yes"            "3.6.1"
grDevices     NA                    NA      NA     "yes"            "3.6.1"
grid          NA                    NA      NA     "yes"            "3.6.1"
gtable        NA                    NA      NA     "no"             "3.6.0"
haven         NA                    NA      NA     "yes"            "3.6.0"
highr         NA                    NA      NA     "no"             "3.6.0"
hms           NA                    NA      NA     "no"             "3.6.0"
htmltools     NA                    NA      NA     "yes"            "3.6.1"
htmlwidgets   NA                    NA      NA     "no"             "3.6.1"
httpuv        NA                    NA      NA     "yes"            "3.6.1"
httr          NA                    NA      NA     "no"             "3.6.0"
httr2         NA                    NA      NA     "no"             "3.6.1"
hunspell      NA                    NA      NA     "yes"            "3.6.1"
ids           NA                    NA      NA     "no"             "3.6.1"
igraph        NA                    NA      NA     "yes"            "3.6.1"
ini           NA                    NA      NA     "no"             "3.6.1"
IRdisplay     NA                    NA      NA     "no"             "3.6.0"
IRkernel      NA                    NA      NA     NA               "3.6.0"
isoband       NA                    NA      NA     "yes"            "3.6.1"
janeaustenr   NA                    NA      NA     "no"             "3.6.1"
jpeg          NA                    NA      NA     "yes"            "3.6.1"
jquerylib     NA                    NA      NA     "no"             "3.6.1"
jsonlite      NA                    NA      NA     "yes"            "3.6.1"
kknn          NA                    NA      NA     "yes"            "3.6.1"
knitr         NA                    NA      NA     "no"             "3.6.0"
labeling      NA                    NA      NA     "no"             "3.6.0"
later         NA                    NA      NA     "yes"            "3.6.1"
lattice       NA                    NA      NA     "yes"            "3.6.0"
lazyeval      NA                    NA      NA     "yes"            "3.6.0"
lifecycle     NA                    NA      NA     "no"             "3.6.1"
lintr         NA                    NA      NA     "no"             "3.6.1"
lubridate     NA                    NA      NA     "yes"            "3.6.0"
magrittr      NA                    NA      NA     "no"             "3.6.0"
markdown      NA                    NA      NA     "yes"            "3.6.0"
MASS          NA                    NA      NA     "yes"            "3.6.0"
Matrix        NA                    NA      NA     "yes"            "3.6.0"
memoise       NA                    NA      NA     "no"             "3.6.1"
methods       NA                    NA      NA     "yes"            "3.6.1"
mgcv          NA                    NA      NA     "yes"            "3.6.0"
mime          NA                    NA      NA     "yes"            "3.6.0"
miniUI        NA                    NA      NA     "no"             "3.6.1"
mockery       NA                    NA      NA     "no"             "3.6.1"
modelr        NA                    NA      NA     "no"             "3.6.0"
munsell       NA                    NA      NA     "no"             "3.6.0"
nlme          NA                    NA      NA     "yes"            "3.6.0"
openssl       NA                    NA      NA     "yes"            "3.6.0"
parallel      NA                    NA      NA     "yes"            "3.6.1"
parsedate     NA                    NA      NA     "yes"            "3.6.1"
pbdZMQ        NA                    NA      NA     "yes"            "3.6.1"
pillar        NA                    NA      NA     "no"             "3.6.0"
pingr         NA                    NA      NA     "yes"            "3.6.1"
pkgbuild      NA                    NA      NA     "no"             "3.6.1"
pkgconfig     NA                    NA      NA     "no"             "3.6.0"
pkgload       NA                    NA      NA     "no"             "3.6.1"
plogr         NA                    NA      NA     "no"             "3.6.0"
plyr          NA                    NA      NA     "yes"            "3.6.0"
png           NA                    NA      NA     "yes"            "3.6.1"
polyclip      NA                    NA      NA     "yes"            "3.6.1"
praise        NA                    NA      NA     "no"             "3.6.1"
prettyunits   NA                    NA      NA     "no"             "3.6.0"
processx      NA                    NA      NA     "yes"            "3.6.0"
profvis       NA                    NA      NA     "yes"            "3.6.1"
progress      NA                    NA      NA     "no"             "3.6.0"
promises      NA                    NA      NA     "yes"            "3.6.1"
proxy         NA                    NA      NA     "yes"            "3.6.1"
ps            NA                    NA      NA     "yes"            "3.6.0"
purrr         NA                    NA      NA     "yes"            "3.6.0"
R6            NA                    NA      NA     "no"             "3.6.0"
rappdirs      NA                    NA      NA     "yes"            "3.6.1"
rcmdcheck     NA                    NA      NA     "no"             "3.6.1"
RColorBrewer  NA                    NA      NA     "no"             "3.6.0"
Rcpp          NA                    NA      NA     "yes"            "3.6.1"
RcppArmadillo NA                    NA      NA     "yes"            "3.6.1"
readbitmap    NA                    NA      NA     "no"             "3.6.1"
readr         NA                    NA      NA     "yes"            "3.6.0"
readxl        NA                    NA      NA     "yes"            "3.6.0"
rematch       NA                    NA      NA     "no"             "3.6.0"
rematch2      NA                    NA      NA     "no"             "3.6.1"
remotes       NA                    NA      NA     "no"             "3.6.1"
repr          NA                    NA      NA     "no"             "3.6.0"
reprex        NA                    NA      NA     "no"             "3.6.0"
reshape2      NA                    NA      NA     "yes"            "3.6.0"
rex           NA                    NA      NA     "no"             "3.6.1"
rhub          NA                    NA      NA     "no"             "3.6.1"
rjson         NA                    NA      NA     "yes"            "3.6.1"
rlang         NA                    NA      NA     "yes"            "3.6.1"
rmarkdown     NA                    NA      NA     "no"             "3.6.0"
roxygen2      NA                    NA      NA     "yes"            "3.6.1"
rprojroot     NA                    NA      NA     "no"             "3.6.1"
rstudioapi    NA                    NA      NA     "no"             "3.6.0"
rversions     NA                    NA      NA     "no"             "3.6.1"
rvest         NA                    NA      NA     "no"             "3.6.0"
sass          NA                    NA      NA     "yes"            "3.6.1"
scales        NA                    NA      NA     "yes"            "3.6.0"
selectr       NA                    NA      NA     "no"             "3.6.0"
sessioninfo   NA                    NA      NA     "no"             "3.6.1"
shiny         NA                    NA      NA     "no"             "3.6.1"
SnowballC     NA                    NA      NA     "yes"            "3.6.1"
sourcetools   NA                    NA      NA     "yes"            "3.6.1"
spelling      NA                    NA      NA     "no"             "3.6.1"
splines       NA                    NA      NA     "yes"            "3.6.1"
stats         NA                    NA      NA     "yes"            "3.6.1"
stats4        NA                    NA      NA     NA               "3.6.1"
stringi       NA                    NA      NA     "yes"            "3.6.0"
stringr       NA                    NA      NA     "no"             "3.6.0"
sys           NA                    NA      NA     "yes"            "3.6.0"
systemfonts   NA                    NA      NA     "yes"            "3.6.1"
tcltk         NA                    NA      NA     "yes"            "3.6.1"
testthat      NA                    NA      NA     "yes"            "3.6.1"
textshaping   NA                    NA      NA     "yes"            "3.6.1"
tibble        NA                    NA      NA     "yes"            "3.6.0"
tidyr         NA                    NA      NA     "yes"            "3.6.0"
tidyselect    NA                    NA      NA     "yes"            "3.6.0"
tidytext      NA                    NA      NA     "no"             "3.6.1"
tidyverse     NA                    NA      NA     "no"             "3.6.0"
tiff          NA                    NA      NA     "yes"            "3.6.1"
tinytex       NA                    NA      NA     "no"             "3.6.0"
tokenizers    NA                    NA      NA     "yes"            "3.6.1"
tools         NA                    NA      NA     "yes"            "3.6.1"
twitteR       NA                    NA      NA     "no"             "3.6.1"
tzdb          NA                    NA      NA     "yes"            "3.6.1"
urlchecker    NA                    NA      NA     "no"             "3.6.1"
usethis       NA                    NA      NA     "no"             "3.6.1"
utf8          NA                    NA      NA     "yes"            "3.6.0"
utils         NA                    NA      NA     "yes"            "3.6.1"
uuid          NA                    NA      NA     "yes"            "3.6.0"
vctrs         NA                    NA      NA     "yes"            "3.6.1"
viridisLite   NA                    NA      NA     "no"             "3.6.0"
vroom         NA                    NA      NA     "yes"            "3.6.1"
waldo         NA                    NA      NA     "no"             "3.6.1"
whisker       NA                    NA      NA     "no"             "3.6.0"
whoami        NA                    NA      NA     "no"             "3.6.1"
withr         NA                    NA      NA     "no"             "3.6.0"
xfun          NA                    NA      NA     "no"             "3.6.0"
XML           NA                    NA      NA     "yes"            "3.6.1"
xml2          NA                    NA      NA     "yes"            "3.6.0"
xmlparsedata  NA                    NA      NA     "no"             "3.6.1"
xopen         NA                    NA      NA     "no"             "3.6.1"
xtable        NA                    NA      NA     "no"             "3.6.1"
yaml          NA                    NA      NA     "yes"            "3.6.0"
zip           NA    
"""

from optparse import OptionParser

#!/home/jack/miniconda3/envs/cloned_base/bin/python
from PIL import Image
import time
import os
import sys
from optparse import OptionParser
n=5
# Parse options from the command line
"""
parser = OptionParser()
parser.add_option("-d", "--dst", dest="dst",
                      help="transfer palette palette to ..", metavar="FILE")
parser.add_option("-s", "--src", dest="src", metavar="FILE",
                      help="transfer palette palette from ..")
parser.add_option("-o", "--out", dest="output", metavar="FILE",
                      help="save output to FILE", default="output.png")
(options, args) = parser.parse_args()
if not options.dst or not options.src:
        raise Exception("Missing arguments. See help for more info.")
        
"""        

class Palettize():
    src = "/home/jack/Desktop/dockercommands/test/XXX20220925-075848_480.jpg"
    dst ="0-original-images/nEu4mGcdKdZ2Cwa4KibKwVPjh2riI3hMYfnki5gSDNmyV-1x8axjnQ==.jpg"
    #dst ="otoro-net/0001jav.png"

    aa = Image.open(dst).convert("RGB")
    bb = Image.open(src).convert("RGB")
    xx=aa.resize((720,480), Image.NEAREST)
    yy=bb.resize((720,480), Image.NEAREST)
    xx.save("junk/aa.png")
    yy.save("junk/bb.png")
    src = Image.open('junk/aa.png').convert('RGB')
    dst = Image.open('junk/bb.png').convert('RGB')
    src.save("junk/aa.png")
    dst.save("junk/bb.png")
    n = 5 #number of partitions per channel.
    src_handle = Image.open("junk/bb.png")
    dst_handle = Image.open("junk/aa.png")
    src = src_handle.load()
    dst = dst_handle.load()
    assert src_handle.size[0]*src_handle.size[1] == dst_handle.size[0]*dst_handle.size[1],"images same size"

    def makePixelList(img):
        l = []
        for x in range(img.size[0]):
            for y in range(img.size[1]):
                l.append((x,y))
        return l

    lsrc = makePixelList(src_handle)
    ldst = makePixelList(dst_handle)

    def sortAndDivide(coordlist,pixelimage,channel): #core
        global src,dst,n
        retlist = []
        #sort
        coordlist.sort(key=lambda t: pixelimage[t][channel])
        #divide
        partitionLength = int(len(coordlist)/n)
        if partitionLength <= 0:
            partitionLength = 1
        if channel < 2:
            for i in range(0,len(coordlist),partitionLength):
                retlist += sortAndDivide(coordlist[i:i+partitionLength],pixelimage,channel+1)
        else:
            retlist += coordlist
        

        print(src[lsrc[0]])
        lsrc = sortAndDivide(lsrc,src,0)
        ldst = sortAndDivide(ldst,dst,0)

        for i in range(len(ldst)):
            dst[ldst[i]] = src[lsrc[i]]
            
    def resize640(src):
        Bp=Image.open(src)
        width, height = Bp.size
        w1=int((width-height)/2)
        w2 = int(width-w1)
        h1=height-height
        h2=height
        Cc=Bp.crop((w1,h1,w2,h2))
        result = Cc.resize((720,480), Image.NEAREST)
        print(result)
        return result

 
    #resize640(src).save("newtest/NEwtest2.png")
    dst_handle.save("newtest/NEwtest2.png")
    print ("newtest/NEwtest2.png")
    
img = Palettize()
img

from PIL import Image
im = Image.open("newtest/result.png")
im

!ls newtest

from PIL import Image
im = Image.open("newtest/collage2.jpg")
im.size

!ls newtest

!python collagemaker.py -f 0-original-images -o newtest/collage2.jpg -w 4000 -i 1400 -s    

!python palettize3.py -d "test/XXX20220925-075848_480.jpg" -s  "0-original-images/nEu4mGcdKdZ2Cwa4KibKwVPjh2riI3hMYfnki5gSDNmyV-1x8axjnQ==.jpg" -o "newtest/collage2.jpg"

!python palettize.py -d test/XXX20220925-075848_480.jpg -s 0-original-images/nEu4mGcdKdZ2Cwa4KibKwVPjh2riI3hMYfnki5gSDNmyV-1x8axjnQ==.jpg -o newtest/collage2.jpg

%%writefile palettize3.py
#!/home/jack/anaconda2/bin/python
from PIL import Image
import time
import os
import sys
from optparse import OptionParser
n=5
# Parse options from the command line
parser = OptionParser()
parser.add_option("-d", "--dst", dest="dst",
                      help="transfer palette palette to ..", metavar="FILE")
parser.add_option("-s", "--src", dest="src", metavar="FILE",
                      help="transfer palette palette from ..")
parser.add_option("-o", "--out", dest="output", metavar="FILE",
                      help="save output to FILE", default="output.png")
(options, args) = parser.parse_args()
if not options.dst or not options.src:
        raise Exception("Missing arguments. See help for more info.")
#dst = "/home/jack/Documents/MechanicalChaos3.png"
#src ="outBorgPalette.jpg"

aa = Image.open(options.dst).convert("RGB")
#bb = Image.open("/home/jack/Documents/GG.jpg").convert("RGB")
bb = Image.open(options.src).convert("RGB")
xx=aa.resize((640,640), Image.NEAREST)
yy=bb.resize((640,640), Image.NEAREST)
xx.save("junk/aa.png")
yy.save("junk/bb.png")
src1 = Image.open('junk/aa.png').convert('RGB')
dst1 = Image.open('junk/bb.png').convert('RGB')
src1.save("junk/aa.png")
dst1.save("junk/bb.png")
n = 5 #number of partitions per channel.
src_handle = Image.open("junk/bb.png")
dst_handle = Image.open("junk/aa.png")
src2 = src_handle.load()
dst2 = dst_handle.load()
assert src_handle.size[0]*src_handle.size[1] == dst_handle.size[0]*dst_handle.size[1],"images must be same size"

def makePixelList(img):
    l = []
    for x in range(img.size[0]):
        for y in range(img.size[1]):
            l.append((x,y))
    return l

lsrc = makePixelList(src_handle)
ldst = makePixelList(dst_handle)

def sortAndDivide(coordlist,pixelimage,channel): #core
    global src2,dst2,n
    retlist = []
    #sort
    coordlist.sort(key=lambda t: pixelimage[t][channel])
    #divide
    partitionLength = int(len(coordlist)/n)
    if partitionLength <= 0:
        partitionLength = 1
    if channel < 2:
        for i in range(0,len(coordlist),partitionLength):
            retlist += sortAndDivide(coordlist[i:i+partitionLength],pixelimage,channel+1)
    else:
        retlist += coordlist
    

    print(src[lsrc[0]])
    lsrc = sortAndDivide(lsrc,src2,0)
    ldst = sortAndDivide(ldst,dst2,0)

    for i in range(len(ldst)):
        dst2[ldst[i]] = src2[lsrc[i]]
        
def resize640(src):
    Bp=Image.open(src)
    width, height = Bp.size
    w1=int((width-height)/2)
    w2 = int(width-w1)
    h1=height-height
    h2=height
    Cc=Bp.crop((w1,h1,w2,h2))
    result = Cc.resize((640,640), Image.NEAREST)
    return result


dst_handle.save(options.output)
print (options.output)

%%writefile palettize.py
#!/home/jack/anaconda2/bin/python
from PIL import Image
import time
import os
import sys
from optparse import OptionParser
n=5
# Parse options from the command line
parser = OptionParser()
parser.add_option("-d", "--dst", dest="dst",
                      help="transfer palette palette to ..", metavar="FILE")
parser.add_option("-s", "--src", dest="src", metavar="FILE",
                      help="transfer palette palette from ..")
parser.add_option("-o", "--out", dest="output", metavar="FILE",
                      help="save output to FILE", default="output.png")
(options, args) = parser.parse_args()
if not options.dst or not options.src:
        raise Exception("Missing arguments. See help for more info.")
#dst = "/home/jack/Documents/MechanicalChaos3.png"
#src ="outBorgPalette.jpg"
class Palettize():

    aa = Image.open(options.dst).convert("RGB")
    print(options.dst,":",aa)
    #bb = Image.open("/home/jack/Documents/GG.jpg").convert("RGB")
    bb = Image.open(options.src).convert("RGB")
    print(options.src,":",bb)    
    xx=aa.resize((720,480), Image.NEAREST)
    yy=bb.resize((720,480), Image.NEAREST)
    xx.save("junk/aaxx.png")
    yy.save("junk/bbxx.png")
    src = Image.open('junk/aaxx.png').convert('RGB')
    dst = Image.open('junk/bbxx.png').convert('RGB')
    src.save("junk/aaxx.png")
    dst.save("junk/bbxx.png")
    n = 5 #number of partitions per channel.
    src_handle = Image.open("junk/bbxx.png")
    dst_handle = Image.open("junk/aaxx.png")
    src = src_handle.load()
    dst = dst_handle.load()
    assert src_handle.size[0]*src_handle.size[1] == dst_handle.size[0]*dst_handle.size[1],"images must be same size"

    def makePixelList(img):
        l = []
        for x in range(img.size[0]):
            for y in range(img.size[1]):
                l.append((x,y))
        return l

    lsrc = makePixelList(src_handle)
    print(lsrc)
    ldst = makePixelList(dst_handle)
    print(ldst)
    def sortAndDivide(coordlist,pixelimage,channel): #core
        global src,dst,n
        retlist = []
        #sort
        coordlist.sort(key=lambda t: pixelimage[t][channel])
        #divide
        partitionLength = int(len(coordlist)/n)
        if partitionLength <= 0:
            partitionLength = 1
        if channel < 2:
            for i in range(0,len(coordlist),partitionLength):
                retlist += sortAndDivide(coordlist[i:i+partitionLength],pixelimage,channel+1)
        else:
            retlist += coordlist
        

        print(src[lsrc[0]])
        lsrc = sortAndDivide(lsrc,src,0)
        ldst = sortAndDivide(ldst,dst,0)

        for i in range(len(ldst)):
            dst[ldst[i]] = src[lsrc[i]]
            
    def resize640(src):
        Bp=Image.open(src)
        width, height = Bp.size
        w1=int((width-height)/2)
        w2 = int(width-w1)
        h1=height-height
        h2=height
        Cc=Bp.crop((w1,h1,w2,h2))
        result = Cc.resize((720,480), Image.NEAREST)
        return result

 
    dst_handle.save(options.output)
    print (options.output)

result

!python palettize.py -d test/XXX20220925-075848_480.jpg -s 0-original-images/nEu4mGcdKdZ2Cwa4KibKwVPjh2riI3hMYfnki5gSDNmyV-1x8axjnQ==.jpg -o newtest/collage2.jpg



%%writefile testpal.py 
from PIL import Image
import time
import os
import sys
from optparse import OptionParser
n=5
# Parse options from the command line
parser = OptionParser()
parser.add_option("-d", "--dst", dest="dst",
                      help="transfer palette palette to ..", metavar="FILE")
parser.add_option("-s", "--src", dest="src", metavar="FILE",
                      help="transfer palette palette from ..")
parser.add_option("-o", "--out", dest="output", metavar="FILE",
                      help="save output to FILE", default="output.png")
(options, args) = parser.parse_args()
if not options.dst or not options.src:
        raise Exception("Missing arguments. See help for more info.")
#dst = "/home/jack/Documents/MechanicalChaos3.png"
#src ="outBorgPalette.jpg"

aa = Image.open(options.dst).convert("RGB")
#bb = Image.open("/home/jack/Documents/GG.jpg").convert("RGB")
bb = Image.open(options.src).convert("RGB")
xx=aa.resize((640,640), Image.NEAREST)
yy=bb.resize((640,640), Image.NEAREST)
xx.save("junk/Pala.png")
yy.save("junk/Palb.png")
src = Image.open('junk/Pala.png').convert('RGB')
dst = Image.open('junk/Palb.png').convert('RGB')
src.save("junk/aa.png")
dst.save("junk/bb.png")
n = 5 #number of partitions per channel.
src_handle = Image.open("junk/bb.png")
dst_handle = Image.open("junk/aa.png")
src = src_handle.load()
dst = dst_handle.load()
assert src_handle.size[0]*src_handle.size[1] == dst_handle.size[0]*dst_handle.size[1],"images must be same size"

def makePixelList(img):
    l = []
    for x in range(img.size[0]):
        for y in range(img.size[1]):
            l.append((x,y))
    return l

lsrc = makePixelList(src_handle)
ldst = makePixelList(dst_handle)
#print (ldst)
ldst.save("junk/testpal.jpg")

!python testpal.py -d test/XXX20220925-075848_480.jpg -s 0-original-images/nEu4mGcdKdZ2Cwa4KibKwVPjh2riI3hMYfnki5gSDNmyV-1x8axjnQ==.jpg -o newtest/collage2.jpg



-

### import os
import sys
from PIL import Image
import shutil
import time
import random
filename0= '/home/jack/Desktop/3DFRACT/Mandelbulb3Dv199/MutaGen5B93367881C0506~.png'
filename1='/home/jack/Desktop/3DFRACT/Mandelbulb3Dv199/sea3.jpg'
shutil.copy2(filename0, 'instagram/')
shutil.copy2(filename1, 'instagram/')
aa = Image.open(filename0).convert("RGB")
bb = Image.open(filename1).convert("RGB")
xx=aa.resize((640,640), Image.NEAREST)
yy=bb.resize((640,640), Image.NEAREST)
xx.save("junk/aa.png")
yy.save("junk/bb.png")
src = Image.open('junk/aa.png').convert('RGB')
dst = Image.open('junk/bb.png').convert('RGB')
src.save("junk/aa.png")
dst.save("junk/bb.png")
n = 5 #number of partitions per channel.
src_handle = Image.open("junk/bb.png")
dst_handle = Image.open("junk/aa.png")
src = src_handle.load()
dst = dst_handle.load()
assert src_handle.size[0]*src_handle.size[1] == dst_handle.size[0]*dst_handle.size[1],"images must be same size"
def makePixelList(img):
    l = []
    for x in range(img.size[0]):
        for y in range(img.size[1]):
            l.append((x,y))
    return l
lsrc = makePixelList(src_handle)
ldst = makePixelList(dst_handle)
def sortAndDivide(coordlist,pixelimage,channel): #core
    global src,dst,n
    retlist = []
    #sort
    coordlist.sort(key=lambda t: pixelimage[t][channel])
    #divide
    partitionLength = int(len(coordlist)/n)
    if partitionLength <= 0:
        partitionLength = 1
    if channel < 2:
        for i in range(0,len(coordlist),partitionLength):
            retlist += sortAndDivide(coordlist[i:i+partitionLength],pixelimage,channel+1)
    else:
        retlist += coordlist
    return retlist

print(src[lsrc[0]])
lsrc = sortAndDivide(lsrc,src,0)
ldst = sortAndDivide(ldst,dst,0)
for i in range(len(ldst)):
    dst[ldst[i]] = src[lsrc[i]]
#filename = time.strftime("junk/post-color2560.png")
filename = time.strftime("/home/jack/Desktop/3DFRACT/Mandelbulb3Dv199/MutaGen0005.jpg")
dst_handle.save(filename)
shutil.copy2(filename, "instagram/")
print filename

!showme home/jack/Desktop/text-stuff/junk/post-color5.png

%reset -f

!ls

!locate Immanip

from Immanip import SwapPalettes
filename0 = '/home/jack/Desktop/text_stuff/instagram/PalletteTemp.png'
filename1 = '/home/jack/Desktop/text_stuff/instagram/sea1.jpg'
filename = 'pallet_test.jpg'
SwapPalettes.swappalettes(filename0,filename1,filename)

!rm /home/jack/anaconda2/lib/python2.7/site-packages/Immanip/SwapPalettes.pyc

%%writefile /home/jack/anaconda2/lib/python2.7/site-packages/Immanip/SwapPalettes.py
import os, errno
import sys
from PIL import Image
import shutil
import time
import random

def swappalettes(filename0,filename1,filename):
    try:
        os.makedirs('copies')
    except OSError as e:
        if e.errno != errno.EEXIST:
            raise    
    try:
        os.makedirs('tempS')
    except OSError as e:
        if e.errno != errno.EEXIST:
            raise    
    
    shutil.copy2(filename0, 'copies/')
    shutil.copy2(filename1, 'copies/')
    aa = Image.open(filename0).convert("RGB")
    bb = Image.open(filename1).convert("RGB")
    xx=aa.resize((640,640), Image.NEAREST)
    yy=bb.resize((640,640), Image.NEAREST)
    xx.save("tempS/aa.png")
    yy.save("tempS/bb.png")
    src = Image.open('tempS/aa.png').convert('RGB')
    dst = Image.open('tempS/bb.png').convert('RGB')
    src.save("tempS/aa.png")
    dst.save("tempS/bb.png")
    n = 5 #number of partitions per channel.
    src_handle = Image.open("tempS/bb.png")
    dst_handle = Image.open("tempS/aa.png")
    src = src_handle.load()
    dst = dst_handle.load()
    assert src_handle.size[0]*src_handle.size[1] == dst_handle.size[0]*dst_handle.size[1],"images must be same size"
    def makePixelList(img):
        l = []
        for x in range(img.size[0]):
            for y in range(img.size[1]):
                l.append((x,y))
        return l
    lsrc = makePixelList(src_handle)
    ldst = makePixelList(dst_handle)
    def sortAndDivide(coordlist,pixelimage,channel): #core
        global src,dst,n
        retlist = []
        #sort
        coordlist.sort(key=lambda t: pixelimage[t][channel])
        #divide
        partitionLength = int(len(coordlist)/5)
        if partitionLength <= 0:
            partitionLength = 1
        if channel < 2:
            for i in range(0,len(coordlist),partitionLength):
                retlist += sortAndDivide(coordlist[i:i+partitionLength],pixelimage,channel+1)
        else:
            retlist += coordlist
        return retlist

    print(src[lsrc[0]])
    lsrc = sortAndDivide(lsrc,src,0)
    ldst = sortAndDivide(ldst,dst,0)
    for i in range(len(ldst)):
        dst[ldst[i]] = src[lsrc[i]]
    dst_handle.save(filename)
    shutil.copy2(filename, "copies/")
    print filename

%%writefile /home/jack/anaconda2/lib/python2.7/site-packages/Immanip/paletts.py
import os
import sys
from PIL import Image
import shutil
import time
import random
filename0= sys.argv[1]
filename1= sys.argv[2]
filename= sys.argv[3]
shutil.copy2(filename0, 'instagram/')
shutil.copy2(filename1, 'instagram/')
aa = Image.open(filename0).convert("RGB")
bb = Image.open(filename1).convert("RGB")
xx=aa.resize((640,640), Image.NEAREST)
yy=bb.resize((640,640), Image.NEAREST)
xx.save("junk/aa.png")
yy.save("junk/bb.png")
src = Image.open('junk/aa.png').convert('RGB')
dst = Image.open('junk/bb.png').convert('RGB')
src.save("junk/aa.png")
dst.save("junk/bb.png")
n = 5 #number of partitions per channel.
src_handle = Image.open("junk/bb.png")
dst_handle = Image.open("junk/aa.png")
src = src_handle.load()
dst = dst_handle.load()
assert src_handle.size[0]*src_handle.size[1] == dst_handle.size[0]*dst_handle.size[1],"images must be same size"
def makePixelList(img):
    l = []
    for x in range(img.size[0]):
        for y in range(img.size[1]):
            l.append((x,y))
    return l
lsrc = makePixelList(src_handle)
ldst = makePixelList(dst_handle)
def sortAndDivide(coordlist,pixelimage,channel): #core
    global src,dst,n
    retlist = []
    #sort
    coordlist.sort(key=lambda t: pixelimage[t][channel])
    #divide
    partitionLength = int(len(coordlist)/n)
    if partitionLength <= 0:
        partitionLength = 1
    if channel < 2:
        for i in range(0,len(coordlist),partitionLength):
            retlist += sortAndDivide(coordlist[i:i+partitionLength],pixelimage,channel+1)
    else:
        retlist += coordlist
    return retlist

print(src[lsrc[0]])
lsrc = sortAndDivide(lsrc,src,0)
ldst = sortAndDivide(ldst,dst,0)
for i in range(len(ldst)):
    dst[ldst[i]] = src[lsrc[i]]
dst_handle.save(filename)
shutil.copy2(filename, "instagram/")
print filename

!python paletts.py junk/aa.png instagram/bb.png junk/skyPallette.png

from PIL import Image
im = Image.open("junk/Pallette.png")
im

%%writefile resize640.py
#!/home/jack/anaconda2/bin
from PIL import Image
import sys
sys.argv
def resize640(image, output):
    Bp=Image.open(image)
    width, height = Bp.size
    w1=int((width-height)/2)
    w2 = int(width-w1)
    h1=height-height
    h2=height
    Cc=Bp.crop((w1,h1,w2,h2))
    result = Cc.resize((640,640), Image.NEAREST)
    result.save(output)
if __name__ == '__main__':
    image = sys.arg[1:]
    output = sys.arg[2:]
    resize640(image, output)        

sys.argv

if __name__ == '__main__':
    dst = sys.arg[1:]
    src = sys.arg[2:]
    resize640(image, output) 

from PIL import Image, ImageOps
im = Image.open("junk/aa.png").convert('LA').convert('RGB')
im.save('junk/aaout.jpg')
im = Image.open("junk/aaout.jpg").convert('L')
#im.load() # make sure it's loaded into memory
assert im.mode == "L"
# create a lookup table (r, g, b, r, g, b, r, g, b, ...)
lut = []
for i in range(256):
    lut.extend([255-i, i/2, i])
im.putpalette(lut)
assert im.mode == "P" # now has a palette
im.save("junk/out.gif")
im

original_path = 'junk/posterize_gogh.jpg'
original = Image.open(original_path)
original

from PIL import Image, ImageFilter
import os
import cv2
import random
import time
path = r"AUGposT/"
#path = r"crawler4/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
    ])
filename0=(path+base_image)
im = Image.open(filename0)
imP = im.convert('RGB').convert('P', palette=Image.ADAPTIVE, colors=6)
imP.putpalette([
     243,164,10,
     157,17,17,
     66,99,166,
     70,155,53,
     0,0,0,
     70,70,140,
     ])


im2 = Image.open(filename0)
mask0 = im2.convert('L') # need a greyscale image to create a mask
mask = Image.eval(mask0, lambda a: 255 if a == 0 else 0)
mask = mask.filter(ImageFilter.MinFilter(3))
imP.paste(2, mask) # Paste the color of index 2 using image2 as a mask
filename = time.strftime("junk/PILStuff%Y%m%d%H%M%S.png")
imP.save(filename)

print filename
imP

from PIL import Image, ImageFilter
import os
import cv2
import random
import time
path = r"AUGposT/"
#path = r"crawler4/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
    ])
filename0=(path+base_image)
im = Image.open(filename0)
imP = im.convert('RGB').convert('P', palette=Image.ADAPTIVE, colors=6)
#imP.putpalette([
#     243,164,10,
#     157,17,17,
#     66,99,166,
#     70,155,53,
#     0,0,0,
#     70,70,140,
#     ])

list1 =  """ [0,0,0, 255,0,0, 0,255,0, 0,0,255, 125,125,125, 255,255,255,]
"""
imP.putpalette('%s' % (list1))




im2 = Image.open(filename0)
mask0 = im2.convert('L') # need a greyscale image to create a mask
mask = Image.eval(mask0, lambda a: 255 if a == 0 else 0)
mask = mask.filter(ImageFilter.MinFilter(3))
imP.paste(2, mask) # Paste the color of index 2 using image2 as a mask
filename = time.strftime("junk/PILStuff%Y%m%d%H%M%S.png")
imP.save(filename)

print filename
imP

# appears to be NON RGB
from PIL import Image, ImageMath
im1 = Image.open("junk/PILStuff20170826124220.png").convert("L")
im2 = Image.open("junk/YTUG.png").convert("L")
#out = ImageMath.eval("convert(min(a, b), 'RGB')", a=im1, b=im2)
out = ImageMath.eval("convert(min(a, b), 'L')", a=im1, b=im2)
out.save("junk/newResult2.jpg")
out

import numpy as np
from PIL import Image

def palette(img):
    """
    Return palette in descending order of frequency
    """
    arr = np.asarray(img)
    palette, index = np.unique(asvoid(arr).ravel(), return_inverse=True)
    palette = palette.view(arr.dtype).reshape(-1, arr.shape[-1])
    count = np.bincount(index)
    order = np.argsort(count)
    return palette[order[::-1]]

def asvoid(arr):
    """View the array as dtype np.void (bytes)
    This collapses ND-arrays to 1D-arrays, so you can perform 1D operations on them.
    http://stackoverflow.com/a/16216866/190597 (Jaime)
    http://stackoverflow.com/a/16840350/190597 (Jaime)
    Warning:
    >>> asvoid([-0.]) == asvoid([0.])
    array([False], dtype=bool)
    """
    arr = np.ascontiguousarray(arr)
    return arr.view(np.dtype((np.void, arr.dtype.itemsize * arr.shape[-1])))


img = Image.open('junk/PILStuff20170826142340.png', 'r').convert('RGB')
print(palette(img))

from PIL import Image
import time
def makePixelList(img):
    l = []
    for x in range(img.size[0]):
        for y in range(img.size[1]):
            l.append((x,y))
    return l

lsrc = makePixelList(src_handle)
ldst = makePixelList(dst_handle)

def sortAndDivide(coordlist,pixelimage,channel): #core
    global src,dst,n
    retlist = []
    #sort
    coordlist.sort(key=lambda t: pixelimage[t][channel])
    #divide
    partitionLength = int(len(coordlist)/n)
    if partitionLength <= 0:
        partitionLength = 1
    if channel < 2:
        for i in range(0,len(coordlist),partitionLength):
            retlist += sortAndDivide(coordlist[i:i+partitionLength],pixelimage,channel+1)
    else:
        retlist += coordlist
    return retlist

print(src[lsrc[0]])

lsrc = sortAndDivide(lsrc,src,0)
ldst = sortAndDivide(ldst,dst,0)

for i in range(len(ldst)):
    dst[ldst[i]] = src[lsrc[i]]

#dst_handle.save("exchange"+str(src_index)+str(dst_index)+".png")
filename = time.strftime("junk/exchange%Y%m%d%H%M%S.png")
dst_handle.save(filename)
print filename


from colorthief import ColorThief
import string
import re
color_thief = ColorThief('junk/exchange20170826173902.png')
# build a color palette
palette = color_thief.get_palette(color_count=6)
name = " ".join(str(x) for x in palette)
table = string.maketrans( '', '' )
print name.translate(table,"(){}<>")

from PIL import Image, ImageFilter
import os
import cv2
import random
import time
path = r"AUGposT/"
#path = r"crawler4/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
    ])
filename0=(path+base_image)
im = Image.open(filename0)
imP = im.convert('RGB').convert('P', palette=Image.ADAPTIVE, colors=6)

list1 =  """ [0,0,0, 255,0,0, 0,255,0, 0,0,255, 125,125,125, 255,255,255,]
"""
imP.putpalette('%s' % (list1))


im2 = Image.open(filename0)
mask0 = im2.convert('L') # need a greyscale image to create a mask
mask = Image.eval(mask0, lambda a: 255 if a == 0 else 0)
mask = mask.filter(ImageFilter.MinFilter(3))
imP.paste(2, mask) # Paste the color of index 2 using image2 as a mask
filename = time.strftime("junk/PILStuff%Y%m%d%H%M%S.png")
imP.save(filename)

print filename
imP

from PIL import Image, ImageFilter
import os
import cv2
import random
import time
"""
path = r"AUGposT/"
#path = r"crawler4/"
base_image = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
    ])
filename0=(path+base_image)
im = Image.open(filename0)
"""
im= Image.open('crawler1/0032myth.jpg')
imP = im.convert('RGB').convert('P', palette=Image.ADAPTIVE, colors=6)

list1 =  """ [244,164,12,68,87,154,68,156,52,156,20,20,4,4,4,204,168,84,]
"""
imP.putpalette('%s' % (list1))

#name = 'marcog'
#number = 42
#print '%s %d' % (name, number)

#imP.putpalette(
#[244,164,12,68,87,154,68,156,52,156,20,20,4,4,4,204,168,84,]   
#)
# print "pasting at: (%s, %s)" % (paste_left, paste_top)
im2 = Image.open(filename0)
mask0 = im2.convert('L') # need a greyscale image to create a mask
mask = Image.eval(mask0, lambda a: 255 if a == 0 else 0)
mask = mask.filter(ImageFilter.MinFilter(3))
imP.paste(2, mask) # Paste the color of index 2 using image2 as a mask
filename = time.strftime("junk/PILStuff%Y%m%d%H%M%S.png")
imP.save(filename)

print filename
imP

from colorthief import ColorThief
import string
import re
color_thief = ColorThief('junk/PILStuff20170826124220.png')
# build a color palette
palette = color_thief.get_palette(color_count=6)
name = " ".join(str(x) for x in palette)
table = string.maketrans( '', '' )
newT = name.translate(table,",(){}<>")
palette = newT.replace(" ", ",")
print palette

# Works Fine
import PIL
from PIL import Image
file="junk/newResult2.jpg"
im = Image.open(file)
im_web = im.convert("P")
im_256 = im.convert("P", palette=PIL.Image.ADAPTIVE, colors=256)
im_16 = im.convert("P", palette=PIL.Image.ADAPTIVE, colors=16)
im_16

# ImageOps.
def _border(border):

def _color(color, mode):

def _lut(image, lut):

def autocontrast(image, cutoff=0, ignore=None):

def colorize(image, black, white):

def crop(image, border=0):

def deform(image, deformer, resample=Image.BILINEAR):

def equalize(image, mask=None):

def expand(image, border=0, fill=0):

def fit(image, size, method=Image.NEAREST, bleed=0.0, centering=(0.5, 0.5)):

def flip(image):

def grayscale(image):

def invert(image):

def mirror(image):

def posterize(image, bits):

def solarize(image, threshold=128):

def gaussian_blur(im, radius=None):

def unsharp_mask(im, radius=None, percent=None, threshold=None):


from PIL import Image,ImageOps
im = Image.open("crawler1/0010van_gogh.jpg")
solar=ImageOps.solarize(im, threshold=12)
solar

from PIL import Image
im = Image.open("crawler1/0010van_gogh.jpg").convert('LA').convert('RGB')
im.load() # make sure it's loaded into memory
im

from PIL import ImagePalette

ImagePalette(object)

%%writefile test002.py
#!/usr/bin/python
__author__ = 'Jack Northrup'
import sys, getopt
from PIL import Image 
image=''
output=''
 
###############################
# o == option
# a == argument passed to the o
###############################
# Cache an error with try..except 
# Note: options is the string of option letters that the script wants to recognize, with 
# options that require an argument followed by a colon (':') i.e. -i fileName
#
try:
    myopts, args = getopt.getopt(sys.argv[1:],"i:o:")
except getopt.GetoptError as e:
    print (str(e))
    print("Usage: %s -i input -o output" % sys.argv[0])
    sys.exit(2)
 
for o, a in myopts:
    if o == '-i':
        image=a
    elif o == '-o':
        output=a
 
# Display input and output file name passed as the args
print ("Input file : %s and output file: %s" % (image,output) )

!ls instagram

from PIL import Image
import scipy
import scipy.cluster
from pprint import pprint
image = Image.open('instagram/640fish.jpg')
NUM_CLUSTERS = 5

# Convert image into array of values for each point.
ar = scipy.misc.fromimage(image)
shape = ar.shape

# Reshape array of values to merge color bands.
if len(shape) > 2:
       ar = ar.reshape(scipy.product(shape[:2]), shape[2])

# Get NUM_CLUSTERS worth of centroids.
codes, _ = scipy.cluster.vq.kmeans(ar, NUM_CLUSTERS)

# Pare centroids, removing blacks and whites and shades of really dark and really light.
original_codes = codes
for low, hi in [(60, 200), (35, 230), (10, 250)]:
        codes = scipy.array([code for code in codes 
        if not ((code[0] < low and code[1] < low and code[2] < low) or
              (code[0] > hi and code[1] > hi and code[2] > hi))])
        if not len(codes): codes = original_codes
        else: break

# Assign codes (vector quantization). Each vector is compared to the centroids
# and assigned the nearest one.
vecs, _ = scipy.cluster.vq.vq(ar, codes)

# Count occurences of each clustered vector.
counts, bins = scipy.histogram(vecs, len(codes))

# Show colors for each code in its hex value.
colors = [''.join(chr(c) for c in code).encode('hex') for code in codes]
total = scipy.sum(counts)
color_dist = dict(zip(colors, [count/float(total) for count in counts]))
pprint(color_dist)

# Find the most frequent color, based on the counts.
index_max = scipy.argmax(counts)
peak = codes[index_max]
color = ''.join(chr(c) for c in peak).encode('hex')

import struct
from PIL import Image
import scipy
import scipy.misc
import scipy.cluster

NUM_CLUSTERS = 5

print 'reading image'
im = Image.open('instagram/640fish.jpg')
im = im.resize((640, 640))      # optional, to reduce time
ar = scipy.misc.fromimage(im)
shape = ar.shape
ar = ar.reshape(scipy.product(shape[:2]), shape[2])

#print 'finding clusters'
codes, dist = scipy.cluster.vq.kmeans(ar, NUM_CLUSTERS)
#print 'cluster centres:\n', codes

#vecs, dist = scipy.cluster.vq.vq(ar, codes)         # assign codes
#counts, bins = scipy.histogram(vecs, len(codes))    # count occurrences

#index_max = scipy.argmax(counts)                    # find most frequent
#peak = codes[index_max]
#colour = ''.join(chr(c) for c in peak).encode('hex')
#print 'most frequent is %s (#%s)' % (peak, colour)

https://hhsprings.bitbucket.io/docs/programming/examples/python/PIL/Image__class_Image.html

import os
import requests
from StringIO import StringIO
import lxml.html as html
from PIL import Image
import scipy
import scipy.misc
import scipy.cluster
import numpy as np

NUM_CLUSTERS = 5

def detect_color(imgurl):
    im = Image.open(imgurl)
    im = im.resize((250, 250))      # optional, to reduce time
    ar = scipy.misc.fromimage(im)
    shape = ar.shape
    ar = ar.reshape(scipy.product(shape[:2]), shape[2])
    ar = ar.astype(float)

    codes, dist = scipy.cluster.vq.kmeans(ar, NUM_CLUSTERS)

    vecs, dist = scipy.cluster.vq.vq(ar, codes)         # assign codes
    counts, bins = scipy.histogram(vecs, len(codes))    # count occurrences

    index_max = np.argmax(counts)                    # find most frequent
    peak = codes[index_max]
    colour = ''.join(chr(int(round(c))) for c in peak).encode('hex')
    if colour == "ffffff":
        value_second_max = np.sort(counts)[-2]
        index_second_max = np.where(counts==value_second_max)
        index_max = index_second_max[0][0]
        peak = codes[index_max]
        colour = ''.join(chr(int(round(c))) for c in peak).encode('hex')
    return colour
detect_color('instagram/640fish.jpg')

def hex2rgb(hexcode):
    rgb = tuple(map(ord,hexcode[1:].decode('hex')))
    return rgb
hexcode = raw_input("Enter a hex value: ")
rgbvalue = hex2rgb(hexcode)
print(rgbvalue)

# from pure python list data
from PIL import Image
img = Image.new("RGB", (640, 640),(29, 117, 100))  # multiple bands
img.save("hex.jpg")

from PIL import Image
im = Image.open("hex.jpg")
im

def rgb2hex(r,g,b):
    hex = "#{:02x}{:02x}{:02x}".format(r,g,b)
    return hex
def hex2rgb(hexcode):
    rgb = tuple(map(ord,hexcode[1:].decode('hex')))
    return rgb

r = int(input("Enter r: "))
g = int(input("Enter g: "))
b = int(input("Enter b: "))
rgb = (r,g,b)
hexvalue = rgb2hex(rgb[0],rgb[1],rgb[2])
print(hexvalue)

hexcode = raw_input("Enter a hex value: ")
rgbvalue = hex2rgb(hexcode)
print(rgbvalue)

import os
import os.path
import tempfile
import time

# the variable this_notebook is injectected in a cell above by the test framework.
this_notebook = 'A'
other_notebook = 'B'
directory = os.environ['NBEXECUTE_TEST_PARALLEL_TMPDIR']
with open(os.path.join(directory, 'test_file_{}.txt'.format(this_notebook)), 'w') as f:
    f.write('Hello from {}'.format(this_notebook))

start = time.time()
timeout = 5
end = start + timeout
target_file = os.path.join(directory, 'test_file_{}.txt'.format(other_notebook))
while time.time() < end:
    time.sleep(0.1)
    if os.path.exists(target_file):
        with open(target_file, 'r') as f:
            text = f.read()
        if text == 'Hello from {}'.format(other_notebook):
            break
else:
    assert False, "Timed out didn't get a message from {}".format(other_notebook)

import os
import os.path
import tempfile
import time

# the variable this_notebook is injectected in a cell above by the test framework.
this_notebook = 'A'
other_notebook = 'B'
directory = os.environ['NBEXECUTE_TEST_PARALLEL_TMPDIR']
with open(os.path.join(directory, 'test_file_{}.txt'.format(this_notebook)), 'w') as f:
    f.write('Hello from {}'.format(this_notebook))

start = time.time()
timeout = 5
end = start + timeout
target_file = os.path.join(directory, 'test_file_{}.txt'.format(other_notebook))
while time.time() < end:
    time.sleep(0.1)
    if os.path.exists(target_file):
        with open(target_file, 'r') as f:
            text = f.read()
        if text == 'Hello from {}'.format(other_notebook):
            break
else:
    assert False, "Timed out didn't get a message from {}".format(other_notebook)

import os
import os.path
import tempfile
import time

# the variable this_notebook is injectected in a cell above by the test framework.
this_notebook = 'B'
other_notebook = 'A'
directory = os.environ['NBEXECUTE_TEST_PARALLEL_TMPDIR']
with open(os.path.join(directory, 'test_file_{}.txt'.format(this_notebook)), 'w') as f:
    f.write('Hello from {}'.format(this_notebook))

start = time.time()
timeout = 5
end = start + timeout
target_file = os.path.join(directory, 'test_file_{}.txt'.format(other_notebook))
while time.time() < end:
    time.sleep(0.1)
    if os.path.exists(target_file):
        with open(target_file, 'r') as f:
            text = f.read()
        if text == 'Hello from {}'.format(other_notebook):
            break
else:
    assert False, "Timed out didn't get a message from {}".format(other_notebook)

import os
import os.path
import tempfile
import time

# the variable this_notebook is injectected in a cell above by the test framework.
this_notebook = 'B'
other_notebook = 'A'
directory = os.environ['NBEXECUTE_TEST_PARALLEL_TMPDIR']
with open(os.path.join(directory, 'test_file_{}.txt'.format(this_notebook)), 'w') as f:
    f.write('Hello from {}'.format(this_notebook))

start = time.time()
timeout = 5
end = start + timeout
target_file = os.path.join(directory, 'test_file_{}.txt'.format(other_notebook))
while time.time() < end:
    time.sleep(0.1)
    if os.path.exists(target_file):
        with open(target_file, 'r') as f:
            text = f.read()
        if text == 'Hello from {}'.format(other_notebook):
            break
else:
    assert False, "Timed out didn't get a message from {}".format(other_notebook)

from parrot import Parrot
import torch
import warnings
warnings.filterwarnings("ignore")

def random_state(seed):
  torch.manual_seed(seed)
  if torch.cuda.is_available():
    torch.cuda.manual_seed_all(seed)

random_state(1234)

parrot = Parrot(model_tag="prithivida/parrot_paraphraser_on_T5", use_gpu=False)

phrases = ["""To be or not to be, that is the question, Whether it is nobler in the mind to suffer
The slings and arrows of outrageous fortune."""]

for phrase in phrases:
  print("-"*100)
  print("Input_phrase: ", phrase)
  print("-"*100)
  para_phrases = parrot.augment(input_phrase=phrase)
  for para_phrase in para_phrases:
   print(para_phrase)



import sqlite3
import feedparser
import time
import sqlite3
Dbase = 'bigfeedfts.db'
conn = sqlite3.connect(Dbase)
c = conn.cursor()
#c.execute('''
#CREATE TABLE IF NOT EXISTS bbctech
#(head text, feed text)
#''');
c.execute("""
CREATE VIRTUAL TABLE IF NOT EXISTS bbctech 
USING FTS3(head, feed);
""")
count=0
while count<35:
    count=count+1
    if count==1:feed='http://feeds.bbci.co.uk/news/technology/rss.xml'
    if count==2:feed='http://www.cbn.com/cbnnews/us/feed/'
    if count==3:feed='http://feeds.reuters.com/Reuters/worldNews'
    if count==4:feed='http://feeds.bbci.co.uk/news/technology/rss.xml'
    if count==5:feed='http://news.sky.com/info/rss'
    if count==6:feed='http://www.cbn.com/cbnnews/us/feed/'
    if count==7:feed='http://feeds.reuters.com/Reuters/domesticNews'
    if count==8:feed='http://news.yahoo.com/rss/'
    if count==9:feed='http://www.techradar.com/rss'
    if count==10:feed='https://www.wired.com/feed/rss'
    if count==11:feed='http://www.zdnet.com/zdnet.opml'
    if count==12:feed='http://www.computerweekly.com/rss/All-Computer-Weekly-content.xml'
    if count==13:feed='http://gadgets.ndtv.com/rss/feeds'
    if count==14:feed='http://feeds.arstechnica.com/arstechnica/index'        
    if count==15:feed='https://www.techworld.com/news/rss'
    if count==16:feed='https://www.infoworld.com/index.rss'        
    if count==18:feed='https://www.pcworld.com/index.rss'   
    if count==19:feed='http://tech.economictimes.indiatimes.com/rss/technology'
    if count==20:feed='https://www.technologyreview.com/stories.rss'        
    if count==21:feed='http://tech.economictimes.indiatimes.com/rss/topstories'
    if count==22:feed='http://feeds.feedburner.com/digit/latest-from-digit'
    if count==23:feed='http://feeds.techsoup.org/TechSoup_Articles'
    if count==24:feed='http://rss.sciam.com/ScientificAmerican-News?format=xml'
    if count==25:feed='https://www.sciencedaily.com/rss/all.xml'    
    if count==26:feed='http://feeds.nanowerk.com/nanowerk/agWB'
    if count==27:feed='http://feeds.nanowerk.com/NanowerkNanotechnologySpotlight'
    if count==28:feed='http://feeds.nanowerk.com/feedburner/NanowerkRoboticsNews'
    if count==29:feed='http://feeds.nanowerk.com/NanowerkSpaceExplorationNews'
    if count==30:feed='http://www.npr.org/rss/rss.php?id=1019'
    if count==31:feed='http://feeds.nature.com/news/rss/news_s16?format=xml'
    if count==32:feed='http://feeds.latimes.com/latimes/technology?format=xml'
    if count==33:feed='http://feeds.feedburner.com/BadAstronomyBlog?format=xml'
    if count==34:feed='http://feeds.newscientist.com/physics-math'
    if count==35:feed='http://rss.slashdot.org/Slashdot/slashdotMain'
    d = feedparser.parse(feed)
    for post in d.entries:
        aa = `d['feed']['title'],d['feed']['link'],d.entries[0]['link']`
        bb = `post.title + ": " + post.link + ""`
        conn = sqlite3.connect(Dbase)
        c = conn.cursor()
        c.execute("INSERT INTO bbctech VALUES (?,?)", (aa,bb))
        conn.commit()
        conn.close()
        
        
conn = sqlite3.connect(Dbase)
c = conn.cursor()# Never
count=0
for row in c.execute('SELECT * FROM bbctech ORDER BY rowid DESC'):
    row=str(row)
    row=row.replace("(u","");row=row.replace('", u"u',"\n")
    row=row.replace("/', u'","   ");row=row.replace('"',"")
    row=row.replace("', u'","  ");row=row.replace("')","  ")
    row=row.replace("'","");row=row.replace("  , uu","\n")
    count=count+1
    print"\nNumber :",count," -----\n",(row)

import sqlite3
import sys
conn = sqlite3.connect('bigfeedfts.db')
c = conn.cursor()# Never 
count=0
req = 5000
for row in c.execute('SELECT * FROM bbctech'):    
    count=count+1
    row=str(row)
    row=row.replace("(u","");row=row.replace('", u"u',"\n")
    row=row.replace("/', u'","   ");row=row.replace('"',"")
    row=row.replace("', u'","  ");row=row.replace("')","  ")
    row=row.replace("'","");row=row.replace("  , uu","\n")
    print"\nNumber :",count," -----\n",(row)    
    if count > req:
        conn.close()
        sys.exit()
        

import sqlite3
import sys
conn = sqlite3.connect('collection.db')
c = conn.cursor()
count=0
# limits query to 1000
req=1000
search = raw_input("Search : ")

for row in c.execute('SELECT rowid,* FROM tweets WHERE text MATCH ?', (search,)):    
    count=count+1
    
    print count,"-",(row)[1]," -- by",(row)[2],"\n"
    if count > req:
        conn.close()
        sys.exit()

import sqlite3
import sys
conn = sqlite3.connect('bigfeedfts.db')
c = conn.cursor()# Never 
count=0
req = 5000
search = raw_input("Search : ")

for row in c.execute('SELECT rowid,* FROM bbctech WHERE feed MATCH ?', (search,)):    
#for row in c.execute('SELECT * FROM bbctech WHERE feed LIKE "%phone%"'):    
    count=count+1
    row=str(row)
    row=row.replace("(u","");row=row.replace('", u"u',"\n")
    row=row.replace("/', u'","   ");row=row.replace('"',"")
    row=row.replace("', u'","  ");row=row.replace("')","  ")
    row=row.replace("'","");row=row.replace("  , uu","\n")
    print"\nNumber :",count," -----\n",(row)    
    if count > req:
        conn.close()
        sys.exit()
        

import sqlite3
import sys
conn = sqlite3.connect('bigfeedfts.db')
c = conn.cursor()# Never 
count=0
req = 5000
search = raw_input("Get by ROWID : ")

for row in c.execute('SELECT rowid,* FROM bbctech WHERE rowid=?', (search,)):    
#for row in c.execute('SELECT * FROM bbctech WHERE feed LIKE "%phone%"'):    
    count=count+1
    row=str(row)
    row=row.replace("(u","");row=row.replace('", u"u',"\n")
    row=row.replace("/', u'","   ");row=row.replace('"',"")
    row=row.replace("', u'","  ");row=row.replace("')","  ")
    row=row.replace("'","");row=row.replace("  , uu","\n")
    print"\nNumber :",count," -----\n",(row)    
    if count > req:
        conn.close()
        sys.exit()
        

import sqlite3
import sys
conn = sqlite3.connect('bigfeedfts.db')
c = conn.cursor()# Never 
count=0
req = 5000
for row in c.execute('SELECT * FROM bbctech WHERE feed LIKE "%phone%"'):    
    count=count+1
    row=str(row)
    row=row.replace("(u","");row=row.replace('", u"u',"\n")
    row=row.replace("/', u'","   ");row=row.replace('"',"")
    row=row.replace("', u'","  ");row=row.replace("')","  ")
    row=row.replace("'","");row=row.replace("  , uu","\n")
    print"\nNumber :",count," -----\n",(row)    
    if count > req:
        conn.close()
        sys.exit()
        

# WORKS
import sqlite3
import sys
conn = sqlite3.connect('bigfeedfts.db')
c = conn.cursor()# Never 
txt = raw_input("What are you looking for?")

for row in c.execute("SELECT * FROM bbctech WHERE feed MATCH ?", (txt,)):
    data = c.fetchall()
    data=data.replace('(u"(u','\n')
    print data,"\n-----\n","\n"

import sqlite3
import sys
conn = sqlite3.connect('bigfeedfts.db')
c = conn.cursor()
count=0
# Limited Amount of Results to 100
req=100
term = raw_input("Search Term : ")
for row in c.execute("SELECT * FROM bbctech WHERE feed MATCH ?", (term,)):
    row=str(row)
    row=row.replace("(u\"(u","");row=row.replace("', u'","  ");
    row=row.replace("u'"," ");row=row.replace(')", u" ', "\n");
    row=row.replace(" http://","\nhttp://");row=row.replace('")','')
    row=row.replace("'","");row=row.replace("#tk.rss_all", "")
    count=count+1
    print "\n",count,"-----\n",(row)
    if count > req:
        conn.close()
        sys.exit()

!sqlite3 bigfeed2.db "PRAGMA integrity_check"

# WORKS
import sqlite3
import sys
conn = sqlite3.connect('bigfeedfts.db')
c = conn.cursor()# Never 
count=0
req=4
num = raw_input("What line are you looking for?")

for row in c.execute("SELECT * FROM bbctech WHERE feed MATCH ?", (num,)):
    count=count+1
    print(row),"\n-----\n"
    if count > req:
        conn.close()
        sys.exit()
        

import sqlite3
import feedparser
import time
import sqlite3
Dbase = 'test4.db'
conn = sqlite3.connect(Dbase)
c = conn.cursor()
c.execute('''
CREATE TABLE IF NOT EXISTS bbctech
(head text, feed text)
''');
count=0
while count<8:
    count=count+1
    if count==3:feed='http://www.zdnet.com/zdnet.opml'
    d = feedparser.parse(feed)
    for post in d.entries:
        aa = `d['feed']['title'],d['feed']['link'],d.entries[0]['link']`
        bb = `post.title + ": " + post.link + ""`
        conn = sqlite3.connect(Dbase)
        c = conn.cursor()
        c.execute("INSERT INTO bbctech VALUES (?,?)", (aa,bb))
        conn.commit()
        conn.close()
conn = sqlite3.connect(Dbase)
c = conn.cursor()# Never
count=0
for row in c.execute('SELECT * FROM bbctech ORDER BY rowid DESC'):
    row=str(row)
    row=row.replace("(u","");row=row.replace('", u"u',"\n")
    row=row.replace("/', u'","   ");row=row.replace('"',"")
    row=row.replace("', u'","  ");row=row.replace("')","  ")
    row=row.replace("'","");row=row.replace("  , uu","\n")
    count=count+1
    print"\nNumber :",count," -----\n",(row)

import sqlite3
import feedparser
import time
import sqlite3
Dbase = 'test3.db'
conn = sqlite3.connect(Dbase)
c = conn.cursor()
c.execute('''
CREATE TABLE IF NOT EXISTS bbctech
(head text, feed text)
''');
count=0
while count<8:
    count=count+1
    if count==1:feed='http://www.techradar.com/rss'
    if count==2:feed='https://www.wired.com/feed/rss'
    if count==3:feed='http://www.zdnet.com/zdnet.opml'
    if count==4:feed='http://www.computerweekly.com/rss/All-Computer-Weekly-content.xml'
    if count==5:feed='http://gadgets.ndtv.com/rss/feeds'
    if count==6:feed='http://feeds.arstechnica.com/arstechnica/index'
    if count==7:feed='https://www.techworld.com/news/rss'
    if count==8:feed='https://www.infoworld.com/index.rss'
    d = feedparser.parse(feed)
    for post in d.entries:
        aa = `d['feed']['title'],d['feed']['link'],d.entries[0]['link']`
        bb = `post.title + ": " + post.link + ""`
        conn = sqlite3.connect(Dbase)
        c = conn.cursor()
        c.execute("INSERT INTO bbctech VALUES (?,?)", (aa,bb))
        conn.commit()
        conn.close()
conn = sqlite3.connect(Dbase)
c = conn.cursor()# Never
count=0
for row in c.execute('SELECT * FROM bbctech ORDER BY rowid DESC'):
    row=str(row)
    row=row.replace("(u","");row=row.replace('", u"u',"\n")
    row=row.replace("/', u'","   ");row=row.replace('"',"")
    row=row.replace("', u'","  ");row=row.replace("')","  ")
    row=row.replace("'","");row=row.replace("  , uu","\n")
    count=count+1
    print"\nNumber :",count," -----\n",(row)

import sqlite3
import feedparser
import time
import sqlite3
Dbase = 'news.db'
conn = sqlite3.connect(Dbase)
c = conn.cursor()
c.execute('''
CREATE TABLE IF NOT EXISTS bbctech
(head text, feed text)
''');
A_In='http://feeds.bbci.co.uk/news/technology/rss.xml'
B_In='http://www.cbn.com/cbnnews/us/feed/'
C_In='http://feeds.reuters.com/Reuters/worldNews'
D_In='http://feeds.bbci.co.uk/news/technology/rss.xml'
E_In='http://news.sky.com/info/rss'
F_In='http://www.cbn.com/cbnnews/us/feed/'
G_In='http://feeds.reuters.com/Reuters/domesticNews'
H_In='http://news.yahoo.com/rss/'
count=0
d = feedparser.parse(A_In)
for post in d.entries:
    aa = `d['feed']['title'],d['feed']['link'],d.entries[0]['link']`
    bb = `post.title + ": " + post.link + ""`
    conn = sqlite3.connect(Dbase)
    c = conn.cursor()
    c.execute("INSERT INTO bbctech VALUES (?,?)", (aa,bb))
    conn.commit()
    conn.close()
conn = sqlite3.connect(Dbase)
c = conn.cursor()# Never 
for row in c.execute('SELECT * FROM bbctech ORDER BY rowid DESC'):
        row=str(row)
        row=row.replace("(u","");row=row.replace('", u"u',"\n")
        row=row.replace("/', u'","   ");row=row.replace('"',"")
        row=row.replace("', u'","  ");row=row.replace("')","  ")
        row=row.replace("'","");row=row.replace("  , uu","\n")
        count=count+1
        print"\nNumber :",count," -----\n",(row)

import sqlite3
conn = sqlite3.connect('news.db')
c = conn.cursor()# Never 
for row in c.execute('SELECT * FROM bbctech ORDER BY rowid'):
        row=str(row)
        row=row.replace("(u"," ")
        row=row.replace('", u"u',"\n")
        print(row),"\n-----\n"

import sqlite3
import feedparser
import time
import sqlite3
conn = sqlite3.connect('news.db')
#conn = sqlite3.connect('testrss.db')
c = conn.cursor()
c.execute('''
CREATE TABLE IF NOT EXISTS bbctech
(head text, feed text)
''');

test01 = 'http://feeds.feedburner.com/TechCrunch/'
test02 = 'http://feeds.feedburner.com/crunchgear'
test03 = 'http://feeds.feedburner.com/TechCrunch/Twitter'
test04 = 'https://www.cnet.com/cnet-podcasts/'
test05 = 'https://www.cnet.com/rss/news/'
    
    
count=0
d = feedparser.parse(test01)
for post in d.entries:
    aa = `d['feed']['title'],d['feed']['link'],d.entries[0]['link']`
    bb = `post.title + ": " + post.link + ""`
    conn = sqlite3.connect('newnews.db')
    c = conn.cursor()
    c.execute("INSERT INTO bbctech VALUES (?,?)", (aa,bb))
    conn.commit()
    conn.close()
conn = sqlite3.connect('newnews.db')
c = conn.cursor()# Never 
for row in c.execute('SELECT * FROM bbctech ORDER BY rowid DESC'):
        row=str(row)
        row=row.replace("(u","");row=row.replace('", u"u',"\n")
        row=row.replace("/', u'","   ");row=row.replace('"',"")
        row=row.replace("', u'","  ");row=row.replace("')","  ")
        row=row.replace("'","");row=row.replace("  , uu","\n")
        row=row.replace(" \\u2013", "")
        count=count+1
        print"\nNumber :",count," -----\n",(row)

import sqlite3
import feedparser
import time
import sqlite3
conn = sqlite3.connect('news.db')
#conn = sqlite3.connect('testrss.db')
c = conn.cursor()
c.execute('''
CREATE TABLE IF NOT EXISTS bbctech
(head text, feed text)
''');

test01 = 'http://feeds.feedburner.com/TechCrunch/'
test02 = 'http://feeds.feedburner.com/crunchgear'
test03 = 'http://feeds.feedburner.com/TechCrunch/Twitter'
test04 = 'https://www.cnet.com/cnet-podcasts/'
test05 = 'https://www.cnet.com/rss/news/'
    
    
count=0
d = feedparser.parse(test02)
for post in d.entries:
    aa = `d['feed']['title'],d['feed']['link'],d.entries[0]['link']`
    bb = `post.title + ": " + post.link + ""`
    conn = sqlite3.connect('newnews.db')
    c = conn.cursor()
    c.execute("INSERT INTO bbctech VALUES (?,?)", (aa,bb))
    conn.commit()
    conn.close()
conn = sqlite3.connect('newnews.db')
c = conn.cursor()# Never 
for row in c.execute('SELECT * FROM bbctech ORDER BY rowid DESC'):
        row=str(row)
        row=row.replace("(u","");row=row.replace('", u"u',"\n")
        row=row.replace("/', u'","   ");row=row.replace('"',"")
        row=row.replace("', u'","  ");row=row.replace("')","  ")
        row=row.replace("'","");row=row.replace("  , uu","\n")
        row=row.replace(" \\u2013", "")
        count=count+1
        print"\nNumber :",count," -----\n",(row)

import sqlite3
import feedparser
import time
import sqlite3
conn = sqlite3.connect('news.db')
#conn = sqlite3.connect('testrss.db')
c = conn.cursor()
c.execute('''
CREATE TABLE IF NOT EXISTS bbctech
(head text, feed text)
''');

test01 = 'http://feeds.feedburner.com/TechCrunch/'
test02 = 'http://feeds.feedburner.com/crunchgear'
test03 = 'http://feeds.feedburner.com/TechCrunch/Twitter'
test04 = 'https://www.cnet.com/cnet-podcasts/'
test05 = 'https://www.cnet.com/rss/news/'
    
    
count=0
d = feedparser.parse(test03)
for post in d.entries:
    aa = `d['feed']['title'],d['feed']['link'],d.entries[0]['link']`
    bb = `post.title + ": " + post.link + ""`
    conn = sqlite3.connect('newnews.db')
    c = conn.cursor()
    c.execute("INSERT INTO bbctech VALUES (?,?)", (aa,bb))
    conn.commit()
    conn.close()
conn = sqlite3.connect('newnews.db')
c = conn.cursor()# Never 
for row in c.execute('SELECT * FROM bbctech ORDER BY rowid DESC'):
        row=str(row)
        row=row.replace("(u","");row=row.replace('", u"u',"\n")
        row=row.replace("/', u'","   ");row=row.replace('"',"")
        row=row.replace("', u'","  ");row=row.replace("')","  ")
        row=row.replace("'","");row=row.replace("  , uu","\n")
        row=row.replace(" \\u2013", "")
        count=count+1
        print"\nNumber :",count," -----\n",(row)

import sqlite3
import feedparser
import time
import sqlite3
conn = sqlite3.connect('news.db')
#conn = sqlite3.connect('testrss.db')
c = conn.cursor()
c.execute('''
CREATE TABLE IF NOT EXISTS bbctech
(head text, feed text)
''');

test01 = 'http://feeds.feedburner.com/TechCrunch/'
test02 = 'http://feeds.feedburner.com/crunchgear'
test03 = 'http://feeds.feedburner.com/TechCrunch/Twitter'
test04 = 'https://www.cnet.com/cnet-podcasts/'
test05 = 'https://www.cnet.com/rss/news/'
    
    
count=0
d = feedparser.parse(test04)
for post in d.entries:
    aa = `d['feed']['title'],d['feed']['link'],d.entries[0]['link']`
    bb = `post.title + ": " + post.link + ""`
    conn = sqlite3.connect('newnews.db')
    c = conn.cursor()
    c.execute("INSERT INTO bbctech VALUES (?,?)", (aa,bb))
    conn.commit()
    conn.close()
conn = sqlite3.connect('newnews.db')
c = conn.cursor()# Never 
for row in c.execute('SELECT * FROM bbctech ORDER BY rowid DESC'):
        row=str(row)
        row=row.replace("(u","");row=row.replace('", u"u',"\n")
        row=row.replace("/', u'","   ");row=row.replace('"',"")
        row=row.replace("', u'","  ");row=row.replace("')","  ")
        row=row.replace("'","");row=row.replace("  , uu","\n")
        row=row.replace(" \\u2013", "")
        count=count+1
        print"\nNumber :",count," -----\n",(row)

import sqlite3
import feedparser
import time
import sqlite3
conn = sqlite3.connect('news.db')
#conn = sqlite3.connect('testrss.db')
c = conn.cursor()
c.execute('''
CREATE TABLE IF NOT EXISTS bbctech
(head text, feed text)
''');

test01 = 'http://feeds.feedburner.com/TechCrunch/'
test02 = 'http://feeds.feedburner.com/crunchgear'
test03 = 'http://feeds.feedburner.com/TechCrunch/Twitter'
test04 = 'https://www.cnet.com/cnet-podcasts/'
test05 = 'https://www.cnet.com/rss/news/'
    
    
count=0
d = feedparser.parse(test05)
for post in d.entries:
    aa = `d['feed']['title'],d['feed']['link'],d.entries[0]['link']`
    bb = `post.title + ": " + post.link + ""`
    conn = sqlite3.connect('newnews.db')
    c = conn.cursor()
    c.execute("INSERT INTO bbctech VALUES (?,?)", (aa,bb))
    conn.commit()
    conn.close()
conn = sqlite3.connect('newnews.db')
c = conn.cursor()# Never 
for row in c.execute('SELECT * FROM bbctech ORDER BY rowid DESC'):
        row=str(row)
        row=row.replace("(u","");row=row.replace('", u"u',"\n")
        row=row.replace("/', u'","   ");row=row.replace('"',"")
        row=row.replace("', u'","  ");row=row.replace("')","  ")
        row=row.replace("'","");row=row.replace("  , uu","\n")
        row=row.replace(" \\u2013", "")
        count=count+1
        print"\nNumber :",count," -----\n",(row)

import sqlite3
import feedparser
import time
import sqlite3
Dbase = 'bigfeedfts.db'
conn = sqlite3.connect(Dbase)
c = conn.cursor()
c.execute("""
CREATE VIRTUAL TABLE IF NOT EXISTS bbctech 
USING FTS3(head, feed);
""")
count=0
while count<35:
    count=count+1
    if count==1:feed='http://feeds.bbci.co.uk/news/technology/rss.xml'
    if count==2:feed='http://www.cbn.com/cbnnews/us/feed/'
    d = feedparser.parse(feed)
    for post in d.entries:
        aa = `d['feed']['title'],d['feed']['link'],d.entries[0]['link']`
        bb = `post.title + ": " + post.link + ""`
        conn = sqlite3.connect(Dbase)
        c = conn.cursor()
        c.execute("INSERT INTO bbctech VALUES (?,?)", (aa,bb))
        conn.commit()
        conn.close()
        
        
conn = sqlite3.connect(Dbase)
c = conn.cursor()# Never
count=0
for row in c.execute('SELECT * FROM bbctech ORDER BY rowid DESC'):
    row=str(row)
    row=row.replace("(u","");row=row.replace('", u"u',"\n")
    row=row.replace("/', u'","   ");row=row.replace('"',"")
    row=row.replace("', u'","  ");row=row.replace("')","  ")
    row=row.replace("'","");row=row.replace("  , uu","\n")
    count=count+1
    print"\nNumber :",count," -----\n",(row)

https://note.nkmk.me/en/python-pillow-paste/

!locate data/src/rocket.jpg

from random import randint
import random
import os
CHOOSE =[]
Paths = open("directory.list","r")
for path in Paths:
    path = str(path).replace("\n","")
    CHOOSE.append(path)
def usefile():
    ID = randint(0, len(CHOOSE)-1)
    DIR = CHOOSE[ID]
    return DIR

print(usefile())

path = usefile()
base_image = random.choice([
x for x in os.listdir(path)
if os.path.isfile(os.path.join(path, x))
        ])
filename0=(path+base_image)
print(filename0)

from PIL import Image, ImageDraw, ImageFilter
from random import randint
import random
import os
CHOOSE =[]
Paths = open("directory.list","r")
for path in Paths:
    path = str(path).replace("\n","")
    CHOOSE.append(path)
def usefile():
    ID = randint(0, len(CHOOSE)-1)
    DIR = CHOOSE[ID]
    return DIR

path = usefile()
base_image = random.choice([
x for x in os.listdir(path)
if os.path.isfile(os.path.join(path, x))
        ])
filename0=(path+base_image)
print(filename0)

im1 = Image.open(filename0)

path0 = usefile()
base_image = random.choice([
x for x in os.listdir(path0)
if os.path.isfile(os.path.join(path, x))
        ])
filename00=(path0+base_image)
print(filename00)
im2 = Image.open(filename00)


im1.paste(im2)
#im1.save('data/dst/rocket_pillow_paste.jpg', quality=95)
im1

im1 = Image.open(filename00)
im2 = Image.open(filename0)

back_im = im1.copy()
back_im.paste(im2)
#back_im.save('data/dst/rocket_pillow_paste.jpg', quality=95)
back_im

#Specify the position to paste

#The position to paste is specified by a tuple (x coordinate in upper left, y coordinate in upper left) 
#in the second parameter box.

back_im = im1.copy()
back_im.paste(im2, (100, 50))
#back_im.save('data/dst/rocket_pillow_paste_pos.jpg', quality=95)
back_im

#If the pasted image extends outside the region of the base image, the area that extends is ignored.

back_im = im1.copy()
back_im.paste(im2, (400, 100))
#back_im.save('data/dst/rocket_pillow_paste_out.jpg', quality=95)
back_im

from PIL import Image
mask_im = Image.new("L", im2.size, 0)
draw = ImageDraw.Draw(mask_im)
draw.ellipse((140, 50, 260, 170), fill=255)
#mask_im.save('junk/mask_circle.jpg', quality=95)
mask_im


back_im = im1.copy()
back_im.paste(im2, (0, 0), mask_im)
back_im.save('junk/mask_circle.jpg', quality=95)
back_im

mask_im_blur = mask_im.filter(ImageFilter.GaussianBlur(10))
mask_im_blur.save('junk/mask_circle_blur.jpg', quality=95)

mask_im_blur

back_im = im1.copy()
back_im.paste(im2, (0, 0), mask_im_blur)
back_im.save('junk/_mask_circle_blur.jpg', quality=95)
back_im

#After the image is read by open(), it is adjusted to the size of the pasted image by resize(),
#and the mode is converted to 'L' (grayscale) by convert().

mask_im = Image.open(filename00).resize(im2.size).convert('L')

back_im = im1.copy()
back_im.paste(im2, (100, 50), mask_im)
back_im.save('junk/_paste_mask_horse.jpg', quality=95)
back_im

from PIL import Image, ImageDraw

images = []

width = 200
center = width // 2
color_1 = (0, 0, 0)
color_2 = (255, 255, 255)
max_radius = int(center * 1.5)
step = 8

for i in range(0, max_radius, step):
    im = Image.new('RGB', (width, width), color_1)
    draw = ImageDraw.Draw(im)
    draw.ellipse((center - i, center - i, center + i, center + i), fill=color_2)
    images.append(im)

for i in range(0, max_radius, step):
    im = Image.new('RGB', (width, width), color_2)
    draw = ImageDraw.Draw(im)
    draw.ellipse((center - i, center - i, center + i, center + i), fill=color_1)
    images.append(im)

images[0].save('junk/pillow_imagedraw.gif',
               save_all=True, append_images=images[1:], optimize=False, duration=40, loop=0)


im = Image.new('RGB', (500, 250), (128, 128, 128))
draw = ImageDraw.Draw(im)

draw.line(((30, 200), (130, 100), (80, 50)), fill=(255, 255, 0))
draw.line(((80, 200), (180, 100), (130, 50)), fill=(255, 255, 0), width=10)
draw.polygon(((200, 200), (800, 100), (250, 50)), fill=(255, 255, 0), outline=(0, 0, 0))
draw.point(((350, 200), (450, 100), (400, 50)), fill=(255, 255, 0))
im

im = Image.new('RGB', (600, 250), (128, 128, 128))
draw = ImageDraw.Draw(im)

draw.arc((25, 50, 175, 200), start=30, end=270, fill=(255, 255, 0))
draw.chord((225, 50, 375, 200), start=30, end=270, fill=(255, 255, 0), outline=(0, 0, 0))
draw.pieslice((425, 50, 575, 200), start=30, end=270, fill=(255, 255, 0), outline=(0, 0, 0))


im = Image.open(filename00)
draw = ImageDraw.Draw(im)

draw.pieslice((15, 50, 140, 175), start=30, end=330, fill=(255, 255, 0))
im

from PIL import Image, ImageDraw, ImageFilter

im_rgb = Image.open(filename0)
im_rgba = im_rgb.copy()
im_rgba.putalpha(128)
im_rgba.save('junk/pillow_putalpha_solid.png')
im_rgba

im_a = Image.new("L", im_rgb.size, 0)
draw = ImageDraw.Draw(im_a)
draw.ellipse((140, 50, 260, 170), fill=255)
im_a

im_rgba = im_rgb.copy()
im_rgba.putalpha(im_a)
im_rgba_crop = im_rgba.crop((140, 50, 260, 170))
im_rgba_crop.save('junk/pillow_putalpha_circle.png')

im_rgba_crop

m_rgba = im_rgb.copy()
im_rgba.putalpha(im_a_blur)
im_rgba_crop = im_rgba.crop((135, 45, 265, 175))
im_rgba_crop.save('junk/pillow_putalpha_circle_blur.png')

im_rgba_crop





:import "fmt"

:import "github.com/sjwhitworth/golearn/base"

:import "github.com/sjwhitworth/golearn/evaluation"

:import "github.com/sjwhitworth/golearn/knn"

// Load in a dataset, with headers. Header attributes will be stored.
// Think of instances as a Data Frame structure in R or Pandas.
// You can also create instances from scratch.
rawData, err := base.ParseCSVToInstances("/usr/local/lib/python2.7/dist-packages/pandas/io/tests/data/iris.csv
", false)

//Initialises a new KNN classifier
cls := knn.NewKnnClassifier("euclidean", 2)

//Do a training-test split
trainData, testData := base.InstancesTrainTestSplit(rawData, 0.50)
cls.Fit(trainData)

//Calculates the Euclidean distance and returns the most popular label
predictions := cls.Predict(testData)

// Calculate precision/recall metrics, and summarize results
confusionMat, err := evaluation.GetConfusionMatrix(testData, predictions)
fmt.Println(evaluation.GetSummary(confusionMat))



:import "fmt"

:import "github.com/sjwhitworth/golearn/base"

:import "github.com/sjwhitworth/golearn/evaluation"

:import "github.com/sjwhitworth/golearn/knn"

// Load in a dataset, with headers. Header attributes will be stored.
// Think of instances as a Data Frame structure in R or Pandas.
// You can also create instances from scratch.
rawData, err := base.ParseCSVToInstances("/usr/local/lib/python2.7/dist-packages/pandas/io/tests/data/iris.csv
", false)

//Initialises a new KNN classifier
cls := knn.NewKnnClassifier("euclidean", 2)

//Do a training-test split
trainData, testData := base.InstancesTrainTestSplit(rawData, 0.50)
cls.Fit(trainData)

//Calculates the Euclidean distance and returns the most popular label
predictions := cls.Predict(testData)

// Calculate precision/recall metrics, and summarize results
confusionMat, err := evaluation.GetConfusionMatrix(testData, predictions)
fmt.Println(evaluation.GetSummary(confusionMat))



# ImageDraw Module
# ImagePalette.py
# ImageColor Module
# ImageChops

<a href ="#Top">Page Top</a>

# ImageDraw Module

The ImageDraw module provide simple 2D graphics for Image objects. 
You can use this module to create new images, annotate or retouch existing images, 
and to generate graphics on the fly for web use.

For a more advanced drawing library for PIL, see the aggdraw module.
Example: Draw a gray cross over an image

from PIL import Image, ImageDraw
im = Image.open("lena.pgm")

draw = ImageDraw.Draw(im)
draw.line((0, 0) + im.size, fill=128)
draw.line((0, im.size[1], im.size[0], 0), fill=128)
del draw

# write to stdout
im.save(sys.stdout, "PNG")

Concepts
Coordinates
The graphics interface uses the same coordinate system as PIL itself, with (0, 0) in the upper left corner.
Colors
To specify colors, you can use numbers or tuples just as you would use with PIL.Image.Image.new() 
or PIL.Image.Image.putpixel(). For 1, L, and I images, use integers. For RGB images, 
use a 3-tuple containing integer values. For F images, use integer or floating point values.

For palette images (mode P), use integers as color indexes. In 1.1.4 and later, 
you can also use RGB 3-tuples or color names (see below). The drawing layer will automatically assign color indexes, 
as long as you dont draw with more than 256 colors.
Color Names
See Color Names for the color names supported by Pillow.
Fonts
PIL can use bitmap fonts or OpenType/TrueType fonts.
Bitmap fonts are stored in PILs own format, where each font typically consists of a two files, 
one named .pil and the other usually named .pbm. The former contains font metrics, the latter raster data.
To load a bitmap font, use the load functions in the ImageFont module.
To load a OpenType/TrueType font, use the truetype function in the ImageFont module. 
Note that this function depends on third-party libraries, and may not available in all PIL builds.
Example: Draw Partial Opacity Text

from PIL import Image, ImageDraw, ImageFont
# get an image
base = Image.open('Pillow/Tests/images/lena.png').convert('RGBA')

# make a blank image for the text, initialized to transparent text color
txt = Image.new('RGBA', base.size, (255,255,255,0))

# get a font
fnt = ImageFont.truetype('Pillow/Tests/fonts/FreeMono.ttf', 40)
# get a drawing context
d = ImageDraw.Draw(txt)

# draw text, half opacity
d.text((10,10), "Hello", font=fnt, fill=(255,255,255,128))
# draw text, full opacity
d.text((10,60), "World", font=fnt, fill=(255,255,255,255))

out = Image.alpha_composite(base, txt)

out.show()

Functions

class PIL.ImageDraw.Draw(im, mode=None)
    Creates an object that can be used to draw in the given image.
    Note that the image will be modified in place.
    Parameters:	
        im  The image to draw in.
        mode  Optional mode to use for color values. For RGB images, this argument can be RGB or RGBA (to blend the drawing into the image). For all other modes, this argument must be the same as the image mode. If omitted, the mode defaults to the mode of the image.

Methods
PIL.ImageDraw.Draw.arc(xy, start, end, fill=None)
    Draws an arc (a portion of a circle outline) between the start and end angles, inside the given bounding box.
    Parameters:	
        xy  Four points to define the bounding box. Sequence of [(x0, y0), (x1, y1)] or [x0, y0, x1, y1].
        start  Starting angle, in degrees. Angles are measured from 3 oclock, increasing clockwise.
        end  Ending angle, in degrees.
        fill  Color to use for the arc.

PIL.ImageDraw.Draw.bitmap(xy, bitmap, fill=None)
    Draws a bitmap (mask) at the given position, using the current fill color for the non-zero portions. The bitmap should be a valid transparency mask (mode 1) or matte (mode L or RGBA).
    This is equivalent to doing image.paste(xy, color, bitmap).
    To paste pixel data into an image, use the paste() method on the image itself.

PIL.ImageDraw.Draw.chord(xy, start, end, fill=None, outline=None)
    Same as arc(), but connects the end points with a straight line.
    Parameters:	

        xy  Four points to define the bounding box. Sequence of [(x0, y0), (x1, y1)] or [x0, y0, x1, y1].
        outline  Color to use for the outline.
        fill  Color to use for the fill.

PIL.ImageDraw.Draw.ellipse(xy, fill=None, outline=None)
    Draws an ellipse inside the given bounding box.
    Parameters:	

        xy  Four points to define the bounding box. Sequence of either [(x0, y0), (x1, y1)] or [x0, y0, x1, y1].
        outline  Color to use for the outline.
        fill  Color to use for the fill.

PIL.ImageDraw.Draw.line(xy, fill=None, width=0)
    Draws a line between the coordinates in the xy list.
    Parameters:	

        xy  Sequence of either 2-tuples like [(x, y), (x, y), ...] or numeric values like [x, y, x, y, ...].
        fill  Color to use for the line.
        width 

        The line width, in pixels. Note that line joins are not handled well, so wide polylines will not look good.

        New in version 1.1.5.

        Note

        This option was broken until version 1.1.6.

PIL.ImageDraw.Draw.pieslice(xy, start, end, fill=None, outline=None)
    Same as arc, but also draws straight lines between the end points and the center of the bounding box.
    Parameters:	

        xy  Four points to define the bounding box. Sequence of [(x0, y0), (x1, y1)] or [x0, y0, x1, y1].
        start  Starting angle, in degrees. Angles are measured from 3 oclock, increasing clockwise.
        end  Ending angle, in degrees.
        fill  Color to use for the fill.
        outline  Color to use for the outline.

PIL.ImageDraw.Draw.point(xy, fill=None)
    Draws points (individual pixels) at the given coordinates.
    Parameters:	

        xy  Sequence of either 2-tuples like [(x, y), (x, y), ...] or numeric values like [x, y, x, y, ...].
        fill  Color to use for the point.

PIL.ImageDraw.Draw.polygon(xy, fill=None, outline=None)
    Draws a polygon.

    The polygon outline consists of straight lines between the given coordinates, plus a straight line between the last and the first coordinate.
    Parameters:	

        xy  Sequence of either 2-tuples like [(x, y), (x, y), ...] or numeric values like [x, y, x, y, ...].
        outline  Color to use for the outline.
        fill  Color to use for the fill.

PIL.ImageDraw.Draw.rectangle(xy, fill=None, outline=None)
    Draws a rectangle.
    Parameters:	

        xy  Four points to define the bounding box. Sequence of either [(x0, y0), (x1, y1)] or [x0, y0, x1, y1]. The second point is just outside the drawn rectangle.
        outline  Color to use for the outline.
        fill  Color to use for the fill.

PIL.ImageDraw.Draw.shape(shape, fill=None, outline=None)
    Warning

    This method is experimental.

    Draw a shape.

PIL.ImageDraw.Draw.text(xy, text, fill=None, font=None, anchor=None, spacing=0, align="left")
    Draws the string at the given position.
    Parameters:	

        xy  Top left corner of the text.
        text  Text to be drawn. If it contains any newline characters, the text is passed on to multiline_text()
        fill  Color to use for the text.
        font  An ImageFont instance.
        spacing  If the text is passed on to multiline_text(), the number of pixels between lines.
        align  If the text is passed on to multiline_text(), left, center or right.

PIL.ImageDraw.Draw.multiline_text(xy, text, fill=None, font=None, anchor=None, spacing=0, align="left")
    Draws the string at the given position.
    Parameters:	

        xy  Top left corner of the text.
        text  Text to be drawn.
        fill  Color to use for the text.
        font  An ImageFont instance.
        spacing  The number of pixels between lines.
        align  left, center or right.

PIL.ImageDraw.Draw.textsize(text, font=None, spacing=0)
    Return the size of the given string, in pixels.
    Parameters:	

        text  Text to be measured. If it contains any newline characters, the text is passed on to multiline_textsize()
        font  An ImageFont instance.
        spacing  If the text is passed on to multiline_textsize(), the number of pixels between lines.

PIL.ImageDraw.Draw.multiline_textsize(text, font=None, spacing=0)
    Return the size of the given string, in pixels.
    Parameters:	

        text  Text to be measured.
        font  An ImageFont instance.
        spacing  The number of pixels between lines.



# ImagePalette.py
# The Python Imaging Library.
# $Id$
#
# image palette object
#
# History:
# 1996-03-11 fl   Rewritten.
# 1997-01-03 fl   Up and running.
# 1997-08-23 fl   Added load hack
# 2001-04-16 fl   Fixed randint shadow bug in random()
#
# Copyright (c) 1997-2001 by Secret Labs AB
# Copyright (c) 1996-1997 by Fredrik Lundh
#
# See the README file for information on usage and redistribution.
#

import array
from PIL import ImageColor
from PIL import GimpPaletteFile
from PIL import GimpGradientFile
from PIL import PaletteFile


class ImagePalette(object):
    """
    Color palette for palette mapped images

    :param mode: The mode to use for the Palette. See:
        :ref:`concept-modes`. Defaults to "RGB"
    :param palette: An optional palette. If given, it must be a bytearray,
        an array or a list of ints between 0-255 and of length ``size``
        times the number of colors in ``mode``. The list must be aligned
        by channel (All R values must be contiguous in the list before G
        and B values.) Defaults to 0 through 255 per channel.
    :param size: An optional palette size. If given, it cannot be equal to
        or greater than 256. Defaults to 0.
    """

    def __init__(self, mode="RGB", palette=None, size=0):
        self.mode = mode
        self.rawmode = None  # if set, palette contains raw data
        self.palette = palette or bytearray(range(256))*len(self.mode)
        self.colors = {}
        self.dirty = None
        if ((size == 0 and len(self.mode)*256 != len(self.palette)) or
                (size != 0 and size != len(self.palette))):
            raise ValueError("wrong palette size")

    def copy(self):
        new = ImagePalette()

        new.mode = self.mode
        new.rawmode = self.rawmode
        if self.palette is not None:
            new.palette = self.palette[:]
        new.colors = self.colors.copy()
        new.dirty = self.dirty

        return new

    def getdata(self):
        """
        Get palette contents in format suitable # for the low-level
        ``im.putpalette`` primitive.

        .. warning:: This method is experimental.
        """
        if self.rawmode:
            return self.rawmode, self.palette
        return self.mode + ";L", self.tobytes()

    def tobytes(self):
        """Convert palette to bytes.

        .. warning:: This method is experimental.
        """
        if self.rawmode:
            raise ValueError("palette contains raw palette data")
        if isinstance(self.palette, bytes):
            return self.palette
        arr = array.array("B", self.palette)
        if hasattr(arr, 'tobytes'):
            return arr.tobytes()
        return arr.tostring()

    # Declare tostring as an alias for tobytes
    tostring = tobytes

    def getcolor(self, color):
        """Given an rgb tuple, allocate palette entry.

        .. warning:: This method is experimental.
        """
        if self.rawmode:
            raise ValueError("palette contains raw palette data")
        if isinstance(color, tuple):
            try:
                return self.colors[color]
            except KeyError:
                # allocate new color slot
                if isinstance(self.palette, bytes):
                    self.palette = bytearray(self.palette)
                index = len(self.colors)
                if index >= 256:
                    raise ValueError("cannot allocate more than 256 colors")
                self.colors[color] = index
                self.palette[index] = color[0]
                self.palette[index+256] = color[1]
                self.palette[index+512] = color[2]
                self.dirty = 1
                return index
        else:
            raise ValueError("unknown color specifier: %r" % color)

    def save(self, fp):
        """Save palette to text file.

        .. warning:: This method is experimental.
        """
        if self.rawmode:
            raise ValueError("palette contains raw palette data")
        if isinstance(fp, str):
            fp = open(fp, "w")
        fp.write("# Palette\n")
        fp.write("# Mode: %s\n" % self.mode)
        for i in range(256):
            fp.write("%d" % i)
            for j in range(i*len(self.mode), (i+1)*len(self.mode)):
                try:
                    fp.write(" %d" % self.palette[j])
                except IndexError:
                    fp.write(" 0")
            fp.write("\n")
        fp.close()


# --------------------------------------------------------------------
# Internal

def raw(rawmode, data):
    palette = ImagePalette()
    palette.rawmode = rawmode
    palette.palette = data
    palette.dirty = 1
    return palette


# --------------------------------------------------------------------
# Factories

def make_linear_lut(black, white):
    lut = []
    if black == 0:
        for i in range(256):
            lut.append(white*i//255)
    else:
        raise NotImplementedError  # FIXME
    return lut


def make_gamma_lut(exp):
    lut = []
    for i in range(256):
        lut.append(int(((i / 255.0) ** exp) * 255.0 + 0.5))
    return lut


def negative(mode="RGB"):
    palette = list(range(256))
    palette.reverse()
    return ImagePalette(mode, palette * len(mode))


def random(mode="RGB"):
    from random import randint
    palette = []
    for i in range(256*len(mode)):
        palette.append(randint(0, 255))
    return ImagePalette(mode, palette)


def sepia(white="#fff0c0"):
    r, g, b = ImageColor.getrgb(white)
    r = make_linear_lut(0, r)
    g = make_linear_lut(0, g)
    b = make_linear_lut(0, b)
    return ImagePalette("RGB", r + g + b)


def wedge(mode="RGB"):
    return ImagePalette(mode, list(range(256)) * len(mode))


def load(filename):

    # FIXME: supports GIMP gradients only

    with open(filename, "rb") as fp:

        for paletteHandler in [
            GimpPaletteFile.GimpPaletteFile,
            GimpGradientFile.GimpGradientFile,
            PaletteFile.PaletteFile
        ]:
            try:
                fp.seek(0)
                lut = paletteHandler(fp).getpalette()
                if lut:
                    break
            except (SyntaxError, ValueError):
                # import traceback
                # traceback.print_exc()
                pass
        else:
            raise IOError("cannot load palette")

    return lut  # data, rawmode


# ImageFont Module

The ImageFont module defines a class with the same name. Instances of this class store bitmap fonts, 
and are used with the PIL.ImageDraw.Draw.text() method.
PIL uses its own font file format to store bitmap fonts. You can use the :command`pilfont` 
utility to convert BDF and PCF font descriptors (X window font formats) to this format.
Starting with version 1.1.4, PIL can be configured to support TrueType and OpenType fonts 
(as well as other font formats supported by the FreeType library). For earlier versions, TrueType support is only available as part of the imToolkit package


from PIL import ImageFont, ImageDraw
draw = ImageDraw.Draw(image)

# use a bitmap font
font = ImageFont.load("arial.pil")

draw.text((10, 10), "hello", font=font)
# use a truetype font
font = ImageFont.truetype("arial.ttf", 15)

draw.text((10, 25), "world", font=font)
Functions

PIL.ImageFont.load(filename)
    Load a font file. This function loads a font object from the given bitmap font file, and returns 
    the corresponding font object.
    Parameters:	filename  Name of font file.
    Returns:	A font object.
    Raises:	IOError  If the file could not be read.

PIL.ImageFont.load_path(filename)
    Load font file. Same as load(), but searches for a bitmap font along the Python path.
    Parameters:	filename  Name of font file.
    Returns:	A font object.
    Raises:	IOError  If the file could not be read.

PIL.ImageFont.truetype(font=None, size=10, index=0, encoding='')
    Load a TrueType or OpenType font file, and create a font object. This function loads a font object 
    from the given file, and creates a font object for a font of the given size.

    This function requires the _imagingft service.
    Parameters:	

        font  A truetype font file. Under Windows, if the file is not found in this filename, the loader 
        also looks in Windows fonts/ directory.
        size  The requested size, in points.
        index  Which font face to load (default is first available face).
        encoding  Which font encoding to use (default is Unicode). Common encodings are unic (Unicode), 
        symb (Microsoft Symbol), ADOB (Adobe Standard), ADBE (Adobe Expert), and armn (Apple Roman). 
        See the FreeType documentation for more information.
    Returns:	
    A font object.

PIL.ImageFont.load_default()
    Load a better than nothing default font.
    New in version 1.1.4.
    Returns:	A font object.

Methods:
PIL.ImageFont.ImageFont.getsize(text)
    Returns:	(width, height)

PIL.ImageFont.ImageFont.getmask(text, mode='')
    Create a bitmap for the text.
    If the font uses antialiasing, the bitmap should have mode L and use a maximum value of 255. 
    Otherwise, it should have mode 1.
    Parameters:	
        text  Text to render.
        mode 
        Used by some graphics drivers to indicate what mode the driver prefers; if empty, 
        the renderer may return either mode. Note that the mode is always a string, to simplify C-level 
    implementations.
        New in version 1.1.5.

    Returns:	
    An internal PIL storage memory instance as defined by the PIL.Image.core interface module.

# ImageChops (Channel Operations) Module

At this time, most channel operations are only implemented for 8-bit images (e.g. L and RGB).


Most channel operations take one or two image arguments and returns a new image. 
Unless otherwise noted, the result of a channel operation is always clipped to the range 0 to MAX 
(which is 255 for all modes supported by the operations in this module).

PIL.ImageChops.add(image1, image2, scale=1.0, offset=0)

    Adds two images, dividing the result by scale and adding the offset. 
    If omitted, scale defaults to 1.0, and offset to 0.0.
    out = ((image1 + image2) / scale + offset)

PIL.ImageChops.add_modulo(image1, image2)
    Add two images, without clipping the result.
    out = ((image1 + image2) % MAX)

PIL.ImageChops.blend(image1, image2, alpha)
    Blend images using constant transparency weight. Alias for PIL.Image.Image.blend().

PIL.ImageChops.composite(image1, image2, mask)
    Create composite using transparency mask. Alias for PIL.Image.Image.composite().

PIL.ImageChops.constant(image, value)
    Fill a channel with a given grey level.

PIL.ImageChops.darker(image1, image2)
    Compares the two images, pixel by pixel, and returns a new image containing the darker values.
    out = min(image1, image2)

PIL.ImageChops.difference(image1, image2)
    Returns the absolute value of the pixel-by-pixel difference between the two images.
    out = abs(image1 - image2)

PIL.ImageChops.duplicate(image)
    Copy a channel. Alias for PIL.Image.Image.copy().

PIL.ImageChops.invert(image)
    Invert an image (channel).
    out = MAX - image

PIL.ImageChops.lighter(image1, image2)
    Compares the two images, pixel by pixel, and returns a new image containing the lighter values.
    out = max(image1, image2)

PIL.ImageChops.logical_and(image1, image2)
    Logical AND between two images.
    out = ((image1 and image2) % MAX)

PIL.ImageChops.logical_or(image1, image2)
    Logical OR between two images.
    out = ((image1 or image2) % MAX)

PIL.ImageChops.multiply(image1, image2)
    Superimposes two images on top of each other.
    If you multiply an image with a solid black image, the result is black. 
    If you multiply with a solid white image, the image is unaffected.
    out = image1 * image2 / MAX

PIL.ImageChops.offset(image, xoffset, yoffset=None)
    Returns a copy of the image where data has been offset by the given distances. 
    Data wraps around the edges. If yoffset is omitted, it is assumed to be equal to xoffset.
    Parameters:	
        xoffset  The horizontal distance.
        yoffset  The vertical distance. If omitted, both distances are set to the same value.

PIL.ImageChops.screen(image1, image2)
    Superimposes two inverted images on top of each other.
    out = MAX - ((MAX - image1) * (MAX - image2) / MAX)

PIL.ImageChops.subtract(image1, image2, scale=1.0, offset=0)
    Subtracts two images, dividing the result by scale and adding the offset. If omitted, scale defaults to 1.0, and offset to 0.0.
    out = ((image1 - image2) / scale + offset)

PIL.ImageChops.subtract_modulo(image1, image2)
    Subtract two images, without clipping the result.
    out = ((image1 - image2) % MAX)



# ImageEnhance Module

The ImageEnhance can be used for image enhancement.

from PIL import ImageEnhance
enhancer = ImageEnhance.Sharpness(image)
for i in range(8):
    factor = i / 4.0
    enhancer.enhance(factor).show("Sharpness %f" % factor)

Also see the enhancer.py demo program in the Scripts/ directory.
Classes

All enhancement classes implement a common interface, containing a single method:

class PIL.ImageEnhance._Enhance
    enhance(factor)
    Returns an enhanced image.
    Parameters:	factor  A floating point value controlling the enhancement. Factor 1.0 always returns a copy of the original image, lower factors mean less color (brightness, contrast, etc), and higher values more. There are no restrictions on this value.
    Return type:	Image

class PIL.ImageEnhance.Color(image)
    Adjust image color balance.
    This class can be used to adjust the colour balance of an image, in a manner similar to the 
    controls on a colour TV set. An enhancement factor of 0.0 gives a black and white image. 
    A factor of 1.0 gives the original image.
    
class PIL.ImageEnhance.Contrast(image)
    Adjust image contrast.
    This class can be used to control the contrast of an image, similar to the contrast control 
    on a TV set. An enhancement factor of 0.0 gives a solid grey image. A factor of 1.0 gives the original image.

class PIL.ImageEnhance.Brightness(image)
    Adjust image brightness.
    This class can be used to control the brightness of an image. 
    An enhancement factor of 0.0 gives a black image. A factor of 1.0 gives the original image.

class PIL.ImageEnhance.Sharpness(image)
    Adjust image sharpness.
    This class can be used to adjust the sharpness of an image. 
    An enhancement factor of 0.0 gives a blurred image, a factor of 1.0 gives the original image, 
    and a factor of 2.0 gives a sharpened image.



# ImageMath Module

The ImageMath module can be used to evaluate image expressions. 
The module provides a single eval function, which takes an expression string and one or more images.
Example: Using the ImageMath module

from PIL import Image, ImageMath

im1 = Image.open("image1.jpg")
im2 = Image.open("image2.jpg")

out = ImageMath.eval("convert(min(a, b), 'L')", a=im1, b=im2)
out.save("result.png")

PIL.ImageMath.eval(expression, environment)
    Evaluate expression in the given environment.
    In the current version, ImageMath only supports single-layer images. To process multi-band images, 
    use the split() method or merge() function.
    Parameters:	
        expression  A string which uses the standard Python expression syntax. In addition to the standard operators, you can also use the functions described below.
        environment  A dictionary that maps image names to Image instances. You can use one or more keyword arguments instead of a dictionary, as shown in the above example. Note that the names must be valid Python identifiers.

    Returns:	
    An image, an integer value, a floating point value, or a pixel tuple, depending on the expression.

Expression syntax
Expressions are standard Python expressions, but theyre evaluated in a non-standard environment. 
You can use PIL methods as usual, plus the following set of operators and functions:
Standard Operators
You can use standard arithmetical operators for addition (+), subtraction (-), multiplication (*), 
and division (/).

The module also supports unary minus (-), modulo (%), and power (**) operators.
Note that all operations are done with 32-bit integers or 32-bit floating point values, as necessary. For example, if you add two 8-bit images, the result will be a 32-bit integer image. If you add a floating point constant to an 8-bit image, the result will be a 32-bit floating point image.

You can force conversion using the convert(), float(), and int() functions described below.
Bitwise Operators

The module also provides operations that operate on individual bits. This includes and (&), or (|), 
and exclusive or (^). You can also invert (~) all pixel bits.
Note that the operands are converted to 32-bit signed integers before the bitwise operation is applied. 
This means that youll get negative values if you invert an ordinary greyscale image. 
You can use the and (&) operator to mask off unwanted bits.

Bitwise operators dont work on floating point images.
Logical Operators

Logical operators like and, or, and not work on entire images, rather than individual pixels.

An empty image (all pixels zero) is treated as false. All other images are treated as true.

Note that and and or return the last evaluated operand, while not always returns a boolean value.
Built-in Functions

These functions are applied to each individual pixel.

abs(image)
    Absolute value.

convert(image, mode)
    Convert image to the given mode. The mode must be given as a string constant.

float(image)
    Convert image to 32-bit floating point. This is equivalent to convert(image, F).

int(image)
    Convert image to 32-bit integer. This is equivalent to convert(image, I).
    Note that 1-bit and 8-bit images are automatically converted to 32-bit integers if necessary to get a correct result.

max(image1, image2)
    Maximum value.

min(image1, image2)
    Minimum value.



# ImageColor Module

The ImageColor module supports the following string formats:
    Hexadecimal color specifiers, given as #rgb or #rrggbb. For example, #ff0000 specifies pure red.
    RGB functions, given as rgb(red, green, blue) where the color values are integers in the range 0 to 255.
    Alternatively, the color values can be given as three percentages (0% to 100%). 
    For example, rgb(255,0,0) and rgb(100%,0%,0%) both specify pure red.
    Hue-Saturation-Lightness (HSL) functions, given as hsl(hue, saturation%, lightness%) where hue 
    is the color given as an angle between 0 and 360 (red=0, green=120, blue=240), 
    saturation is a value between 0% and 100% (gray=0%, full color=100%), and lightness is a 
    value between 0% and 100% (black=0%, normal=50%, white=100%). For example, hsl(0,100%,50%) is pure red.
    Common HTML color names. The ImageColor module provides some 140 standard color names, 
    based on the colors supported by the X Window system and most web browsers. color names 
    are case insensitive. For example, red and Red both specify pure red.
    
PIL.ImageColor.getrgb(color)

    Convert a color string to an RGB tuple. If the string cannot be parsed, this function raises a 
    ValueError exception.
    Parameters:	color  A color string

PIL.ImageColor.getcolor(color, mode)

    Same as getrgb(), but converts the RGB value to a greyscale value if the mode is not color 
    or a palette image. If the string cannot be parsed, this function raises a ValueError exception.
    Parameters:	color  A color string
    Returns:	(graylevel [, alpha]) or (red, green, blue[, alpha])

# Image processing

PIL.Image.alpha_composite(im1, im2)
        im1  The first image. Must have mode RGBA.
        im2  The second image. Must have mode RGBA, and the same size as the first image.

PIL.Image.blend(im1, im2, alpha)
        im1  The first image.
        im2  The second image. Must have the same mode and size as the first image.
        alpha  The interpolation alpha factor. 
        If alpha is 0.0, a copy of the first image is returned. 
        If alpha is 1.0, a copy of the second image is returned.
        
PIL.Image.composite(image1, image2, mask)
        image1  The first image.
        image2  The second image. Must have the same mode and size as the first image.
        mask  A mask image. This image can have mode 1, L, or RGBA, 
        and must have the same size as the other two images.

PIL.Image.eval(image, *args)

    Applies the function (which should take one argument) to each pixel in the given image. 
    If the image has more than one band, the same function is applied to each band. 
    Note that the function is evaluated once for each possible pixel value, so you cannot 
    use random components or other generators.
    Parameters:	

PIL.Image.merge(mode, bands)

        mode  The mode to use for the output image. See: Modes.
        bands  A sequence containing one single-band image for each band in 
        the output image. All bands must have the same size.

PIL.Image.new(mode, size, color=0)

        mode  The mode to use for the new image. See: Modes.
        size  A 2-tuple, containing (width, height) in pixels.
        color  What color to use for the image. Default is black. 
        If given, this should be a single integer or floating point value for 
        single-band modes, and a tuple for multi-band modes (one value per band). 
        When creating RGB images, you can also use color strings as supported 
        by the ImageColor module. If the color is None, the image is not initialised.

PIL.Image.fromarray(obj, mode=None)

    Creates an image memory from an object exporting the array interface (using the buffer protocol).
    If obj is not contiguous, then the tobytes method is called and frombuffer() is used.

PIL.Image.frombytes(mode, size, data, decoder_name='raw', *args)
        mode  The image mode. See: Modes.
        size  The image size.
        data  A byte buffer containing raw data for the given mode.
        decoder_name  What decoder to use.
        args  Additional parameters for the given decoder.


PIL.Image.fromstring(*args, **kw)
PIL.Image.frombuffer(mode, size, data, decoder_name='raw', *args)
PIL.Image.register_open(id, factory, accept=None)
PIL.Image.register_mime(id, mimetype)
PIL.Image.register_save(id, driver)
PIL.Image.register_extension(id, extension)

class PIL.Image.Image
        open()
        new()
        frombytes()


Image.convert(mode=None, matrix=None, dither=None, palette=0, colors=256)

    Returns a converted copy of this image. For the P mode, this method 
    translates pixels through the palette. If mode is omitted, a mode is 
    chosen so that all information in the image and the palette can be represented without a palette.
    The current version supports all possible conversions between L, RGB and CMYK. 
    The matrix argument only supports L and RGB.
    When translating a color image to black and white (mode L), the library uses the 
    ITU-R 601-2 luma transform:
    L = R * 299/1000 + G * 587/1000 + B * 114/1000
    The default method of converting a greyscale (L) or RGB image into a bilevel (mode 1) image uses Floyd-Steinberg dither to approximate the original image luminosity levels. If dither is NONE, all non-zero values are set to 255 (white). To use other thresholds, use the point() method.
    Parameters:	

        mode  The requested mode. See: Modes.
        matrix  An optional conversion matrix. If given, this should be 4- or 12-tuple containing floating point values.
        dither  Dithering method, used when converting from mode RGB to P or from RGB or L to 1. Available methods are NONE or FLOYDSTEINBERG (default).
        palette  Palette to use when converting from mode RGB to P. Available palettes are WEB or ADAPTIVE.
        colors  Number of colors to use for the ADAPTIVE palette. Defaults to 256.

The following example converts an RGB image (linearly calibrated according to ITU-R 709, 
                                             using the D65 luminant) to the CIE XYZ color space:

rgb2xyz = (
    0.412453, 0.357580, 0.180423, 0,
    0.212671, 0.715160, 0.072169, 0,
    0.019334, 0.119193, 0.950227, 0 )
out = im.convert("RGB", rgb2xyz)

Image.copy()
    Copies this image. Use this method if you wish to paste things into an image, but still retain the original.

Image.crop(box=None)
    The box is a 4-tuple defining the left, upper, right, and lower pixel coordinate.

Image.draft(mode, size)

    Configures the image file loader so it returns a version of the image that as closely 
    as possible matches the given mode and size. For example, you can use this method to 
    convert a color JPEG to greyscale while loading it, or to extract a 128x192 version from a PCD file.

Image.filter(filter)

    Filters this image using the given filter. See the ImageFilter module.
    
Image.getbands()

    Returns a tuple containing the name of each band in this image. For example, getbands on an 
    RGB image returns (R, G, B).

Image.getbbox()

    Calculates the bounding box of the non-zero regions in the image.
    Returns:	The bounding box is returned as a 4-tuple defining the 
    left, upper, right, and lower pixel coordinate. If the image is completely empty, this method returns None.

Image.getcolors(maxcolors=256)

    Returns a list of colors used in this image.
    Parameters:	maxcolors  Maximum number of colors. If this number is exceeded, 
        this method returns None. The default limit is 256 colors.

Image.getdata(band=None)

    Returns the contents of this image as a sequence object containing pixel values. 
    The sequence object is flattened, so that values for line one follow directly 
    after the values of line zero, and so on.
    Note that the sequence object returned by this method is an internal PIL data type, which only supports certain sequence operations. To convert it to an ordinary sequence (e.g. for printing), use list(im.getdata()).
    Parameters:	band  What band to return. The default is to return all bands. 
    To return a single band, pass in the index value (e.g. 0 to get the R band from an RGB image).
    

Image.getextrema()

    Gets the the minimum and maximum pixel values for each band in the image.
    
Image.getpalette()

    Returns the image palette as a list.


Image.getpixel(xy)

    Returns the pixel value at a given position.

Image.histogram(mask=None, extrema=None)

    Returns a histogram for the image. The histogram is returned as a list of pixel counts, 
    one for each pixel value in the source image. If the image has more than one band, 
    the histograms for all bands are concatenated (for example, the histogram for an RGB 
    image contains 768 values).
    A bilevel image (mode 1) is treated as a greyscale (L) image by this method.

    If a mask is provided, the method returns a histogram for those parts of the image 
    where the mask image is non-zero. The mask image must have the same size as the image, 
    and be either a bi-level image (mode 1) or a greyscale image (L).
    
Image.offset(xoffset, yoffset=None)

Image.paste(im, box=None, mask=None)

    Pastes another image into this image. The box argument is either a 2-tuple 
    giving the upper left corner, a 4-tuple defining the left, upper, right, and 
    lower pixel coordinate, or None (same as (0, 0)). If a 4-tuple is given, the 
    size of the pasted image must match the size of the region.

    If the modes dont match, the pasted image is converted to the mode of this 
    image (see the convert() method for details).

    Instead of an image, the source can be a integer or tuple containing pixel 
    values. The method then fills the region with the given color. When creating 
    RGB images, you can also use color strings as supported by the ImageColor module.

    If a mask is given, this method updates only the regions indicated by the mask. 
    You can use either 1, L or RGBA images (in the latter case, the alpha 
    band is used as mask). Where the mask is 255, the given image is copied as is. 
    Where the mask is 0, the current value is preserved. Intermediate values will mix 
    the two images together, including their alpha channels if they have them.

    See alpha_composite() if you want to combine images with respect to their alpha channels.
    Parameters:	

        im  Source image or pixel value (integer or tuple).
        box 

        An optional 4-tuple giving the region to paste into. If a 2-tuple is used instead, its treated as the upper left corner. If omitted or None, the source is pasted into the upper left corner.

        If an image is given as the second argument and there is no third, the box defaults to (0, 0), and the second argument is interpreted as a mask image.
        mask  An optional mask image.

Image.point(lut, mode=None)

        lut  A lookup table, containing 256 (or 65336 if self.mode==I and mode == L) values per band in the image. A function can be used instead, it should take a single argument. The function is called once for each possible pixel value, and the resulting table is applied to all bands of the image.
        mode  Output mode (default is same as input). In the current version, this can only be used if the source image has mode L or P, and the output has mode 1 or the source image mode is I and the output mode is L.

Image.putalpha(alpha)

    Adds or replaces the alpha layer in this image. If the image does not have an alpha layer, 
    its converted to LA or RGBA. The new layer must be either L or 1.
    Parameters:	alpha  The new alpha layer. This can either be an L or 1 
        image having the same size as this image, or an integer or other color value.

Image.putdata(data, scale=1.0, offset=0.0)

    Copies pixel data to this image. This method copies data from a sequence object into the image, 
    starting at the upper left corner (0, 0), and continuing until either the image or the sequence ends. The scale and offset values are used to adjust the sequence values: pixel = value*scale + offset.
    Parameters:	
        data  A sequence object.
        scale  An optional scale value. The default is 1.0.
        offset  An optional offset value. The default is 0.0.

Image.putpalette(data, rawmode='RGB')

    Attaches a palette to this image. The image must be a P or L image, 
    and the palette sequence must contain 768 integer values, where each group of 
    three values represent the red, green, and blue values for the corresponding pixel index. 
    Instead of an integer sequence, you can use an 8-bit string.
    Parameters:	data  A palette sequence (either a list or a string).

Image.putpixel(xy, value)

    Modifies the pixel at the given position. The color is given as a single numerical 
    value for single-band images, and a tuple for multi-band images.

    Note that this method is relatively slow. For more extensive changes, use paste() 
    or the ImageDraw module instead.
    See:
        paste()
        putdata()
        ImageDraw
    Parameters:	
        xy  The pixel coordinate, given as (x, y).
        value  The pixel value.

Image.quantize(colors=256, method=None, kmeans=0, palette=None)

    Convert the image to P mode with the specified number of colors.
    Parameters:	
        colors  The desired number of colors, <= 256
        method  0 = median cut 1 = maximum coverage 2 = fast octree 3 = libimagequant
        kmeans  Integer
        palette  Quantize to the PIL.ImagingPalette palette.

Image.resize(size, resample=0)

    Returns a resized copy of this image.
    Parameters:	
        size  The requested size in pixels, as a 2-tuple: (width, height).
        resample  An optional resampling filter. This can be one of PIL.Image.NEAREST, PIL.Image.BOX, PIL.Image.BILINEAR, PIL.Image.HAMMING, PIL.Image.BICUBIC or PIL.Image.LANCZOS. If omitted, or if the image has mode 1 or P, it is set PIL.Image.NEAREST. See: Filters.

Image.rotate(angle, resample=0, expand=0, center=None, translate=None)

    Returns a rotated copy of this image. This method returns a copy of this image, rotated the given number of degrees counter clockwise around its centre.
    Parameters:	
        angle  In degrees counter clockwise.
        resample  An optional resampling filter. This can be one of PIL.Image.NEAREST (use nearest neighbour), 
        PIL.Image.BILINEAR (linear interpolation in a 2x2 environment), 
        or PIL.Image.BICUBIC (cubic spline interpolation in a 4x4 environment). 
        If omitted, or if the image has mode 1 or P, it is set PIL.Image.NEAREST. See Filters.
        expand  Optional expansion flag. If true, expands the output image to make it large enough 
        to hold the entire rotated image. If false or omitted, make the output image the same size 
        as the input image. Note that the expand flag assumes rotation around the center and no translation.
        center  Optional center of rotation (a 2-tuple). Origin is the upper left corner. 
        Default is the center of the image.
        translate  An optional post-rotate translation (a 2-tuple).

Image.save(fp, format=None, **params)

    Saves this image under the given filename. If no format is specified, the format to use 
    is determined from the filename extension, if possible.

    Keyword options can be used to provide additional instructions to the writer. 
    If a writer doesnt recognise an option, it is silently ignored. 
    The available options are described in the image format documentation for each writer.
   
    You can use a file object instead of a filename. In this case, you must always specify the format. 
    The file object must implement the seek, tell, and write methods, and be opened in binary mode.
    Parameters:	

        fp  A filename (string), pathlib.Path object or file object.
        format  Optional format override. If omitted, the format to use is determined from the filename extension. If a file object was used instead of a filename, this parameter should always be used.
        options  Extra parameters to the image writer.

        KeyError  If the output format could not be determined from the file name. Use the format option to solve this.
        IOError  If the file could not be written. The file may have been created, and may contain partial data.

Image.seek(frame)

    Seeks to the given frame in this sequence file. If you seek beyond the end of the sequence, 
    the method raises an EOFError exception. When a sequence file is opened, the library 
    automatically seeks to frame 0.

    Note that in the current version of the library, most sequence formats only allows you 
    to seek to the next frame.
    See tell().
    Parameters:	frame  Frame number, starting at 0.
    Raises:	EOFError  If the call attempts to seek beyond the end of the sequence.

Image.show(title=None, command=None)

    Displays this image. This method is mainly intended for debugging purposes.
    On Unix platforms, this method saves the image to a temporary PPM file, and calls 
    either the xv utility or the display utility, depending on which one can be found.
    title  Optional title to use for the image window, where possible.
    command  command used to show the image

Image.split()

    Split this image into individual bands. This method returns a tuple of individual image bands 
    from an image. For example, splitting an RGB image creates three new images each containing 
    a copy of one of the original bands (red, green, blue).

Image.tell()

    Returns the current frame number. See seek(). Returns:	Frame number, starting with 0.

Image.thumbnail(size, resample=3)

    Make this image into a thumbnail. This method modifies the image to contain a thumbnail 
    version of itself, no larger than the given size. This method calculates an appropriate 
    thumbnail size to preserve the aspect of the image, calls the draft() method to configure 
    the file reader (where applicable), and finally resizes the image.

    Note that this function modifies the Image object in place. If you need to use the full 
    resolution image as well, apply this method to a copy() of the original image.
    Parameters:	

    size  Requested size.
    resample  Optional resampling filter. This can be one of PIL.Image.NEAREST, PIL.Image.BILINEAR, PIL.Image.BICUBIC, or PIL.Image.LANCZOS. If omitted, it defaults to PIL.Image.BICUBIC. (was PIL.Image.NEAREST prior to version 2.5.0)

Image.tobitmap(name='image')

    Returns the image converted to an X11 bitmap.
    This method only works for mode 1 images.
    Parameters:	name  The name prefix to use for the bitmap variables.
    Returns:	A string containing an X11 bitmap.
    Raises:	ValueError  If the mode is not 1

Image.tobytes(encoder_name='raw', *args)

    Return image as a bytes object.
    Warning
    This method returns the raw image data from the internal storage. For compressed 
    image data (e.g. PNG, JPEG) use save(), with a BytesIO parameter for in-memory data.
    Parameters:	
        encoder_name  What encoder to use. The default is to use the standard raw encoder.
        args  Extra arguments to the encoder.

Image.tostring(*args, **kw)

Image.transform(size, method, data=None, resample=0, fill=1)

    Transforms this image. This method creates a new image with the given size, 
    and the same mode as the original, and copies data to the new image using the given transform.
    Parameters:	
        size  The output size.
        method  The transformation method. This is one of PIL.Image.EXTENT (cut out a rectangular subregion), PIL.Image.AFFINE (affine transform), PIL.Image.PERSPECTIVE (perspective transform), PIL.Image.QUAD (map a quadrilateral to a rectangle), or PIL.Image.MESH (map a number of source quadrilaterals in one operation).
        data  Extra data to the transformation method.
        resample  Optional resampling filter. It can be one of PIL.Image.NEAREST (use nearest neighbour), PIL.Image.BILINEAR (linear interpolation in a 2x2 environment), or PIL.Image.BICUBIC (cubic spline interpolation in a 4x4 environment). If omitted, or if the image has mode 1 or P, it is set to PIL.Image.NEAREST.

Image.transpose(method)

    Transpose image (flip or rotate in 90 degree steps)
    Parameters:	method  One of PIL.Image.FLIP_LEFT_RIGHT, PIL.Image.FLIP_TOP_BOTTOM, PIL.Image.ROTATE_90, PIL.Image.ROTATE_180, PIL.Image.ROTATE_270 or PIL.Image.TRANSPOSE.
    Returns:	Returns a flipped or rotated copy of this image.

Image.verify()

    Verifies the contents of a file. For data read from a file, this method attempts to 
    determine if the file is broken, without actually decoding the image data. If this method finds any problems, it raises suitable exceptions. If you need to load the image after using this method, you must reopen the image file.

Image.fromstring(*args, **kw)

Image.load()

    Allocates storage for the image and loads the pixel data. In normal cases, 
    you dont need to call this method, since the Image class automatically loads an 
    opened image when it is accessed for the first time. This method will close the 
    file associated with the image.
    Returns:	An image access object.
    Return type:	PixelAccess Class or PIL.PyAccess

Image.close()

    Closes the file pointer, if possible.
    This operation will destroy the image core and release its memory. 
    The image data will be unusable afterward.
    This function is only required to close images that have not had their file 
    read and closed by the load() method.

Instances of the Image class have the following attributes:

PIL.Image.format
    The file format of the source file. For images created by the library itself 
    (via a factory function, or by running a method on an existing image), this attribute is set to None.
    Type:	string or None

PIL.Image.mode
    Image mode. This is a string specifying the pixel format used by the image. 
    Typical values are 1, L, RGB, or CMYK. See Modes for a full list.
    Type:	string

PIL.Image.size
    Image size, in pixels. The size is given as a 2-tuple (width, height).
    Type:	(width, height)

PIL.Image.width
    Image width, in pixels.
    Type:	int

PIL.Image.height
    Image height, in pixels.
    Type:	int

PIL.Image.palette
    Colour palette table, if any. If mode is P, this should be an instance of the 
    ImagePalette class. Otherwise, it should be set to None.
    Type:	ImagePalette or None

PIL.Image.info
    A dictionary holding data associated with the image. This dictionary is used by file 
    handlers to pass on various non-image information read from the file. See documentation 
    for the various file handlers for details.
    Most methods ignore the dictionary when returning new images; since the keys are not 
    standardized, its not possible for a method to know if the operation affects the 
    dictionary. If you need the information later on, keep a reference to the info 
    dictionary returned from the open method.

from PIL import Image
filename = "/home/jack/Pictures/A_full_sized_highly_detailed_cad_drawn_blueprint_of_a_Mechanical_Toad_artistic_style_of_H._R._Giger (2).png" 
im = Image.open(filename)
im

from OutlineImage import outlineP
filename1 = "/home/jack/Pictures/A_full_sized_highly_detailed_cad_drawn_blueprint_of_a_Mechanical_Toad_artistic_style_of_H._R._Giger (2).png" 
filename1 = "onevid/tempp.png"
outfile_png = "onevid/temppp.png" 
outlineP(filename1,outfile_png)

from PIL import Image
#filename = "/home/jack/Pictures/A_full_sized_highly_detailed_cad_drawn_blueprint_of_a_Mechanical_Toad_artistic_style_of_H._R._Giger (2).png" 
im = Image.open(outfile_png)
im

photo_image_path = "/home/jack/Pictures/A_full_sized_highly_detailed_cad_drawn_blueprint_of_a_Mechanical_Toad_artistic_style_of_H._R._Giger (2).png" 
watermark_image_path = "/home/jack/Desktop/dockercommands/frame-lite.png"
image = Image.open(photo_image_path).convert('RGBA')
w,h = image.size
watermark = Image.open(watermark_image_path).convert('RGBA')
watermark = watermark.resize((w,h),Image.NEAREST)
layer = Image.new('RGBA', image.size, (0, 0, 0, 0))
x=0
y=0
layer.paste(watermark, (x, y))

# Create a copy of the layer
layer2 = layer.copy()

# Put alpha on the copy
layer2.putalpha(65)

# merge layers with mask
layer.paste(layer2, layer)


result = Image.alpha_composite(image, layer)

result

from PIL import Image
from PIL.Image import Exif
from PIL.ExifTags import TAGS, GPSTAGS

def get_exif(file_name) -> Exif:
    image: Image.Image = Image.open(file_name)
    return image.getexif()


def get_labeled_exif(exif):
    return {
        TAGS.get(key, key): value
        for key, value in exif.items()
    }


def get_geo(labeled_exif):
    gps_info = labeled_exif.get("GPSInfo", {})
    return {
        GPSTAGS.get(key, key): value
        for key, value in gps_info.items()
    }

if __name__ == '__main__':
    exif = get_exif("/home/jack/Pictures/content_example_ibiza.jpg")
    labeled_exif = get_labeled_exif(exif)
    #geo = get_geo(labeled_exif)
    #print(geo)
    print(labeled_exif)

class Foo(object):
    def __init__(self, val=2):
        self.val = val
    def __getstate__(self):
        print("I'm being pickled")
        self.val *= 2
        return self.__dict__
    def __setstate__(self, d):
        print("I'm being unpickled with these values: " + repr(d))
        self.__dict__ = d
        self.val *= 3

import pickle
f = Foo()
f_data = pickle.dumps(f)
f_new = pickle.loads(f_data)


img = Image.open("/home/jack/Pictures/content_example_ibiza.jpg")
img


# importing Image module from PIL package
from PIL import Image

# creating image object
img = Image.open("/home/jack/Pictures/content_example_ibiza.jpg")

# using image transform method
img1 = img.transform((300, 300), Image.EXTENT,
	data =[200, 20, 100 + img.width // 2, img.height // 2 ])
img1.save("junk/SHIP.jpg")
img1


import sys
from PIL import Image

img = Image.open("junk/SHIP.jpg")
width, height = img.size
m = -0.5
xshift = abs(m) * width
new_width = width + int(round(xshift))
img = img.transform((new_width, height), Image.AFFINE,
        (1, m, -xshift if m > 0 else 0, 0, 1, 0), Image.BICUBIC)
img.save("junk/SHIP-T.jpg")
img

import os
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt


def find_coefs(original_coords, warped_coords):
        matrix = []
        for p1, p2 in zip(original_coords, warped_coords):
            matrix.append([p1[0], p1[1], 1, 0, 0, 0, -p2[0]*p1[0], -p2[0]*p1[1]])
            matrix.append([0, 0, 0, p1[0], p1[1], 1, -p2[1]*p1[0], -p2[1]*p1[1]])

        A = np.matrix(matrix, dtype=float)
        B = np.array(warped_coords).reshape(8)

        res = np.dot(np.linalg.inv(A.T * A) * A.T, B)
        return np.array(res).reshape(8)


coefs = find_coefs(
                  [(867,652), (1020,580), (1206,666), (1057,757)],
                  [(700,732), (869,754), (906,916), (712,906)]
                  )

coefs_inv = find_coefs(
                  [(700,732), (869,754), (906,916), (712,906)],
                  [(867,652), (1020,580), (1206,666), (1057,757)]
                  )
filename = "/home/jack/Pictures/content_example_ibiza.jpg"
image = Image.open(filename)

img = image.transform(((1500,800)),
                      method=Image.PERSPECTIVE,
                      data=coefs_inv)

a, b, c, d, e, f, g, h = coefs

old_p1 = [50, 100]
x,y = old_p1
new_x = (a * x + b * y + c) / (g * x + h * y + 1)
new_y = (d * x + e * y + f) / (g * x + h * y + 1)
new_p1 = (int(new_x),int(new_y))

old_p2 = [400, 500]
x,y = old_p2
new_x = (a * x + b * y + c) / (g * x + h * y + 1)
new_y = (d * x + e * y + f) / (g * x + h * y + 1)
new_p2 = (int(new_x),int(new_y))



plt.figure()
plt.imshow(image)
plt.scatter([old_p1[0], old_p2[0]],[old_p1[1], old_p2[1]]  , s=150, marker='.', c='b')
plt.show()


plt.figure()
plt.imshow(img)
plt.scatter([new_p1[0], new_p2[0]],[new_p1[1], new_p2[1]]  , s=150, marker='.', c='r')

plt.show()

I = np.asarray(Image.open("junk/SHIP.jpg"))
#Do some stuff to I, then, convert it back to an image:

from PIL import ImageFilter

# Open an already existing image


# Apply sharp filter
#sharpened1 = I.filter(ImageFilter.SHARPEN);
#I = sharpened1.filter(ImageFilter.SHARPEN);


im = Image.fromarray(np.uint8(I))
im

import numpy as np
from PIL import Image
import scipy.signal
from scipy.signal import convolve2d
filename = "/home/jack/Pictures/content_example_ibiza.jpg"
image = Image.open(filename)
img_array = np.array(image)


def RGB_convolve(image,kern):
    image2 = np.empty_like(image)
    for dim in range(image.shape[-1]):
        image2[:,:,dim]=convolve2d(image[:,:,dim],kern, 'same')
    return image2

KERNEL_sharpen = np.array([[0,-1,0],[-1,5,-1],[0,-1,0]])
im_filtered = RGB_convolve(img_array,KERNEL_sharpen)

#output_image = Image.fromarray(im_filtered)
#display(output_image)
output_image = Image.fromarray(im_filtered.astype('uint8'))
display(output_image)

# Load image
import cv2
import numpy as np
from matplotlib import pyplot as plt

# Load image as grayscale
filename = "/home/jack/Pictures/content_example_ibiza.jpg"
image = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)
# Create kernel
kernel = np.array([[0, -1, 0], 
                   [-1, 5,-1], 
                   [0, -1, 0]])

# Sharpen image
image_sharp = cv2.filter2D(image, -1, kernel)
# Show image
plt.imshow(image_sharp, cmap='gray'), plt.axis("off")
plt.show()


import numpy as np

def create_perspective_transform_matrix(src, dst):
    """ Creates a perspective transformation matrix which transforms points
        in quadrilateral ``src`` to the corresponding points on quadrilateral
        ``dst``.

        Will raise a ``np.linalg.LinAlgError`` on invalid input.
        """
    # See:
    # * http://xenia.media.mit.edu/~cwren/interpolator/
    # * http://stackoverflow.com/a/14178717/71522
    in_matrix = []
    for (x, y), (X, Y) in zip(src, dst):
        in_matrix.extend([
            [x, y, 1, 0, 0, 0, -X * x, -X * y],
            [0, 0, 0, x, y, 1, -Y * x, -Y * y],
        ])

    A = np.matrix(in_matrix, dtype=np.float)
    B = np.array(dst).reshape(8)
    af = np.dot(np.linalg.inv(A.T * A) * A.T, B)
    return np.append(np.array(af).reshape(8), 1).reshape((3, 3))


def create_perspective_transform(src, dst, round=False, splat_args=False):
    """ Returns a function which will transform points in quadrilateral
        ``src`` to the corresponding points on quadrilateral ``dst``::

            >>> transform = create_perspective_transform(
            ...     [(0, 0), (10, 0), (10, 10), (0, 10)],
            ...     [(50, 50), (100, 50), (100, 100), (50, 100)],
            ... )
            >>> transform((5, 5))
            (74.99999999999639, 74.999999999999957)

        If ``round`` is ``True`` then points will be rounded to the nearest
        integer and integer values will be returned.

            >>> transform = create_perspective_transform(
            ...     [(0, 0), (10, 0), (10, 10), (0, 10)],
            ...     [(50, 50), (100, 50), (100, 100), (50, 100)],
            ...     round=True,
            ... )
            >>> transform((5, 5))
            (75, 75)

        If ``splat_args`` is ``True`` the function will accept two arguments
        instead of a tuple.

            >>> transform = create_perspective_transform(
            ...     [(0, 0), (10, 0), (10, 10), (0, 10)],
            ...     [(50, 50), (100, 50), (100, 100), (50, 100)],
            ...     splat_args=True,
            ... )
            >>> transform(5, 5)
            (74.99999999999639, 74.999999999999957)

        If the input values yield an invalid transformation matrix an identity
        function will be returned and the ``error`` attribute will be set to a
        description of the error::

            >>> tranform = create_perspective_transform(
            ...     np.zeros((4, 2)),
            ...     np.zeros((4, 2)),
            ... )
            >>> transform((5, 5))
            (5.0, 5.0)
            >>> transform.error
            'invalid input quads (...): Singular matrix
        """
    try:
        transform_matrix = create_perspective_transform_matrix(src, dst)
        error = None
    except np.linalg.LinAlgError as e:
        transform_matrix = np.identity(3, dtype=np.float)
        error = "invalid input quads (%s and %s): %s" %(src, dst, e)
        error = error.replace("\n", "")

    to_eval = "def perspective_transform(%s):\n" %(
        splat_args and "*pt" or "pt",
    )
    to_eval += "  res = np.dot(transform_matrix, ((pt[0], ), (pt[1], ), (1, )))\n"
    to_eval += "  res = res / res[2]\n"
    if round:
        to_eval += "  return (int(round(res[0][0])), int(round(res[1][0])))\n"
    else:
        to_eval += "  return (res[0][0], res[1][0])\n"
    locals = {
        "transform_matrix": transform_matrix,
    }
    locals.update(globals())
    exec to_eval in locals, locals
    res = locals["perspective_transform"]
    res.matrix = transform_matrix
    res.error = error
    return res


from PyDraw import pydraw
img = pydraw.Image().new(width=500,height=500)
img.drawbezier([(22,22),(88,88),(188,22),(333,88)], fillcolor=(222,0,0))
img.drawcircle(333,111,fillsize=55,outlinecolor=(222,222,0))
img.drawline(0,250,499,250, fillcolor=(222,222,222))
img.floodfill(444,444,fillcolor=(0,222,0))
img.floodfill(222,222,fillcolor=(0,0,222))
img.view()

from __future__ import absolute_import

from pyping.core import *
#from .core import *

import pydraw

https://pypi.org/project/pydraw/

from pydraw import *
from tkinter import Tk
import sys
screen = Screen(800, 600, 'My First Project!')

# Here we create a rectangle at x=50, y=50 that is 50 pixels wide and 50 pixels tall.
# It is top-left anchored. This means that the position is the location of the top left corner.
# It's important to know that pydraw's canvas has the origin in the top left, with
# positive-y at the bottom of the screen, and positive-x to the right of the screen.
box = Rectangle(screen, 50, 50, 50, 50) 
a = Tk()
fps = 30
running = True
while running:
    screen.update()
    screen.sleep(1 / fps)

#screen.sys.exit()
#screen.exit()

def shutdown_ttk_repeat():
    a.eval('::ttk::CancelRepeat')
    a.destroy()
    tk.destroy()

a.protocol("WM_DELETE_WINDOW", shutdown_ttk_repeat)
a.mainloop()


self.parent.quit()
parent.quit()

winfo.distroy()
tk.destroy()

screen.close()
box.close()


I've encountered a similar problem recently. The error message is exactly the same. 
I solved that by adding a a.quit() in an Exit method. (before that there was only 
                                                       a.destroy() in this method) 
Maybe you have already solved this question. But schlenk's answer doesn't work well 
on me. So I hope my answer can give another clue to such question


del box
del screen

from tkinter import Tk,Label,Button
from tkinter import ttk
from tkinter.ttk import Combobox

def cbox_do(event):
    'Used for cbox.'
    clabel.config(text=cbox.get())

a = Tk()
cbox = Combobox(a, value=('Luke','Biggs','Wedge'), takefocus=0)
cbox.bind("<<ComboboxSelected>>", cbox_do)
cbox.pack()
clabel = Label(a)
clabel.pack()

def shutdown_ttk_repeat():
    a.eval('::ttk::CancelRepeat')
    a.destroy()

a.protocol("WM_DELETE_WINDOW", shutdown_ttk_repeat)
a.mainloop()



from PIL import Image
filename = "/home/jack/Pictures/A_full_sized_highly_detailed_cad_drawn_blueprint_of_a_Mechanical_Toad_artistic_style_of_H._R._Giger (2).png" 
im = Image.open(filename)
im

from OutlineImage import outlineP
filename1 = "/home/jack/Pictures/A_full_sized_highly_detailed_cad_drawn_blueprint_of_a_Mechanical_Toad_artistic_style_of_H._R._Giger (2).png" 
filename1 = "onevid/tempp.png"
outfile_png = "onevid/temppp.png" 
outlineP(filename1,outfile_png)

from PIL import Image
#filename = "/home/jack/Pictures/A_full_sized_highly_detailed_cad_drawn_blueprint_of_a_Mechanical_Toad_artistic_style_of_H._R._Giger (2).png" 
im = Image.open(outfile_png)
im

photo_image_path = "/home/jack/Pictures/A_full_sized_highly_detailed_cad_drawn_blueprint_of_a_Mechanical_Toad_artistic_style_of_H._R._Giger (2).png" 
watermark_image_path = "/home/jack/Desktop/dockercommands/frame-lite.png"
image = Image.open(photo_image_path).convert('RGBA')
w,h = image.size
watermark = Image.open(watermark_image_path).convert('RGBA')
watermark = watermark.resize((w,h),Image.NEAREST)
layer = Image.new('RGBA', image.size, (0, 0, 0, 0))
x=0
y=0
layer.paste(watermark, (x, y))

# Create a copy of the layer
layer2 = layer.copy()

# Put alpha on the copy
layer2.putalpha(65)

# merge layers with mask
layer.paste(layer2, layer)


result = Image.alpha_composite(image, layer)

result

from PIL import Image
from PIL.Image import Exif
from PIL.ExifTags import TAGS, GPSTAGS

def get_exif(file_name) -> Exif:
    image: Image.Image = Image.open(file_name)
    return image.getexif()


def get_labeled_exif(exif):
    return {
        TAGS.get(key, key): value
        for key, value in exif.items()
    }


def get_geo(labeled_exif):
    gps_info = labeled_exif.get("GPSInfo", {})
    return {
        GPSTAGS.get(key, key): value
        for key, value in gps_info.items()
    }

if __name__ == '__main__':
    exif = get_exif("/home/jack/Pictures/content_example_ibiza.jpg")
    labeled_exif = get_labeled_exif(exif)
    #geo = get_geo(labeled_exif)
    #print(geo)
    print(labeled_exif)

class Foo(object):
    def __init__(self, val=2):
        self.val = val
    def __getstate__(self):
        print("I'm being pickled")
        self.val *= 2
        return self.__dict__
    def __setstate__(self, d):
        print("I'm being unpickled with these values: " + repr(d))
        self.__dict__ = d
        self.val *= 3

import pickle
f = Foo()
f_data = pickle.dumps(f)
f_new = pickle.loads(f_data)


img = Image.open("/home/jack/Pictures/content_example_ibiza.jpg")
img


# importing Image module from PIL package
from PIL import Image

# creating image object
img = Image.open("/home/jack/Pictures/content_example_ibiza.jpg")

# using image transform method
img1 = img.transform((300, 300), Image.EXTENT,
	data =[200, 20, 100 + img.width // 2, img.height // 2 ])
img1.save("junk/SHIP.jpg")
img1


import sys
from PIL import Image

img = Image.open("junk/SHIP.jpg")
width, height = img.size
m = -0.5
xshift = abs(m) * width
new_width = width + int(round(xshift))
img = img.transform((new_width, height), Image.AFFINE,
        (1, m, -xshift if m > 0 else 0, 0, 1, 0), Image.BICUBIC)
img.save("junk/SHIP-T.jpg")
img

import os
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt


def find_coefs(original_coords, warped_coords):
        matrix = []
        for p1, p2 in zip(original_coords, warped_coords):
            matrix.append([p1[0], p1[1], 1, 0, 0, 0, -p2[0]*p1[0], -p2[0]*p1[1]])
            matrix.append([0, 0, 0, p1[0], p1[1], 1, -p2[1]*p1[0], -p2[1]*p1[1]])

        A = np.matrix(matrix, dtype=float)
        B = np.array(warped_coords).reshape(8)

        res = np.dot(np.linalg.inv(A.T * A) * A.T, B)
        return np.array(res).reshape(8)


coefs = find_coefs(
                  [(867,652), (1020,580), (1206,666), (1057,757)],
                  [(700,732), (869,754), (906,916), (712,906)]
                  )

coefs_inv = find_coefs(
                  [(700,732), (869,754), (906,916), (712,906)],
                  [(867,652), (1020,580), (1206,666), (1057,757)]
                  )
filename = "/home/jack/Pictures/content_example_ibiza.jpg"
image = Image.open(filename)

img = image.transform(((1500,800)),
                      method=Image.PERSPECTIVE,
                      data=coefs_inv)

a, b, c, d, e, f, g, h = coefs

old_p1 = [50, 100]
x,y = old_p1
new_x = (a * x + b * y + c) / (g * x + h * y + 1)
new_y = (d * x + e * y + f) / (g * x + h * y + 1)
new_p1 = (int(new_x),int(new_y))

old_p2 = [400, 500]
x,y = old_p2
new_x = (a * x + b * y + c) / (g * x + h * y + 1)
new_y = (d * x + e * y + f) / (g * x + h * y + 1)
new_p2 = (int(new_x),int(new_y))



plt.figure()
plt.imshow(image)
plt.scatter([old_p1[0], old_p2[0]],[old_p1[1], old_p2[1]]  , s=150, marker='.', c='b')
plt.show()


plt.figure()
plt.imshow(img)
plt.scatter([new_p1[0], new_p2[0]],[new_p1[1], new_p2[1]]  , s=150, marker='.', c='r')

plt.show()

I = np.asarray(Image.open("junk/SHIP.jpg"))
#Do some stuff to I, then, convert it back to an image:

from PIL import ImageFilter

# Open an already existing image


# Apply sharp filter
#sharpened1 = I.filter(ImageFilter.SHARPEN);
#I = sharpened1.filter(ImageFilter.SHARPEN);


im = Image.fromarray(np.uint8(I))
im

import numpy as np
from PIL import Image
import scipy.signal
from scipy.signal import convolve2d
filename = "/home/jack/Pictures/content_example_ibiza.jpg"
image = Image.open(filename)
img_array = np.array(image)


def RGB_convolve(image,kern):
    image2 = np.empty_like(image)
    for dim in range(image.shape[-1]):
        image2[:,:,dim]=convolve2d(image[:,:,dim],kern, 'same')
    return image2

KERNEL_sharpen = np.array([[0,-1,0],[-1,5,-1],[0,-1,0]])
im_filtered = RGB_convolve(img_array,KERNEL_sharpen)

#output_image = Image.fromarray(im_filtered)
#display(output_image)
output_image = Image.fromarray(im_filtered.astype('uint8'))
display(output_image)

# Load image
import cv2
import numpy as np
from matplotlib import pyplot as plt

# Load image as grayscale
filename = "/home/jack/Pictures/content_example_ibiza.jpg"
image = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)
# Create kernel
kernel = np.array([[0, -1, 0], 
                   [-1, 5,-1], 
                   [0, -1, 0]])

# Sharpen image
image_sharp = cv2.filter2D(image, -1, kernel)
# Show image
plt.imshow(image_sharp, cmap='gray'), plt.axis("off")
plt.show()


import numpy as np

def create_perspective_transform_matrix(src, dst):
    """ Creates a perspective transformation matrix which transforms points
        in quadrilateral ``src`` to the corresponding points on quadrilateral
        ``dst``.

        Will raise a ``np.linalg.LinAlgError`` on invalid input.
        """
    # See:
    # * http://xenia.media.mit.edu/~cwren/interpolator/
    # * http://stackoverflow.com/a/14178717/71522
    in_matrix = []
    for (x, y), (X, Y) in zip(src, dst):
        in_matrix.extend([
            [x, y, 1, 0, 0, 0, -X * x, -X * y],
            [0, 0, 0, x, y, 1, -Y * x, -Y * y],
        ])

    A = np.matrix(in_matrix, dtype=np.float)
    B = np.array(dst).reshape(8)
    af = np.dot(np.linalg.inv(A.T * A) * A.T, B)
    return np.append(np.array(af).reshape(8), 1).reshape((3, 3))


def create_perspective_transform(src, dst, round=False, splat_args=False):
    """ Returns a function which will transform points in quadrilateral
        ``src`` to the corresponding points on quadrilateral ``dst``::

            >>> transform = create_perspective_transform(
            ...     [(0, 0), (10, 0), (10, 10), (0, 10)],
            ...     [(50, 50), (100, 50), (100, 100), (50, 100)],
            ... )
            >>> transform((5, 5))
            (74.99999999999639, 74.999999999999957)

        If ``round`` is ``True`` then points will be rounded to the nearest
        integer and integer values will be returned.

            >>> transform = create_perspective_transform(
            ...     [(0, 0), (10, 0), (10, 10), (0, 10)],
            ...     [(50, 50), (100, 50), (100, 100), (50, 100)],
            ...     round=True,
            ... )
            >>> transform((5, 5))
            (75, 75)

        If ``splat_args`` is ``True`` the function will accept two arguments
        instead of a tuple.

            >>> transform = create_perspective_transform(
            ...     [(0, 0), (10, 0), (10, 10), (0, 10)],
            ...     [(50, 50), (100, 50), (100, 100), (50, 100)],
            ...     splat_args=True,
            ... )
            >>> transform(5, 5)
            (74.99999999999639, 74.999999999999957)

        If the input values yield an invalid transformation matrix an identity
        function will be returned and the ``error`` attribute will be set to a
        description of the error::

            >>> tranform = create_perspective_transform(
            ...     np.zeros((4, 2)),
            ...     np.zeros((4, 2)),
            ... )
            >>> transform((5, 5))
            (5.0, 5.0)
            >>> transform.error
            'invalid input quads (...): Singular matrix
        """
    try:
        transform_matrix = create_perspective_transform_matrix(src, dst)
        error = None
    except np.linalg.LinAlgError as e:
        transform_matrix = np.identity(3, dtype=np.float)
        error = "invalid input quads (%s and %s): %s" %(src, dst, e)
        error = error.replace("\n", "")

    to_eval = "def perspective_transform(%s):\n" %(
        splat_args and "*pt" or "pt",
    )
    to_eval += "  res = np.dot(transform_matrix, ((pt[0], ), (pt[1], ), (1, )))\n"
    to_eval += "  res = res / res[2]\n"
    if round:
        to_eval += "  return (int(round(res[0][0])), int(round(res[1][0])))\n"
    else:
        to_eval += "  return (res[0][0], res[1][0])\n"
    locals = {
        "transform_matrix": transform_matrix,
    }
    locals.update(globals())
    exec to_eval in locals, locals
    res = locals["perspective_transform"]
    res.matrix = transform_matrix
    res.error = error
    return res


from PyDraw import pydraw
img = pydraw.Image().new(width=500,height=500)
img.drawbezier([(22,22),(88,88),(188,22),(333,88)], fillcolor=(222,0,0))
img.drawcircle(333,111,fillsize=55,outlinecolor=(222,222,0))
img.drawline(0,250,499,250, fillcolor=(222,222,222))
img.floodfill(444,444,fillcolor=(0,222,0))
img.floodfill(222,222,fillcolor=(0,0,222))
img.view()

from __future__ import absolute_import

from pyping.core import *
#from .core import *

import pydraw

https://pypi.org/project/pydraw/

from pydraw import *
from tkinter import Tk
import sys
screen = Screen(800, 600, 'My First Project!')

# Here we create a rectangle at x=50, y=50 that is 50 pixels wide and 50 pixels tall.
# It is top-left anchored. This means that the position is the location of the top left corner.
# It's important to know that pydraw's canvas has the origin in the top left, with
# positive-y at the bottom of the screen, and positive-x to the right of the screen.
box = Rectangle(screen, 50, 50, 50, 50) 
a = Tk()
fps = 30
running = True
while running:
    screen.update()
    screen.sleep(1 / fps)

#screen.sys.exit()
#screen.exit()

def shutdown_ttk_repeat():
    a.eval('::ttk::CancelRepeat')
    a.destroy()

a.protocol("WM_DELETE_WINDOW", shutdown_ttk_repeat)
a.mainloop()


winfo.distroy()

screen.close()
box.close()


I've encountered a similar problem recently. The error message is exactly the same. 
I solved that by adding a a.quit() in an Exit method. (before that there was only 
                                                       a.destroy() in this method) 
Maybe you have already solved this question. But schlenk's answer doesn't work well 
on me. So I hope my answer can give another clue to such question


del box
del screen

from tkinter import Tk,Label,Button
from tkinter import ttk
from tkinter.ttk import Combobox

def cbox_do(event):
    'Used for cbox.'
    clabel.config(text=cbox.get())

a = Tk()
cbox = Combobox(a, value=('Luke','Biggs','Wedge'), takefocus=0)
cbox.bind("<<ComboboxSelected>>", cbox_do)
cbox.pack()
clabel = Label(a)
clabel.pack()

def shutdown_ttk_repeat():
    a.eval('::ttk::CancelRepeat')
    a.destroy()

a.protocol("WM_DELETE_WINDOW", shutdown_ttk_repeat)
a.mainloop()



from PIL import Image, ImageDraw, ImageFilter
im1 = Image.open('data/src/lena.jpg')
im2 = Image.open('data/src/rocket.jpg').resize(im1.size)
mask = Image.new('L', im1.size, 128)
im = Image.composite(im1, im2, mask)
# im = Image.blend(im1, im2, 0.5)
mask = Image.new('L', im1.size, 0)
draw = ImageDraw.Draw(mask)
draw.ellipse((140, 50, 260, 170), fill=255)
im = Image.composite(im1, im2, mask)
mask = Image.open('data/src/horse.png').convert('L').resize(im1.size)
im = Image.composite(im1, im2, mask)


from PIL import Image
filename = "/home/jack/Pictures/A_full_sized_highly_detailed_cad_drawn_blueprint_of_a_Mechanical_Toad_artistic_style_of_H._R._Giger (2).png" 
im = Image.open(filename)
im

from OutlineImage import outlineP
filename1 = "/home/jack/Pictures/A_full_sized_highly_detailed_cad_drawn_blueprint_of_a_Mechanical_Toad_artistic_style_of_H._R._Giger (2).png" 
filename1 = "onevid/tempp.png"
outfile_png = "onevid/temppp.png" 
outlineP(filename1,outfile_png)

from PIL import Image
#filename = "/home/jack/Pictures/A_full_sized_highly_detailed_cad_drawn_blueprint_of_a_Mechanical_Toad_artistic_style_of_H._R._Giger (2).png" 
im = Image.open(outfile_png)
im

photo_image_path = "/home/jack/Pictures/A_full_sized_highly_detailed_cad_drawn_blueprint_of_a_Mechanical_Toad_artistic_style_of_H._R._Giger (2).png" 
watermark_image_path = "/home/jack/Desktop/dockercommands/frame-lite.png"
image = Image.open(photo_image_path).convert('RGBA')
w,h = image.size
watermark = Image.open(watermark_image_path).convert('RGBA')
watermark = watermark.resize((w,h),Image.NEAREST)
layer = Image.new('RGBA', image.size, (0, 0, 0, 0))
x=0
y=0
layer.paste(watermark, (x, y))

# Create a copy of the layer
layer2 = layer.copy()

# Put alpha on the copy
layer2.putalpha(65)

# merge layers with mask
layer.paste(layer2, layer)


result = Image.alpha_composite(image, layer)

result

from PIL import Image
from PIL.Image import Exif
from PIL.ExifTags import TAGS, GPSTAGS

def get_exif(file_name) -> Exif:
    image: Image.Image = Image.open(file_name)
    return image.getexif()


def get_labeled_exif(exif):
    return {
        TAGS.get(key, key): value
        for key, value in exif.items()
    }


def get_geo(labeled_exif):
    gps_info = labeled_exif.get("GPSInfo", {})
    return {
        GPSTAGS.get(key, key): value
        for key, value in gps_info.items()
    }

if __name__ == '__main__':
    exif = get_exif("/home/jack/Pictures/content_example_ibiza.jpg")
    labeled_exif = get_labeled_exif(exif)
    #geo = get_geo(labeled_exif)
    #print(geo)
    print(labeled_exif)

class Foo(object):
    def __init__(self, val=2):
        self.val = val
    def __getstate__(self):
        print("I'm being pickled")
        self.val *= 2
        return self.__dict__
    def __setstate__(self, d):
        print("I'm being unpickled with these values: " + repr(d))
        self.__dict__ = d
        self.val *= 3

import pickle
f = Foo()
f_data = pickle.dumps(f)
f_new = pickle.loads(f_data)


img = Image.open("/home/jack/Pictures/content_example_ibiza.jpg")
img


# importing Image module from PIL package
from PIL import Image

# creating image object
img = Image.open("/home/jack/Pictures/content_example_ibiza.jpg")

# using image transform method
img1 = img.transform((300, 300), Image.EXTENT,
	data =[200, 20, 100 + img.width // 2, img.height // 2 ])
img1.save("junk/SHIP.jpg")
img1


import sys
from PIL import Image

img = Image.open("junk/SHIP.jpg")
width, height = img.size
m = -0.5
xshift = abs(m) * width
new_width = width + int(round(xshift))
img = img.transform((new_width, height), Image.AFFINE,
        (1, m, -xshift if m > 0 else 0, 0, 1, 0), Image.BICUBIC)
img.save("junk/SHIP-T.jpg")
img

import os
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt


def find_coefs(original_coords, warped_coords):
        matrix = []
        for p1, p2 in zip(original_coords, warped_coords):
            matrix.append([p1[0], p1[1], 1, 0, 0, 0, -p2[0]*p1[0], -p2[0]*p1[1]])
            matrix.append([0, 0, 0, p1[0], p1[1], 1, -p2[1]*p1[0], -p2[1]*p1[1]])

        A = np.matrix(matrix, dtype=float)
        B = np.array(warped_coords).reshape(8)

        res = np.dot(np.linalg.inv(A.T * A) * A.T, B)
        return np.array(res).reshape(8)


coefs = find_coefs(
                  [(867,652), (1020,580), (1206,666), (1057,757)],
                  [(700,732), (869,754), (906,916), (712,906)]
                  )

coefs_inv = find_coefs(
                  [(700,732), (869,754), (906,916), (712,906)],
                  [(867,652), (1020,580), (1206,666), (1057,757)]
                  )
filename = "/home/jack/Pictures/content_example_ibiza.jpg"
image = Image.open(filename)

img = image.transform(((1500,800)),
                      method=Image.PERSPECTIVE,
                      data=coefs_inv)

a, b, c, d, e, f, g, h = coefs

old_p1 = [50, 100]
x,y = old_p1
new_x = (a * x + b * y + c) / (g * x + h * y + 1)
new_y = (d * x + e * y + f) / (g * x + h * y + 1)
new_p1 = (int(new_x),int(new_y))

old_p2 = [400, 500]
x,y = old_p2
new_x = (a * x + b * y + c) / (g * x + h * y + 1)
new_y = (d * x + e * y + f) / (g * x + h * y + 1)
new_p2 = (int(new_x),int(new_y))



plt.figure()
plt.imshow(image)
plt.scatter([old_p1[0], old_p2[0]],[old_p1[1], old_p2[1]]  , s=150, marker='.', c='b')
plt.show()


plt.figure()
plt.imshow(img)
plt.scatter([new_p1[0], new_p2[0]],[new_p1[1], new_p2[1]]  , s=150, marker='.', c='r')

plt.show()

I = np.asarray(Image.open("junk/SHIP.jpg"))
#Do some stuff to I, then, convert it back to an image:

from PIL import ImageFilter

# Open an already existing image


# Apply sharp filter
#sharpened1 = I.filter(ImageFilter.SHARPEN);
#I = sharpened1.filter(ImageFilter.SHARPEN);


im = Image.fromarray(np.uint8(I))
im

import numpy as np
from PIL import Image
import scipy.signal
from scipy.signal import convolve2d
filename = "/home/jack/Pictures/content_example_ibiza.jpg"
image = Image.open(filename)
img_array = np.array(image)


def RGB_convolve(image,kern):
    image2 = np.empty_like(image)
    for dim in range(image.shape[-1]):
        image2[:,:,dim]=convolve2d(image[:,:,dim],kern, 'same')
    return image2

KERNEL_sharpen = np.array([[0,-1,0],[-1,5,-1],[0,-1,0]])
im_filtered = RGB_convolve(img_array,KERNEL_sharpen)

#output_image = Image.fromarray(im_filtered)
#display(output_image)
output_image = Image.fromarray(im_filtered.astype('uint8'))
display(output_image)

# Load image
import cv2
import numpy as np
from matplotlib import pyplot as plt

# Load image as grayscale
filename = "/home/jack/Pictures/content_example_ibiza.jpg"
image = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)
# Create kernel
kernel = np.array([[0, -1, 0], 
                   [-1, 5,-1], 
                   [0, -1, 0]])

# Sharpen image
image_sharp = cv2.filter2D(image, -1, kernel)
# Show image
plt.imshow(image_sharp, cmap='gray'), plt.axis("off")
plt.show()


import numpy as np
import cv2
from PIL import Image
def create_perspective_transform_matrix(src, dst):
    """ Creates a perspective transformation matrix which transforms points
        in quadrilateral ``src`` to the corresponding points on quadrilateral
        ``dst``.

        Will raise a ``np.linalg.LinAlgError`` on invalid input.
        """
    # See:
    # * http://xenia.media.mit.edu/~cwren/interpolator/
    # * http://stackoverflow.com/a/14178717/71522
    in_matrix = []
    for (x, y), (X, Y) in zip(src, dst):
        in_matrix.extend([
            [x, y, 1, 0, 0, 0, -X * x, -X * y],
            [0, 0, 0, x, y, 1, -Y * x, -Y * y],
        ])

    A = np.matrix(in_matrix, dtype=np.float)
    B = np.array(dst).reshape(8)
    af = np.dot(np.linalg.inv(A.T * A) * A.T, B)
    return np.append(np.array(af).reshape(8), 1).reshape((3, 3))


def create_perspective_transform(src, dst, round=False, splat_args=False):
    """ Returns a function which will transform points in quadrilateral
        ``src`` to the corresponding points on quadrilateral ``dst``::

            >>> transform = create_perspective_transform(
            ...     [(0, 0), (10, 0), (10, 10), (0, 10)],
            ...     [(50, 50), (100, 50), (100, 100), (50, 100)],
            ... )
            >>> transform((5, 5))
            (74.99999999999639, 74.999999999999957)

        If ``round`` is ``True`` then points will be rounded to the nearest
        integer and integer values will be returned.

            >>> transform = create_perspective_transform(
            ...     [(0, 0), (10, 0), (10, 10), (0, 10)],
            ...     [(50, 50), (100, 50), (100, 100), (50, 100)],
            ...     round=True,
            ... )
            >>> transform((5, 5))
            (75, 75)

        If ``splat_args`` is ``True`` the function will accept two arguments
        instead of a tuple.

            >>> transform = create_perspective_transform(
            ...     [(0, 0), (10, 0), (10, 10), (0, 10)],
            ...     [(50, 50), (100, 50), (100, 100), (50, 100)],
            ...     splat_args=True,
            ... )
            >>> transform(5, 5)
            (74.99999999999639, 74.999999999999957)

        If the input values yield an invalid transformation matrix an identity
        function will be returned and the ``error`` attribute will be set to a
        description of the error::

            >>> tranform = create_perspective_transform(
            ...     np.zeros((4, 2)),
            ...     np.zeros((4, 2)),
            ... )
            >>> transform((5, 5))
            (5.0, 5.0)
            >>> transform.error
            'invalid input quads (...): Singular matrix
        """
    try:
        transform_matrix = create_perspective_transform_matrix(src, dst)
        error = None
    except np.linalg.LinAlgError as e:
        transform_matrix = np.identity(3, dtype=np.float)
        error = "invalid input quads (%s and %s): %s" %(src, dst, e)
        error = error.replace("\n", "")

    to_eval = "def perspective_transform(%s):\n" %(
        splat_args and "*pt" or "pt",
    )
    to_eval += "  res = np.dot(transform_matrix, ((pt[0], ), (pt[1], ), (1, )))\n"
    to_eval += "  res = res / res[2]\n"
    if round:
        to_eval += "  return (int(round(res[0][0])), int(round(res[1][0])))\n"
    else:
        to_eval += "  return (res[0][0], res[1][0])\n"
    locals = {
        "transform_matrix": transform_matrix,
    }
    locals.update(globals())
    #exec to_eval in locals, locals
    res = locals["perspective_transform"]
    res.matrix = transform_matrix
    res.error = error
    return res


filename = "/home/jack/Pictures/content_example_ibiza.jpg"
img = Image.open(filename)
src = np.asarray(img)
dst =im
create_perspective_transform_matrix(src, dst)

from PyDraw import pydraw
img = pydraw.Image().new(width=500,height=500)
img.drawbezier([(22,22),(88,88),(188,22),(333,88)], fillcolor=(222,0,0))
img.drawcircle(333,111,fillsize=55,outlinecolor=(222,222,0))
img.drawline(0,250,499,250, fillcolor=(222,222,222))
img.floodfill(444,444,fillcolor=(0,222,0))
img.floodfill(222,222,fillcolor=(0,0,222))
img.view()

from __future__ import absolute_import

from pyping.core import *
#from .core import *

import pydraw

https://pypi.org/project/pydraw/

from pydraw import *
from tkinter import Tk
import sys
screen = Screen(800, 600, 'My First Project!')

# Here we create a rectangle at x=50, y=50 that is 50 pixels wide and 50 pixels tall.
# It is top-left anchored. This means that the position is the location of the top left corner.
# It's important to know that pydraw's canvas has the origin in the top left, with
# positive-y at the bottom of the screen, and positive-x to the right of the screen.
box = Rectangle(screen, 50, 50, 50, 50) 
a = Tk()
fps = 30
running = True
while running:
    screen.update()
    screen.sleep(1 / fps)

#screen.sys.exit()
#screen.exit()

def shutdown_ttk_repeat():
    a.eval('::ttk::CancelRepeat')
    a.destroy()
    tk.destroy()

a.protocol("WM_DELETE_WINDOW", shutdown_ttk_repeat)
a.mainloop()


self.parent.quit()
parent.quit()

winfo.distroy()
tk.destroy()

screen.close()
box.close()


I've encountered a similar problem recently. The error message is exactly the same. 
I solved that by adding a a.quit() in an Exit method. (before that there was only 
                                                       a.destroy() in this method) 
Maybe you have already solved this question. But schlenk's answer doesn't work well 
on me. So I hope my answer can give another clue to such question


del box
del screen

from tkinter import Tk,Label,Button
from tkinter import ttk
from tkinter.ttk import Combobox

def cbox_do(event):
    'Used for cbox.'
    clabel.config(text=cbox.get())

a = Tk()
cbox = Combobox(a, value=('Luke','Biggs','Wedge'), takefocus=0)
cbox.bind("<<ComboboxSelected>>", cbox_do)
cbox.pack()
clabel = Label(a)
clabel.pack()

def shutdown_ttk_repeat():
    a.eval('::ttk::CancelRepeat')
    a.destroy()

a.protocol("WM_DELETE_WINDOW", shutdown_ttk_repeat)
a.mainloop()



import random
from random import randint
import time
import markovify
import os
import sys
sys.path.insert(1, "/home/jack/hidden")
import key
sys.path.insert(1, "/home/jack/Desktop/pycode/vpython2")
import twython
from twython import Twython
from PIL import Image, ImageChops, ImageDraw, ImageFont, ImageFilter
# %load mkplot.py
#!/usr/local/bin/python
from __future__ import division
import glob
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline 
import numpy as np 


from PIL import Image
from PIL import ImageFont, ImageDraw, ImageFilter, ImageChops
import textwrap
til = Image.new("RGB",(640,640))
#image = "img = 'wiki/Training-Loss-Graph-forwiki_2018-0609062255.png'"
im = Image.open("Last-GRU-network-loss-1.1179-plot-for-Directory-uranbible_2018-0617131414.png") #600x400

til.paste(im,(20,35))
til2 = Image.new("RGB",(600,160),(250,250,250))
til.paste(til2,(20,450))
w,h = im.size
samp = []
cwd = os.getcwd()
directory = raw_input("USE Directory: ")
PATH = cwd+"/"+directory+"/"
files = glob.glob(PATH+"GRU*.t7")
files.sort(key=os.path.getmtime)
line = ("\n".join(files))
samp.append(line)
#fname = "Here shows the effect of changing the LearningRate"
fname = "Filename parsed for data:"
# read a text file as a list of lines
# find the last line, change to a file you have
filename = "/home/jack/Desktop/char-rnn/uranbible_.txt"
fileHandle = open (filename,"r" )
lineList = fileHandle.readlines()
fileHandle.close()
line = lineList[-1]
text0 = "This is the loss of the last model: ",line[-9:-3]
text1 = "This is the Epoch: ",line[-14:-10]
text2 = "Current learning_rate: ", line[-51:-38]
text3 = "rnn-size: ", line[-28:-25]

Text = str(line[-51:])
SPACE = "-----------------------------------------------"
text0 = str(text0)
text1 = str(text1)
text2 = str(text2)
text3 = str(text3)
text3 = str(text3)
draw = ImageDraw.Draw(til)
font = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 18)
draw.text((70,450), fname, font=font, fill= "black")
font = ImageFont.truetype("/home/jack/.fonts/dontmix.ttf", 20)
#draw.text((320,450), fname0, font=font, fill= "black")
#font = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 16)
#draw.text((70,474), text0, font=font, fill= "red")
font = ImageFont.truetype("/home/jack/.fonts/dontmix.ttf", 22)
draw.text((70,472), Text, font=font, fill= "navy")
draw.text((70,490), SPACE, font=font, fill= "black")
draw.text((70,510), text0, font=font, fill= "navy")  
draw.text((70,530), text1, font=font, fill= "navy")    
draw.text((70,550), text2, font=font, fill= "navy")    
draw.text((70,570), text3, font=font, fill= "navy")    
#draw.text((70,552), text4, font=font, fill= "navy")    
#draw.text((70,572), text5, font=font, fill= "navy")
filename = "testtiles.png"
til.save(filename)
filename0= filename
def generate_the_word(infile):
        with open(infile) as f:
            contents_of_file = f.read()
        lines = contents_of_file.splitlines()
        line_number = random.randrange(0, len(lines))
        return lines[line_number]

def draw_blurred_back(img, position, text, font, col, halo_col):
    halo = Image.new('RGBA', img.size, (0, 0, 0, 0))
    ImageDraw.Draw(halo).text(position, text, font = font, fill = halo_col)
    blurred_halo = halo.filter(ImageFilter.BLUR)
    ImageDraw.Draw(blurred_halo).text(position, text, font = font, fill = col)
    return Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))

if __name__ == '__main__':
    inp = Image.open(filename0)
    inp = inp.resize((640,640), Image.ANTIALIAS)
    font = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 35)
    text_title = (255, 30,30) # bright green
    blur_title = (0, 0, 0)   # black
    #textin = (generate_the_word("wordcloud.txt"))
    i2 = draw_blurred_back(inp, (320, 85), "PlotBot", font, text_title, blur_title)
    font0 = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 25)
    i2 = draw_blurred_back(i2, (320, 127), "Live Plot for this", font0, text_title, blur_title)    
    i2 = draw_blurred_back(i2, (320, 160), "Lua text generator.", font0, text_title, blur_title)    
    
    #txt = Image.new('RGBA', i.size, (255,255,255,0))

    # get a font
    fnt = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 20)
    # get a drawing context
    signature_ = "@Jacknorthrup Instagram and @jacklnorthrup TwitterBot Project" 
    #get length in pixel of signature_
    sizeS,ln = fnt.getsize(signature_)
    #add 15 pixels to right border
    pt = sizeS+25
    width, height = inp.size
    #marginx starting point of signature_
    marginx = pt
    #bottom margin
    marginy = 30
    x = width - marginx
    y = height - marginy
    

    text_sig = (255, 55,30) # bright green
    blur_sig = (0, 0, 0)   # black
    txt=draw_blurred_back(i2,(x,y), signature_, fnt, text_sig, blur_sig)
    out = Image.alpha_composite(i2, txt)
    out.save("TM_POST.png")

#removed keys for privacy reasons
CONSUMER_KEY = key.twiter()[0]
CONSUMER_SECRET = key.twiter()[1]
ACCESS_KEY = key.twiter()[2]
ACCESS_SECRET = key.twiter()[3]

twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)
f = open("MYTEXT.txt")
text = f.read()
text_model = markovify.Text(text)
STR = (text_model.make_short_sentence(200))
#STR = ("8conv3fc_DSN.caffemodel Layer pool4. Snow capped mouintains Yah right . Dream on !")
# USE BELOW for no signature
#PATH = "/home/jack/Desktop/deep-dream-generator/notebooks/STUFF/experiment/experiment8.jpg"
PATH = "TM_POST.png"
#photo = open('/home/jack/Desktop/deep-dream-generator/notebooks/images/'+file_list[rnd]+'.jpg','rb')
image = open(PATH,'rb')
#response = twitter.upload_media(media=image)
#twitter.update_status(status=STR, media_ids=[response['media_id']])

print STR
!showme TM_POST.png
out

#ONE TIME MANUAL POSTS
#!/home/jack/anaconda2/python
import random
from random import randint
import time
import markovify
import os
import sys
sys.path.insert(1, "/home/jack/hidden")
import key
sys.path.insert(1, "/home/jack/Desktop/pycode/vpython2")
import twython
from twython import Twython
from PIL import Image, ImageChops, ImageDraw, ImageFont, ImageFilter
# %load mkplot.py
#!/usr/local/bin/python
from __future__ import division
import sys
import glob
import time
import os
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline 
import numpy as np 
#if len(sys.argv)==1: sys.exit("\n=========================\nThe directory of *.t7 files required. Example:\npython mktext-n-plot.py uranbible\n=========================\n")
#directory = sys.argv[1]
#directory ="wiki"
directory = raw_input("Use Directory: ")
#f0= open(title,"w");f.close()
cwd = os.getcwd()
PATH = cwd+"/"+directory
filename = PATH+"_.dat"
filenameD = directory+"_.dat"
# Function to get loss from the model filename in the list 'samp'  
def rateloss(iteR):
    for x in iteR:leng = len(x)
    for x in iteR:X= x[leng-9:leng-3]
    return X
def decrate(iteR):
    for x in iteR:leng = len(x)
    for x in iteR:Y = x[leng-51:leng-38]
    return Y
def epoch(iteR):
    for z in iteR:leng = len(z)
    for z in iteR:Z = z[leng-14:leng-10]
    return Z
try:
    os.remove(filenameD)
except:
    pass
# built is list ' samp ' of all models in a directory
samp = []
cwd = os.getcwd()
PATH = cwd+"/"+directory+"/"
files = glob.glob(PATH+"GRU*.t7")
files.sort(key=os.path.getmtime)
line = ("\n".join(files))
samp.append(line)
# clear the memory of any prior files that may have been created
# prevents the accidental printing of memory to the file 
try:
    del line
    del li
except:
    pass
fn = open(filenameD, "a")
count = 0
for line in samp:
    line = line.split()
    for li in line:
        count = count +1
        #if count>2:
        if len(li)>50:
            #print count-2,li
            li = li[-9:-3]
            #skips the first entry then print a comma before every ' li ' written
            # this avoids a tailing comma
            #if count>3:fn.write(", ")
            if count>1:fn.write(", ")
            fn.write(li)            
fn.close() 
"""
num = 0
for n in open(filenameD, "r").read().split(","):
    num = num+1
b = num    
a = 14
"""
f = open(filenameD).read()
f = str(f).split()
a = len(f)
A= str(a)
b = int(a)+1
print "---",A,a
c = a / b
c = 12
#np.arange(0.0, a, c)
#steps = 1
#c = range(b,steps)
iteR = samp    
LosR = rateloss(iteR) 
DecR = decrate(iteR)
E = epoch(iteR)
fname = filenameD
s = np.loadtxt(fname, dtype='float', comments='#', delimiter=",")
#s = (2.8920 , 2.2190 , 2.0573 , 1.9742 , 1.8616 , 1.8021 , 1.7422 , 1.7081 , 1.6884 , 1.6534 , 1.6351 , 1.6167 , 1.6084 , 1.5963 , 1.5953 , 1.5796 , 1.5654 , 1.5635 , 1.5472 , 1.5382 , 1.5329 , 1.5264 , 1.5266 , 1.5185 , 1.5118 , 1.5068 , 1.5075 , 1.5025 , 1.4998 , 1.4988 , 1.4974 , 1.4933 , 1.4945 , 1.4968 , 1.4859 , 1.4848 , 1.4840 , 1.4762 , 1.4718 , 1.4735 , 1.4684 , 1.4658 , 1.4609 , 1.4645 , 1.4587 , 1.4571 , 1.4533 , 1.4508 , 1.4483 , 1.4420 , 1.4363 , 1.4290 , 1.4219 , 1.4170 , 1.4013 , 1.3768 , 1.3657 , 1.3676 , 1.3694 , 1.3784 , 1.3823 , 1.3918 , 1.3867 , 1.3873 , 1.3894 , 1.3933 , 1.4013 , 1.3953 , 1.3955 , 1.3954 , 1.4042 , 1.3995 , 1.3992 , 1.3995 , 1.4001 , 1.3994 , 1.3983 , 1.3922 , 1.3970 )
#t = np.arange(0.0, a, c)
#t = np.arange(0.0, b, c)
e = len(s)
ss = range(0,e)
aa = np.array(ss)
#t = np.arange(0.0, aa, c)
# Note that using plt.subplots below is equivalent to using
# fig = plt.figure() and then ax = fig.add_subplot(111)
fig, ax = plt.subplots(dpi=100)
"""
print t
print"-------------"
print s
print"-------------"
print e
print"-------------"
print ss
"""
ax.plot(aa, s)
DT = time.strftime("%Y-%m-%d:%H")
ax.set(xlabel='DATE: '+DT+'      Samples(Scale = 1 per sample)', ylabel='Training Loss',
       title='Training Loss Plot from Last '+A+' Samples.   Epoch: '+E+' \n Last: ModelLoss: '+LosR+"    DecayRate: "+DecR )

ax.grid()
tm = time.strftime("%Y-%m%d%H%M%S")
Filename = "Last-GRU-network-loss-"+LosR+"-plot-for-Directory-"+directory+"_"+tm+".png"
#print Filename
fig.savefig(Filename)
#plt.show()
#custom = "Last-GRU-network-loss-1.1296-plot-for-Directory-uranbible_2018-0617100544.png"
filename0= Filename
def generate_the_word(infile):
        with open(infile) as f:
            contents_of_file = f.read()
        lines = contents_of_file.splitlines()
        line_number = random.randrange(0, len(lines))
        return lines[line_number]

def draw_blurred_back(img, position, text, font, col, halo_col):
    halo = Image.new('RGBA', img.size, (0, 0, 0, 0))
    ImageDraw.Draw(halo).text(position, text, font = font, fill = halo_col)
    blurred_halo = halo.filter(ImageFilter.BLUR)
    ImageDraw.Draw(blurred_halo).text(position, text, font = font, fill = col)
    return Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))

if __name__ == '__main__':
    inp = Image.open(filename0)
    inp = inp.resize((640,640), Image.ANTIALIAS)
    font = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 35)
    text_title = (255, 30,30) # bright green
    blur_title = (0, 0, 0)   # black
    #textin = (generate_the_word("wordcloud.txt"))
    i2 = draw_blurred_back(inp, (270, 100), "PlotBot", font, text_title, blur_title)
    font0 = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 25)
    i2 = draw_blurred_back(i2, (270, 142), "Live Plot for this", font0, text_title, blur_title)    
    i2 = draw_blurred_back(i2, (270, 175), "Lua text generator.", font0, text_title, blur_title)    
    
    #txt = Image.new('RGBA', i.size, (255,255,255,0))

    # get a font
    fnt = ImageFont.truetype("/home/jack/.fonts/Exo-Black.ttf", 20)
    # get a drawing context
    signature_ = "@Jacknorthrup Instagram and @jacklnorthrup TwitterBot Project" 
    #get length in pixel of signature_
    sizeS,ln = fnt.getsize(signature_)
    #add 15 pixels to right border
    pt = sizeS+25
    width, height = inp.size
    #marginx starting point of signature_
    marginx = pt
    #bottom margin
    marginy = 30
    x = width - marginx
    y = height - marginy
    

    text_sig = (255, 55,30) # bright green
    blur_sig = (0, 0, 0)   # black
    txt=draw_blurred_back(i2,(x,y), signature_, fnt, text_sig, blur_sig)
    out = Image.alpha_composite(i2, txt)
    out.save("TM_POST.png")

#removed keys for privacy reasons
CONSUMER_KEY = key.twiter()[0]
CONSUMER_SECRET = key.twiter()[1]
ACCESS_KEY = key.twiter()[2]
ACCESS_SECRET = key.twiter()[3]

twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_KEY, ACCESS_SECRET)
f = open("MYTEXT.txt")
text = f.read()
text_model = markovify.Text(text)
STR = (text_model.make_short_sentence(200))
#STR = ("8conv3fc_DSN.caffemodel Layer pool4. Snow capped mouintains Yah right . Dream on !")
# USE BELOW for no signature
#PATH = "/home/jack/Desktop/deep-dream-generator/notebooks/STUFF/experiment/experiment8.jpg"
PATH = "TM_POST.png"
#photo = open('/home/jack/Desktop/deep-dream-generator/notebooks/images/'+file_list[rnd]+'.jpg','rb')
image = open(PATH,'rb')
response = twitter.upload_media(media=image)
twitter.update_status(status=STR, media_ids=[response['media_id']])

print STR
!showme TM_POST.png
out

from PIL import Image
from PIL import ImageFont, ImageDraw
import random
import time
import textwrap
import glob
import os
try:
    del f0
    del line
except:
    pass
Samp = []
directory = raw_input("Use Directory: ")
#f0= open(title,"w");f.close()

cwd = os.getcwd()
PATH = cwd+"/"+directory
filename = PATH+"_.txt"
try:
    os.remove(filename)
except:
    pass
f0= open(filename,"w")
files = glob.glob(PATH+"/*.t7")
files.sort(key=os.path.getmtime)
line = ("\n".join(files))
if ".t7" in line:
    f0.write(line)
    Samp.append(line)
    print filename
f0.close()    ]

